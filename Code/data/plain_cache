{"https:\/\/github.com\/jonas-schmitt\/evostencils":{"c4d96fb433a4e7894a30575c55e7545b61e73b65":{"url":"https:\/\/api.github.com\/repos\/jonas-schmitt\/evostencils\/commits\/c4d96fb433a4e7894a30575c55e7545b61e73b65","html_url":"https:\/\/github.com\/jonas-schmitt\/evostencils\/commit\/c4d96fb433a4e7894a30575c55e7545b61e73b65","message":"Bugfix: Update individual caches with communicated offspring to prevent integer overflows within allgather implementations based on pickle","sha":"c4d96fb433a4e7894a30575c55e7545b61e73b65","keyword":"cache overflow update","diff":"diff --git a\/evostencils\/optimization\/program.py b\/evostencils\/optimization\/program.py\nindex c94034f..6d96b21 100644\n--- a\/evostencils\/optimization\/program.py\n+++ b\/evostencils\/optimization\/program.py\n@@ -579,6 +579,11 @@ def ea_mu_plus_lambda(self, initial_population_size, generations, mu_, lambda_,\n         population = self.allgather(population)\n         population = self.toolbox.select(population, mu_)\n         hof.update(population)\n+        if self.mpi_comm is not None and self.number_of_mpi_processes > 1:\n+            individual_caches = self.mpi_comm.allgather(self.individual_cache)\n+            for i, cache in enumerate(individual_caches):\n+                if i != self.mpi_rank:\n+                    self.individual_cache.update(cache)\n         record = mstats.compile(population) if mstats is not None else {}\n         logbook.record(gen=min_generation, nevals=len(population), **record)\n         if self.is_root():\n@@ -589,7 +594,6 @@ def ea_mu_plus_lambda(self, initial_population_size, generations, mu_, lambda_,\n         evaluation_max_level = max_level\n         level_offset = 0\n         optimization_interval = 500\n-        evaluation_time_threshold = self.infinity # seconds\n         number_of_samples = 1\n         for gen in range(min_generation + 1, max_generation + 1):\n             self._total_evaluation_time = 0.0\n@@ -619,11 +623,7 @@ def ea_mu_plus_lambda(self, initial_population_size, generations, mu_, lambda_,\n                     population[i].fitness.values = values\n                 population = self.toolbox.select(population, mu_)\n                 hof.update(population)\n-            if self.mpi_comm is not None and self.number_of_mpi_processes > 1:\n-                individual_caches = self.mpi_comm.allgather(self.individual_cache)\n-                for i, cache in enumerate(individual_caches):\n-                    if i != self.mpi_rank:\n-                        self.individual_cache.update(cache)\n+\n             number_of_parents = lambda_\n             if number_of_parents % 2 == 1:\n                 number_of_parents += 1\n@@ -662,8 +662,12 @@ def ea_mu_plus_lambda(self, initial_population_size, generations, mu_, lambda_,\n             self._total_evaluation_time = self.allreduce(self.total_evaluation_time)\n             self._total_number_of_evaluations = self.allreduce(self._total_number_of_evaluations)\n             offspring = self.allgather(offspring)\n-\n             hof.update(offspring)\n+\n+            if self.mpi_comm is not None and self.number_of_mpi_processes > 1:\n+                for ind in offspring:\n+                    if not self.individual_in_cache(ind):\n+                        self.add_individual_to_cache(ind, ind.fitness.values)\n             if self.is_root():\n                 print(\"Average evaluation time:\", self.total_evaluation_time \/ self._total_number_of_evaluations, flush=True)\n \ndiff --git a\/examples\/evaluate_evolved_solver.py b\/examples\/evaluate_evolved_solver.py\nindex 6b60a8b..ae56cf2 100644\n--- a\/examples\/evaluate_evolved_solver.py\n+++ b\/examples\/evaluate_evolved_solver.py\n@@ -7,8 +7,8 @@ def main():\n     # TODO adapt to actual path to exastencils project\n \n     cwd = os.getcwd()\n-    compiler_path = f'{cwd}\/..\/exastencils\/Compiler\/Compiler.jar'\n-    base_path = f'{cwd}\/..\/exastencils\/Examples'\n+    compiler_path = f'{cwd}\/..\/exastencils-meggie\/Compiler\/Compiler.jar'\n+    base_path = f'{cwd}\/..\/exastencils-meggie\/Examples'\n \n     # 2D Finite difference discretized Poisson\n     # settings_path = f'Poisson\/2D_FD_Poisson_fromL2.settings'\n@@ -35,14 +35,14 @@ def main():\n     # knowledge_path = f'Stokes\/2D_FD_Stokes_fromL2.knowledge'\n \n     # 2D Finite difference discretized linear elasticity\n-    # settings_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.settings'\n-    # knowledge_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.knowledge'\n+    settings_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.settings'\n+    knowledge_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.knowledge'\n \n     # settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL2.settings'\n     # knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL2.knowledge'\n-    settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings'\n-    knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge'\n-    cycle_name = \"VCycle\"\n+    # settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings'\n+    # knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge'\n+    cycle_name= \"gen_mgCycle\"\n \n     program_generator = ProgramGenerator(compiler_path, base_path, settings_path, knowledge_path, cycle_name=cycle_name)\n \n@@ -57,7 +57,7 @@ def main():\n     fields = program_generator.fields\n \n     infinity = 1e100\n-    epsilon = 1e-6\n+    epsilon = 1e-12\n     problem_name = program_generator.problem_name\n \n     if not os.path.exists(f'{cwd}\/{problem_name}'):\n@@ -66,15 +66,9 @@ def main():\n                           program_generator=program_generator,\n                           epsilon=epsilon, infinity=infinity)\n     maximum_block_size = 8\n-    minimum_solver_iterations = 2**3\n-    maximum_solver_iterations = 2**10\n-    krylov_subspace_methods = ()\n     with open('grammar_tree.txt', 'r') as file:\n         grammar_string = file.read()\n     optimizer.generate_and_evaluate_program_from_grammar_representation(grammar_string, maximum_block_size,\n-                                                                        krylov_subspace_methods=krylov_subspace_methods,\n-                                                                        minimum_solver_iterations=minimum_solver_iterations,\n-                                                                        maximum_solver_iterations=maximum_solver_iterations,\n                                                                         optimize_relaxation_factors=False)\n \n \n","files":{"\/evostencils\/optimization\/program.py":{"changes":[{"diff":"\n         evaluation_max_level = max_level\n         level_offset = 0\n         optimization_interval = 500\n-        evaluation_time_threshold = self.infinity # seconds\n         number_of_samples = 1\n         for gen in range(min_generation + 1, max_generation + 1):\n             self._total_evaluation_time = 0.0\n","add":0,"remove":1,"filename":"\/evostencils\/optimization\/program.py","badparts":["        evaluation_time_threshold = self.infinity # seconds"],"goodparts":[]},{"diff":"\n                     population[i].fitness.values = values\n                 population = self.toolbox.select(population, mu_)\n                 hof.update(population)\n-            if self.mpi_comm is not None and self.number_of_mpi_processes > 1:\n-                individual_caches = self.mpi_comm.allgather(self.individual_cache)\n-                for i, cache in enumerate(individual_caches):\n-                    if i != self.mpi_rank:\n-                        self.individual_cache.update(cache)\n+\n             number_of_parents = lambda_\n             if number_of_parents % 2 == 1:\n                 number_of_parents += 1\n","add":1,"remove":5,"filename":"\/evostencils\/optimization\/program.py","badparts":["            if self.mpi_comm is not None and self.number_of_mpi_processes > 1:","                individual_caches = self.mpi_comm.allgather(self.individual_cache)","                for i, cache in enumerate(individual_caches):","                    if i != self.mpi_rank:","                        self.individual_cache.update(cache)"],"goodparts":[]}]},"\/examples\/evaluate_evolved_solver.py":{"changes":[{"diff":"\n     # TODO adapt to actual path to exastencils project\n \n     cwd = os.getcwd()\n-    compiler_path = f'{cwd}\/..\/exastencils\/Compiler\/Compiler.jar'\n-    base_path = f'{cwd}\/..\/exastencils\/Examples'\n+    compiler_path = f'{cwd}\/..\/exastencils-meggie\/Compiler\/Compiler.jar'\n+    base_path = f'{cwd}\/..\/exastencils-meggie\/Examples'\n \n     # 2D Finite difference discretized Poisson\n     # settings_path = f'Poisson\/2D_FD_Poisson_fromL2.settings'\n","add":2,"remove":2,"filename":"\/examples\/evaluate_evolved_solver.py","badparts":["    compiler_path = f'{cwd}\/..\/exastencils\/Compiler\/Compiler.jar'","    base_path = f'{cwd}\/..\/exastencils\/Examples'"],"goodparts":["    compiler_path = f'{cwd}\/..\/exastencils-meggie\/Compiler\/Compiler.jar'","    base_path = f'{cwd}\/..\/exastencils-meggie\/Examples'"]},{"diff":"\n     # knowledge_path = f'Stokes\/2D_FD_Stokes_fromL2.knowledge'\n \n     # 2D Finite difference discretized linear elasticity\n-    # settings_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.settings'\n-    # knowledge_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.knowledge'\n+    settings_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.settings'\n+    knowledge_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.knowledge'\n \n     # settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL2.settings'\n     # knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL2.knowledge'\n-    settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings'\n-    knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge'\n-    cycle_name = \"VCycle\"\n+    # settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings'\n+    # knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge'\n+    cycle_name= \"gen_mgCycle\"\n \n     program_generator = ProgramGenerator(compiler_path, base_path, settings_path, knowledge_path, cycle_name=cycle_name)\n \n","add":5,"remove":5,"filename":"\/examples\/evaluate_evolved_solver.py","badparts":["    settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings'","    knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge'","    cycle_name = \"VCycle\""],"goodparts":["    settings_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.settings'","    knowledge_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.knowledge'","    cycle_name= \"gen_mgCycle\""]},{"diff":"\n     fields = program_generator.fields\n \n     infinity = 1e100\n-    epsilon = 1e-6\n+    epsilon = 1e-12\n     problem_name = program_generator.problem_name\n \n     if not os.path.exists(f'{cwd}\/{problem_name}'):\n","add":1,"remove":1,"filename":"\/examples\/evaluate_evolved_solver.py","badparts":["    epsilon = 1e-6"],"goodparts":["    epsilon = 1e-12"]},{"diff":"\n                           program_generator=program_generator,\n                           epsilon=epsilon, infinity=infinity)\n     maximum_block_size = 8\n-    minimum_solver_iterations = 2**3\n-    maximum_solver_iterations = 2**10\n-    krylov_subspace_methods = ()\n     with open('grammar_tree.txt', 'r') as file:\n         grammar_string = file.read()\n     optimizer.generate_and_evaluate_program_from_grammar_representation(grammar_string, maximum_block_size,\n-                                                                        krylov_subspace_methods=krylov_subspace_methods,\n-                                                                        minimum_solver_iterations=minimum_solver_iterations,\n-                                                                        maximum_solver_iterations=maximum_solver_iterations,\n                                                                         optimize_relaxation_factors=False)\n \n \n","add":0,"remove":6,"filename":"\/examples\/evaluate_evolved_solver.py","badparts":["    minimum_solver_iterations = 2**3","    maximum_solver_iterations = 2**10","    krylov_subspace_methods = ()","                                                                        krylov_subspace_methods=krylov_subspace_methods,","                                                                        minimum_solver_iterations=minimum_solver_iterations,","                                                                        maximum_solver_iterations=maximum_solver_iterations,"],"goodparts":[]}],"source":"\nfrom evostencils.optimization.program import Optimizer from evostencils.code_generation.exastencils import ProgramGenerator import os def main(): cwd=os.getcwd() compiler_path=f'{cwd}\/..\/exastencils\/Compiler\/Compiler.jar' base_path=f'{cwd}\/..\/exastencils\/Examples' settings_path=f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings' knowledge_path=f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge' cycle_name=\"VCycle\" program_generator=ProgramGenerator(compiler_path, base_path, settings_path, knowledge_path, cycle_name=cycle_name) dimension=program_generator.dimension finest_grid=program_generator.finest_grid coarsening_factors=program_generator.coarsening_factor min_level=program_generator.min_level max_level=program_generator.max_level equations=program_generator.equations operators=program_generator.operators fields=program_generator.fields infinity=1e100 epsilon=1e-6 problem_name=program_generator.problem_name if not os.path.exists(f'{cwd}\/{problem_name}'): os.makedirs(f'{cwd}\/{problem_name}') optimizer=Optimizer(dimension, finest_grid, coarsening_factors, min_level, max_level, equations, operators, fields, program_generator=program_generator, epsilon=epsilon, infinity=infinity) maximum_block_size=8 minimum_solver_iterations=2**3 maximum_solver_iterations=2**10 krylov_subspace_methods=() with open('grammar_tree.txt', 'r') as file: grammar_string=file.read() optimizer.generate_and_evaluate_program_from_grammar_representation(grammar_string, maximum_block_size, krylov_subspace_methods=krylov_subspace_methods, minimum_solver_iterations=minimum_solver_iterations, maximum_solver_iterations=maximum_solver_iterations, optimize_relaxation_factors=False) if __name__==\"__main__\": main() ","sourceWithComments":"from evostencils.optimization.program import Optimizer\nfrom evostencils.code_generation.exastencils import ProgramGenerator\nimport os\n\n\ndef main():\n    # TODO adapt to actual path to exastencils project\n\n    cwd = os.getcwd()\n    compiler_path = f'{cwd}\/..\/exastencils\/Compiler\/Compiler.jar'\n    base_path = f'{cwd}\/..\/exastencils\/Examples'\n\n    # 2D Finite difference discretized Poisson\n    # settings_path = f'Poisson\/2D_FD_Poisson_fromL2.settings'\n    # knowledge_path = f'Poisson\/2D_FD_Poisson_fromL2.knowledge'\n\n    # 3D Finite difference discretized Poisson\n    # settings_path = f'Poisson\/3D_FD_Poisson_fromL2.settings'\n    # knowledge_path = f'Poisson\/3D_FD_Poisson_fromL2.knowledge'\n\n    # 2D Finite volume discretized Poisson\n    # settings_path = f'Poisson\/2D_FV_Poisson_fromL2.settings'\n    # knowledge_path = f'Poisson\/2D_FV_Poisson_fromL2.knowledge'\n\n    # 3D Finite volume discretized Poisson\n    # settings_path = f'Poisson\/3D_FV_Poisson_fromL2.settings'\n    # knowledge_path = f'Poisson\/3D_FV_Poisson_fromL2.knowledge'\n\n    # 2D Finite difference discretized Bi-Harmonic Equation\n    # settings_path = f'BiHarmonic\/2D_FD_BiHarmonic_fromL2.settings'\n    # knowledge_path = f'BiHarmonic\/2D_FD_BiHarmonic_fromL2.knowledge'\n\n    # 2D Finite volume discretized Stokes\n    # settings_path = f'Stokes\/2D_FD_Stokes_fromL2.settings'\n    # knowledge_path = f'Stokes\/2D_FD_Stokes_fromL2.knowledge'\n\n    # 2D Finite difference discretized linear elasticity\n    # settings_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.settings'\n    # knowledge_path = f'LinearElasticity\/2D_FD_LinearElasticity_fromL2.knowledge'\n\n    # settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL2.settings'\n    # knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL2.knowledge'\n    settings_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.settings'\n    knowledge_path = f'Helmholtz\/2D_FD_Helmholtz_fromL3.knowledge'\n    cycle_name = \"VCycle\"\n\n    program_generator = ProgramGenerator(compiler_path, base_path, settings_path, knowledge_path, cycle_name=cycle_name)\n\n    # Obtain extracted information from program generator\n    dimension = program_generator.dimension\n    finest_grid = program_generator.finest_grid\n    coarsening_factors = program_generator.coarsening_factor\n    min_level = program_generator.min_level\n    max_level = program_generator.max_level\n    equations = program_generator.equations\n    operators = program_generator.operators\n    fields = program_generator.fields\n\n    infinity = 1e100\n    epsilon = 1e-6\n    problem_name = program_generator.problem_name\n\n    if not os.path.exists(f'{cwd}\/{problem_name}'):\n        os.makedirs(f'{cwd}\/{problem_name}')\n    optimizer = Optimizer(dimension, finest_grid, coarsening_factors, min_level, max_level, equations, operators, fields,\n                          program_generator=program_generator,\n                          epsilon=epsilon, infinity=infinity)\n    maximum_block_size = 8\n    minimum_solver_iterations = 2**3\n    maximum_solver_iterations = 2**10\n    krylov_subspace_methods = ()\n    with open('grammar_tree.txt', 'r') as file:\n        grammar_string = file.read()\n    optimizer.generate_and_evaluate_program_from_grammar_representation(grammar_string, maximum_block_size,\n                                                                        krylov_subspace_methods=krylov_subspace_methods,\n                                                                        minimum_solver_iterations=minimum_solver_iterations,\n                                                                        maximum_solver_iterations=maximum_solver_iterations,\n                                                                        optimize_relaxation_factors=False)\n\n\nif __name__ == \"__main__\":\n    main()\n\n"}},"msg":"Bugfix: Update individual caches with communicated offspring to prevent integer overflows within allgather implementations based on pickle"}},"https:\/\/github.com\/kittsville\/Organiser":{"309447df4606ea06889159e30e6a3e5b34646738":{"url":"https:\/\/api.github.com\/repos\/kittsville\/Organiser\/commits\/309447df4606ea06889159e30e6a3e5b34646738","html_url":"https:\/\/github.com\/kittsville\/Organiser\/commit\/309447df4606ea06889159e30e6a3e5b34646738","message":"Improve frontend\n\nAdd cache busting of CSS\/JS\nImprove layout (although it still overflows on mobile)","sha":"309447df4606ea06889159e30e6a3e5b34646738","keyword":"cache overflow improve","diff":"diff --git a\/app.py b\/app.py\nindex 7e2f92c..66e7095 100644\n--- a\/app.py\n+++ b\/app.py\n@@ -2,6 +2,7 @@\n import web\n import uuid\n import redis\n+import time\n \n from user import User\n \n@@ -9,8 +10,9 @@\n     '\/lists\/(.+)', 'list_management',\n     '\/(.*)', 'homepage'\n )\n-render = web.template.render('templates\/')\n-app = web.application(urls, globals())\n+cacheBust   = int(time.time())\n+render      = web.template.render('templates\/')\n+app         = web.application(urls, globals())\n \n redis_url = os.getenv('REDIS_URL', 'redis:\/\/localhost:6379')\n r = redis.from_url(redis_url, decode_responses=True)\n@@ -21,7 +23,7 @@ def GET(self, raw_uuid):\n         if not raw_uuid:\n             raise web.found(f'\/{uuid.uuid4()}')\n             \n-        return render.homepage()\n+        return render.homepage(cacheBust)\n \n class list_management:\n     def GET(self, raw_uuid):\ndiff --git a\/static\/styles.css b\/static\/styles.css\nindex a65ba93..8565b76 100644\n--- a\/static\/styles.css\n+++ b\/static\/styles.css\n@@ -7,6 +7,7 @@ body {\n }\n \n main {\n+  width: 100%;\n   max-width: 1200px;\n }\n \n@@ -36,5 +37,6 @@ footer a:not(:hover) {\n   h1.mdc-typography.mdc-typography--headline1 {\n     font-size: 2.5em;\n \t  width: 100%;\n+    margin: 0px;\n   }\n }\ndiff --git a\/templates\/homepage.html b\/templates\/homepage.html\nindex 1937f06..77be9a9 100644\n--- a\/templates\/homepage.html\n+++ b\/templates\/homepage.html\n@@ -1,3 +1,4 @@\n+$def with (cacheBust)\n <!DOCTYPE html>\n <html lang=\"en\">\n   <head>\n@@ -22,7 +23,7 @@\n     <link href=\"https:\/\/fonts.googleapis.com\/css?family=Roboto:300,400,500\" rel=\"stylesheet\">\n     <link href=\"\/static\/material-components-web.min.css\" rel=\"stylesheet\">\n \n-    <link href=\"\/static\/styles.css\" rel=\"stylesheet\">\n+    <link href=\"\/static\/styles.css?v=$cacheBust\" rel=\"stylesheet\">\n \n     <!-- <link rel=\"icon\" type=\"image\/png\" sizes=\"32x32\" href=\"\/static\/favicons\/favicon-32x32.png\">\n     <link rel=\"icon\" type=\"image\/png\" sizes=\"16x16\" href=\"\/static\/favicons\/favicon-16x16.png\">\n@@ -52,7 +53,7 @@ <h1 class=\"mdc-typography mdc-typography--headline1\">Organiser<\/h1>\n \n     <div>\n       <script src=\"\/static\/material-components-web.min.js\"><\/script>\n-      <script src=\"\/static\/scripts.js\"><\/script>\n+      <script src=\"\/static\/scripts.js?v=$cacheBust\"><\/script>\n     <\/div>\n   <\/body>\n <\/html>\ndiff --git a\/user.py b\/user.py\nindex a870afe..1484b61 100644\n--- a\/user.py\n+++ b\/user.py\n@@ -29,6 +29,22 @@ def genDefaultState():\n                     'Comb',\n                     'Progesterone'\n                 ]\n+            },\n+            {\n+                'name': 'Bike Trip',\n+                'id': str(uuid.uuid4()),\n+                'items': [\n+                    'Flapjacks',\n+                    'Sandwich',\n+                    '2 x Water bottle',\n+                    'Wallet',\n+                    'Check tyre pressure',\n+                    'Keys',\n+                    'Jumper',\n+                    'Rain jacket',\n+                    'GT85',\n+                    'Bike Multitool'\n+                ]\n             }\n         ]  \n     }\n","files":{"\/app.py":{"changes":[{"diff":"\n     '\/(.*)', 'homepage'\n )\n-render = web.template.render('templates\/')\n-app = web.application(urls, globals())\n+cacheBust   = int(time.time())\n+render      = web.template.render('templates\/')\n+app         = web.application(urls, globals())\n \n redis_url = os.getenv('REDIS_URL', 'redis:\/\/localhost:6379')\n r = redis.from_url(redis_url, decode_responses=True)\n","add":3,"remove":2,"filename":"\/app.py","badparts":["render = web.template.render('templates\/')","app = web.application(urls, globals())"],"goodparts":["cacheBust   = int(time.time())","render      = web.template.render('templates\/')","app         = web.application(urls, globals())"]},{"diff":"\n         if not raw_uuid:\n             raise web.found(f'\/{uuid.uuid4()}')\n             \n-        return render.homepage()\n+        return render.homepage(cacheBust)\n \n class list_management:\n     def GET(self, raw_uuid):","add":1,"remove":1,"filename":"\/app.py","badparts":["        return render.homepage()"],"goodparts":["        return render.homepage(cacheBust)"]}],"source":"\nimport os import web import uuid import redis from user import User urls=( '\/lists\/(.+)', 'list_management', '\/(.*)', 'homepage' ) render=web.template.render('templates\/') app=web.application(urls, globals()) redis_url=os.getenv('REDIS_URL', 'redis:\/\/localhost:6379') r=redis.from_url(redis_url, decode_responses=True) r.ping() class homepage: def GET(self, raw_uuid): if not raw_uuid: raise web.found(f'\/{uuid.uuid4()}') return render.homepage() class list_management: def GET(self, raw_uuid): user_uuid=uuid.UUID(raw_uuid, version=4) user=User(user_uuid) return user.get_lists(r) if __name__==\"__main__\": app.run() ","sourceWithComments":"import os\nimport web\nimport uuid\nimport redis\n\nfrom user import User\n\nurls = (\n    '\/lists\/(.+)', 'list_management',\n    '\/(.*)', 'homepage'\n)\nrender = web.template.render('templates\/')\napp = web.application(urls, globals())\n\nredis_url = os.getenv('REDIS_URL', 'redis:\/\/localhost:6379')\nr = redis.from_url(redis_url, decode_responses=True)\nr.ping()\n\nclass homepage:\n    def GET(self, raw_uuid):\n        if not raw_uuid:\n            raise web.found(f'\/{uuid.uuid4()}')\n            \n        return render.homepage()\n\nclass list_management:\n    def GET(self, raw_uuid):\n        user_uuid = uuid.UUID(raw_uuid, version=4)\n\n        user = User(user_uuid)\n\n        return user.get_lists(r)\n\nif __name__ == \"__main__\":\n    app.run()"}},"msg":"Improve frontend\n\nAdd cache busting of CSS\/JS\nImprove layout (although it still overflows on mobile)"}},"https:\/\/github.com\/jsiembida\/python-sensors":{"233f72272da3f9780e237eae73f2b829d3b37af5":{"url":"https:\/\/api.github.com\/repos\/jsiembida\/python-sensors\/commits\/233f72272da3f9780e237eae73f2b829d3b37af5","html_url":"https:\/\/github.com\/jsiembida\/python-sensors\/commit\/233f72272da3f9780e237eae73f2b829d3b37af5","message":"Properly handle overflow of CPU and RAPL counters. Improve I\/O caching.","sha":"233f72272da3f9780e237eae73f2b829d3b37af5","keyword":"cache overflow improve","diff":"diff --git a\/sense.py b\/sense.py\nindex db0aac5..5948c68 100755\n--- a\/sense.py\n+++ b\/sense.py\n@@ -13,37 +13,41 @@\n \n \n class Sensors:\n+    MAX_ULL = 2 ** 64\n+\n     def __init__(self):\n-        self._listdir_count = 0\n-        self._listdir_cache = {}\n+        self._io_count = 0\n+        self._io_cache = {}\n \n-    def _listdir(self, *paths):\n-        cache = self._listdir_cache\n+    def _cached_io(self, io, *paths):\n+        cache = self._io_cache\n         now = monotonic()\n         value = None\n         error = None\n         v = cache.get(paths)\n         if v is None or (now - v[0]) > 60:\n             try:\n-                value = tuple(sorted(os.listdir(os.path.join(*paths))))\n+                value = io(os.path.join(*paths))\n             except BaseException as e:\n                 error = e\n             cache[paths] = now, value, error\n         else:\n-            value = v[1]\n-            error = v[2]\n+            _, value, error = v\n \n-        self._listdir_count += 1\n-        if self._listdir_count >= 100:\n+        self._io_count += 1\n+        if self._io_count >= 300:\n             for k, (t, v, e) in tuple(cache.items()):\n                 if now - t > 3600:\n                     cache.pop(k)\n-            self._listdir_count = 0\n+            self._io_count = 0\n \n         if error is None:\n             return value\n         raise error\n \n+    def _list_dir(self, *paths):\n+        return tuple(sorted(os.listdir(os.path.join(*paths))))\n+\n     #\n     # The idiom:\n     #\n@@ -122,7 +126,7 @@ def read_cpu_ticks(self, path='\/proc\/stat'):\n \n     def read_cpu_freqs(self, root='\/sys\/devices\/system\/cpu'):\n         try:\n-            for cpu_name in self._listdir(root):\n+            for cpu_name in self._cached_io(self._list_dir, root):\n                 if not cpu_name.startswith('cpu'):\n                     continue\n \n@@ -136,19 +140,20 @@ def read_cpu_freqs(self, root='\/sys\/devices\/system\/cpu'):\n \n     def read_power_caps(self, root='\/sys\/class\/powercap'):\n         try:\n-            for powercap_name in self._listdir(root):\n-                powercap_description = self._read_string(root, powercap_name, 'name')\n+            for powercap_name in self._cached_io(self._list_dir, root):\n+                powercap_description = self._cached_io(self._read_string, root, powercap_name, 'name')\n                 if not powercap_description:\n                     continue\n                 powercap_value = self._read_integer(root, powercap_name, 'energy_uj')\n                 if powercap_value is not None:\n-                    yield powercap_name, powercap_description, powercap_value \/ 1000000\n+                    powercap_max = self._cached_io(self._read_integer, root, powercap_name, 'max_energy_range_uj')\n+                    yield powercap_name, powercap_description, powercap_value, powercap_max\n         except OSError:\n             pass\n \n     def read_hardware_sensors(self, root='\/sys\/class\/hwmon', sensors_re=re.compile(r'^((temp|fan)(\\d+))_input$')):\n         try:\n-            for i in self._listdir(root):\n+            for i in self._cached_io(self._list_dir, root):\n                 if not i.startswith('hwmon'):\n                     continue\n                 hwmon_number = i[5:]\n@@ -158,13 +163,13 @@ def read_hardware_sensors(self, root='\/sys\/class\/hwmon', sensors_re=re.compile(r\n \n                 inputs = set()\n \n-                files = set(self._listdir(root, i))\n+                files = set(self._cached_io(self._list_dir, root, i))\n                 for j in files:\n                     match = sensors_re.match(j)\n                     if match:\n                         inputs.add(match.groups())\n \n-                sensor_name = self._read_string(root, i, 'name')\n+                sensor_name = self._cached_io(self._read_string, root, i, 'name')\n                 if not sensor_name:\n                     continue\n \n@@ -183,7 +188,9 @@ def read_hardware_sensors(self, root='\/sys\/class\/hwmon', sensors_re=re.compile(r\n                     if input_value is None:\n                         continue\n                     description_file = input_name + '_label'\n-                    input_description = self._read_string(root, i, description_file) if description_file in files else None\n+                    input_description = None\n+                    if description_file in files:\n+                        input_description = self._cached_io(self._read_string, root, i, description_file)\n                     offset_file = input_name + '_offset'\n                     if offset_file in files:\n                         offset_value = self._read_integer(root, i, offset_file)\n@@ -215,7 +222,11 @@ def read(self, *, cpu_usage=True, cpu_freq=True, power_caps=True, hardware_senso\n                             curr_total_ticks, curr_spare_ticks = curr_v\n                             prev_total_ticks, prev_spare_ticks = prev_v\n                             total_ticks = curr_total_ticks - prev_total_ticks\n+                            while total_ticks < 0:\n+                                total_ticks += self.MAX_ULL\n                             spare_ticks = curr_spare_ticks - prev_spare_ticks\n+                            while spare_ticks < 0:\n+                                spare_ticks += self.MAX_ULL\n                             curr_results.append({\n                                 'resource': 'cpu',\n                                 'instance': (instance,),\n@@ -233,15 +244,17 @@ def read(self, *, cpu_usage=True, cpu_freq=True, power_caps=True, hardware_senso\n                     for instance, curr_v in curr_power_caps.items():\n                         prev_v = prev_power_caps.get(instance)\n                         if prev_v is not None:\n-                            curr_description, curr_energy = curr_v\n-                            prev_description, prev_energy = prev_v\n+                            curr_description, curr_energy, curr_max = curr_v\n+                            prev_description, prev_energy, prev_max = prev_v\n                             energy_used = curr_energy - prev_energy\n+                            while energy_used < 0:\n+                                energy_used += 1 + curr_max\n                             curr_results.append({\n                                 'resource': 'power',\n                                 'instance': (instance,),\n                                 'description': curr_description,\n                                 'quantity': 'power',\n-                                'value': energy_used \/ dt,\n+                                'value': energy_used \/ dt \/ 1000000.0,\n                                 'unit': 'W',\n                             })\n                 prev_power_caps = curr_power_caps\n","files":{"\/sense.py":{"changes":[{"diff":"\n \n \n class Sensors:\n+    MAX_ULL = 2 ** 64\n+\n     def __init__(self):\n-        self._listdir_count = 0\n-        self._listdir_cache = {}\n+        self._io_count = 0\n+        self._io_cache = {}\n \n-    def _listdir(self, *paths):\n-        cache = self._listdir_cache\n+    def _cached_io(self, io, *paths):\n+        cache = self._io_cache\n         now = monotonic()\n         value = None\n         error = None\n         v = cache.get(paths)\n         if v is None or (now - v[0]) > 60:\n             try:\n-                value = tuple(sorted(os.listdir(os.path.join(*paths))))\n+                value = io(os.path.join(*paths))\n             except BaseException as e:\n                 error = e\n             cache[paths] = now, value, error\n         else:\n-            value = v[1]\n-            error = v[2]\n+            _, value, error = v\n \n-        self._listdir_count += 1\n-        if self._listdir_count >= 100:\n+        self._io_count += 1\n+        if self._io_count >= 300:\n             for k, (t, v, e) in tuple(cache.items()):\n                 if now - t > 3600:\n                     cache.pop(k)\n-            self._listdir_count = 0\n+            self._io_count = 0\n \n         if error is None:\n             return value\n         raise error\n \n+    def _list_dir(self, *paths):\n+        return tuple(sorted(os.listdir(os.path.join(*paths))))\n+\n     #\n     # The idiom:\n     #\n","add":14,"remove":10,"filename":"\/sense.py","badparts":["        self._listdir_count = 0","        self._listdir_cache = {}","    def _listdir(self, *paths):","        cache = self._listdir_cache","                value = tuple(sorted(os.listdir(os.path.join(*paths))))","            value = v[1]","            error = v[2]","        self._listdir_count += 1","        if self._listdir_count >= 100:","            self._listdir_count = 0"],"goodparts":["    MAX_ULL = 2 ** 64","        self._io_count = 0","        self._io_cache = {}","    def _cached_io(self, io, *paths):","        cache = self._io_cache","                value = io(os.path.join(*paths))","            _, value, error = v","        self._io_count += 1","        if self._io_count >= 300:","            self._io_count = 0","    def _list_dir(self, *paths):","        return tuple(sorted(os.listdir(os.path.join(*paths))))"]},{"diff":"\n \n     def read_cpu_freqs(self, root='\/sys\/devices\/system\/cpu'):\n         try:\n-            for cpu_name in self._listdir(root):\n+            for cpu_name in self._cached_io(self._list_dir, root):\n                 if not cpu_name.startswith('cpu'):\n                     continue\n \n","add":1,"remove":1,"filename":"\/sense.py","badparts":["            for cpu_name in self._listdir(root):"],"goodparts":["            for cpu_name in self._cached_io(self._list_dir, root):"]},{"diff":"\n \n     def read_power_caps(self, root='\/sys\/class\/powercap'):\n         try:\n-            for powercap_name in self._listdir(root):\n-                powercap_description = self._read_string(root, powercap_name, 'name')\n+            for powercap_name in self._cached_io(self._list_dir, root):\n+                powercap_description = self._cached_io(self._read_string, root, powercap_name, 'name')\n                 if not powercap_description:\n                     continue\n                 powercap_value = self._read_integer(root, powercap_name, 'energy_uj')\n                 if powercap_value is not None:\n-                    yield powercap_name, powercap_description, powercap_value \/ 1000000\n+                    powercap_max = self._cached_io(self._read_integer, root, powercap_name, 'max_energy_range_uj')\n+                    yield powercap_name, powercap_description, powercap_value, powercap_max\n         except OSError:\n             pass\n \n     def read_hardware_sensors(self, root='\/sys\/class\/hwmon', sensors_re=re.compile(r'^((temp|fan)(\\d+))_input$')):\n         try:\n-            for i in self._listdir(root):\n+            for i in self._cached_io(self._list_dir, root):\n                 if not i.startswith('hwmon'):\n                     continue\n                 hwmon_number = i[5:]\n","add":5,"remove":4,"filename":"\/sense.py","badparts":["            for powercap_name in self._listdir(root):","                powercap_description = self._read_string(root, powercap_name, 'name')","                    yield powercap_name, powercap_description, powercap_value \/ 1000000","            for i in self._listdir(root):"],"goodparts":["            for powercap_name in self._cached_io(self._list_dir, root):","                powercap_description = self._cached_io(self._read_string, root, powercap_name, 'name')","                    powercap_max = self._cached_io(self._read_integer, root, powercap_name, 'max_energy_range_uj')","                    yield powercap_name, powercap_description, powercap_value, powercap_max","            for i in self._cached_io(self._list_dir, root):"]},{"diff":"\n \n                 inputs = set()\n \n-                files = set(self._listdir(root, i))\n+                files = set(self._cached_io(self._list_dir, root, i))\n                 for j in files:\n                     match = sensors_re.match(j)\n                     if match:\n                         inputs.add(match.groups())\n \n-                sensor_name = self._read_string(root, i, 'name')\n+                sensor_name = self._cached_io(self._read_string, root, i, 'name')\n                 if not sensor_name:\n                     continue\n \n","add":2,"remove":2,"filename":"\/sense.py","badparts":["                files = set(self._listdir(root, i))","                sensor_name = self._read_string(root, i, 'name')"],"goodparts":["                files = set(self._cached_io(self._list_dir, root, i))","                sensor_name = self._cached_io(self._read_string, root, i, 'name')"]},{"diff":"\n                     if input_value is None:\n                         continue\n                     description_file = input_name + '_label'\n-                    input_description = self._read_string(root, i, description_file) if description_file in files else None\n+                    input_description = None\n+                    if description_file in files:\n+                        input_description = self._cached_io(self._read_string, root, i, description_file)\n                     offset_file = input_name + '_offset'\n                     if offset_file in files:\n                         offset_value = self._read_integer(root, i, offset_file)\n","add":3,"remove":1,"filename":"\/sense.py","badparts":["                    input_description = self._read_string(root, i, description_file) if description_file in files else None"],"goodparts":["                    input_description = None","                    if description_file in files:","                        input_description = self._cached_io(self._read_string, root, i, description_file)"]},{"diff":"\n                     for instance, curr_v in curr_power_caps.items():\n                         prev_v = prev_power_caps.get(instance)\n                         if prev_v is not None:\n-                            curr_description, curr_energy = curr_v\n-                            prev_description, prev_energy = prev_v\n+                            curr_description, curr_energy, curr_max = curr_v\n+                            prev_description, prev_energy, prev_max = prev_v\n                             energy_used = curr_energy - prev_energy\n+                            while energy_used < 0:\n+                                energy_used += 1 + curr_max\n                             curr_results.append({\n                                 'resource': 'power',\n                                 'instance': (instance,),\n                                 'description': curr_description,\n                                 'quantity': 'power',\n-                                'value': energy_used \/ dt,\n+                                'value': energy_used \/ dt \/ 1000000.0,\n                                 'unit': 'W',\n                             })\n                 prev_power_caps = curr_power_caps\n","add":5,"remove":3,"filename":"\/sense.py","badparts":["                            curr_description, curr_energy = curr_v","                            prev_description, prev_energy = prev_v","                                'value': energy_used \/ dt,"],"goodparts":["                            curr_description, curr_energy, curr_max = curr_v","                            prev_description, prev_energy, prev_max = prev_v","                            while energy_used < 0:","                                energy_used += 1 + curr_max","                                'value': energy_used \/ dt \/ 1000000.0,"]}],"source":"\n import os import re from collections import defaultdict from csv import DictWriter from datetime import datetime, timezone from io import StringIO from json import dumps from time import time, sleep, monotonic class Sensors: def __init__(self): self._listdir_count=0 self._listdir_cache={} def _listdir(self, *paths): cache=self._listdir_cache now=monotonic() value=None error=None v=cache.get(paths) if v is None or(now -v[0]) > 60: try: value=tuple(sorted(os.listdir(os.path.join(*paths)))) except BaseException as e: error=e cache[paths]=now, value, error else: value=v[1] error=v[2] self._listdir_count +=1 if self._listdir_count >=100: for k,(t, v, e) in tuple(cache.items()): if now -t > 3600: cache.pop(k) self._listdir_count=0 if error is None: return value raise error def _read_string(self, *paths, default=None): fd=None chunk_size=16 * 1024 try: fd=os.open(os.path.join(*paths), os.O_RDONLY) content=b'' while True: chunk=os.read(fd, chunk_size) content +=chunk if len(chunk) < chunk_size: break return content.decode().strip() except IOError: pass finally: if fd is not None: os.close(fd) return default def _read_integer(self, *paths): try: return int(self._read_string(*paths)) except TypeError: pass def read_cpu_ticks(self, path='\/proc\/stat'): for i in self._read_string(path, default='').splitlines(): if not i.startswith('cpu'): continue tokens=i.strip().split() cpu_name=tokens[0] if cpu_name=='cpu': continue cpu_number=int(cpu_name[3:]) +1 cpu_stats=tuple(int(i) for i in tokens[1:]) cpu_total_ticks=sum(cpu_stats) cpu_spare_ticks=cpu_stats[3] +cpu_stats[4] yield cpu_number, cpu_total_ticks, cpu_spare_ticks def read_cpu_freqs(self, root='\/sys\/devices\/system\/cpu'): try: for cpu_name in self._listdir(root): if not cpu_name.startswith('cpu'): continue cpu_number=cpu_name[3:] if cpu_number.isdecimal(): cpu_freq=self._read_integer(root, cpu_name, 'cpufreq', 'scaling_cur_freq') if cpu_freq is not None: yield int(cpu_number) +1, cpu_freq * 1000 except OSError: pass def read_power_caps(self, root='\/sys\/class\/powercap'): try: for powercap_name in self._listdir(root): powercap_description=self._read_string(root, powercap_name, 'name') if not powercap_description: continue powercap_value=self._read_integer(root, powercap_name, 'energy_uj') if powercap_value is not None: yield powercap_name, powercap_description, powercap_value \/ 1000000 except OSError: pass def read_hardware_sensors(self, root='\/sys\/class\/hwmon', sensors_re=re.compile(r'^((temp|fan)(\\d+))_input$')): try: for i in self._listdir(root): if not i.startswith('hwmon'): continue hwmon_number=i[5:] if not hwmon_number.isdecimal(): continue hwmon_number=int(hwmon_number) inputs=set() files=set(self._listdir(root, i)) for j in files: match=sensors_re.match(j) if match: inputs.add(match.groups()) sensor_name=self._read_string(root, i, 'name') if not sensor_name: continue input_offset=0 if sensor_name=='coretemp': sensor_device=os.readlink(os.path.join(root, i, 'device')) _, hwmon_number=sensor_device.rsplit('.', maxsplit=1) hwmon_number=int(hwmon_number) +1 sensor_name='core' input_offset=-1 for input_name, input_type, input_number in sorted(inputs): input_number=int(input_number) +input_offset input_file=input_name +'_input' input_value=self._read_integer(root, i, input_file) if input_value is None: continue description_file=input_name +'_label' input_description=self._read_string(root, i, description_file) if description_file in files else None offset_file=input_name +'_offset' if offset_file in files: offset_value=self._read_integer(root, i, offset_file) if offset_value is not None: input_value +=offset_value if input_type=='temp': input_value=float(input_value) \/ 1000 +273.15 yield sensor_name, hwmon_number, input_number, input_description, input_value, 'temp', 'K' elif input_type=='fan': yield sensor_name, hwmon_number, input_number, input_description, input_value, 'freq', 'RPM' except OSError: pass def read(self, *, cpu_usage=True, cpu_freq=True, power_caps=True, hardware_sensors=True): prev_timestamp=None prev_cpu_ticks=None prev_power_caps=None while True: curr_timestamp=monotonic() curr_results=[] if cpu_usage: curr_cpu_ticks={i[0]: i[1:] for i in self.read_cpu_ticks()} if prev_cpu_ticks is not None: for instance, curr_v in curr_cpu_ticks.items(): prev_v=prev_cpu_ticks.get(instance) if prev_v is not None: curr_total_ticks, curr_spare_ticks=curr_v prev_total_ticks, prev_spare_ticks=prev_v total_ticks=curr_total_ticks -prev_total_ticks spare_ticks=curr_spare_ticks -prev_spare_ticks curr_results.append({ 'resource': 'cpu', 'instance':(instance,), 'description': None, 'quantity': 'usage', 'value': 100 -100 * spare_ticks \/ total_ticks, 'unit': '%', }) prev_cpu_ticks=curr_cpu_ticks if power_caps: curr_power_caps={i[0]: i[1:] for i in self.read_power_caps()} if prev_power_caps is not None: dt=curr_timestamp -prev_timestamp for instance, curr_v in curr_power_caps.items(): prev_v=prev_power_caps.get(instance) if prev_v is not None: curr_description, curr_energy=curr_v prev_description, prev_energy=prev_v energy_used=curr_energy -prev_energy curr_results.append({ 'resource': 'power', 'instance':(instance,), 'description': curr_description, 'quantity': 'power', 'value': energy_used \/ dt, 'unit': 'W', }) prev_power_caps=curr_power_caps if cpu_freq: for instance, freq in self.read_cpu_freqs(): curr_results.append({ 'resource': 'cpu', 'instance':(instance,), 'description': None, 'quantity': 'freq', 'value': freq, 'unit': 'Hz', }) if hardware_sensors: for name, hwmon, instance, description, value, quantity, unit in self.read_hardware_sensors(): curr_results.append({ 'resource': name, 'instance':(hwmon, instance), 'description': description, 'quantity': quantity, 'value': value, 'unit': unit, }) prev_timestamp=curr_timestamp yield curr_results def _convert_temperature_to_k(datapoint): if datapoint['quantity']=='temp' and datapoint['unit']=='K': return datapoint def _convert_temperature_to_c(datapoint): if datapoint['quantity']=='temp' and datapoint['unit']=='K': datapoint['value'] -=273.15 datapoint['unit']='C' return datapoint def _convert_temperature_to_f(datapoint): if datapoint['quantity']=='temp' and datapoint['unit']=='K': datapoint['value']=datapoint['value'] * 1.8 -459.67 datapoint['unit']='F' return datapoint def _convert_frequency_to_mhz(datapoint): if datapoint['quantity']=='freq' and datapoint['unit']=='Hz': datapoint['value'] \/=1000000 datapoint['unit']='MHz' return datapoint def _convert_frequency_to_ghz(datapoint): if datapoint['quantity']=='freq' and datapoint['unit']=='Hz': datapoint['value'] \/=1000000000 datapoint['unit']='GHz' return datapoint def _convert_power_to_kw(datapoint): if datapoint['quantity']=='power' and datapoint['unit']=='W': datapoint['value'] \/=1000 datapoint['unit']='kW' return datapoint def _convert_power_to_mw(datapoint): if datapoint['quantity']=='power' and datapoint['unit']=='W': datapoint['value'] *=1000 datapoint['unit']='mW' return datapoint def _format_ndjson(timestamp, datapoints): timestamp=round(timestamp * 1000) for i in datapoints: i['timestamp']=timestamp return dumps(datapoints) def _format_csv(timestamp, datapoints): timestamp=round(timestamp * 1000) columns=('timestamp', 'resource', 'instance', 'quantity', 'value', 'unit', 'description') with StringIO() as buffer: csv=DictWriter(buffer, columns, restval='', extrasaction='ignore') csv.writeheader() for i in datapoints: i['timestamp']=timestamp instance=i['instance'] if instance: i['instance']='\/'.join(map(str, instance)) csv.writerow(i) return buffer.getvalue() def _format_simple(timestamp, datapoints): dt=datetime.fromtimestamp(timestamp, tz=timezone.utc).astimezone() lines=['', dt.isoformat()] resources=defaultdict(list) for datapoint in datapoints: resources[(datapoint['resource'], datapoint['instance'])].append(datapoint) for k in sorted(resources): resource, instance=k name='{}\/{}'.format(resource, '\/'.join(map(str, instance))) if instance else resource cells=[] description=None for i in resources[k]: cells.append('{}={}{}'.format(i['quantity'], round(i['value'], 3), i['unit'])) if description is None: description=i.get('description') description='({})'.format(description) if description else '' lines.append(' {}{}{}'.format(name, description, ' '.join(cells))) return '\\n'.join(lines) def _format_table(timestamp, datapoints): dt=datetime.fromtimestamp(timestamp, tz=timezone.utc).astimezone() lines=['', dt.isoformat(), ''] resources=defaultdict(dict) column_names=set() for datapoint in datapoints: resource=datapoint['resource'] instance=datapoint['instance'] description=datapoint['description'] k=resource, instance if instance: instance='\/'.join(map(str, instance)) quantity=datapoint['quantity'] column_names.add(quantity) value=datapoint['value'] unit=datapoint['unit'] if isinstance(value, int): value='{}{}'.format(value, unit) else: value='{:.3f}{}'.format(value, unit) datapoint=resources[k] datapoint['resource']=resource datapoint['instance']=instance or '' datapoint['description']=description or '' datapoint[quantity]=value resources=tuple(resources[k] for k in sorted(resources)) column_names=sorted(column_names) column_names.insert(0, 'instance') column_names.insert(0, 'resource') column_names.append('description') formats=[] columns=[] for name in column_names: column=[name, ''] for resource in resources: column.append(resource.get(name, '')) column_width=max(map(len, column)) if name==column_names[-1]: formats.append(' {{:<{}}}'.format(column_width)) else: formats.append(' {{:>{}}}'.format(column_width)) columns.append(column) line_format=''.join(formats) lines.extend(map(line_format.format, *columns)) return '\\n'.join(lines) def main( interval=10, count=0, output_format='ndjson', converters=(), cpu_usage=True, cpu_freq=True, power_caps=True, hardware_sensors=True, ): first=True sensors=Sensors() formatter=globals().get('_format_{}'.format(output_format), _format_simple) if count==0: count=-1 for datapoints in sensors.read( cpu_usage=cpu_usage, cpu_freq=cpu_freq, power_caps=power_caps, hardware_sensors=hardware_sensors, ): if first: first=False sleep(min(interval, 1)) last_timestamp=time() next_timestamp=last_timestamp +interval continue for i in datapoints: for j in converters: if j(i): break print(formatter(last_timestamp, datapoints), flush=True) if count > 0: count -=1 if count==0: break curr_timestamp=time() pause=max(next_timestamp -curr_timestamp, 0.1) sleep(pause) next_timestamp +=interval last_timestamp=time() if __name__=='__main__': from argparse import ArgumentParser parser=ArgumentParser(description='Power, temperature and usage monitor.') parser.add_argument('--interval', metavar='SECONDS', type=float, default='10', help='The interval between updates. Default is 10 seconds.') parser.add_argument('--count', metavar='N', type=int, default=0, help='Number of updates. When zero(which is default) repeat forever.') parser.add_argument('--output-format', choices=['ndjson', 'csv', 'simple', 'table'], default='simple', help='Choice of the output format. Default is simple.') parser.add_argument('--skip-cpu-usage', action='store_true', default=False, help='Skip CPU usage.') parser.add_argument('--skip-cpu-freq', action='store_true', default=False, help='Skip CPU frequencies.') parser.add_argument('--skip-power-usage', action='store_true', default=False, help='Skip power usage sensors.') parser.add_argument('--skip-hardware-sensors', action='store_true', default=False, help='Skip available hardware sensors.') parser.add_argument('--freq-unit', choices=['Hz', 'MHz', 'GHz'], default='GHz', help='Choice of frequency units. Default is GHz.') parser.add_argument('--temp-unit', choices=['C', 'K', 'F'], default='C', help='Choice of temperature units. Default is C.') parser.add_argument('--power-unit', choices=['mW', 'W', 'kW'], default='W', help='Choice of power units. Default is W.') args=parser.parse_args() converters=[] if args.freq_unit=='MHz': converters.append(_convert_frequency_to_mhz) elif args.freq_unit=='GHz': converters.append(_convert_frequency_to_ghz) if args.temp_unit=='C': converters.append(_convert_temperature_to_c) elif args.temp_unit=='F': converters.append(_convert_temperature_to_f) if args.power_unit=='mW': converters.append(_convert_power_to_mw) elif args.freq_unit=='kW': converters.append(_convert_power_to_kw) main( interval=min(max(0.1, args.interval), 24 * 3600), count=args.count, output_format=args.output_format, converters=converters, cpu_usage=not args.skip_cpu_usage, cpu_freq=not args.skip_cpu_freq, power_caps=not args.skip_power_usage, hardware_sensors=not args.skip_hardware_sensors, ) ","sourceWithComments":"#!\/usr\/bin\/env python3\n# -*- coding: utf-8 -*-\n\n\nimport os\nimport re\nfrom collections import defaultdict\nfrom csv import DictWriter\nfrom datetime import datetime, timezone\nfrom io import StringIO\nfrom json import dumps\nfrom time import time, sleep, monotonic\n\n\nclass Sensors:\n    def __init__(self):\n        self._listdir_count = 0\n        self._listdir_cache = {}\n\n    def _listdir(self, *paths):\n        cache = self._listdir_cache\n        now = monotonic()\n        value = None\n        error = None\n        v = cache.get(paths)\n        if v is None or (now - v[0]) > 60:\n            try:\n                value = tuple(sorted(os.listdir(os.path.join(*paths))))\n            except BaseException as e:\n                error = e\n            cache[paths] = now, value, error\n        else:\n            value = v[1]\n            error = v[2]\n\n        self._listdir_count += 1\n        if self._listdir_count >= 100:\n            for k, (t, v, e) in tuple(cache.items()):\n                if now - t > 3600:\n                    cache.pop(k)\n            self._listdir_count = 0\n\n        if error is None:\n            return value\n        raise error\n\n    #\n    # The idiom:\n    #\n    #   with open(...) as f:\n    #     return f.read()\n    #\n    # Produces plenty of syscalls that in our use case are really unnecessary:\n    #\n    #   openat(AT_FDCWD, \"\/sys\/devices\/system\/cpu\/cpu0\/cpufreq\/scaling_cur_freq\", O_RDONLY|O_CLOEXEC) = 3\n    #   fstat(3, {st_mode=S_IFREG|0444, st_size=4096, ...}) = 0\n    #   ioctl(3, TCGETS, 0x7fd9221130)          = -1 ENOTTY (Inappropriate ioctl for device)\n    #   lseek(3, 0, SEEK_CUR)                   = 0\n    #   ioctl(3, TCGETS, 0x7fd9220f30)          = -1 ENOTTY (Inappropriate ioctl for device)\n    #   lseek(3, 0, SEEK_CUR)\n    #   fstat(3, {st_mode=S_IFREG|0444, st_size=4096, ...}) = 0\n    #   read(3, \"600000\\n\", 4097)               = 7\n    #   read(3, \"\", 4090)\n    #   close(3)\n    #\n    # The _read_string below produces:\n    #\n    #   openat(AT_FDCWD, \"\/sys\/devices\/system\/cpu\/cpu0\/cpufreq\/scaling_cur_freq\", O_RDONLY|O_CLOEXEC) = 3\n    #   read(3, \"600000\\n\", 16384)\n    #   close(3)\n    #\n    # We use a 16kB buffer, for large buffers Python tries to optimize i\/o with memory mapping, which produces:\n    #\n    #   openat(AT_FDCWD, \"\/sys\/devices\/system\/cpu\/cpu0\/cpufreq\/scaling_cur_freq\", O_RDONLY|O_CLOEXEC) = 3\n    #   mmap(NULL, 1052672, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f8b400000\n    #   read(3, \"600000\\n\", 1048576)            = 7\n    #   mremap(0x7f8b400000, 1052672, 4096, MREMAP_MAYMOVE) = 0x7f8b400000\n    #   close(3)\n    #\n    def _read_string(self, *paths, default=None):\n        fd = None\n        chunk_size = 16 * 1024\n        try:\n            fd = os.open(os.path.join(*paths), os.O_RDONLY)\n            content = b''\n            while True:\n                chunk = os.read(fd, chunk_size)\n                content += chunk\n                if len(chunk) < chunk_size:\n                    break\n            return content.decode().strip()\n        except IOError:\n            pass\n        finally:\n            if fd is not None:\n                os.close(fd)\n        return default\n\n    def _read_integer(self, *paths):\n        try:\n            return int(self._read_string(*paths))\n        except TypeError:\n            pass\n\n    def read_cpu_ticks(self, path='\/proc\/stat'):\n        for i in self._read_string(path, default='').splitlines():\n            if not i.startswith('cpu'):\n                continue\n\n            tokens = i.strip().split()\n            cpu_name = tokens[0]\n            if cpu_name == 'cpu':\n                continue\n\n            cpu_number = int(cpu_name[3:]) + 1\n            cpu_stats = tuple(int(i) for i in tokens[1:])\n            cpu_total_ticks = sum(cpu_stats)\n            # Consider idle+iowait ticks as spare cpu cycles and everything else as used cpu cycles\n            # See https:\/\/github.com\/torvalds\/linux\/blob\/master\/fs\/proc\/stat.c\n            cpu_spare_ticks = cpu_stats[3] + cpu_stats[4]\n            yield cpu_number, cpu_total_ticks, cpu_spare_ticks\n\n    def read_cpu_freqs(self, root='\/sys\/devices\/system\/cpu'):\n        try:\n            for cpu_name in self._listdir(root):\n                if not cpu_name.startswith('cpu'):\n                    continue\n\n                cpu_number = cpu_name[3:]\n                if cpu_number.isdecimal():\n                    cpu_freq = self._read_integer(root, cpu_name, 'cpufreq', 'scaling_cur_freq')\n                    if cpu_freq is not None:\n                        yield int(cpu_number) + 1, cpu_freq * 1000\n        except OSError:\n            pass\n\n    def read_power_caps(self, root='\/sys\/class\/powercap'):\n        try:\n            for powercap_name in self._listdir(root):\n                powercap_description = self._read_string(root, powercap_name, 'name')\n                if not powercap_description:\n                    continue\n                powercap_value = self._read_integer(root, powercap_name, 'energy_uj')\n                if powercap_value is not None:\n                    yield powercap_name, powercap_description, powercap_value \/ 1000000\n        except OSError:\n            pass\n\n    def read_hardware_sensors(self, root='\/sys\/class\/hwmon', sensors_re=re.compile(r'^((temp|fan)(\\d+))_input$')):\n        try:\n            for i in self._listdir(root):\n                if not i.startswith('hwmon'):\n                    continue\n                hwmon_number = i[5:]\n                if not hwmon_number.isdecimal():\n                    continue\n                hwmon_number = int(hwmon_number)\n\n                inputs = set()\n\n                files = set(self._listdir(root, i))\n                for j in files:\n                    match = sensors_re.match(j)\n                    if match:\n                        inputs.add(match.groups())\n\n                sensor_name = self._read_string(root, i, 'name')\n                if not sensor_name:\n                    continue\n\n                input_offset = 0\n                if sensor_name == 'coretemp':\n                    sensor_device = os.readlink(os.path.join(root, i, 'device'))\n                    _, hwmon_number = sensor_device.rsplit('.', maxsplit=1)\n                    hwmon_number = int(hwmon_number) + 1\n                    sensor_name = 'core'\n                    input_offset = -1\n\n                for input_name, input_type, input_number in sorted(inputs):\n                    input_number = int(input_number) + input_offset\n                    input_file = input_name + '_input'\n                    input_value = self._read_integer(root, i, input_file)\n                    if input_value is None:\n                        continue\n                    description_file = input_name + '_label'\n                    input_description = self._read_string(root, i, description_file) if description_file in files else None\n                    offset_file = input_name + '_offset'\n                    if offset_file in files:\n                        offset_value = self._read_integer(root, i, offset_file)\n                        if offset_value is not None:\n                            input_value += offset_value\n                    if input_type == 'temp':\n                        input_value = float(input_value) \/ 1000 + 273.15\n                        yield sensor_name, hwmon_number, input_number, input_description, input_value, 'temp', 'K'\n                    elif input_type == 'fan':\n                        yield sensor_name, hwmon_number, input_number, input_description, input_value, 'freq', 'RPM'\n        except OSError:\n            pass\n\n    def read(self, *, cpu_usage=True, cpu_freq=True, power_caps=True, hardware_sensors=True):\n        prev_timestamp = None\n        prev_cpu_ticks = None\n        prev_power_caps = None\n\n        while True:\n            curr_timestamp = monotonic()\n            curr_results = []\n\n            if cpu_usage:\n                curr_cpu_ticks = {i[0]: i[1:] for i in self.read_cpu_ticks()}\n                if prev_cpu_ticks is not None:\n                    for instance, curr_v in curr_cpu_ticks.items():\n                        prev_v = prev_cpu_ticks.get(instance)\n                        if prev_v is not None:\n                            curr_total_ticks, curr_spare_ticks = curr_v\n                            prev_total_ticks, prev_spare_ticks = prev_v\n                            total_ticks = curr_total_ticks - prev_total_ticks\n                            spare_ticks = curr_spare_ticks - prev_spare_ticks\n                            curr_results.append({\n                                'resource': 'cpu',\n                                'instance': (instance,),\n                                'description': None,\n                                'quantity': 'usage',\n                                'value': 100 - 100 * spare_ticks \/ total_ticks,\n                                'unit': '%',\n                            })\n                prev_cpu_ticks = curr_cpu_ticks\n\n            if power_caps:\n                curr_power_caps = {i[0]: i[1:] for i in self.read_power_caps()}\n                if prev_power_caps is not None:\n                    dt = curr_timestamp - prev_timestamp\n                    for instance, curr_v in curr_power_caps.items():\n                        prev_v = prev_power_caps.get(instance)\n                        if prev_v is not None:\n                            curr_description, curr_energy = curr_v\n                            prev_description, prev_energy = prev_v\n                            energy_used = curr_energy - prev_energy\n                            curr_results.append({\n                                'resource': 'power',\n                                'instance': (instance,),\n                                'description': curr_description,\n                                'quantity': 'power',\n                                'value': energy_used \/ dt,\n                                'unit': 'W',\n                            })\n                prev_power_caps = curr_power_caps\n\n            if cpu_freq:\n                for instance, freq in self.read_cpu_freqs():\n                    curr_results.append({\n                        'resource': 'cpu',\n                        'instance': (instance,),\n                        'description': None,\n                        'quantity': 'freq',\n                        'value': freq,\n                        'unit': 'Hz',\n                    })\n\n            if hardware_sensors:\n                for name, hwmon, instance, description, value, quantity, unit in self.read_hardware_sensors():\n                    curr_results.append({\n                        'resource': name,\n                        'instance': (hwmon, instance),\n                        'description': description,\n                        'quantity': quantity,\n                        'value': value,\n                        'unit': unit,\n                    })\n\n            prev_timestamp = curr_timestamp\n            yield curr_results\n\n\ndef _convert_temperature_to_k(datapoint):\n    if datapoint['quantity'] == 'temp' and datapoint['unit'] == 'K':\n        return datapoint\n\n\ndef _convert_temperature_to_c(datapoint):\n    if datapoint['quantity'] == 'temp' and datapoint['unit'] == 'K':\n        datapoint['value'] -= 273.15\n        datapoint['unit'] = 'C'\n        return datapoint\n\n\ndef _convert_temperature_to_f(datapoint):\n    if datapoint['quantity'] == 'temp' and datapoint['unit'] == 'K':\n        datapoint['value'] = datapoint['value'] * 1.8 - 459.67\n        datapoint['unit'] = 'F'\n        return datapoint\n\n\ndef _convert_frequency_to_mhz(datapoint):\n    if datapoint['quantity'] == 'freq' and datapoint['unit'] == 'Hz':\n        datapoint['value'] \/= 1000000\n        datapoint['unit'] = 'MHz'\n        return datapoint\n\n\ndef _convert_frequency_to_ghz(datapoint):\n    if datapoint['quantity'] == 'freq' and datapoint['unit'] == 'Hz':\n        datapoint['value'] \/= 1000000000\n        datapoint['unit'] = 'GHz'\n        return datapoint\n\n\ndef _convert_power_to_kw(datapoint):\n    if datapoint['quantity'] == 'power' and datapoint['unit'] == 'W':\n        datapoint['value'] \/= 1000\n        datapoint['unit'] = 'kW'\n        return datapoint\n\n\ndef _convert_power_to_mw(datapoint):\n    if datapoint['quantity'] == 'power' and datapoint['unit'] == 'W':\n        datapoint['value'] *= 1000\n        datapoint['unit'] = 'mW'\n        return datapoint\n\n\ndef _format_ndjson(timestamp, datapoints):\n    timestamp = round(timestamp * 1000)\n    for i in datapoints:\n        i['timestamp'] = timestamp\n    return dumps(datapoints)\n\n\ndef _format_csv(timestamp, datapoints):\n    timestamp = round(timestamp * 1000)\n    columns = ('timestamp', 'resource', 'instance', 'quantity', 'value', 'unit', 'description')\n    with StringIO() as buffer:\n        csv = DictWriter(buffer, columns, restval='', extrasaction='ignore')\n        csv.writeheader()\n        for i in datapoints:\n            i['timestamp'] = timestamp\n            instance = i['instance']\n            if instance:\n                i['instance'] = '\/'.join(map(str, instance))\n            csv.writerow(i)\n        return buffer.getvalue()\n\n\ndef _format_simple(timestamp, datapoints):\n    dt = datetime.fromtimestamp(timestamp, tz=timezone.utc).astimezone()\n    lines = ['', dt.isoformat()]\n    resources = defaultdict(list)\n    for datapoint in datapoints:\n        resources[(datapoint['resource'], datapoint['instance'])].append(datapoint)\n    for k in sorted(resources):\n        resource, instance = k\n        name = '{}\/{}'.format(resource, '\/'.join(map(str, instance))) if instance else resource\n        cells = []\n        description = None\n        for i in resources[k]:\n            cells.append('{}={}{}'.format(i['quantity'], round(i['value'], 3), i['unit']))\n            if description is None:\n                description = i.get('description')\n        description = ' ({})'.format(description) if description else ''\n        lines.append('   {}{} {}'.format(name, description, ' '.join(cells)))\n    return '\\n'.join(lines)\n\n\ndef _format_table(timestamp, datapoints):\n    dt = datetime.fromtimestamp(timestamp, tz=timezone.utc).astimezone()\n    lines = ['', dt.isoformat(), '']\n    resources = defaultdict(dict)\n    column_names = set()\n    for datapoint in datapoints:\n        resource = datapoint['resource']\n        instance = datapoint['instance']\n        description = datapoint['description']\n        k = resource, instance\n        if instance:\n            instance = '\/'.join(map(str, instance))\n        quantity = datapoint['quantity']\n        column_names.add(quantity)\n        value = datapoint['value']\n        unit = datapoint['unit']\n        if isinstance(value, int):\n            value = '{}{}'.format(value, unit)\n        else:\n            value = '{:.3f}{}'.format(value, unit)\n        datapoint = resources[k]\n        datapoint['resource'] = resource\n        datapoint['instance'] = instance or ''\n        datapoint['description'] = description or ''\n        datapoint[quantity] = value\n    resources = tuple(resources[k] for k in sorted(resources))\n    column_names = sorted(column_names)\n    column_names.insert(0, 'instance')\n    column_names.insert(0, 'resource')\n    column_names.append('description')\n    formats = []\n    columns = []\n    for name in column_names:\n        column = [name, '']\n        for resource in resources:\n            column.append(resource.get(name, ''))\n        column_width = max(map(len, column))\n        if name == column_names[-1]:\n            formats.append('   {{:<{}}}'.format(column_width))\n        else:\n            formats.append('   {{:>{}}}'.format(column_width))\n        columns.append(column)\n    line_format = ''.join(formats)\n    lines.extend(map(line_format.format, *columns))\n    return '\\n'.join(lines)\n\n\ndef main(\n        interval=10,\n        count=0,\n        output_format='ndjson',\n        converters=(),\n        cpu_usage=True,\n        cpu_freq=True,\n        power_caps=True,\n        hardware_sensors=True,\n):\n    first = True\n    sensors = Sensors()\n    formatter = globals().get('_format_{}'.format(output_format), _format_simple)\n    if count == 0:\n        count = -1\n\n    for datapoints in sensors.read(\n            cpu_usage=cpu_usage,\n            cpu_freq=cpu_freq,\n            power_caps=power_caps,\n            hardware_sensors=hardware_sensors,\n    ):\n        if first:\n            first = False\n            sleep(min(interval, 1))\n            last_timestamp = time()\n            next_timestamp = last_timestamp + interval\n            continue\n\n        for i in datapoints:\n            for j in converters:\n                if j(i):\n                    break\n\n        print(formatter(last_timestamp, datapoints), flush=True)\n\n        if count > 0:\n            count -= 1\n        if count == 0:\n            break\n\n        curr_timestamp = time()\n        pause = max(next_timestamp - curr_timestamp, 0.1)\n        sleep(pause)\n        next_timestamp += interval\n        last_timestamp = time()\n\n\nif __name__ == '__main__':\n    from argparse import ArgumentParser\n\n    parser = ArgumentParser(description='Power, temperature and usage monitor.')\n    parser.add_argument('--interval', metavar='SECONDS', type=float, default='10',\n                        help='The interval between updates. Default is 10 seconds.')\n    parser.add_argument('--count', metavar='N', type=int, default=0,\n                        help='Number of updates. When zero (which is default) repeat forever.')\n    parser.add_argument('--output-format', choices=['ndjson', 'csv', 'simple', 'table'], default='simple',\n                        help='Choice of the output format. Default is simple.')\n    parser.add_argument('--skip-cpu-usage', action='store_true', default=False,\n                        help='Skip CPU usage.')\n    parser.add_argument('--skip-cpu-freq', action='store_true', default=False,\n                        help='Skip CPU frequencies.')\n    parser.add_argument('--skip-power-usage', action='store_true', default=False,\n                        help='Skip power usage sensors.')\n    parser.add_argument('--skip-hardware-sensors', action='store_true', default=False,\n                        help='Skip available hardware sensors.')\n    parser.add_argument('--freq-unit', choices=['Hz', 'MHz', 'GHz'], default='GHz',\n                        help='Choice of frequency units. Default is GHz.')\n    parser.add_argument('--temp-unit', choices=['C', 'K', 'F'], default='C',\n                        help='Choice of temperature units. Default is C.')\n    parser.add_argument('--power-unit', choices=['mW', 'W', 'kW'], default='W',\n                        help='Choice of power units. Default is W.')\n    args = parser.parse_args()\n\n    converters = []\n    if args.freq_unit == 'MHz':\n        converters.append(_convert_frequency_to_mhz)\n    elif args.freq_unit == 'GHz':\n        converters.append(_convert_frequency_to_ghz)\n    if args.temp_unit == 'C':\n        converters.append(_convert_temperature_to_c)\n    elif args.temp_unit == 'F':\n        converters.append(_convert_temperature_to_f)\n    if args.power_unit == 'mW':\n        converters.append(_convert_power_to_mw)\n    elif args.freq_unit == 'kW':\n        converters.append(_convert_power_to_kw)\n\n    main(\n        interval=min(max(0.1, args.interval), 24 * 3600),\n        count=args.count,\n        output_format=args.output_format,\n        converters=converters,\n        cpu_usage=not args.skip_cpu_usage,\n        cpu_freq=not args.skip_cpu_freq,\n        power_caps=not args.skip_power_usage,\n        hardware_sensors=not args.skip_hardware_sensors,\n    )\n"}},"msg":"Properly handle overflow of CPU and RAPL counters. Improve I\/O caching."}}}