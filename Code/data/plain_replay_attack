{"https:\/\/github.com\/reviewboard\/reviewboard":{"d61d4aaec3199103efcfae9f7d16e53222834e8f":{"url":"https:\/\/api.github.com\/repos\/reviewboard\/reviewboard\/commits\/d61d4aaec3199103efcfae9f7d16e53222834e8f","html_url":"https:\/\/github.com\/reviewboard\/reviewboard\/commit\/d61d4aaec3199103efcfae9f7d16e53222834e8f","sha":"d61d4aaec3199103efcfae9f7d16e53222834e8f","keyword":"replay attack change","diff":"diff --git a\/reviewboard\/accounts\/sso\/backends\/saml\/views.py b\/reviewboard\/accounts\/sso\/backends\/saml\/views.py\nindex 64f3a88a8b..ff32385c05 100644\n--- a\/reviewboard\/accounts\/sso\/backends\/saml\/views.py\n+++ b\/reviewboard\/accounts\/sso\/backends\/saml\/views.py\n@@ -11,6 +11,7 @@\n from django.conf import settings\n from django.contrib.auth.models import User\n from django.contrib.auth.views import LoginView\n+from django.core.cache import cache\n from django.http import (Http404,\n                          HttpResponse,\n                          HttpResponseBadRequest,\n@@ -19,6 +20,7 @@\n from django.utils.decorators import method_decorator\n from django.views.decorators.csrf import csrf_protect\n from django.views.generic.base import View\n+from djblets.cache.backend import make_cache_key\n from djblets.db.query import get_object_or_none\n from djblets.siteconfig.models import SiteConfiguration\n from djblets.util.decorators import cached_property\n@@ -118,6 +120,34 @@ def get_saml_auth(self, request):\n \n         return self._saml_auth\n \n+    def is_replay_attack(self, message_id):\n+        \"\"\"Check for potential replay attacks.\n+\n+        SAML authentication is potentially vulnerable to a replay attack from a\n+        man in the middle. This is mitigated by keeping track of recent message\n+        IDs and rejecting the authentication attempt if we've seen them before.\n+\n+        Args:\n+            message_id (str):\n+                The ID to check.\n+\n+        Returns:\n+            bool:\n+            ``True`` if we've seen the response or assertion IDs before. False\n+            if this appears to be a valid request.\n+        \"\"\"\n+        if message_id is None:\n+            return False\n+\n+        cache_key = make_cache_key('saml_replay_id_%s' % message_id,\n+                                   use_encryption=True)\n+        is_replay = cache.get(cache_key) is not None\n+\n+        if not is_replay:\n+            cache.set(cache_key, True)\n+\n+        return is_replay\n+\n     def dispatch(self, *args, **kwargs):\n         \"\"\"Handle a dispatch for the view.\n \n@@ -210,8 +240,11 @@ def post(self, request, *args, **kwargs):\n             return HttpResponseBadRequest('Bad SSO response: %s' % str(e),\n                                           content_type='text\/plain')\n \n-        # TODO: store\/check last request ID, last message ID, last assertion ID\n-        # to prevent replay attacks.\n+        if (self.is_replay_attack(auth.get_last_message_id()) or\n+            self.is_replay_attack(auth.get_last_assertion_id())):\n+            logger.error('SAML: Detected replay attack', request=request)\n+            return HttpResponseBadRequest(\n+                'SAML message IDs have already been used')\n \n         error = auth.get_last_error_reason()\n \n@@ -579,7 +612,7 @@ class SAMLSLSView(SAMLViewMixin, BaseSSOView):\n     \"\"\"\n \n     def get(self, request, *args, **kwargs):\n-        \"\"\"Handle a POST request.\n+        \"\"\"Handle a GET request.\n \n         Args:\n             request (django.http.HttpRequest):\n@@ -605,12 +638,17 @@ def get(self, request, *args, **kwargs):\n             request_id=request_id,\n             delete_session_cb=lambda: request.session.flush())\n \n-        errors = auth.get_errors()\n+        if (self.is_replay_attack(auth.get_last_message_id()) or\n+            self.is_replay_attack(auth.get_last_request_id())):\n+            logger.error('SAML: Detected replay attack', request=request)\n+            return HttpResponseBadRequest(\n+                'SAML message IDs have already been used')\n \n-        if errors:\n-            error_text = ', '.join(errors)\n-            logger.error('SAML: Unable to process SLO request: %s', error_text)\n-            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,\n+        error = auth.get_last_error_reason()\n+\n+        if error:\n+            logger.error('SAML: Unable to process SLO request: %s', error)\n+            return HttpResponseBadRequest('Bad SLO response: %s' % error,\n                                           content_type='text\/plain')\n \n         if redirect_url:\ndiff --git a\/reviewboard\/accounts\/tests\/test_saml_views.py b\/reviewboard\/accounts\/tests\/test_saml_views.py\nindex c093b207f5..1a60b57a69 100644\n--- a\/reviewboard\/accounts\/tests\/test_saml_views.py\n+++ b\/reviewboard\/accounts\/tests\/test_saml_views.py\n@@ -2,10 +2,13 @@\n \n from xml.etree import ElementTree\n \n+import kgb\n from django.contrib.auth.models import User\n from django.urls import reverse\n \n-from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView\n+from reviewboard.accounts.sso.backends.saml.views import (SAMLACSView,\n+                                                          SAMLLinkUserView,\n+                                                          SAMLSLSView)\n from reviewboard.testing import TestCase\n \n \n@@ -26,7 +29,7 @@\n -----END CERTIFICATE-----\"\"\"\n \n \n-class SAMLViewTests(TestCase):\n+class SAMLViewTests(kgb.SpyAgency, TestCase):\n     \"\"\"Unit tests for SAML views.\"\"\"\n \n     fixtures = ['test_users']\n@@ -270,3 +273,91 @@ def test_post_link_user_provision(self):\n             linked_account = linked_accounts[0]\n             self.assertEqual(linked_account.service_id, 'sso:saml')\n             self.assertEqual(linked_account.service_user_id, 'sleepy')\n+\n+    def test_post_assertion_replay_countermeasures(self):\n+        \"\"\"Testing replay attack countermeasures with SAMLACSView POST\"\"\"\n+        class FakeAuth:\n+            def process_response(*args, **kwargs):\n+                pass\n+\n+            def get_last_message_id(self):\n+                return 'message-id'\n+\n+            def get_last_assertion_id(self):\n+                return 'assertion-id'\n+\n+            def get_last_error_reason(self):\n+                return None\n+\n+            def get_nameid(self):\n+                return 'username'\n+\n+            def get_attribute(self, attr):\n+                return ['a']\n+\n+            def get_attributes(self):\n+                return {}\n+\n+            def get_session_index(self):\n+                return 1\n+\n+        fake_auth = FakeAuth()\n+\n+        self.spy_on(SAMLACSView.get_saml_auth,\n+                    op=kgb.SpyOpReturn(fake_auth),\n+                    owner=SAMLACSView)\n+\n+        settings = {\n+            'saml_enabled': True,\n+        }\n+\n+        with self.siteconfig_settings(settings):\n+            url = reverse('sso:saml:acs', kwargs={'backend_id': 'saml'})\n+\n+            # First one should succeed and redirect us to the link user view.\n+            rsp = self.client.post(url, {})\n+            self.assertEqual(rsp.status_code, 302)\n+\n+            # Second one should fail.\n+            rsp = self.client.post(url, {})\n+            self.assertEqual(rsp.status_code, 400)\n+            self.assertEqual(rsp.content,\n+                             b'SAML message IDs have already been used')\n+\n+    def test_get_sls_replay_countermeasures(self):\n+        \"\"\"Testing replay attack countermeasures with SAMLSLSView GET\"\"\"\n+        class FakeAuth:\n+            def process_slo(*args, **kwargs):\n+                pass\n+\n+            def get_last_message_id(self):\n+                return 'message-id'\n+\n+            def get_last_request_id(self):\n+                return 'request-id'\n+\n+            def get_last_error_reason(self):\n+                return None\n+\n+        fake_auth = FakeAuth()\n+\n+        self.spy_on(SAMLSLSView.get_saml_auth,\n+                    op=kgb.SpyOpReturn(fake_auth),\n+                    owner=SAMLSLSView)\n+\n+        settings = {\n+            'saml_enabled': True,\n+        }\n+\n+        with self.siteconfig_settings(settings):\n+            url = reverse('sso:saml:sls', kwargs={'backend_id': 'saml'})\n+\n+            # First one should succeed and redirect us to the link user view.\n+            rsp = self.client.get(url, {})\n+            self.assertEqual(rsp.status_code, 302)\n+\n+            # Second one should fail.\n+            rsp = self.client.get(url, {})\n+            self.assertEqual(rsp.status_code, 400)\n+            self.assertEqual(rsp.content,\n+                             b'SAML message IDs have already been used')\n","message":"","files":{"\/reviewboard\/accounts\/sso\/backends\/saml\/views.py":{"changes":[{"diff":"\n     \"\"\"\n \n     def get(self, request, *args, **kwargs):\n-        \"\"\"Handle a POST request.\n+        \"\"\"Handle a GET request.\n \n         Args:\n             request (django.http.HttpRequest):\n","add":1,"remove":1,"filename":"\/reviewboard\/accounts\/sso\/backends\/saml\/views.py","badparts":["        \"\"\"Handle a POST request."],"goodparts":["        \"\"\"Handle a GET request."]},{"diff":"\n             request_id=request_id,\n             delete_session_cb=lambda: request.session.flush())\n \n-        errors = auth.get_errors()\n+        if (self.is_replay_attack(auth.get_last_message_id()) or\n+            self.is_replay_attack(auth.get_last_request_id())):\n+            logger.error('SAML: Detected replay attack', request=request)\n+            return HttpResponseBadRequest(\n+                'SAML message IDs have already been used')\n \n-        if errors:\n-            error_text = ', '.join(errors)\n-            logger.error('SAML: Unable to process SLO request: %s', error_text)\n-            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,\n+        error = auth.get_last_error_reason()\n+\n+        if error:\n+            logger.error('SAML: Unable to process SLO request: %s', error)\n+            return HttpResponseBadRequest('Bad SLO response: %s' % error,\n                                           content_type='text\/plain')\n \n         if redirect_url:","add":10,"remove":5,"filename":"\/reviewboard\/accounts\/sso\/backends\/saml\/views.py","badparts":["        errors = auth.get_errors()","        if errors:","            error_text = ', '.join(errors)","            logger.error('SAML: Unable to process SLO request: %s', error_text)","            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,"],"goodparts":["        if (self.is_replay_attack(auth.get_last_message_id()) or","            self.is_replay_attack(auth.get_last_request_id())):","            logger.error('SAML: Detected replay attack', request=request)","            return HttpResponseBadRequest(","                'SAML message IDs have already been used')","        error = auth.get_last_error_reason()","        if error:","            logger.error('SAML: Unable to process SLO request: %s', error)","            return HttpResponseBadRequest('Bad SLO response: %s' % error,"]}],"source":"\n\"\"\"Views for SAML SSO. Version Added: 5.0 \"\"\" from enum import Enum from urllib.parse import urlparse import logging from django.conf import settings from django.contrib.auth.models import User from django.contrib.auth.views import LoginView from django.http import(Http404, HttpResponse, HttpResponseBadRequest, HttpResponseRedirect, HttpResponseServerError) from django.utils.decorators import method_decorator from django.views.decorators.csrf import csrf_protect from django.views.generic.base import View from djblets.db.query import get_object_or_none from djblets.siteconfig.models import SiteConfiguration from djblets.util.decorators import cached_property try: from onelogin.saml2.auth import OneLogin_Saml2_Auth from onelogin.saml2.errors import OneLogin_Saml2_Error from onelogin.saml2.settings import OneLogin_Saml2_Settings from onelogin.saml2.utils import OneLogin_Saml2_Utils except ImportError: OneLogin_Saml2_Auth=None OneLogin_Saml2_Error=None OneLogin_Saml2_Settings=None OneLogin_Saml2_Utils=None from reviewboard.accounts.models import LinkedAccount from reviewboard.accounts.sso.backends.saml.forms import SAMLLinkUserForm from reviewboard.accounts.sso.backends.saml.settings import get_saml2_settings from reviewboard.accounts.sso.users import(find_suggested_username, find_user_for_sso_user_id) from reviewboard.accounts.sso.views import BaseSSOView from reviewboard.admin.server import get_server_url from reviewboard.site.urlresolvers import local_site_reverse logger=logging.getLogger(__file__) class SAMLViewMixin(View): \"\"\"Mixin to provide common functionality for SAML views. Version Added: 5.0 \"\"\" def __init__(self, *args, **kwargs): \"\"\"Initialize the view. Args: *args(tuple): Positional arguments to pass through to the base class. **kwargs(dict): Keyword arguments to pass through to the base class. \"\"\" super().__init__(*args, **kwargs) self._saml_auth=None self._saml_request=None def get_saml_request(self, request): \"\"\"Return the SAML request. Args: request(django.http.HttpRequest): The HTTP request from the client. Returns: dict: Information about the SAML request. \"\"\" if self._saml_request is None: server_url=urlparse(get_server_url()) if server_url.scheme=='https': https='on' else: https='off' self._saml_request={ 'https': https, 'http_host': server_url.hostname, 'get_data': request.GET.copy(), 'post_data': request.POST.copy(), 'query_string': request.META['QUERY_STRING'], 'request_uri': request.path, 'script_name': request.META['PATH_INFO'], 'server_port': server_url.port, } return self._saml_request def get_saml_auth(self, request): \"\"\"Return the SAML auth information. Args: request(django.http.HttpRequest): The HTTP request from the client. Returns: onelogin.saml2.auth.OneLogin_Saml2_Auth: The SAML Auth object. \"\"\" if self._saml_auth is None: assert OneLogin_Saml2_Auth is not None self._saml_auth=OneLogin_Saml2_Auth( self.get_saml_request(request), get_saml2_settings()) return self._saml_auth def dispatch(self, *args, **kwargs): \"\"\"Handle a dispatch for the view. Args: *args(tuple): Positional arguments to pass through to the parent class. **kwargs(dict): Keyword arguments to pass through to the parent class. Returns: django.http.HttpResponse: The response to send back to the client. Raises: django.http.Http404: The SAML backend is not enabled, so treat all SAML views as 404. \"\"\" if not self.sso_backend.is_enabled(): raise Http404 return super().dispatch(*args, **kwargs) class SAMLACSView(SAMLViewMixin, BaseSSOView): \"\"\"ACS view for SAML SSO. Version Added: 5.0 \"\"\" @property def success_url(self): \"\"\"The URL to redirect to after a successful login. Type: str \"\"\" url=self.request.POST.get('RelayState') assert OneLogin_Saml2_Utils is not None self_url=OneLogin_Saml2_Utils.get_self_url( self.get_saml_request(self.request)) if url is not None and self_url !=url: saml_auth=self.get_saml_auth(self.request) return saml_auth.redirect_to(url) else: return settings.LOGIN_REDIRECT_URL @cached_property def link_user_url(self): \"\"\"The URL to the link-user flow. Type: str \"\"\" assert self.sso_backend is not None return local_site_reverse( 'sso:%s:link-user' % self.sso_backend.backend_id, request=self.request, kwargs={'backend_id': self.sso_backend.backend_id}) def post(self, request, *args, **kwargs): \"\"\"Handle a POST request. Args: request(django.http.HttpRequest): The request from the client. *args(tuple): Additional positional arguments. **kwargs(dict): Additional keyword arguments. Returns: django.http.HttpResponse: The response to send back to the client. \"\"\" auth=self.get_saml_auth(request) session=request.session try: auth.process_response(request_id=session.get('AuthNRequestID')) except OneLogin_Saml2_Error as e: logger.exception('SAML: Unable to process SSO request: %s', e, exc_info=True) return HttpResponseBadRequest('Bad SSO response: %s' % str(e), content_type='text\/plain') error=auth.get_last_error_reason() if error: logger.error('SAML: Unable to process SSO request: %s', error) return HttpResponseBadRequest('Bad SSO response: %s' % error, content_type='text\/plain') session.pop('AuthNRequestID', None) linked_account=get_object_or_none(LinkedAccount, service_id='sso:saml', service_user_id=auth.get_nameid()) if linked_account: user=linked_account.user self.sso_backend.login_user(request, user) return HttpResponseRedirect(self.success_url) else: username=auth.get_nameid() try: email=self._get_user_attr_value(auth, 'User.email') first_name=self._get_user_attr_value(auth, 'User.FirstName') last_name=self._get_user_attr_value(auth, 'User.LastName') except KeyError as e: logger.error('SAML: Assertion is missing %s attribute', e) return HttpResponseBadRequest('Bad SSO response: assertion is ' 'missing %s attribute' % e, content_type='text\/plain') request.session['sso']={ 'user_data':{ 'id': username, 'first_name': first_name, 'last_name': last_name, 'email': email, }, 'raw_user_attrs': auth.get_attributes(), 'session_index': auth.get_session_index(), } return HttpResponseRedirect(self.link_user_url) def _get_user_attr_value(self, auth, key): \"\"\"Return the value of a user attribute. Args: auth(onelogin.saml2.auth.OneLogin_Saml2_Auth): The SAML authentication object. key(str): The key to look up. Returns: str: The attribute, if it exists. Raises: KeyError: The given key was not present in the SAML assertion. \"\"\" value=auth.get_attribute(key) if value and isinstance(value, list): return value[0] raise KeyError(key) @method_decorator(csrf_protect, name='dispatch') class SAMLLinkUserView(SAMLViewMixin, BaseSSOView, LoginView): \"\"\"Link user view for SAML SSO. This can have several behaviors depending on what combination of state we get from the Identity Provider and what we have stored in the database. The first major case is where we are given data that matches an existing user in the database. Ideally this is via the \"username\" field, but may also be a matching e-mail address, or parsing a username out of the e-mail address. In this case, there are two paths. The simple path is where the administrator trusts both the authority and integrity of their Identity Provider and has turned off the \"Require login to link\" setting. For this, we'll just create the LinkedAccount, authenticate the user, and redirect to the success URL. If the require login setting is turned on, the user will have a choice. They can enter the password for the detected user to complete the link. If they have an account but the detected one is not correct, they can log in with their username and password to link the other account. Finally, they can provision a new user if they do not yet have one. The second major case is where we cannot find an existing user. In this case, we'll offer the user a choice: if they have an existing login that wasn't found, they can log in with their(non-SSO) username and password. If they don't have an account, they will be able to provision one. Version Added: 5.0 \"\"\" form_class=SAMLLinkUserForm class Mode(Enum): CONNECT_EXISTING_ACCOUNT='connect' CONNECT_WITH_LOGIN='connect-login' PROVISION='provision' def dispatch(self, *args, **kwargs): \"\"\"Dispatch the view. Args: *args(tuple): Positional arguments to pass to the parent class. **kwargs(dict): Keyword arguments to pass to the parent class. \"\"\" self._sso_user_data=\\ self.request.session.get('sso',{}).get('user_data') self._sso_data_username=self._sso_user_data.get('id') self._sso_data_email=self._sso_user_data.get('email') computed_username=find_suggested_username(self._sso_data_email) self._provision_username=self._sso_data_username or computed_username self._sso_user=find_user_for_sso_user_id( self._sso_data_username, self._sso_data_email, computed_username) requested_mode=self.request.GET.get('mode') if requested_mode and requested_mode in self.Mode: self._mode=requested_mode elif self._sso_user: self._mode=self.Mode.CONNECT_EXISTING_ACCOUNT else: self._mode=self.Mode.PROVISION return super(SAMLLinkUserView, self).dispatch(*args, **kwargs) def get_template_names(self): \"\"\"Return the template to use when rendering. Returns: list: A single-item list with the template name to use when rendering. Raises: ValueError: The current mode is not valid. \"\"\" if self._mode==self.Mode.CONNECT_EXISTING_ACCOUNT: return['accounts\/sso\/link-user-connect-existing.html'] elif self._mode==self.Mode.CONNECT_WITH_LOGIN: return['accounts\/sso\/link-user-login.html'] elif self._mode==self.Mode.PROVISION: return['accounts\/sso\/link-user-provision.html'] else: raise ValueError('Unknown link-user mode \"%s\"' % self._mode) def get_initial(self): \"\"\"Return the initial data for the form. Returns: dict: Initial data for the form. \"\"\" initial=super(SAMLLinkUserView, self).get_initial() if self._sso_user is not None: initial['username']=self._sso_user.username else: initial['username']=self._provision_username initial['provision']=(self._mode==self.Mode.PROVISION) return initial def get_context_data(self, **kwargs): \"\"\"Return additional context data for rendering the template. Args: **kwargs(dict): Keyword arguments for the view. Returns: dict: Additional data to inject into the render context. \"\"\" context=super(SAMLLinkUserView, self).get_context_data(**kwargs) context['user']=self._sso_user context['mode']=self._mode context['username']=self._provision_username return context def get(self, request, *args, **kwargs): \"\"\"Handle a GET request for the form. Args: request(django.http.HttpRequest): The HTTP request from the client. *args(tuple): Positional arguments to pass through to the base class. **kwargs(dict): Keyword arguments to pass through to the base class. Returns: django.http.HttpResponse: The response to send back to the client. \"\"\" if not self._sso_user_data: return HttpResponseRedirect( local_site_reverse('login', request=request)) siteconfig=SiteConfiguration.objects.get_current() if self._sso_user and not siteconfig.get('saml_require_login_to_link'): return self.link_user(self._sso_user) return super(SAMLLinkUserView, self).get(request, *args, **kwargs) def form_valid(self, form): \"\"\"Handler for when the form has successfully authenticated. Args: form(reviewboard.accounts.sso.backends.saml.forms. SAMLLinkUserForm): The link-user form. Returns: django.http.HttpResponseRedirect: A redirect to the next page. \"\"\" if form.cleaned_data['provision']: assert not self._sso_user assert self._provision_username first_name=self._sso_user_data.get('first_name') last_name=self._sso_user_data.get('last_name') logger.info('SAML: Provisioning user \"%s\"(%s <%s %s>)', self._provision_username, self._sso_data_email, first_name, last_name) user=User.objects.create( username=self._provision_username, email=self._sso_data_email, first_name=first_name, last_name=last_name) else: user=form.get_user() return self.link_user(user) def link_user(self, user): \"\"\"Link the given user. Args: user(django.contrib.auth.models.User): The user to link. Returns: django.http.HttpResponseRedirect: A redirect to the success URL. \"\"\" sso_id=self._sso_user_data.get('id') logger.info('SAML: Linking SSO user \"%s\" to Review Board user \"%s\"', sso_id, user.username) user.linked_accounts.create( service_id='sso:saml', service_user_id=sso_id) self.sso_backend.login_user(self.request, user) return HttpResponseRedirect(self.get_success_url()) class SAMLLoginView(SAMLViewMixin, BaseSSOView): \"\"\"Login view for SAML SSO. Version Added: 5.0 \"\"\" def get(self, request, *args, **kwargs): \"\"\"Handle a GET request for the login URL. Args: request(django.http.HttpRequest): The request from the client. *args(tuple, unused): Additional positional arguments. **kwargs(dict, unused): Additional keyword arguments. Returns: django.http.HttpResponseRedirect: A redirect to start the login flow. \"\"\" auth=self.get_saml_auth(request) return HttpResponseRedirect( auth.login(settings.LOGIN_REDIRECT_URL)) class SAMLMetadataView(SAMLViewMixin, BaseSSOView): \"\"\"Metadata view for SAML SSO. Version Added: 5.0 \"\"\" def get(self, request, *args, **kwargs): \"\"\"Handle a GET request. Args: request(django.http.HttpRequest): The HTTP request from the client. *args(tuple): Positional arguments from the URL definition. **kwargs(dict): Keyword arguments from the URL definition. \"\"\" assert OneLogin_Saml2_Settings is not None saml_settings=OneLogin_Saml2_Settings( get_saml2_settings(), sp_validation_only=True) metadata=saml_settings.get_sp_metadata() errors=saml_settings.validate_metadata(metadata) if errors: logger.error('SAML: Got errors from metadata validation: %s', ', '.join(errors)) return HttpResponseServerError(', '.join(errors), content_type='text\/plain') return HttpResponse(metadata, content_type='text\/xml') class SAMLSLSView(SAMLViewMixin, BaseSSOView): \"\"\"SLS view for SAML SSO. Version Added: 5.0 \"\"\" def get(self, request, *args, **kwargs): \"\"\"Handle a POST request. Args: request(django.http.HttpRequest): The request from the client. *args(tuple): Additional positional arguments. **kwargs(dict): Additional keyword arguments. Returns: django.http.HttpResponse: The response to send back to the client. \"\"\" auth=self.get_saml_auth(request) request_id=None if 'LogoutRequestId' in request.session: request_id=request.session['LogoutRequestId'] redirect_url=auth.process_slo( request_id=request_id, delete_session_cb=lambda: request.session.flush()) errors=auth.get_errors() if errors: error_text=', '.join(errors) logger.error('SAML: Unable to process SLO request: %s', error_text) return HttpResponseBadRequest('Bad SLO response: %s' % error_text, content_type='text\/plain') if redirect_url: return HttpResponseRedirect(redirect_url) else: return HttpResponseRedirect(settings.LOGIN_URL) ","sourceWithComments":"\"\"\"Views for SAML SSO.\n\nVersion Added:\n    5.0\n\"\"\"\n\nfrom enum import Enum\nfrom urllib.parse import urlparse\nimport logging\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.views import LoginView\nfrom django.http import (Http404,\n                         HttpResponse,\n                         HttpResponseBadRequest,\n                         HttpResponseRedirect,\n                         HttpResponseServerError)\nfrom django.utils.decorators import method_decorator\nfrom django.views.decorators.csrf import csrf_protect\nfrom django.views.generic.base import View\nfrom djblets.db.query import get_object_or_none\nfrom djblets.siteconfig.models import SiteConfiguration\nfrom djblets.util.decorators import cached_property\ntry:\n    from onelogin.saml2.auth import OneLogin_Saml2_Auth\n    from onelogin.saml2.errors import OneLogin_Saml2_Error\n    from onelogin.saml2.settings import OneLogin_Saml2_Settings\n    from onelogin.saml2.utils import OneLogin_Saml2_Utils\nexcept ImportError:\n    OneLogin_Saml2_Auth = None\n    OneLogin_Saml2_Error = None\n    OneLogin_Saml2_Settings = None\n    OneLogin_Saml2_Utils = None\n\nfrom reviewboard.accounts.models import LinkedAccount\nfrom reviewboard.accounts.sso.backends.saml.forms import SAMLLinkUserForm\nfrom reviewboard.accounts.sso.backends.saml.settings import get_saml2_settings\nfrom reviewboard.accounts.sso.users import (find_suggested_username,\n                                            find_user_for_sso_user_id)\nfrom reviewboard.accounts.sso.views import BaseSSOView\nfrom reviewboard.admin.server import get_server_url\nfrom reviewboard.site.urlresolvers import local_site_reverse\n\n\nlogger = logging.getLogger(__file__)\n\n\nclass SAMLViewMixin(View):\n    \"\"\"Mixin to provide common functionality for SAML views.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize the view.\n\n        Args:\n            *args (tuple):\n                Positional arguments to pass through to the base class.\n\n            **kwargs (dict):\n                Keyword arguments to pass through to the base class.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self._saml_auth = None\n        self._saml_request = None\n\n    def get_saml_request(self, request):\n        \"\"\"Return the SAML request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n        Returns:\n            dict:\n            Information about the SAML request.\n        \"\"\"\n        if self._saml_request is None:\n            server_url = urlparse(get_server_url())\n\n            if server_url.scheme == 'https':\n                https = 'on'\n            else:\n                https = 'off'\n\n            self._saml_request = {\n                'https': https,\n                'http_host': server_url.hostname,\n                'get_data': request.GET.copy(),\n                'post_data': request.POST.copy(),\n                'query_string': request.META['QUERY_STRING'],\n                'request_uri': request.path,\n                'script_name': request.META['PATH_INFO'],\n                'server_port': server_url.port,\n            }\n\n        return self._saml_request\n\n    def get_saml_auth(self, request):\n        \"\"\"Return the SAML auth information.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n        Returns:\n            onelogin.saml2.auth.OneLogin_Saml2_Auth:\n            The SAML Auth object.\n        \"\"\"\n        if self._saml_auth is None:\n            assert OneLogin_Saml2_Auth is not None\n            self._saml_auth = OneLogin_Saml2_Auth(\n                self.get_saml_request(request),\n                get_saml2_settings())\n\n        return self._saml_auth\n\n    def dispatch(self, *args, **kwargs):\n        \"\"\"Handle a dispatch for the view.\n\n        Args:\n            *args (tuple):\n                Positional arguments to pass through to the parent class.\n\n            **kwargs (dict):\n                Keyword arguments to pass through to the parent class.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n\n        Raises:\n            django.http.Http404:\n                The SAML backend is not enabled, so treat all SAML views as\n                404.\n        \"\"\"\n        if not self.sso_backend.is_enabled():\n            raise Http404\n\n        return super().dispatch(*args, **kwargs)\n\n\nclass SAMLACSView(SAMLViewMixin, BaseSSOView):\n    \"\"\"ACS view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    @property\n    def success_url(self):\n        \"\"\"The URL to redirect to after a successful login.\n\n        Type:\n            str\n        \"\"\"\n        url = self.request.POST.get('RelayState')\n\n        assert OneLogin_Saml2_Utils is not None\n        self_url = OneLogin_Saml2_Utils.get_self_url(\n            self.get_saml_request(self.request))\n\n        if url is not None and self_url != url:\n            saml_auth = self.get_saml_auth(self.request)\n            return saml_auth.redirect_to(url)\n        else:\n            return settings.LOGIN_REDIRECT_URL\n\n    @cached_property\n    def link_user_url(self):\n        \"\"\"The URL to the link-user flow.\n\n        Type:\n            str\n        \"\"\"\n        assert self.sso_backend is not None\n        return local_site_reverse(\n            'sso:%s:link-user' % self.sso_backend.backend_id,\n            request=self.request,\n            kwargs={'backend_id': self.sso_backend.backend_id})\n\n    def post(self, request, *args, **kwargs):\n        \"\"\"Handle a POST request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The request from the client.\n\n            *args (tuple):\n                Additional positional arguments.\n\n            **kwargs (dict):\n                Additional keyword arguments.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n        \"\"\"\n        auth = self.get_saml_auth(request)\n        session = request.session\n\n        try:\n            auth.process_response(request_id=session.get('AuthNRequestID'))\n        except OneLogin_Saml2_Error as e:\n            logger.exception('SAML: Unable to process SSO request: %s', e,\n                             exc_info=True)\n            return HttpResponseBadRequest('Bad SSO response: %s' % str(e),\n                                          content_type='text\/plain')\n\n        # TODO: store\/check last request ID, last message ID, last assertion ID\n        # to prevent replay attacks.\n\n        error = auth.get_last_error_reason()\n\n        if error:\n            logger.error('SAML: Unable to process SSO request: %s', error)\n            return HttpResponseBadRequest('Bad SSO response: %s' % error,\n                                          content_type='text\/plain')\n\n        # Store some state on the session to identify where we are in the SAML\n        # workflow.\n        session.pop('AuthNRequestID', None)\n\n        linked_account = get_object_or_none(LinkedAccount,\n                                            service_id='sso:saml',\n                                            service_user_id=auth.get_nameid())\n\n        if linked_account:\n            user = linked_account.user\n            self.sso_backend.login_user(request, user)\n            return HttpResponseRedirect(self.success_url)\n        else:\n            username = auth.get_nameid()\n\n            try:\n                email = self._get_user_attr_value(auth, 'User.email')\n                first_name = self._get_user_attr_value(auth, 'User.FirstName')\n                last_name = self._get_user_attr_value(auth, 'User.LastName')\n            except KeyError as e:\n                logger.error('SAML: Assertion is missing %s attribute', e)\n                return HttpResponseBadRequest('Bad SSO response: assertion is '\n                                              'missing %s attribute'\n                                              % e,\n                                              content_type='text\/plain')\n\n            request.session['sso'] = {\n                'user_data': {\n                    'id': username,\n                    'first_name': first_name,\n                    'last_name': last_name,\n                    'email': email,\n                },\n                'raw_user_attrs': auth.get_attributes(),\n                'session_index': auth.get_session_index(),\n            }\n\n            return HttpResponseRedirect(self.link_user_url)\n\n    def _get_user_attr_value(self, auth, key):\n        \"\"\"Return the value of a user attribute.\n\n        Args:\n            auth (onelogin.saml2.auth.OneLogin_Saml2_Auth):\n                The SAML authentication object.\n\n            key (str):\n                The key to look up.\n\n        Returns:\n            str:\n            The attribute, if it exists.\n\n        Raises:\n            KeyError:\n                The given key was not present in the SAML assertion.\n        \"\"\"\n        value = auth.get_attribute(key)\n\n        if value and isinstance(value, list):\n            return value[0]\n\n        raise KeyError(key)\n\n\n@method_decorator(csrf_protect, name='dispatch')\nclass SAMLLinkUserView(SAMLViewMixin, BaseSSOView, LoginView):\n    \"\"\"Link user view for SAML SSO.\n\n    This can have several behaviors depending on what combination of state we\n    get from the Identity Provider and what we have stored in the database.\n\n    The first major case is where we are given data that matches an existing\n    user in the database. Ideally this is via the \"username\" field, but may\n    also be a matching e-mail address, or parsing a username out of the e-mail\n    address.\n\n    In this case, there are two paths. The simple path is where the\n    administrator trusts both the authority and integrity of their Identity\n    Provider and has turned off the \"Require login to link\" setting. For this,\n    we'll just create the LinkedAccount, authenticate the user, and redirect to\n    the success URL.\n\n    If the require login setting is turned on, the user will have a choice.\n    They can enter the password for the detected user to complete the link. If\n    they have an account but the detected one is not correct, they can log in\n    with their username and password to link the other account. Finally, they\n    can provision a new user if they do not yet have one.\n\n    The second major case is where we cannot find an existing user. In this\n    case, we'll offer the user a choice: if they have an existing login that\n    wasn't found, they can log in with their (non-SSO) username and password.\n    If they don't have an account, they will be able to provision one.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    # TODO: This has a lot of logic which will likely be applicable to other\n    # SSO backend implementations. When we add a new backend, this should be\n    # refactored to pull out most of the logic into a common base class, and\n    # just implement SAML-specific data here.\n\n    form_class = SAMLLinkUserForm\n\n    class Mode(Enum):\n        CONNECT_EXISTING_ACCOUNT = 'connect'\n        CONNECT_WITH_LOGIN = 'connect-login'\n        PROVISION = 'provision'\n\n    def dispatch(self, *args, **kwargs):\n        \"\"\"Dispatch the view.\n\n        Args:\n            *args (tuple):\n                Positional arguments to pass to the parent class.\n\n            **kwargs (dict):\n                Keyword arguments to pass to the parent class.\n        \"\"\"\n        self._sso_user_data = \\\n            self.request.session.get('sso', {}).get('user_data')\n        self._sso_data_username = self._sso_user_data.get('id')\n        self._sso_data_email = self._sso_user_data.get('email')\n        computed_username = find_suggested_username(self._sso_data_email)\n        self._provision_username = self._sso_data_username or computed_username\n        self._sso_user = find_user_for_sso_user_id(\n            self._sso_data_username,\n            self._sso_data_email,\n            computed_username)\n\n        requested_mode = self.request.GET.get('mode')\n\n        if requested_mode and requested_mode in self.Mode:\n            self._mode = requested_mode\n        elif self._sso_user:\n            self._mode = self.Mode.CONNECT_EXISTING_ACCOUNT\n        else:\n            self._mode = self.Mode.PROVISION\n\n        return super(SAMLLinkUserView, self).dispatch(*args, **kwargs)\n\n    def get_template_names(self):\n        \"\"\"Return the template to use when rendering.\n\n        Returns:\n            list:\n            A single-item list with the template name to use when rendering.\n\n        Raises:\n            ValueError:\n                The current mode is not valid.\n        \"\"\"\n        if self._mode == self.Mode.CONNECT_EXISTING_ACCOUNT:\n            return ['accounts\/sso\/link-user-connect-existing.html']\n        elif self._mode == self.Mode.CONNECT_WITH_LOGIN:\n            return ['accounts\/sso\/link-user-login.html']\n        elif self._mode == self.Mode.PROVISION:\n            return ['accounts\/sso\/link-user-provision.html']\n        else:\n            raise ValueError('Unknown link-user mode \"%s\"' % self._mode)\n\n    def get_initial(self):\n        \"\"\"Return the initial data for the form.\n\n        Returns:\n            dict:\n            Initial data for the form.\n        \"\"\"\n        initial = super(SAMLLinkUserView, self).get_initial()\n\n        if self._sso_user is not None:\n            initial['username'] = self._sso_user.username\n        else:\n            initial['username'] = self._provision_username\n\n        initial['provision'] = (self._mode == self.Mode.PROVISION)\n\n        return initial\n\n    def get_context_data(self, **kwargs):\n        \"\"\"Return additional context data for rendering the template.\n\n        Args:\n            **kwargs (dict):\n                Keyword arguments for the view.\n\n        Returns:\n            dict:\n            Additional data to inject into the render context.\n        \"\"\"\n        context = super(SAMLLinkUserView, self).get_context_data(**kwargs)\n        context['user'] = self._sso_user\n        context['mode'] = self._mode\n        context['username'] = self._provision_username\n\n        return context\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a GET request for the form.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n            *args (tuple):\n                Positional arguments to pass through to the base class.\n\n            **kwargs (dict):\n                Keyword arguments to pass through to the base class.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n        \"\"\"\n        if not self._sso_user_data:\n            return HttpResponseRedirect(\n                local_site_reverse('login', request=request))\n\n        siteconfig = SiteConfiguration.objects.get_current()\n\n        if self._sso_user and not siteconfig.get('saml_require_login_to_link'):\n            return self.link_user(self._sso_user)\n\n        return super(SAMLLinkUserView, self).get(request, *args, **kwargs)\n\n    def form_valid(self, form):\n        \"\"\"Handler for when the form has successfully authenticated.\n\n        Args:\n            form (reviewboard.accounts.sso.backends.saml.forms.\n                  SAMLLinkUserForm):\n                The link-user form.\n\n        Returns:\n            django.http.HttpResponseRedirect:\n            A redirect to the next page.\n        \"\"\"\n        if form.cleaned_data['provision']:\n            # We can't provision if there's an existing matching user.\n            # TODO: show an error?\n            assert not self._sso_user\n            assert self._provision_username\n\n            first_name = self._sso_user_data.get('first_name')\n            last_name = self._sso_user_data.get('last_name')\n\n            logger.info('SAML: Provisioning user \"%s\" (%s <%s %s>)',\n                        self._provision_username, self._sso_data_email,\n                        first_name, last_name)\n\n            user = User.objects.create(\n                username=self._provision_username,\n                email=self._sso_data_email,\n                first_name=first_name,\n                last_name=last_name)\n        else:\n            user = form.get_user()\n\n        return self.link_user(user)\n\n    def link_user(self, user):\n        \"\"\"Link the given user.\n\n        Args:\n            user (django.contrib.auth.models.User):\n                The user to link.\n\n        Returns:\n            django.http.HttpResponseRedirect:\n            A redirect to the success URL.\n        \"\"\"\n        sso_id = self._sso_user_data.get('id')\n\n        logger.info('SAML: Linking SSO user \"%s\" to Review Board user \"%s\"',\n                    sso_id, user.username)\n\n        user.linked_accounts.create(\n            service_id='sso:saml',\n            service_user_id=sso_id)\n        self.sso_backend.login_user(self.request, user)\n        return HttpResponseRedirect(self.get_success_url())\n\n\nclass SAMLLoginView(SAMLViewMixin, BaseSSOView):\n    \"\"\"Login view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a GET request for the login URL.\n\n        Args:\n            request (django.http.HttpRequest):\n                The request from the client.\n\n            *args (tuple, unused):\n                Additional positional arguments.\n\n            **kwargs (dict, unused):\n                Additional keyword arguments.\n\n        Returns:\n            django.http.HttpResponseRedirect:\n            A redirect to start the login flow.\n        \"\"\"\n        auth = self.get_saml_auth(request)\n\n        return HttpResponseRedirect(\n            auth.login(settings.LOGIN_REDIRECT_URL))\n\n\nclass SAMLMetadataView(SAMLViewMixin, BaseSSOView):\n    \"\"\"Metadata view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a GET request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n            *args (tuple):\n                Positional arguments from the URL definition.\n\n            **kwargs (dict):\n                Keyword arguments from the URL definition.\n        \"\"\"\n        assert OneLogin_Saml2_Settings is not None\n        saml_settings = OneLogin_Saml2_Settings(\n            get_saml2_settings(),\n            sp_validation_only=True)\n\n        metadata = saml_settings.get_sp_metadata()\n        errors = saml_settings.validate_metadata(metadata)\n\n        if errors:\n            logger.error('SAML: Got errors from metadata validation: %s',\n                         ', '.join(errors))\n            return HttpResponseServerError(', '.join(errors),\n                                           content_type='text\/plain')\n\n        return HttpResponse(metadata, content_type='text\/xml')\n\n\nclass SAMLSLSView(SAMLViewMixin, BaseSSOView):\n    \"\"\"SLS view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a POST request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The request from the client.\n\n            *args (tuple):\n                Additional positional arguments.\n\n            **kwargs (dict):\n                Additional keyword arguments.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n        \"\"\"\n        auth = self.get_saml_auth(request)\n        request_id = None\n\n        if 'LogoutRequestId' in request.session:\n            request_id = request.session['LogoutRequestId']\n\n        redirect_url = auth.process_slo(\n            request_id=request_id,\n            delete_session_cb=lambda: request.session.flush())\n\n        errors = auth.get_errors()\n\n        if errors:\n            error_text = ', '.join(errors)\n            logger.error('SAML: Unable to process SLO request: %s', error_text)\n            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,\n                                          content_type='text\/plain')\n\n        if redirect_url:\n            return HttpResponseRedirect(redirect_url)\n        else:\n            return HttpResponseRedirect(settings.LOGIN_URL)\n"},"\/reviewboard\/accounts\/tests\/test_saml_views.py":{"changes":[{"diff":"\n \n from xml.etree import ElementTree\n \n+import kgb\n from django.contrib.auth.models import User\n from django.urls import reverse\n \n-from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView\n+from reviewboard.accounts.sso.backends.saml.views import (SAMLACSView,\n+                                                          SAMLLinkUserView,\n+                                                          SAMLSLSView)\n from reviewboard.testing import TestCase\n \n \n","add":4,"remove":1,"filename":"\/reviewboard\/accounts\/tests\/test_saml_views.py","badparts":["from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView"],"goodparts":["import kgb","from reviewboard.accounts.sso.backends.saml.views import (SAMLACSView,","                                                          SAMLLinkUserView,","                                                          SAMLSLSView)"]},{"diff":"\n \n \n-class SAMLViewTests(TestCase):\n+class SAMLViewTests(kgb.SpyAgency, TestCase):\n     \"\"\"Unit tests for SAML views.\"\"\"\n \n     fixtures = ['test_users']\n","add":1,"remove":1,"filename":"\/reviewboard\/accounts\/tests\/test_saml_views.py","badparts":["class SAMLViewTests(TestCase):"],"goodparts":["class SAMLViewTests(kgb.SpyAgency, TestCase):"]}],"source":"\n\"\"\"Unit tests for SAML views.\"\"\" from xml.etree import ElementTree from django.contrib.auth.models import User from django.urls import reverse from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView from reviewboard.testing import TestCase VALID_CERT=\"\"\"-----BEGIN CERTIFICATE----- MIICZjCCAc+gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBQMQswCQYDVQQGEwJ1czEL MAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcsIEluYy4xHDAaBgNVBAMME2h0 dHBzOi8vZXhhbXBsZS5jb20wHhcNMjIwNTA2MTU0NjI1WhcNMjMwNTA2MTU0NjI1 WjBQMQswCQYDVQQGEwJ1czELMAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcs IEluYy4xHDAaBgNVBAMME2h0dHBzOi8vZXhhbXBsZS5jb20wgZ8wDQYJKoZIhvcN AQEBBQADgY0AMIGJAoGBANCsbj4mvUiQERBy80R7yqA6hU3FMM4siC2UcUS3ltFF grkVOAPr+zUnrdadmAiTH35AB94oMzf0Qh8OJCr7wG5JQm686TRkVm2xUxhJUcoq 7LjBTKeEXBcrEzdNlagFXxHUSz5bPSdwDt\/zbOfe+9RZKeb4FggFCEYw\/mi69+Dx AgMBAAGjUDBOMB0GA1UdDgQWBBS4cP9Y+IM7ZHZChUDdx68QExTZUDAfBgNVHSME GDAWgBS4cP9Y+IM7ZHZChUDdx68QExTZUDAMBgNVHRMEBTADAQH\/MA0GCSqGSIb3 DQEBDQUAA4GBALht5\/NfJU+GxYfQKiGkZ4Ih\/T\/48rzXAT7\/7f61s7w72UR2S5e2 WsR7\/JPkZ5+u5mCgmABjNcd9NzaBM2RfSrrurwbjXMQ8nb\/+REvhXXJ4STsS48y5 bef2JtIf7mGDw8\/KsUrAA2jEIpCedToGyQxyE6GdN5b69ITWvyAemnIM -----END CERTIFICATE-----\"\"\" class SAMLViewTests(TestCase): \"\"\"Unit tests for SAML views.\"\"\" fixtures=['test_users'] def test_metadata_view(self): \"\"\"Testing SAMLMetadataView\"\"\" settings={ 'saml_enabled': True, 'saml_verification_cert': VALID_CERT, } with self.siteconfig_settings(settings): url=reverse('sso:saml:metadata', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) root=ElementTree.fromstring(rsp.content) namespaces={'md': 'urn:oasis:names:tc:SAML:2.0:metadata'} descriptor=root.find('md:SPSSODescriptor', namespaces) assert descriptor is not None sls=descriptor.find('md:SingleLogoutService', namespaces) assert sls is not None self.assertEqual( sls.get('Binding'), 'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect') self.assertEqual( sls.get('Location'), 'http:\/\/example.com\/account\/sso\/saml\/sls\/') acs=descriptor.find('md:AssertionConsumerService', namespaces) assert acs is not None self.assertEqual( acs.get('Binding'), 'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST') self.assertEqual( acs.get('Location'), 'http:\/\/example.com\/account\/sso\/saml\/acs\/') def test_get_link_user_existing_account(self): \"\"\"Testing SAMLLinkUserView form render with existing account\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.com', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'].username, 'doc') self.assertEqual(context['mode'], SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT) def test_get_link_user_existing_account_email_match(self): \"\"\"Testing SAMLLinkUserView form render with existing account matching email address \"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.com', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'].username, 'doc') self.assertEqual(context['mode'], SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT) def test_get_link_user_existing_account_email_username_match(self): \"\"\"Testing SAMLLinkUserView form render with existing account matching username from email address \"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.org', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'].username, 'doc') self.assertEqual(context['mode'], SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT) def test_get_link_user_no_match(self): \"\"\"Testing SAMLLinkUserView form render with no match\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc2@example.org', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'], None) self.assertEqual(context['mode'], SAMLLinkUserView.Mode.PROVISION) def test_post_link_user_login(self): \"\"\"Testing SAMLLinkUserView form POST with login\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.com', }, } session.save() user=User.objects.get(username='doc') self.assertFalse(user.linked_accounts.exists()) url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.post(url,{ 'username': 'doc', 'password': 'doc', 'provision': False, }) self.assertEqual(rsp.status_code, 302) linked_accounts=list(user.linked_accounts.all()) self.assertEqual(len(linked_accounts), 1) linked_account=linked_accounts[0] self.assertEqual(linked_account.service_id, 'sso:saml') self.assertEqual(linked_account.service_user_id, 'doc2') def test_post_link_user_provision(self): \"\"\"Testing SAMLLinkUserView form POST with provision\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'sleepy', 'first_name': 'Sleepy', 'last_name': 'Dwarf', 'email': 'sleepy@example.com', }, } session.save() self.assertFalse(User.objects.filter(username='sleepy').exists()) url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.post(url,{ 'username': '', 'password': '', 'provision': True, }) self.assertEqual(rsp.status_code, 302) user=User.objects.get(username='sleepy') self.assertEqual(user.first_name, 'Sleepy') self.assertEqual(user.last_name, 'Dwarf') self.assertEqual(user.email, 'sleepy@example.com') linked_accounts=list(user.linked_accounts.all()) self.assertEqual(len(linked_accounts), 1) linked_account=linked_accounts[0] self.assertEqual(linked_account.service_id, 'sso:saml') self.assertEqual(linked_account.service_user_id, 'sleepy') ","sourceWithComments":"\"\"\"Unit tests for SAML views.\"\"\"\n\nfrom xml.etree import ElementTree\n\nfrom django.contrib.auth.models import User\nfrom django.urls import reverse\n\nfrom reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView\nfrom reviewboard.testing import TestCase\n\n\nVALID_CERT = \"\"\"-----BEGIN CERTIFICATE-----\nMIICZjCCAc+gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBQMQswCQYDVQQGEwJ1czEL\nMAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcsIEluYy4xHDAaBgNVBAMME2h0\ndHBzOi8vZXhhbXBsZS5jb20wHhcNMjIwNTA2MTU0NjI1WhcNMjMwNTA2MTU0NjI1\nWjBQMQswCQYDVQQGEwJ1czELMAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcs\nIEluYy4xHDAaBgNVBAMME2h0dHBzOi8vZXhhbXBsZS5jb20wgZ8wDQYJKoZIhvcN\nAQEBBQADgY0AMIGJAoGBANCsbj4mvUiQERBy80R7yqA6hU3FMM4siC2UcUS3ltFF\ngrkVOAPr+zUnrdadmAiTH35AB94oMzf0Qh8OJCr7wG5JQm686TRkVm2xUxhJUcoq\n7LjBTKeEXBcrEzdNlagFXxHUSz5bPSdwDt\/zbOfe+9RZKeb4FggFCEYw\/mi69+Dx\nAgMBAAGjUDBOMB0GA1UdDgQWBBS4cP9Y+IM7ZHZChUDdx68QExTZUDAfBgNVHSME\nGDAWgBS4cP9Y+IM7ZHZChUDdx68QExTZUDAMBgNVHRMEBTADAQH\/MA0GCSqGSIb3\nDQEBDQUAA4GBALht5\/NfJU+GxYfQKiGkZ4Ih\/T\/48rzXAT7\/7f61s7w72UR2S5e2\nWsR7\/JPkZ5+u5mCgmABjNcd9NzaBM2RfSrrurwbjXMQ8nb\/+REvhXXJ4STsS48y5\nbef2JtIf7mGDw8\/KsUrAA2jEIpCedToGyQxyE6GdN5b69ITWvyAemnIM\n-----END CERTIFICATE-----\"\"\"\n\n\nclass SAMLViewTests(TestCase):\n    \"\"\"Unit tests for SAML views.\"\"\"\n\n    fixtures = ['test_users']\n\n    def test_metadata_view(self):\n        \"\"\"Testing SAMLMetadataView\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_verification_cert': VALID_CERT,\n        }\n\n        with self.siteconfig_settings(settings):\n            url = reverse('sso:saml:metadata', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            root = ElementTree.fromstring(rsp.content)\n\n            namespaces = {'md': 'urn:oasis:names:tc:SAML:2.0:metadata'}\n\n            descriptor = root.find('md:SPSSODescriptor', namespaces)\n            assert descriptor is not None\n\n            sls = descriptor.find('md:SingleLogoutService', namespaces)\n            assert sls is not None\n\n            self.assertEqual(\n                sls.get('Binding'),\n                'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect')\n            self.assertEqual(\n                sls.get('Location'),\n                'http:\/\/example.com\/account\/sso\/saml\/sls\/')\n\n            acs = descriptor.find('md:AssertionConsumerService', namespaces)\n            assert acs is not None\n\n            self.assertEqual(\n                acs.get('Binding'),\n                'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST')\n            self.assertEqual(\n                acs.get('Location'),\n                'http:\/\/example.com\/account\/sso\/saml\/acs\/')\n\n    def test_get_link_user_existing_account(self):\n        \"\"\"Testing SAMLLinkUserView form render with existing account\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.com',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'].username, 'doc')\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT)\n\n    def test_get_link_user_existing_account_email_match(self):\n        \"\"\"Testing SAMLLinkUserView form render with existing account matching\n        email address\n        \"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.com',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'].username, 'doc')\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT)\n\n    def test_get_link_user_existing_account_email_username_match(self):\n        \"\"\"Testing SAMLLinkUserView form render with existing account matching\n        username from email address\n        \"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.org',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'].username, 'doc')\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT)\n\n    def test_get_link_user_no_match(self):\n        \"\"\"Testing SAMLLinkUserView form render with no match\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc2@example.org',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'], None)\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.PROVISION)\n\n    def test_post_link_user_login(self):\n        \"\"\"Testing SAMLLinkUserView form POST with login\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.com',\n                },\n            }\n            session.save()\n\n            user = User.objects.get(username='doc')\n            self.assertFalse(user.linked_accounts.exists())\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.post(url, {\n                'username': 'doc',\n                'password': 'doc',\n                'provision': False,\n            })\n\n            self.assertEqual(rsp.status_code, 302)\n\n            linked_accounts = list(user.linked_accounts.all())\n\n            self.assertEqual(len(linked_accounts), 1)\n            linked_account = linked_accounts[0]\n            self.assertEqual(linked_account.service_id, 'sso:saml')\n            self.assertEqual(linked_account.service_user_id, 'doc2')\n\n    def test_post_link_user_provision(self):\n        \"\"\"Testing SAMLLinkUserView form POST with provision\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'sleepy',\n                    'first_name': 'Sleepy',\n                    'last_name': 'Dwarf',\n                    'email': 'sleepy@example.com',\n                },\n            }\n            session.save()\n\n            self.assertFalse(User.objects.filter(username='sleepy').exists())\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.post(url, {\n                'username': '',\n                'password': '',\n                'provision': True,\n            })\n\n            self.assertEqual(rsp.status_code, 302)\n\n            user = User.objects.get(username='sleepy')\n            self.assertEqual(user.first_name, 'Sleepy')\n            self.assertEqual(user.last_name, 'Dwarf')\n            self.assertEqual(user.email, 'sleepy@example.com')\n\n            linked_accounts = list(user.linked_accounts.all())\n\n            self.assertEqual(len(linked_accounts), 1)\n            linked_account = linked_accounts[0]\n            self.assertEqual(linked_account.service_id, 'sso:saml')\n            self.assertEqual(linked_account.service_user_id, 'sleepy')\n"}},"msg":"Implement replay attack mitigation for SAML auth.\n\nSAML is generally quite secure by design, but if there's a man in the\nmiddle, it is susceptible to replay attacks (within a short limited time\nframe). The way this is mitigated is by giving every message and\nassertion a unique ID. The service provider can then store these IDs and\nmake sure that they haven't already been used.\n\nThis change implements that. The used IDs are kept in the cache, and\nchecked before we proceed. While using the cache for this isn't 100%\nreliable, given the very short message lifetime, it's good enough for\nour purposes.\n\nTesting Done:\n- Ran unit tests.\n- Verified that I could still log in with SAML.\n- Crafted a replay and saw that it was successfully blocked."},"65840ccebc4b460778406c76fe5a8c0b9cfa9608":{"url":"https:\/\/api.github.com\/repos\/reviewboard\/reviewboard\/commits\/65840ccebc4b460778406c76fe5a8c0b9cfa9608","html_url":"https:\/\/github.com\/reviewboard\/reviewboard\/commit\/65840ccebc4b460778406c76fe5a8c0b9cfa9608","sha":"65840ccebc4b460778406c76fe5a8c0b9cfa9608","keyword":"replay attack change","diff":"diff --git a\/reviewboard\/accounts\/sso\/backends\/saml\/views.py b\/reviewboard\/accounts\/sso\/backends\/saml\/views.py\nindex 64f3a88a8b..159c409cc5 100644\n--- a\/reviewboard\/accounts\/sso\/backends\/saml\/views.py\n+++ b\/reviewboard\/accounts\/sso\/backends\/saml\/views.py\n@@ -11,6 +11,7 @@\n from django.conf import settings\n from django.contrib.auth.models import User\n from django.contrib.auth.views import LoginView\n+from django.core.cache import cache\n from django.http import (Http404,\n                          HttpResponse,\n                          HttpResponseBadRequest,\n@@ -19,6 +20,7 @@\n from django.utils.decorators import method_decorator\n from django.views.decorators.csrf import csrf_protect\n from django.views.generic.base import View\n+from djblets.cache.backend import make_cache_key\n from djblets.db.query import get_object_or_none\n from djblets.siteconfig.models import SiteConfiguration\n from djblets.util.decorators import cached_property\n@@ -118,6 +120,34 @@ def get_saml_auth(self, request):\n \n         return self._saml_auth\n \n+    def is_replay_attack(self, message_id):\n+        \"\"\"Check for potential replay attacks.\n+\n+        SAML authentication is potentially vulnerable to a replay attack from a\n+        man in the middle. This is mitigated by keeping track of recent message\n+        IDs and rejecting the authentication attempt if we've seen them before.\n+\n+        Args:\n+            message_id (str):\n+                The ID to check.\n+\n+        Returns:\n+            bool:\n+            ``True`` if we've seen the response or assertion IDs before.\n+            ``False`` if this appears to be a valid request.\n+        \"\"\"\n+        if message_id is None:\n+            return False\n+\n+        cache_key = make_cache_key('saml_replay_id_%s' % message_id,\n+                                   use_encryption=True)\n+        is_replay = cache.get(cache_key) is not None\n+\n+        if not is_replay:\n+            cache.set(cache_key, True)\n+\n+        return is_replay\n+\n     def dispatch(self, *args, **kwargs):\n         \"\"\"Handle a dispatch for the view.\n \n@@ -210,8 +240,11 @@ def post(self, request, *args, **kwargs):\n             return HttpResponseBadRequest('Bad SSO response: %s' % str(e),\n                                           content_type='text\/plain')\n \n-        # TODO: store\/check last request ID, last message ID, last assertion ID\n-        # to prevent replay attacks.\n+        if (self.is_replay_attack(auth.get_last_message_id()) or\n+            self.is_replay_attack(auth.get_last_assertion_id())):\n+            logger.error('SAML: Detected replay attack', request=request)\n+            return HttpResponseBadRequest(\n+                'SAML message IDs have already been used')\n \n         error = auth.get_last_error_reason()\n \n@@ -579,7 +612,7 @@ class SAMLSLSView(SAMLViewMixin, BaseSSOView):\n     \"\"\"\n \n     def get(self, request, *args, **kwargs):\n-        \"\"\"Handle a POST request.\n+        \"\"\"Handle a GET request.\n \n         Args:\n             request (django.http.HttpRequest):\n@@ -605,12 +638,17 @@ def get(self, request, *args, **kwargs):\n             request_id=request_id,\n             delete_session_cb=lambda: request.session.flush())\n \n-        errors = auth.get_errors()\n+        if (self.is_replay_attack(auth.get_last_message_id()) or\n+            self.is_replay_attack(auth.get_last_request_id())):\n+            logger.error('SAML: Detected replay attack', request=request)\n+            return HttpResponseBadRequest(\n+                'SAML message IDs have already been used')\n \n-        if errors:\n-            error_text = ', '.join(errors)\n-            logger.error('SAML: Unable to process SLO request: %s', error_text)\n-            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,\n+        error = auth.get_last_error_reason()\n+\n+        if error:\n+            logger.error('SAML: Unable to process SLO request: %s', error)\n+            return HttpResponseBadRequest('Bad SLO response: %s' % error,\n                                           content_type='text\/plain')\n \n         if redirect_url:\ndiff --git a\/reviewboard\/accounts\/tests\/test_saml_views.py b\/reviewboard\/accounts\/tests\/test_saml_views.py\nindex c093b207f5..bda69fe70e 100644\n--- a\/reviewboard\/accounts\/tests\/test_saml_views.py\n+++ b\/reviewboard\/accounts\/tests\/test_saml_views.py\n@@ -2,10 +2,13 @@\n \n from xml.etree import ElementTree\n \n+import kgb\n from django.contrib.auth.models import User\n from django.urls import reverse\n \n-from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView\n+from reviewboard.accounts.sso.backends.saml.views import (SAMLACSView,\n+                                                          SAMLLinkUserView,\n+                                                          SAMLSLSView)\n from reviewboard.testing import TestCase\n \n \n@@ -26,7 +29,7 @@\n -----END CERTIFICATE-----\"\"\"\n \n \n-class SAMLViewTests(TestCase):\n+class SAMLViewTests(kgb.SpyAgency, TestCase):\n     \"\"\"Unit tests for SAML views.\"\"\"\n \n     fixtures = ['test_users']\n@@ -270,3 +273,91 @@ def test_post_link_user_provision(self):\n             linked_account = linked_accounts[0]\n             self.assertEqual(linked_account.service_id, 'sso:saml')\n             self.assertEqual(linked_account.service_user_id, 'sleepy')\n+\n+    def test_post_assertion_replay_countermeasures(self):\n+        \"\"\"Testing SAMLACSView POST replay attack countermeasures\"\"\"\n+        class FakeAuth:\n+            def process_response(*args, **kwargs):\n+                pass\n+\n+            def get_last_message_id(self):\n+                return 'message-id'\n+\n+            def get_last_assertion_id(self):\n+                return 'assertion-id'\n+\n+            def get_last_error_reason(self):\n+                return None\n+\n+            def get_nameid(self):\n+                return 'username'\n+\n+            def get_attribute(self, attr):\n+                return ['a']\n+\n+            def get_attributes(self):\n+                return {}\n+\n+            def get_session_index(self):\n+                return 1\n+\n+        fake_auth = FakeAuth()\n+\n+        self.spy_on(SAMLACSView.get_saml_auth,\n+                    op=kgb.SpyOpReturn(fake_auth),\n+                    owner=SAMLACSView)\n+\n+        settings = {\n+            'saml_enabled': True,\n+        }\n+\n+        with self.siteconfig_settings(settings):\n+            url = reverse('sso:saml:acs', kwargs={'backend_id': 'saml'})\n+\n+            # First one should succeed and redirect us to the link user view.\n+            rsp = self.client.post(url, {})\n+            self.assertEqual(rsp.status_code, 302)\n+\n+            # Second one should fail.\n+            rsp = self.client.post(url, {})\n+            self.assertEqual(rsp.status_code, 400)\n+            self.assertEqual(rsp.content,\n+                             b'SAML message IDs have already been used')\n+\n+    def test_get_sls_replay_countermeasures(self):\n+        \"\"\"Testing SAMLSLSView GET replay attack countermeasures\"\"\"\n+        class FakeAuth:\n+            def process_slo(*args, **kwargs):\n+                pass\n+\n+            def get_last_message_id(self):\n+                return 'message-id'\n+\n+            def get_last_request_id(self):\n+                return 'request-id'\n+\n+            def get_last_error_reason(self):\n+                return None\n+\n+        fake_auth = FakeAuth()\n+\n+        self.spy_on(SAMLSLSView.get_saml_auth,\n+                    op=kgb.SpyOpReturn(fake_auth),\n+                    owner=SAMLSLSView)\n+\n+        settings = {\n+            'saml_enabled': True,\n+        }\n+\n+        with self.siteconfig_settings(settings):\n+            url = reverse('sso:saml:sls', kwargs={'backend_id': 'saml'})\n+\n+            # First one should succeed and redirect us to the link user view.\n+            rsp = self.client.get(url, {})\n+            self.assertEqual(rsp.status_code, 302)\n+\n+            # Second one should fail.\n+            rsp = self.client.get(url, {})\n+            self.assertEqual(rsp.status_code, 400)\n+            self.assertEqual(rsp.content,\n+                             b'SAML message IDs have already been used')\n","message":"","files":{"\/reviewboard\/accounts\/sso\/backends\/saml\/views.py":{"changes":[{"diff":"\n     \"\"\"\n \n     def get(self, request, *args, **kwargs):\n-        \"\"\"Handle a POST request.\n+        \"\"\"Handle a GET request.\n \n         Args:\n             request (django.http.HttpRequest):\n","add":1,"remove":1,"filename":"\/reviewboard\/accounts\/sso\/backends\/saml\/views.py","badparts":["        \"\"\"Handle a POST request."],"goodparts":["        \"\"\"Handle a GET request."]},{"diff":"\n             request_id=request_id,\n             delete_session_cb=lambda: request.session.flush())\n \n-        errors = auth.get_errors()\n+        if (self.is_replay_attack(auth.get_last_message_id()) or\n+            self.is_replay_attack(auth.get_last_request_id())):\n+            logger.error('SAML: Detected replay attack', request=request)\n+            return HttpResponseBadRequest(\n+                'SAML message IDs have already been used')\n \n-        if errors:\n-            error_text = ', '.join(errors)\n-            logger.error('SAML: Unable to process SLO request: %s', error_text)\n-            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,\n+        error = auth.get_last_error_reason()\n+\n+        if error:\n+            logger.error('SAML: Unable to process SLO request: %s', error)\n+            return HttpResponseBadRequest('Bad SLO response: %s' % error,\n                                           content_type='text\/plain')\n \n         if redirect_url:","add":10,"remove":5,"filename":"\/reviewboard\/accounts\/sso\/backends\/saml\/views.py","badparts":["        errors = auth.get_errors()","        if errors:","            error_text = ', '.join(errors)","            logger.error('SAML: Unable to process SLO request: %s', error_text)","            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,"],"goodparts":["        if (self.is_replay_attack(auth.get_last_message_id()) or","            self.is_replay_attack(auth.get_last_request_id())):","            logger.error('SAML: Detected replay attack', request=request)","            return HttpResponseBadRequest(","                'SAML message IDs have already been used')","        error = auth.get_last_error_reason()","        if error:","            logger.error('SAML: Unable to process SLO request: %s', error)","            return HttpResponseBadRequest('Bad SLO response: %s' % error,"]}],"source":"\n\"\"\"Views for SAML SSO. Version Added: 5.0 \"\"\" from enum import Enum from urllib.parse import urlparse import logging from django.conf import settings from django.contrib.auth.models import User from django.contrib.auth.views import LoginView from django.http import(Http404, HttpResponse, HttpResponseBadRequest, HttpResponseRedirect, HttpResponseServerError) from django.utils.decorators import method_decorator from django.views.decorators.csrf import csrf_protect from django.views.generic.base import View from djblets.db.query import get_object_or_none from djblets.siteconfig.models import SiteConfiguration from djblets.util.decorators import cached_property try: from onelogin.saml2.auth import OneLogin_Saml2_Auth from onelogin.saml2.errors import OneLogin_Saml2_Error from onelogin.saml2.settings import OneLogin_Saml2_Settings from onelogin.saml2.utils import OneLogin_Saml2_Utils except ImportError: OneLogin_Saml2_Auth=None OneLogin_Saml2_Error=None OneLogin_Saml2_Settings=None OneLogin_Saml2_Utils=None from reviewboard.accounts.models import LinkedAccount from reviewboard.accounts.sso.backends.saml.forms import SAMLLinkUserForm from reviewboard.accounts.sso.backends.saml.settings import get_saml2_settings from reviewboard.accounts.sso.users import(find_suggested_username, find_user_for_sso_user_id) from reviewboard.accounts.sso.views import BaseSSOView from reviewboard.admin.server import get_server_url from reviewboard.site.urlresolvers import local_site_reverse logger=logging.getLogger(__file__) class SAMLViewMixin(View): \"\"\"Mixin to provide common functionality for SAML views. Version Added: 5.0 \"\"\" def __init__(self, *args, **kwargs): \"\"\"Initialize the view. Args: *args(tuple): Positional arguments to pass through to the base class. **kwargs(dict): Keyword arguments to pass through to the base class. \"\"\" super().__init__(*args, **kwargs) self._saml_auth=None self._saml_request=None def get_saml_request(self, request): \"\"\"Return the SAML request. Args: request(django.http.HttpRequest): The HTTP request from the client. Returns: dict: Information about the SAML request. \"\"\" if self._saml_request is None: server_url=urlparse(get_server_url()) if server_url.scheme=='https': https='on' else: https='off' self._saml_request={ 'https': https, 'http_host': server_url.hostname, 'get_data': request.GET.copy(), 'post_data': request.POST.copy(), 'query_string': request.META['QUERY_STRING'], 'request_uri': request.path, 'script_name': request.META['PATH_INFO'], 'server_port': server_url.port, } return self._saml_request def get_saml_auth(self, request): \"\"\"Return the SAML auth information. Args: request(django.http.HttpRequest): The HTTP request from the client. Returns: onelogin.saml2.auth.OneLogin_Saml2_Auth: The SAML Auth object. \"\"\" if self._saml_auth is None: assert OneLogin_Saml2_Auth is not None self._saml_auth=OneLogin_Saml2_Auth( self.get_saml_request(request), get_saml2_settings()) return self._saml_auth def dispatch(self, *args, **kwargs): \"\"\"Handle a dispatch for the view. Args: *args(tuple): Positional arguments to pass through to the parent class. **kwargs(dict): Keyword arguments to pass through to the parent class. Returns: django.http.HttpResponse: The response to send back to the client. Raises: django.http.Http404: The SAML backend is not enabled, so treat all SAML views as 404. \"\"\" if not self.sso_backend.is_enabled(): raise Http404 return super().dispatch(*args, **kwargs) class SAMLACSView(SAMLViewMixin, BaseSSOView): \"\"\"ACS view for SAML SSO. Version Added: 5.0 \"\"\" @property def success_url(self): \"\"\"The URL to redirect to after a successful login. Type: str \"\"\" url=self.request.POST.get('RelayState') assert OneLogin_Saml2_Utils is not None self_url=OneLogin_Saml2_Utils.get_self_url( self.get_saml_request(self.request)) if url is not None and self_url !=url: saml_auth=self.get_saml_auth(self.request) return saml_auth.redirect_to(url) else: return settings.LOGIN_REDIRECT_URL @cached_property def link_user_url(self): \"\"\"The URL to the link-user flow. Type: str \"\"\" assert self.sso_backend is not None return local_site_reverse( 'sso:%s:link-user' % self.sso_backend.backend_id, request=self.request, kwargs={'backend_id': self.sso_backend.backend_id}) def post(self, request, *args, **kwargs): \"\"\"Handle a POST request. Args: request(django.http.HttpRequest): The request from the client. *args(tuple): Additional positional arguments. **kwargs(dict): Additional keyword arguments. Returns: django.http.HttpResponse: The response to send back to the client. \"\"\" auth=self.get_saml_auth(request) session=request.session try: auth.process_response(request_id=session.get('AuthNRequestID')) except OneLogin_Saml2_Error as e: logger.exception('SAML: Unable to process SSO request: %s', e, exc_info=True) return HttpResponseBadRequest('Bad SSO response: %s' % str(e), content_type='text\/plain') error=auth.get_last_error_reason() if error: logger.error('SAML: Unable to process SSO request: %s', error) return HttpResponseBadRequest('Bad SSO response: %s' % error, content_type='text\/plain') session.pop('AuthNRequestID', None) linked_account=get_object_or_none(LinkedAccount, service_id='sso:saml', service_user_id=auth.get_nameid()) if linked_account: user=linked_account.user self.sso_backend.login_user(request, user) return HttpResponseRedirect(self.success_url) else: username=auth.get_nameid() try: email=self._get_user_attr_value(auth, 'User.email') first_name=self._get_user_attr_value(auth, 'User.FirstName') last_name=self._get_user_attr_value(auth, 'User.LastName') except KeyError as e: logger.error('SAML: Assertion is missing %s attribute', e) return HttpResponseBadRequest('Bad SSO response: assertion is ' 'missing %s attribute' % e, content_type='text\/plain') request.session['sso']={ 'user_data':{ 'id': username, 'first_name': first_name, 'last_name': last_name, 'email': email, }, 'raw_user_attrs': auth.get_attributes(), 'session_index': auth.get_session_index(), } return HttpResponseRedirect(self.link_user_url) def _get_user_attr_value(self, auth, key): \"\"\"Return the value of a user attribute. Args: auth(onelogin.saml2.auth.OneLogin_Saml2_Auth): The SAML authentication object. key(str): The key to look up. Returns: str: The attribute, if it exists. Raises: KeyError: The given key was not present in the SAML assertion. \"\"\" value=auth.get_attribute(key) if value and isinstance(value, list): return value[0] raise KeyError(key) @method_decorator(csrf_protect, name='dispatch') class SAMLLinkUserView(SAMLViewMixin, BaseSSOView, LoginView): \"\"\"Link user view for SAML SSO. This can have several behaviors depending on what combination of state we get from the Identity Provider and what we have stored in the database. The first major case is where we are given data that matches an existing user in the database. Ideally this is via the \"username\" field, but may also be a matching e-mail address, or parsing a username out of the e-mail address. In this case, there are two paths. The simple path is where the administrator trusts both the authority and integrity of their Identity Provider and has turned off the \"Require login to link\" setting. For this, we'll just create the LinkedAccount, authenticate the user, and redirect to the success URL. If the require login setting is turned on, the user will have a choice. They can enter the password for the detected user to complete the link. If they have an account but the detected one is not correct, they can log in with their username and password to link the other account. Finally, they can provision a new user if they do not yet have one. The second major case is where we cannot find an existing user. In this case, we'll offer the user a choice: if they have an existing login that wasn't found, they can log in with their(non-SSO) username and password. If they don't have an account, they will be able to provision one. Version Added: 5.0 \"\"\" form_class=SAMLLinkUserForm class Mode(Enum): CONNECT_EXISTING_ACCOUNT='connect' CONNECT_WITH_LOGIN='connect-login' PROVISION='provision' def dispatch(self, *args, **kwargs): \"\"\"Dispatch the view. Args: *args(tuple): Positional arguments to pass to the parent class. **kwargs(dict): Keyword arguments to pass to the parent class. \"\"\" self._sso_user_data=\\ self.request.session.get('sso',{}).get('user_data') self._sso_data_username=self._sso_user_data.get('id') self._sso_data_email=self._sso_user_data.get('email') computed_username=find_suggested_username(self._sso_data_email) self._provision_username=self._sso_data_username or computed_username self._sso_user=find_user_for_sso_user_id( self._sso_data_username, self._sso_data_email, computed_username) requested_mode=self.request.GET.get('mode') if requested_mode and requested_mode in self.Mode: self._mode=requested_mode elif self._sso_user: self._mode=self.Mode.CONNECT_EXISTING_ACCOUNT else: self._mode=self.Mode.PROVISION return super(SAMLLinkUserView, self).dispatch(*args, **kwargs) def get_template_names(self): \"\"\"Return the template to use when rendering. Returns: list: A single-item list with the template name to use when rendering. Raises: ValueError: The current mode is not valid. \"\"\" if self._mode==self.Mode.CONNECT_EXISTING_ACCOUNT: return['accounts\/sso\/link-user-connect-existing.html'] elif self._mode==self.Mode.CONNECT_WITH_LOGIN: return['accounts\/sso\/link-user-login.html'] elif self._mode==self.Mode.PROVISION: return['accounts\/sso\/link-user-provision.html'] else: raise ValueError('Unknown link-user mode \"%s\"' % self._mode) def get_initial(self): \"\"\"Return the initial data for the form. Returns: dict: Initial data for the form. \"\"\" initial=super(SAMLLinkUserView, self).get_initial() if self._sso_user is not None: initial['username']=self._sso_user.username else: initial['username']=self._provision_username initial['provision']=(self._mode==self.Mode.PROVISION) return initial def get_context_data(self, **kwargs): \"\"\"Return additional context data for rendering the template. Args: **kwargs(dict): Keyword arguments for the view. Returns: dict: Additional data to inject into the render context. \"\"\" context=super(SAMLLinkUserView, self).get_context_data(**kwargs) context['user']=self._sso_user context['mode']=self._mode context['username']=self._provision_username return context def get(self, request, *args, **kwargs): \"\"\"Handle a GET request for the form. Args: request(django.http.HttpRequest): The HTTP request from the client. *args(tuple): Positional arguments to pass through to the base class. **kwargs(dict): Keyword arguments to pass through to the base class. Returns: django.http.HttpResponse: The response to send back to the client. \"\"\" if not self._sso_user_data: return HttpResponseRedirect( local_site_reverse('login', request=request)) siteconfig=SiteConfiguration.objects.get_current() if self._sso_user and not siteconfig.get('saml_require_login_to_link'): return self.link_user(self._sso_user) return super(SAMLLinkUserView, self).get(request, *args, **kwargs) def form_valid(self, form): \"\"\"Handler for when the form has successfully authenticated. Args: form(reviewboard.accounts.sso.backends.saml.forms. SAMLLinkUserForm): The link-user form. Returns: django.http.HttpResponseRedirect: A redirect to the next page. \"\"\" if form.cleaned_data['provision']: assert not self._sso_user assert self._provision_username first_name=self._sso_user_data.get('first_name') last_name=self._sso_user_data.get('last_name') logger.info('SAML: Provisioning user \"%s\"(%s <%s %s>)', self._provision_username, self._sso_data_email, first_name, last_name) user=User.objects.create( username=self._provision_username, email=self._sso_data_email, first_name=first_name, last_name=last_name) else: user=form.get_user() return self.link_user(user) def link_user(self, user): \"\"\"Link the given user. Args: user(django.contrib.auth.models.User): The user to link. Returns: django.http.HttpResponseRedirect: A redirect to the success URL. \"\"\" sso_id=self._sso_user_data.get('id') logger.info('SAML: Linking SSO user \"%s\" to Review Board user \"%s\"', sso_id, user.username) user.linked_accounts.create( service_id='sso:saml', service_user_id=sso_id) self.sso_backend.login_user(self.request, user) return HttpResponseRedirect(self.get_success_url()) class SAMLLoginView(SAMLViewMixin, BaseSSOView): \"\"\"Login view for SAML SSO. Version Added: 5.0 \"\"\" def get(self, request, *args, **kwargs): \"\"\"Handle a GET request for the login URL. Args: request(django.http.HttpRequest): The request from the client. *args(tuple, unused): Additional positional arguments. **kwargs(dict, unused): Additional keyword arguments. Returns: django.http.HttpResponseRedirect: A redirect to start the login flow. \"\"\" auth=self.get_saml_auth(request) return HttpResponseRedirect( auth.login(settings.LOGIN_REDIRECT_URL)) class SAMLMetadataView(SAMLViewMixin, BaseSSOView): \"\"\"Metadata view for SAML SSO. Version Added: 5.0 \"\"\" def get(self, request, *args, **kwargs): \"\"\"Handle a GET request. Args: request(django.http.HttpRequest): The HTTP request from the client. *args(tuple): Positional arguments from the URL definition. **kwargs(dict): Keyword arguments from the URL definition. \"\"\" assert OneLogin_Saml2_Settings is not None saml_settings=OneLogin_Saml2_Settings( get_saml2_settings(), sp_validation_only=True) metadata=saml_settings.get_sp_metadata() errors=saml_settings.validate_metadata(metadata) if errors: logger.error('SAML: Got errors from metadata validation: %s', ', '.join(errors)) return HttpResponseServerError(', '.join(errors), content_type='text\/plain') return HttpResponse(metadata, content_type='text\/xml') class SAMLSLSView(SAMLViewMixin, BaseSSOView): \"\"\"SLS view for SAML SSO. Version Added: 5.0 \"\"\" def get(self, request, *args, **kwargs): \"\"\"Handle a POST request. Args: request(django.http.HttpRequest): The request from the client. *args(tuple): Additional positional arguments. **kwargs(dict): Additional keyword arguments. Returns: django.http.HttpResponse: The response to send back to the client. \"\"\" auth=self.get_saml_auth(request) request_id=None if 'LogoutRequestId' in request.session: request_id=request.session['LogoutRequestId'] redirect_url=auth.process_slo( request_id=request_id, delete_session_cb=lambda: request.session.flush()) errors=auth.get_errors() if errors: error_text=', '.join(errors) logger.error('SAML: Unable to process SLO request: %s', error_text) return HttpResponseBadRequest('Bad SLO response: %s' % error_text, content_type='text\/plain') if redirect_url: return HttpResponseRedirect(redirect_url) else: return HttpResponseRedirect(settings.LOGIN_URL) ","sourceWithComments":"\"\"\"Views for SAML SSO.\n\nVersion Added:\n    5.0\n\"\"\"\n\nfrom enum import Enum\nfrom urllib.parse import urlparse\nimport logging\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.contrib.auth.views import LoginView\nfrom django.http import (Http404,\n                         HttpResponse,\n                         HttpResponseBadRequest,\n                         HttpResponseRedirect,\n                         HttpResponseServerError)\nfrom django.utils.decorators import method_decorator\nfrom django.views.decorators.csrf import csrf_protect\nfrom django.views.generic.base import View\nfrom djblets.db.query import get_object_or_none\nfrom djblets.siteconfig.models import SiteConfiguration\nfrom djblets.util.decorators import cached_property\ntry:\n    from onelogin.saml2.auth import OneLogin_Saml2_Auth\n    from onelogin.saml2.errors import OneLogin_Saml2_Error\n    from onelogin.saml2.settings import OneLogin_Saml2_Settings\n    from onelogin.saml2.utils import OneLogin_Saml2_Utils\nexcept ImportError:\n    OneLogin_Saml2_Auth = None\n    OneLogin_Saml2_Error = None\n    OneLogin_Saml2_Settings = None\n    OneLogin_Saml2_Utils = None\n\nfrom reviewboard.accounts.models import LinkedAccount\nfrom reviewboard.accounts.sso.backends.saml.forms import SAMLLinkUserForm\nfrom reviewboard.accounts.sso.backends.saml.settings import get_saml2_settings\nfrom reviewboard.accounts.sso.users import (find_suggested_username,\n                                            find_user_for_sso_user_id)\nfrom reviewboard.accounts.sso.views import BaseSSOView\nfrom reviewboard.admin.server import get_server_url\nfrom reviewboard.site.urlresolvers import local_site_reverse\n\n\nlogger = logging.getLogger(__file__)\n\n\nclass SAMLViewMixin(View):\n    \"\"\"Mixin to provide common functionality for SAML views.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize the view.\n\n        Args:\n            *args (tuple):\n                Positional arguments to pass through to the base class.\n\n            **kwargs (dict):\n                Keyword arguments to pass through to the base class.\n        \"\"\"\n        super().__init__(*args, **kwargs)\n        self._saml_auth = None\n        self._saml_request = None\n\n    def get_saml_request(self, request):\n        \"\"\"Return the SAML request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n        Returns:\n            dict:\n            Information about the SAML request.\n        \"\"\"\n        if self._saml_request is None:\n            server_url = urlparse(get_server_url())\n\n            if server_url.scheme == 'https':\n                https = 'on'\n            else:\n                https = 'off'\n\n            self._saml_request = {\n                'https': https,\n                'http_host': server_url.hostname,\n                'get_data': request.GET.copy(),\n                'post_data': request.POST.copy(),\n                'query_string': request.META['QUERY_STRING'],\n                'request_uri': request.path,\n                'script_name': request.META['PATH_INFO'],\n                'server_port': server_url.port,\n            }\n\n        return self._saml_request\n\n    def get_saml_auth(self, request):\n        \"\"\"Return the SAML auth information.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n        Returns:\n            onelogin.saml2.auth.OneLogin_Saml2_Auth:\n            The SAML Auth object.\n        \"\"\"\n        if self._saml_auth is None:\n            assert OneLogin_Saml2_Auth is not None\n            self._saml_auth = OneLogin_Saml2_Auth(\n                self.get_saml_request(request),\n                get_saml2_settings())\n\n        return self._saml_auth\n\n    def dispatch(self, *args, **kwargs):\n        \"\"\"Handle a dispatch for the view.\n\n        Args:\n            *args (tuple):\n                Positional arguments to pass through to the parent class.\n\n            **kwargs (dict):\n                Keyword arguments to pass through to the parent class.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n\n        Raises:\n            django.http.Http404:\n                The SAML backend is not enabled, so treat all SAML views as\n                404.\n        \"\"\"\n        if not self.sso_backend.is_enabled():\n            raise Http404\n\n        return super().dispatch(*args, **kwargs)\n\n\nclass SAMLACSView(SAMLViewMixin, BaseSSOView):\n    \"\"\"ACS view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    @property\n    def success_url(self):\n        \"\"\"The URL to redirect to after a successful login.\n\n        Type:\n            str\n        \"\"\"\n        url = self.request.POST.get('RelayState')\n\n        assert OneLogin_Saml2_Utils is not None\n        self_url = OneLogin_Saml2_Utils.get_self_url(\n            self.get_saml_request(self.request))\n\n        if url is not None and self_url != url:\n            saml_auth = self.get_saml_auth(self.request)\n            return saml_auth.redirect_to(url)\n        else:\n            return settings.LOGIN_REDIRECT_URL\n\n    @cached_property\n    def link_user_url(self):\n        \"\"\"The URL to the link-user flow.\n\n        Type:\n            str\n        \"\"\"\n        assert self.sso_backend is not None\n        return local_site_reverse(\n            'sso:%s:link-user' % self.sso_backend.backend_id,\n            request=self.request,\n            kwargs={'backend_id': self.sso_backend.backend_id})\n\n    def post(self, request, *args, **kwargs):\n        \"\"\"Handle a POST request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The request from the client.\n\n            *args (tuple):\n                Additional positional arguments.\n\n            **kwargs (dict):\n                Additional keyword arguments.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n        \"\"\"\n        auth = self.get_saml_auth(request)\n        session = request.session\n\n        try:\n            auth.process_response(request_id=session.get('AuthNRequestID'))\n        except OneLogin_Saml2_Error as e:\n            logger.exception('SAML: Unable to process SSO request: %s', e,\n                             exc_info=True)\n            return HttpResponseBadRequest('Bad SSO response: %s' % str(e),\n                                          content_type='text\/plain')\n\n        # TODO: store\/check last request ID, last message ID, last assertion ID\n        # to prevent replay attacks.\n\n        error = auth.get_last_error_reason()\n\n        if error:\n            logger.error('SAML: Unable to process SSO request: %s', error)\n            return HttpResponseBadRequest('Bad SSO response: %s' % error,\n                                          content_type='text\/plain')\n\n        # Store some state on the session to identify where we are in the SAML\n        # workflow.\n        session.pop('AuthNRequestID', None)\n\n        linked_account = get_object_or_none(LinkedAccount,\n                                            service_id='sso:saml',\n                                            service_user_id=auth.get_nameid())\n\n        if linked_account:\n            user = linked_account.user\n            self.sso_backend.login_user(request, user)\n            return HttpResponseRedirect(self.success_url)\n        else:\n            username = auth.get_nameid()\n\n            try:\n                email = self._get_user_attr_value(auth, 'User.email')\n                first_name = self._get_user_attr_value(auth, 'User.FirstName')\n                last_name = self._get_user_attr_value(auth, 'User.LastName')\n            except KeyError as e:\n                logger.error('SAML: Assertion is missing %s attribute', e)\n                return HttpResponseBadRequest('Bad SSO response: assertion is '\n                                              'missing %s attribute'\n                                              % e,\n                                              content_type='text\/plain')\n\n            request.session['sso'] = {\n                'user_data': {\n                    'id': username,\n                    'first_name': first_name,\n                    'last_name': last_name,\n                    'email': email,\n                },\n                'raw_user_attrs': auth.get_attributes(),\n                'session_index': auth.get_session_index(),\n            }\n\n            return HttpResponseRedirect(self.link_user_url)\n\n    def _get_user_attr_value(self, auth, key):\n        \"\"\"Return the value of a user attribute.\n\n        Args:\n            auth (onelogin.saml2.auth.OneLogin_Saml2_Auth):\n                The SAML authentication object.\n\n            key (str):\n                The key to look up.\n\n        Returns:\n            str:\n            The attribute, if it exists.\n\n        Raises:\n            KeyError:\n                The given key was not present in the SAML assertion.\n        \"\"\"\n        value = auth.get_attribute(key)\n\n        if value and isinstance(value, list):\n            return value[0]\n\n        raise KeyError(key)\n\n\n@method_decorator(csrf_protect, name='dispatch')\nclass SAMLLinkUserView(SAMLViewMixin, BaseSSOView, LoginView):\n    \"\"\"Link user view for SAML SSO.\n\n    This can have several behaviors depending on what combination of state we\n    get from the Identity Provider and what we have stored in the database.\n\n    The first major case is where we are given data that matches an existing\n    user in the database. Ideally this is via the \"username\" field, but may\n    also be a matching e-mail address, or parsing a username out of the e-mail\n    address.\n\n    In this case, there are two paths. The simple path is where the\n    administrator trusts both the authority and integrity of their Identity\n    Provider and has turned off the \"Require login to link\" setting. For this,\n    we'll just create the LinkedAccount, authenticate the user, and redirect to\n    the success URL.\n\n    If the require login setting is turned on, the user will have a choice.\n    They can enter the password for the detected user to complete the link. If\n    they have an account but the detected one is not correct, they can log in\n    with their username and password to link the other account. Finally, they\n    can provision a new user if they do not yet have one.\n\n    The second major case is where we cannot find an existing user. In this\n    case, we'll offer the user a choice: if they have an existing login that\n    wasn't found, they can log in with their (non-SSO) username and password.\n    If they don't have an account, they will be able to provision one.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    # TODO: This has a lot of logic which will likely be applicable to other\n    # SSO backend implementations. When we add a new backend, this should be\n    # refactored to pull out most of the logic into a common base class, and\n    # just implement SAML-specific data here.\n\n    form_class = SAMLLinkUserForm\n\n    class Mode(Enum):\n        CONNECT_EXISTING_ACCOUNT = 'connect'\n        CONNECT_WITH_LOGIN = 'connect-login'\n        PROVISION = 'provision'\n\n    def dispatch(self, *args, **kwargs):\n        \"\"\"Dispatch the view.\n\n        Args:\n            *args (tuple):\n                Positional arguments to pass to the parent class.\n\n            **kwargs (dict):\n                Keyword arguments to pass to the parent class.\n        \"\"\"\n        self._sso_user_data = \\\n            self.request.session.get('sso', {}).get('user_data')\n        self._sso_data_username = self._sso_user_data.get('id')\n        self._sso_data_email = self._sso_user_data.get('email')\n        computed_username = find_suggested_username(self._sso_data_email)\n        self._provision_username = self._sso_data_username or computed_username\n        self._sso_user = find_user_for_sso_user_id(\n            self._sso_data_username,\n            self._sso_data_email,\n            computed_username)\n\n        requested_mode = self.request.GET.get('mode')\n\n        if requested_mode and requested_mode in self.Mode:\n            self._mode = requested_mode\n        elif self._sso_user:\n            self._mode = self.Mode.CONNECT_EXISTING_ACCOUNT\n        else:\n            self._mode = self.Mode.PROVISION\n\n        return super(SAMLLinkUserView, self).dispatch(*args, **kwargs)\n\n    def get_template_names(self):\n        \"\"\"Return the template to use when rendering.\n\n        Returns:\n            list:\n            A single-item list with the template name to use when rendering.\n\n        Raises:\n            ValueError:\n                The current mode is not valid.\n        \"\"\"\n        if self._mode == self.Mode.CONNECT_EXISTING_ACCOUNT:\n            return ['accounts\/sso\/link-user-connect-existing.html']\n        elif self._mode == self.Mode.CONNECT_WITH_LOGIN:\n            return ['accounts\/sso\/link-user-login.html']\n        elif self._mode == self.Mode.PROVISION:\n            return ['accounts\/sso\/link-user-provision.html']\n        else:\n            raise ValueError('Unknown link-user mode \"%s\"' % self._mode)\n\n    def get_initial(self):\n        \"\"\"Return the initial data for the form.\n\n        Returns:\n            dict:\n            Initial data for the form.\n        \"\"\"\n        initial = super(SAMLLinkUserView, self).get_initial()\n\n        if self._sso_user is not None:\n            initial['username'] = self._sso_user.username\n        else:\n            initial['username'] = self._provision_username\n\n        initial['provision'] = (self._mode == self.Mode.PROVISION)\n\n        return initial\n\n    def get_context_data(self, **kwargs):\n        \"\"\"Return additional context data for rendering the template.\n\n        Args:\n            **kwargs (dict):\n                Keyword arguments for the view.\n\n        Returns:\n            dict:\n            Additional data to inject into the render context.\n        \"\"\"\n        context = super(SAMLLinkUserView, self).get_context_data(**kwargs)\n        context['user'] = self._sso_user\n        context['mode'] = self._mode\n        context['username'] = self._provision_username\n\n        return context\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a GET request for the form.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n            *args (tuple):\n                Positional arguments to pass through to the base class.\n\n            **kwargs (dict):\n                Keyword arguments to pass through to the base class.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n        \"\"\"\n        if not self._sso_user_data:\n            return HttpResponseRedirect(\n                local_site_reverse('login', request=request))\n\n        siteconfig = SiteConfiguration.objects.get_current()\n\n        if self._sso_user and not siteconfig.get('saml_require_login_to_link'):\n            return self.link_user(self._sso_user)\n\n        return super(SAMLLinkUserView, self).get(request, *args, **kwargs)\n\n    def form_valid(self, form):\n        \"\"\"Handler for when the form has successfully authenticated.\n\n        Args:\n            form (reviewboard.accounts.sso.backends.saml.forms.\n                  SAMLLinkUserForm):\n                The link-user form.\n\n        Returns:\n            django.http.HttpResponseRedirect:\n            A redirect to the next page.\n        \"\"\"\n        if form.cleaned_data['provision']:\n            # We can't provision if there's an existing matching user.\n            # TODO: show an error?\n            assert not self._sso_user\n            assert self._provision_username\n\n            first_name = self._sso_user_data.get('first_name')\n            last_name = self._sso_user_data.get('last_name')\n\n            logger.info('SAML: Provisioning user \"%s\" (%s <%s %s>)',\n                        self._provision_username, self._sso_data_email,\n                        first_name, last_name)\n\n            user = User.objects.create(\n                username=self._provision_username,\n                email=self._sso_data_email,\n                first_name=first_name,\n                last_name=last_name)\n        else:\n            user = form.get_user()\n\n        return self.link_user(user)\n\n    def link_user(self, user):\n        \"\"\"Link the given user.\n\n        Args:\n            user (django.contrib.auth.models.User):\n                The user to link.\n\n        Returns:\n            django.http.HttpResponseRedirect:\n            A redirect to the success URL.\n        \"\"\"\n        sso_id = self._sso_user_data.get('id')\n\n        logger.info('SAML: Linking SSO user \"%s\" to Review Board user \"%s\"',\n                    sso_id, user.username)\n\n        user.linked_accounts.create(\n            service_id='sso:saml',\n            service_user_id=sso_id)\n        self.sso_backend.login_user(self.request, user)\n        return HttpResponseRedirect(self.get_success_url())\n\n\nclass SAMLLoginView(SAMLViewMixin, BaseSSOView):\n    \"\"\"Login view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a GET request for the login URL.\n\n        Args:\n            request (django.http.HttpRequest):\n                The request from the client.\n\n            *args (tuple, unused):\n                Additional positional arguments.\n\n            **kwargs (dict, unused):\n                Additional keyword arguments.\n\n        Returns:\n            django.http.HttpResponseRedirect:\n            A redirect to start the login flow.\n        \"\"\"\n        auth = self.get_saml_auth(request)\n\n        return HttpResponseRedirect(\n            auth.login(settings.LOGIN_REDIRECT_URL))\n\n\nclass SAMLMetadataView(SAMLViewMixin, BaseSSOView):\n    \"\"\"Metadata view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a GET request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The HTTP request from the client.\n\n            *args (tuple):\n                Positional arguments from the URL definition.\n\n            **kwargs (dict):\n                Keyword arguments from the URL definition.\n        \"\"\"\n        assert OneLogin_Saml2_Settings is not None\n        saml_settings = OneLogin_Saml2_Settings(\n            get_saml2_settings(),\n            sp_validation_only=True)\n\n        metadata = saml_settings.get_sp_metadata()\n        errors = saml_settings.validate_metadata(metadata)\n\n        if errors:\n            logger.error('SAML: Got errors from metadata validation: %s',\n                         ', '.join(errors))\n            return HttpResponseServerError(', '.join(errors),\n                                           content_type='text\/plain')\n\n        return HttpResponse(metadata, content_type='text\/xml')\n\n\nclass SAMLSLSView(SAMLViewMixin, BaseSSOView):\n    \"\"\"SLS view for SAML SSO.\n\n    Version Added:\n        5.0\n    \"\"\"\n\n    def get(self, request, *args, **kwargs):\n        \"\"\"Handle a POST request.\n\n        Args:\n            request (django.http.HttpRequest):\n                The request from the client.\n\n            *args (tuple):\n                Additional positional arguments.\n\n            **kwargs (dict):\n                Additional keyword arguments.\n\n        Returns:\n            django.http.HttpResponse:\n            The response to send back to the client.\n        \"\"\"\n        auth = self.get_saml_auth(request)\n        request_id = None\n\n        if 'LogoutRequestId' in request.session:\n            request_id = request.session['LogoutRequestId']\n\n        redirect_url = auth.process_slo(\n            request_id=request_id,\n            delete_session_cb=lambda: request.session.flush())\n\n        errors = auth.get_errors()\n\n        if errors:\n            error_text = ', '.join(errors)\n            logger.error('SAML: Unable to process SLO request: %s', error_text)\n            return HttpResponseBadRequest('Bad SLO response: %s' % error_text,\n                                          content_type='text\/plain')\n\n        if redirect_url:\n            return HttpResponseRedirect(redirect_url)\n        else:\n            return HttpResponseRedirect(settings.LOGIN_URL)\n"},"\/reviewboard\/accounts\/tests\/test_saml_views.py":{"changes":[{"diff":"\n \n from xml.etree import ElementTree\n \n+import kgb\n from django.contrib.auth.models import User\n from django.urls import reverse\n \n-from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView\n+from reviewboard.accounts.sso.backends.saml.views import (SAMLACSView,\n+                                                          SAMLLinkUserView,\n+                                                          SAMLSLSView)\n from reviewboard.testing import TestCase\n \n \n","add":4,"remove":1,"filename":"\/reviewboard\/accounts\/tests\/test_saml_views.py","badparts":["from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView"],"goodparts":["import kgb","from reviewboard.accounts.sso.backends.saml.views import (SAMLACSView,","                                                          SAMLLinkUserView,","                                                          SAMLSLSView)"]},{"diff":"\n \n \n-class SAMLViewTests(TestCase):\n+class SAMLViewTests(kgb.SpyAgency, TestCase):\n     \"\"\"Unit tests for SAML views.\"\"\"\n \n     fixtures = ['test_users']\n","add":1,"remove":1,"filename":"\/reviewboard\/accounts\/tests\/test_saml_views.py","badparts":["class SAMLViewTests(TestCase):"],"goodparts":["class SAMLViewTests(kgb.SpyAgency, TestCase):"]}],"source":"\n\"\"\"Unit tests for SAML views.\"\"\" from xml.etree import ElementTree from django.contrib.auth.models import User from django.urls import reverse from reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView from reviewboard.testing import TestCase VALID_CERT=\"\"\"-----BEGIN CERTIFICATE----- MIICZjCCAc+gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBQMQswCQYDVQQGEwJ1czEL MAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcsIEluYy4xHDAaBgNVBAMME2h0 dHBzOi8vZXhhbXBsZS5jb20wHhcNMjIwNTA2MTU0NjI1WhcNMjMwNTA2MTU0NjI1 WjBQMQswCQYDVQQGEwJ1czELMAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcs IEluYy4xHDAaBgNVBAMME2h0dHBzOi8vZXhhbXBsZS5jb20wgZ8wDQYJKoZIhvcN AQEBBQADgY0AMIGJAoGBANCsbj4mvUiQERBy80R7yqA6hU3FMM4siC2UcUS3ltFF grkVOAPr+zUnrdadmAiTH35AB94oMzf0Qh8OJCr7wG5JQm686TRkVm2xUxhJUcoq 7LjBTKeEXBcrEzdNlagFXxHUSz5bPSdwDt\/zbOfe+9RZKeb4FggFCEYw\/mi69+Dx AgMBAAGjUDBOMB0GA1UdDgQWBBS4cP9Y+IM7ZHZChUDdx68QExTZUDAfBgNVHSME GDAWgBS4cP9Y+IM7ZHZChUDdx68QExTZUDAMBgNVHRMEBTADAQH\/MA0GCSqGSIb3 DQEBDQUAA4GBALht5\/NfJU+GxYfQKiGkZ4Ih\/T\/48rzXAT7\/7f61s7w72UR2S5e2 WsR7\/JPkZ5+u5mCgmABjNcd9NzaBM2RfSrrurwbjXMQ8nb\/+REvhXXJ4STsS48y5 bef2JtIf7mGDw8\/KsUrAA2jEIpCedToGyQxyE6GdN5b69ITWvyAemnIM -----END CERTIFICATE-----\"\"\" class SAMLViewTests(TestCase): \"\"\"Unit tests for SAML views.\"\"\" fixtures=['test_users'] def test_metadata_view(self): \"\"\"Testing SAMLMetadataView\"\"\" settings={ 'saml_enabled': True, 'saml_verification_cert': VALID_CERT, } with self.siteconfig_settings(settings): url=reverse('sso:saml:metadata', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) root=ElementTree.fromstring(rsp.content) namespaces={'md': 'urn:oasis:names:tc:SAML:2.0:metadata'} descriptor=root.find('md:SPSSODescriptor', namespaces) assert descriptor is not None sls=descriptor.find('md:SingleLogoutService', namespaces) assert sls is not None self.assertEqual( sls.get('Binding'), 'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect') self.assertEqual( sls.get('Location'), 'http:\/\/example.com\/account\/sso\/saml\/sls\/') acs=descriptor.find('md:AssertionConsumerService', namespaces) assert acs is not None self.assertEqual( acs.get('Binding'), 'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST') self.assertEqual( acs.get('Location'), 'http:\/\/example.com\/account\/sso\/saml\/acs\/') def test_get_link_user_existing_account(self): \"\"\"Testing SAMLLinkUserView form render with existing account\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.com', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'].username, 'doc') self.assertEqual(context['mode'], SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT) def test_get_link_user_existing_account_email_match(self): \"\"\"Testing SAMLLinkUserView form render with existing account matching email address \"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.com', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'].username, 'doc') self.assertEqual(context['mode'], SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT) def test_get_link_user_existing_account_email_username_match(self): \"\"\"Testing SAMLLinkUserView form render with existing account matching username from email address \"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.org', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'].username, 'doc') self.assertEqual(context['mode'], SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT) def test_get_link_user_no_match(self): \"\"\"Testing SAMLLinkUserView form render with no match\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc2@example.org', }, } session.save() url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.get(url) self.assertEqual(rsp.status_code, 200) context=rsp.context self.assertEqual(context['user'], None) self.assertEqual(context['mode'], SAMLLinkUserView.Mode.PROVISION) def test_post_link_user_login(self): \"\"\"Testing SAMLLinkUserView form POST with login\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'doc2', 'first_name': 'Doc', 'last_name': 'Dwarf', 'email': 'doc@example.com', }, } session.save() user=User.objects.get(username='doc') self.assertFalse(user.linked_accounts.exists()) url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.post(url,{ 'username': 'doc', 'password': 'doc', 'provision': False, }) self.assertEqual(rsp.status_code, 302) linked_accounts=list(user.linked_accounts.all()) self.assertEqual(len(linked_accounts), 1) linked_account=linked_accounts[0] self.assertEqual(linked_account.service_id, 'sso:saml') self.assertEqual(linked_account.service_user_id, 'doc2') def test_post_link_user_provision(self): \"\"\"Testing SAMLLinkUserView form POST with provision\"\"\" settings={ 'saml_enabled': True, 'saml_require_login_to_link': True, } with self.siteconfig_settings(settings): session=self.client.session session['sso']={ 'user_data':{ 'id': 'sleepy', 'first_name': 'Sleepy', 'last_name': 'Dwarf', 'email': 'sleepy@example.com', }, } session.save() self.assertFalse(User.objects.filter(username='sleepy').exists()) url=reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'}) rsp=self.client.post(url,{ 'username': '', 'password': '', 'provision': True, }) self.assertEqual(rsp.status_code, 302) user=User.objects.get(username='sleepy') self.assertEqual(user.first_name, 'Sleepy') self.assertEqual(user.last_name, 'Dwarf') self.assertEqual(user.email, 'sleepy@example.com') linked_accounts=list(user.linked_accounts.all()) self.assertEqual(len(linked_accounts), 1) linked_account=linked_accounts[0] self.assertEqual(linked_account.service_id, 'sso:saml') self.assertEqual(linked_account.service_user_id, 'sleepy') ","sourceWithComments":"\"\"\"Unit tests for SAML views.\"\"\"\n\nfrom xml.etree import ElementTree\n\nfrom django.contrib.auth.models import User\nfrom django.urls import reverse\n\nfrom reviewboard.accounts.sso.backends.saml.views import SAMLLinkUserView\nfrom reviewboard.testing import TestCase\n\n\nVALID_CERT = \"\"\"-----BEGIN CERTIFICATE-----\nMIICZjCCAc+gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBQMQswCQYDVQQGEwJ1czEL\nMAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcsIEluYy4xHDAaBgNVBAMME2h0\ndHBzOi8vZXhhbXBsZS5jb20wHhcNMjIwNTA2MTU0NjI1WhcNMjMwNTA2MTU0NjI1\nWjBQMQswCQYDVQQGEwJ1czELMAkGA1UECAwCQ0ExFjAUBgNVBAoMDUJlYW5iYWcs\nIEluYy4xHDAaBgNVBAMME2h0dHBzOi8vZXhhbXBsZS5jb20wgZ8wDQYJKoZIhvcN\nAQEBBQADgY0AMIGJAoGBANCsbj4mvUiQERBy80R7yqA6hU3FMM4siC2UcUS3ltFF\ngrkVOAPr+zUnrdadmAiTH35AB94oMzf0Qh8OJCr7wG5JQm686TRkVm2xUxhJUcoq\n7LjBTKeEXBcrEzdNlagFXxHUSz5bPSdwDt\/zbOfe+9RZKeb4FggFCEYw\/mi69+Dx\nAgMBAAGjUDBOMB0GA1UdDgQWBBS4cP9Y+IM7ZHZChUDdx68QExTZUDAfBgNVHSME\nGDAWgBS4cP9Y+IM7ZHZChUDdx68QExTZUDAMBgNVHRMEBTADAQH\/MA0GCSqGSIb3\nDQEBDQUAA4GBALht5\/NfJU+GxYfQKiGkZ4Ih\/T\/48rzXAT7\/7f61s7w72UR2S5e2\nWsR7\/JPkZ5+u5mCgmABjNcd9NzaBM2RfSrrurwbjXMQ8nb\/+REvhXXJ4STsS48y5\nbef2JtIf7mGDw8\/KsUrAA2jEIpCedToGyQxyE6GdN5b69ITWvyAemnIM\n-----END CERTIFICATE-----\"\"\"\n\n\nclass SAMLViewTests(TestCase):\n    \"\"\"Unit tests for SAML views.\"\"\"\n\n    fixtures = ['test_users']\n\n    def test_metadata_view(self):\n        \"\"\"Testing SAMLMetadataView\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_verification_cert': VALID_CERT,\n        }\n\n        with self.siteconfig_settings(settings):\n            url = reverse('sso:saml:metadata', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            root = ElementTree.fromstring(rsp.content)\n\n            namespaces = {'md': 'urn:oasis:names:tc:SAML:2.0:metadata'}\n\n            descriptor = root.find('md:SPSSODescriptor', namespaces)\n            assert descriptor is not None\n\n            sls = descriptor.find('md:SingleLogoutService', namespaces)\n            assert sls is not None\n\n            self.assertEqual(\n                sls.get('Binding'),\n                'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect')\n            self.assertEqual(\n                sls.get('Location'),\n                'http:\/\/example.com\/account\/sso\/saml\/sls\/')\n\n            acs = descriptor.find('md:AssertionConsumerService', namespaces)\n            assert acs is not None\n\n            self.assertEqual(\n                acs.get('Binding'),\n                'urn:oasis:names:tc:SAML:2.0:bindings:HTTP-POST')\n            self.assertEqual(\n                acs.get('Location'),\n                'http:\/\/example.com\/account\/sso\/saml\/acs\/')\n\n    def test_get_link_user_existing_account(self):\n        \"\"\"Testing SAMLLinkUserView form render with existing account\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.com',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'].username, 'doc')\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT)\n\n    def test_get_link_user_existing_account_email_match(self):\n        \"\"\"Testing SAMLLinkUserView form render with existing account matching\n        email address\n        \"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.com',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'].username, 'doc')\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT)\n\n    def test_get_link_user_existing_account_email_username_match(self):\n        \"\"\"Testing SAMLLinkUserView form render with existing account matching\n        username from email address\n        \"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.org',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'].username, 'doc')\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.CONNECT_EXISTING_ACCOUNT)\n\n    def test_get_link_user_no_match(self):\n        \"\"\"Testing SAMLLinkUserView form render with no match\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc2@example.org',\n                },\n            }\n            session.save()\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.get(url)\n\n            self.assertEqual(rsp.status_code, 200)\n\n            context = rsp.context\n            self.assertEqual(context['user'], None)\n            self.assertEqual(context['mode'],\n                             SAMLLinkUserView.Mode.PROVISION)\n\n    def test_post_link_user_login(self):\n        \"\"\"Testing SAMLLinkUserView form POST with login\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'doc2',\n                    'first_name': 'Doc',\n                    'last_name': 'Dwarf',\n                    'email': 'doc@example.com',\n                },\n            }\n            session.save()\n\n            user = User.objects.get(username='doc')\n            self.assertFalse(user.linked_accounts.exists())\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.post(url, {\n                'username': 'doc',\n                'password': 'doc',\n                'provision': False,\n            })\n\n            self.assertEqual(rsp.status_code, 302)\n\n            linked_accounts = list(user.linked_accounts.all())\n\n            self.assertEqual(len(linked_accounts), 1)\n            linked_account = linked_accounts[0]\n            self.assertEqual(linked_account.service_id, 'sso:saml')\n            self.assertEqual(linked_account.service_user_id, 'doc2')\n\n    def test_post_link_user_provision(self):\n        \"\"\"Testing SAMLLinkUserView form POST with provision\"\"\"\n        settings = {\n            'saml_enabled': True,\n            'saml_require_login_to_link': True,\n        }\n\n        with self.siteconfig_settings(settings):\n            session = self.client.session\n            session['sso'] = {\n                'user_data': {\n                    'id': 'sleepy',\n                    'first_name': 'Sleepy',\n                    'last_name': 'Dwarf',\n                    'email': 'sleepy@example.com',\n                },\n            }\n            session.save()\n\n            self.assertFalse(User.objects.filter(username='sleepy').exists())\n\n            url = reverse('sso:saml:link-user', kwargs={'backend_id': 'saml'})\n            rsp = self.client.post(url, {\n                'username': '',\n                'password': '',\n                'provision': True,\n            })\n\n            self.assertEqual(rsp.status_code, 302)\n\n            user = User.objects.get(username='sleepy')\n            self.assertEqual(user.first_name, 'Sleepy')\n            self.assertEqual(user.last_name, 'Dwarf')\n            self.assertEqual(user.email, 'sleepy@example.com')\n\n            linked_accounts = list(user.linked_accounts.all())\n\n            self.assertEqual(len(linked_accounts), 1)\n            linked_account = linked_accounts[0]\n            self.assertEqual(linked_account.service_id, 'sso:saml')\n            self.assertEqual(linked_account.service_user_id, 'sleepy')\n"}},"msg":"Implement replay attack mitigation for SAML auth.\n\nSAML is generally quite secure by design, but if there's a man in the\nmiddle, it is susceptible to replay attacks (within a short limited time\nframe). The way this is mitigated is by giving every message and\nassertion a unique ID. The service provider can then store these IDs and\nmake sure that they haven't already been used.\n\nThis change implements that. The used IDs are kept in the cache, and\nchecked before we proceed. While using the cache for this isn't 100%\nreliable, given the very short message lifetime, it's good enough for\nour purposes.\n\nTesting Done:\n- Ran unit tests.\n- Verified that I could still log in with SAML.\n- Crafted a replay and saw that it was successfully blocked.\n\nReviewed at https:\/\/reviews.reviewboard.org\/r\/12476\/"}},"https:\/\/github.com\/bakwc\/PySyncObj":{"a5e7ae8b3cede67d2f3a13216b5a5a2e6329c2d4":{"url":"https:\/\/api.github.com\/repos\/bakwc\/PySyncObj\/commits\/a5e7ae8b3cede67d2f3a13216b5a5a2e6329c2d4","html_url":"https:\/\/github.com\/bakwc\/PySyncObj\/commit\/a5e7ae8b3cede67d2f3a13216b5a5a2e6329c2d4","message":"Implement basic replay protection\n\nImplements partial protection against attackers transparently proxying our TCP connections.\r\nPreviously PySyncObj allowed such attackers to replay\/delay\/reorder\/drop messages arbitrarily.\r\nReordering\/replaying is now restricted for attackers only to messages with the same timestamp.\r\n\r\nAdvantage of this partial protection over more effective one is that this is no change to message format.\r\nThis means that connection between patched an unpatched servers will still work except connection will\r\nbe closed and immediately reopened when somebody turns clocks on their unpatched servers back.\r\n\r\nAlso, strength of this protection will improve with https:\/\/github.com\/fernet\/spec\/issues\/12 .","sha":"a5e7ae8b3cede67d2f3a13216b5a5a2e6329c2d4","keyword":"replay attack improve","diff":"diff --git a\/pysyncobj\/tcp_connection.py b\/pysyncobj\/tcp_connection.py\nindex 1c0a430..d3fcbf1 100644\n--- a\/pysyncobj\/tcp_connection.py\n+++ b\/pysyncobj\/tcp_connection.py\n@@ -35,6 +35,7 @@ def __init__(self, poller, onMessageReceived = None, onConnected = None, onDisco\n \n         self.sendRandKey = None\n         self.recvRandKey = None\n+        self.recvLastTimestamp = 0\n         self.encryptor = None\n \n         self.__socket = socket\n@@ -101,7 +102,7 @@ def send(self, message):\n             message = (self.sendRandKey, message)\n         data = zlib.compress(pickle.dumps(message), 3)\n         if self.encryptor:\n-            data = self.encryptor.encrypt(data)\n+            data = self.encryptor.encrypt_at_time(data, int(monotonicTime())\n         data = struct.pack('i', len(data)) + data\n         self.__writeBuffer += data\n         self.__trySendBuffer()\n@@ -115,6 +116,7 @@ def disconnect(self):\n             needCallDisconnect = True\n         self.sendRandKey = None\n         self.recvRandKey = None\n+        self.recvLastTimestamp = 0\n         if self.__socket is not None:\n             self.__socket.close()\n             self.__socket = None\n@@ -232,12 +234,17 @@ def __processParseMessage(self):\n         data = self.__readBuffer[4:4 + l]\n         try:\n             if self.encryptor:\n+                dataTimestamp = self.encryptor.extract_timestamp(data)\n+                assert dataTimestamp >= self.recvLastTimestamp\n+                self.recvLastTimestamp = dataTimestamp\n+                # Unfortunately we can't get a timestamp and data in one go\n                 data = self.encryptor.decrypt(data)\n             message = pickle.loads(zlib.decompress(data))\n             if self.recvRandKey:\n                 randKey, message = message\n                 assert randKey == self.recvRandKey\n         except:\n+            # Why no logging of security errors?\n             self.disconnect()\n             return None\n         self.__readBuffer = self.__readBuffer[4 + l:]\n","files":{"\/pysyncobj\/tcp_connection.py":{"changes":[{"diff":"\n             message = (self.sendRandKey, message)\n         data = zlib.compress(pickle.dumps(message), 3)\n         if self.encryptor:\n-            data = self.encryptor.encrypt(data)\n+            data = self.encryptor.encrypt_at_time(data, int(monotonicTime())\n         data = struct.pack('i', len(data)) + data\n         self.__writeBuffer += data\n         self.__trySendBuffer()\n","add":1,"remove":1,"filename":"\/pysyncobj\/tcp_connection.py","badparts":["            data = self.encryptor.encrypt(data)"],"goodparts":["            data = self.encryptor.encrypt_at_time(data, int(monotonicTime())"]}],"source":"\nimport time import socket import zlib import struct import pysyncobj.pickle as pickle import pysyncobj.win_inet_pton from.poller import POLL_EVENT_TYPE from.monotonic import monotonic as monotonicTime class CONNECTION_STATE: DISCONNECTED=0 CONNECTING=1 CONNECTED=2 def _getAddrType(addr): try: socket.inet_aton(addr) return socket.AF_INET except socket.error: pass try: socket.inet_pton(socket.AF_INET6, addr) return socket.AF_INET6 except socket.error: pass raise Exception('unknown address type') class TcpConnection(object): def __init__(self, poller, onMessageReceived=None, onConnected=None, onDisconnected=None, socket=None, timeout=10.0, sendBufferSize=2 ** 13, recvBufferSize=2 ** 13): self.sendRandKey=None self.recvRandKey=None self.encryptor=None self.__socket=socket self.__readBuffer=bytes() self.__writeBuffer=bytes() self.__lastReadTime=monotonicTime() self.__timeout=timeout self.__poller=poller if socket is not None: self.__socket=socket self.__fileno=socket.fileno() self.__state=CONNECTION_STATE.CONNECTED self.__poller.subscribe(self.__fileno, self.__processConnection, POLL_EVENT_TYPE.READ | POLL_EVENT_TYPE.WRITE | POLL_EVENT_TYPE.ERROR) else: self.__state=CONNECTION_STATE.DISCONNECTED self.__fileno=None self.__socket=None self.__onMessageReceived=onMessageReceived self.__onConnected=onConnected self.__onDisconnected=onDisconnected self.__sendBufferSize=sendBufferSize self.__recvBufferSize=recvBufferSize def setOnConnectedCallback(self, onConnected): self.__onConnected=onConnected def setOnMessageReceivedCallback(self, onMessageReceived): self.__onMessageReceived=onMessageReceived def setOnDisconnectedCallback(self, onDisconnected): self.__onDisconnected=onDisconnected def connect(self, host, port): if host is None: return False self.__state=CONNECTION_STATE.DISCONNECTED self.__fileno=None self.__socket=socket.socket(_getAddrType(host), socket.SOCK_STREAM) self.__socket.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, self.__sendBufferSize) self.__socket.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, self.__recvBufferSize) self.__socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) self.__socket.setblocking(0) self.__readBuffer=bytes() self.__writeBuffer=bytes() self.__lastReadTime=monotonicTime() try: self.__socket.connect((host, port)) except socket.error as e: if e.errno not in(socket.errno.EINPROGRESS, socket.errno.EWOULDBLOCK): return False self.__fileno=self.__socket.fileno() self.__state=CONNECTION_STATE.CONNECTING self.__poller.subscribe(self.__fileno, self.__processConnection, POLL_EVENT_TYPE.READ | POLL_EVENT_TYPE.WRITE | POLL_EVENT_TYPE.ERROR) return True def send(self, message): if self.sendRandKey: message=(self.sendRandKey, message) data=zlib.compress(pickle.dumps(message), 3) if self.encryptor: data=self.encryptor.encrypt(data) data=struct.pack('i', len(data)) +data self.__writeBuffer +=data self.__trySendBuffer() def fileno(self): return self.__fileno def disconnect(self): needCallDisconnect=False if self.__onDisconnected is not None and self.__state !=CONNECTION_STATE.DISCONNECTED: needCallDisconnect=True self.sendRandKey=None self.recvRandKey=None if self.__socket is not None: self.__socket.close() self.__socket=None if self.__fileno is not None: self.__poller.unsubscribe(self.__fileno) self.__fileno=None self.__writeBuffer=bytes() self.__readBuffer=bytes() self.__state=CONNECTION_STATE.DISCONNECTED if needCallDisconnect: self.__onDisconnected() def getSendBufferSize(self): return len(self.__writeBuffer) def __processConnection(self, descr, eventType): poller=self.__poller if descr !=self.__fileno: poller.unsubscribe(descr) return if eventType & POLL_EVENT_TYPE.ERROR: self.disconnect() return if monotonicTime() -self.__lastReadTime > self.__timeout: self.disconnect() return if eventType & POLL_EVENT_TYPE.READ or eventType & POLL_EVENT_TYPE.WRITE: if self.__socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR): self.disconnect() return if self.__state==CONNECTION_STATE.CONNECTING: if self.__onConnected is not None: self.__onConnected() if self.__state==CONNECTION_STATE.DISCONNECTED: return self.__state=CONNECTION_STATE.CONNECTED self.__lastReadTime=monotonicTime() return if eventType & POLL_EVENT_TYPE.WRITE: self.__trySendBuffer() if self.__state==CONNECTION_STATE.DISCONNECTED: return event=POLL_EVENT_TYPE.READ | POLL_EVENT_TYPE.ERROR if len(self.__writeBuffer) > 0: event |=POLL_EVENT_TYPE.WRITE poller.subscribe(descr, self.__processConnection, event) if eventType & POLL_EVENT_TYPE.READ: self.__tryReadBuffer() if self.__state==CONNECTION_STATE.DISCONNECTED: return while True: message=self.__processParseMessage() if message is None: break if self.__onMessageReceived is not None: self.__onMessageReceived(message) if self.__state==CONNECTION_STATE.DISCONNECTED: return def __trySendBuffer(self): while self.__processSend(): pass def __processSend(self): if not self.__writeBuffer: return False try: res=self.__socket.send(self.__writeBuffer) if res < 0: self.disconnect() return False if res==0: return False self.__writeBuffer=self.__writeBuffer[res:] return True except socket.error as e: if e.errno not in(socket.errno.EAGAIN, socket.errno.EWOULDBLOCK): self.disconnect() return False def __tryReadBuffer(self): while self.__processRead(): pass self.__lastReadTime=monotonicTime() def __processRead(self): try: incoming=self.__socket.recv(self.__recvBufferSize) except socket.error as e: if e.errno not in(socket.errno.EAGAIN, socket.errno.EWOULDBLOCK): self.disconnect() return False if self.__socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR): self.disconnect() return False if not incoming: self.disconnect() return False self.__readBuffer +=incoming return True def __processParseMessage(self): if len(self.__readBuffer) < 4: return None l=struct.unpack('i', self.__readBuffer[:4])[0] if len(self.__readBuffer) -4 < l: return None data=self.__readBuffer[4:4 +l] try: if self.encryptor: data=self.encryptor.decrypt(data) message=pickle.loads(zlib.decompress(data)) if self.recvRandKey: randKey, message=message assert randKey==self.recvRandKey except: self.disconnect() return None self.__readBuffer=self.__readBuffer[4 +l:] return message @property def state(self): return self.__state ","sourceWithComments":"import time\nimport socket\nimport zlib\nimport struct\n\nimport pysyncobj.pickle as pickle\nimport pysyncobj.win_inet_pton\n\nfrom .poller import POLL_EVENT_TYPE\nfrom .monotonic import monotonic as monotonicTime\n\n\nclass CONNECTION_STATE:\n    DISCONNECTED = 0\n    CONNECTING = 1\n    CONNECTED = 2\n\ndef _getAddrType(addr):\n    try:\n        socket.inet_aton(addr)\n        return socket.AF_INET\n    except socket.error:\n        pass\n    try:\n        socket.inet_pton(socket.AF_INET6, addr)\n        return socket.AF_INET6\n    except socket.error:\n        pass\n    raise Exception('unknown address type')\n\nclass TcpConnection(object):\n\n    def __init__(self, poller, onMessageReceived = None, onConnected = None, onDisconnected = None,\n                 socket=None, timeout=10.0, sendBufferSize = 2 ** 13, recvBufferSize = 2 ** 13):\n\n        self.sendRandKey = None\n        self.recvRandKey = None\n        self.encryptor = None\n\n        self.__socket = socket\n        self.__readBuffer = bytes()\n        self.__writeBuffer = bytes()\n        self.__lastReadTime = monotonicTime()\n        self.__timeout = timeout\n        self.__poller = poller\n        if socket is not None:\n            self.__socket = socket\n            self.__fileno = socket.fileno()\n            self.__state = CONNECTION_STATE.CONNECTED\n            self.__poller.subscribe(self.__fileno,\n                                     self.__processConnection,\n                                     POLL_EVENT_TYPE.READ | POLL_EVENT_TYPE.WRITE | POLL_EVENT_TYPE.ERROR)\n        else:\n            self.__state = CONNECTION_STATE.DISCONNECTED\n            self.__fileno = None\n            self.__socket = None\n\n        self.__onMessageReceived = onMessageReceived\n        self.__onConnected = onConnected\n        self.__onDisconnected = onDisconnected\n        self.__sendBufferSize = sendBufferSize\n        self.__recvBufferSize = recvBufferSize\n\n    def setOnConnectedCallback(self, onConnected):\n        self.__onConnected = onConnected\n\n    def setOnMessageReceivedCallback(self, onMessageReceived):\n        self.__onMessageReceived = onMessageReceived\n\n    def setOnDisconnectedCallback(self, onDisconnected):\n        self.__onDisconnected = onDisconnected\n\n    def connect(self, host, port):\n        if host is None:\n            return False\n        self.__state = CONNECTION_STATE.DISCONNECTED\n        self.__fileno = None\n        self.__socket = socket.socket(_getAddrType(host), socket.SOCK_STREAM)\n        self.__socket.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, self.__sendBufferSize)\n        self.__socket.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, self.__recvBufferSize)\n        self.__socket.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n        self.__socket.setblocking(0)\n        self.__readBuffer = bytes()\n        self.__writeBuffer = bytes()\n        self.__lastReadTime = monotonicTime()\n\n        try:\n            self.__socket.connect((host, port))\n        except socket.error as e:\n            if e.errno not in (socket.errno.EINPROGRESS, socket.errno.EWOULDBLOCK):\n                return False\n        self.__fileno = self.__socket.fileno()\n        self.__state = CONNECTION_STATE.CONNECTING\n        self.__poller.subscribe(self.__fileno,\n                                 self.__processConnection,\n                                 POLL_EVENT_TYPE.READ | POLL_EVENT_TYPE.WRITE | POLL_EVENT_TYPE.ERROR)\n        return True\n\n    def send(self, message):\n        if self.sendRandKey:\n            message = (self.sendRandKey, message)\n        data = zlib.compress(pickle.dumps(message), 3)\n        if self.encryptor:\n            data = self.encryptor.encrypt(data)\n        data = struct.pack('i', len(data)) + data\n        self.__writeBuffer += data\n        self.__trySendBuffer()\n\n    def fileno(self):\n        return self.__fileno\n\n    def disconnect(self):\n        needCallDisconnect = False\n        if self.__onDisconnected is not None and self.__state != CONNECTION_STATE.DISCONNECTED:\n            needCallDisconnect = True\n        self.sendRandKey = None\n        self.recvRandKey = None\n        if self.__socket is not None:\n            self.__socket.close()\n            self.__socket = None\n        if self.__fileno is not None:\n            self.__poller.unsubscribe(self.__fileno)\n            self.__fileno = None\n        self.__writeBuffer = bytes()\n        self.__readBuffer = bytes()\n        self.__state = CONNECTION_STATE.DISCONNECTED\n        if needCallDisconnect:\n            self.__onDisconnected()\n\n    def getSendBufferSize(self):\n        return len(self.__writeBuffer)\n\n    def __processConnection(self, descr, eventType):\n        poller = self.__poller\n        if descr != self.__fileno:\n            poller.unsubscribe(descr)\n            return\n\n        if eventType & POLL_EVENT_TYPE.ERROR:\n            self.disconnect()\n            return\n\n        if monotonicTime() - self.__lastReadTime > self.__timeout:\n            self.disconnect()\n            return\n\n        if eventType & POLL_EVENT_TYPE.READ or eventType & POLL_EVENT_TYPE.WRITE:\n            if self.__socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR):\n                self.disconnect()\n                return\n\n            if self.__state == CONNECTION_STATE.CONNECTING:\n                if self.__onConnected is not None:\n                    self.__onConnected()\n                if self.__state == CONNECTION_STATE.DISCONNECTED:\n                    return\n                self.__state = CONNECTION_STATE.CONNECTED\n                self.__lastReadTime = monotonicTime()\n                return\n\n        if eventType & POLL_EVENT_TYPE.WRITE:\n            self.__trySendBuffer()\n            if self.__state == CONNECTION_STATE.DISCONNECTED:\n                return\n            event = POLL_EVENT_TYPE.READ | POLL_EVENT_TYPE.ERROR\n            if len(self.__writeBuffer) > 0:\n                event |= POLL_EVENT_TYPE.WRITE\n            poller.subscribe(descr, self.__processConnection, event)\n\n        if eventType & POLL_EVENT_TYPE.READ:\n            self.__tryReadBuffer()\n            if self.__state == CONNECTION_STATE.DISCONNECTED:\n                return\n\n            while True:\n                message = self.__processParseMessage()\n                if message is None:\n                    break\n                if self.__onMessageReceived is not None:\n                    self.__onMessageReceived(message)\n                if self.__state == CONNECTION_STATE.DISCONNECTED:\n                    return\n\n    def __trySendBuffer(self):\n        while self.__processSend():\n            pass\n\n    def __processSend(self):\n        if not self.__writeBuffer:\n            return False\n        try:\n            res = self.__socket.send(self.__writeBuffer)\n            if res < 0:\n                self.disconnect()\n                return False\n            if res == 0:\n                return False\n            self.__writeBuffer = self.__writeBuffer[res:]\n            return True\n        except socket.error as e:\n            if e.errno not in (socket.errno.EAGAIN, socket.errno.EWOULDBLOCK):\n                self.disconnect()\n            return False\n\n    def __tryReadBuffer(self):\n        while self.__processRead():\n            pass\n        self.__lastReadTime = monotonicTime()\n\n    def __processRead(self):\n        try:\n            incoming = self.__socket.recv(self.__recvBufferSize)\n        except socket.error as e:\n            if e.errno not in (socket.errno.EAGAIN, socket.errno.EWOULDBLOCK):\n                self.disconnect()\n            return False\n        if self.__socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR):\n            self.disconnect()\n            return False\n        if not incoming:\n            self.disconnect()\n            return False\n        self.__readBuffer += incoming\n        return True\n\n    def __processParseMessage(self):\n        if len(self.__readBuffer) < 4:\n            return None\n        l = struct.unpack('i', self.__readBuffer[:4])[0]\n        if len(self.__readBuffer) - 4 < l:\n            return None\n        data = self.__readBuffer[4:4 + l]\n        try:\n            if self.encryptor:\n                data = self.encryptor.decrypt(data)\n            message = pickle.loads(zlib.decompress(data))\n            if self.recvRandKey:\n                randKey, message = message\n                assert randKey == self.recvRandKey\n        except:\n            self.disconnect()\n            return None\n        self.__readBuffer = self.__readBuffer[4 + l:]\n        return message\n\n    @property\n    def state(self):\n        return self.__state\n"}},"msg":"Implement basic replay protection\n\nImplements partial protection against attackers transparently proxying our TCP connections.\r\nPreviously PySyncObj allowed such attackers to replay\/delay\/reorder\/drop messages arbitrarily.\r\nReordering\/replaying is now restricted for attackers only to messages with the same timestamp.\r\n\r\nAdvantage of this partial protection over more effective one is that this is no change to message format.\r\nThis means that connection between patched an unpatched servers will still work except connection will\r\nbe closed and immediately reopened when somebody turns clocks on their unpatched servers back.\r\n\r\nAlso, strength of this protection will improve with https:\/\/github.com\/fernet\/spec\/issues\/12 ."}},"https:\/\/github.com\/bioidiap\/bob.bio.face":{"7a7a007d01ffbd63b1fc3a90c8446d6341a22981":{"url":"https:\/\/api.github.com\/repos\/bioidiap\/bob.bio.face\/commits\/7a7a007d01ffbd63b1fc3a90c8446d6341a22981","html_url":"https:\/\/github.com\/bioidiap\/bob.bio.face\/commit\/7a7a007d01ffbd63b1fc3a90c8446d6341a22981","message":"[replay] improve the score files by adding attack type information","sha":"7a7a007d01ffbd63b1fc3a90c8446d6341a22981","keyword":"replay attack improve","diff":"diff --git a\/bob\/bio\/face\/database\/replay.py b\/bob\/bio\/face\/database\/replay.py\nindex c3a35b40..4d8baee1 100644\n--- a\/bob\/bio\/face\/database\/replay.py\n+++ b\/bob\/bio\/face\/database\/replay.py\n@@ -124,7 +124,7 @@ def objects(self, groups=None, protocol=None, purposes=None, model_ids=None, **k\n                 retval.append(ReplayBioFile(f))\n             else:\n                 temp = ReplayBioFile(f)\n-                temp.client_id = 'attack'\n+                temp.client_id = 'attack\/{}'.format(f.get_attack().attack_device)\n                 retval.append(temp)\n         return retval\n \n","files":{"\/bob\/bio\/face\/database\/replay.py":{"changes":[{"diff":"\n                 retval.append(ReplayBioFile(f))\n             else:\n                 temp = ReplayBioFile(f)\n-                temp.client_id = 'attack'\n+                temp.client_id = 'attack\/{}'.format(f.get_attack().attack_device)\n                 retval.append(temp)\n         return retval\n \n","add":1,"remove":1,"filename":"\/bob\/bio\/face\/database\/replay.py","badparts":["                temp.client_id = 'attack'"],"goodparts":["                temp.client_id = 'attack\/{}'.format(f.get_attack().attack_device)"]}],"source":"\n \"\"\" Replay attack database implementation of bob.bio.base.database.BioDatabase interface. It is an extension of an SQL-based database interface, which directly talks to Replay database, for verification experiments(good to use in bob.bio.base framework). It also implements a kind of hack so that you can run vulnerability analysis with it. \"\"\" from.database import FaceBioFile from bob.bio.base.database import BioDatabase class ReplayBioFile(FaceBioFile): \"\"\"BioFile implementation for the bob.db.replay database\"\"\" def __init__(self, f): super(ReplayBioFile, self).__init__(client_id=f.client_id, path=f.path, file_id=f.id) self._f=f def load(self, directory=None, extension=None): video=self._f.load(directory, extension) return video[10] class ReplayBioDatabase(BioDatabase): \"\"\" Replay attack database implementation of bob.bio.base.database.BioDatabase interface. It is an extension of an SQL-based database interface, which directly talks to Replay database, for verification experiments(good to use in bob.bio.base framework). It also implements a kind of hack so that you can run vulnerability analysis with it. \"\"\" __doc__=__doc__ def __init__(self, **kwargs): super(ReplayBioDatabase, self).__init__(name='replay', **kwargs) from bob.db.replay import Database as LowLevelDatabase self._db=LowLevelDatabase() self.low_level_group_names=('train', 'devel', 'test') self.high_level_group_names=('world', 'dev', 'eval') def protocol_names(self): \"\"\"Returns all registered protocol names Here I am going to hack and double the number of protocols with -licit and -spoof. This is done for running vulnerability analysis\"\"\" names=[p.name +'-licit' for p in self._db.protocols()] names +=[p.name +'-spoof' for p in self._db.protocols()] return names def groups(self): return self.convert_names_to_highlevel( self._db.groups(), self.low_level_group_names, self.high_level_group_names) def annotations(self, file): \"\"\"Will return the bounding box annotation of 10th frame of the video.\"\"\" fn=10 annots=file._f.bbx(directory=self.original_directory) topleft=(annots[fn][2], annots[fn][1]) bottomright=(annots[fn][2] +annots[fn][4], annots[fn][1] +annots[fn][3]) annotations={'topleft': topleft, 'bottomright': bottomright} return annotations def model_ids_with_protocol(self, groups=None, protocol=None, **kwargs): files=self.objects(groups=groups, protocol=protocol, purposes='enroll', **kwargs) return sorted(set(f.client_id for f in files)) def objects(self, groups=None, protocol=None, purposes=None, model_ids=None, **kwargs): if protocol=='.': protocol=None protocol=self.check_parameter_for_validity(protocol, \"protocol\", self.protocol_names(), 'grandtest-licit') groups=self.check_parameters_for_validity(groups, \"group\", self.groups(), self.groups()) purposes=self.check_parameters_for_validity(purposes, \"purpose\",('enroll', 'probe'),('enroll', 'probe')) purposes=list(purposes) groups=self.convert_names_to_lowlevel( groups, self.low_level_group_names, self.high_level_group_names) if '-licit' in protocol: protocol=protocol.replace('-licit', '') if 'probe' in purposes: purposes.remove('probe') purposes.append('real') if len(purposes)==1: model_ids=None elif model_ids: raise NotImplementedError( 'Currently returning both enroll and probe for specific ' 'client(s) in the licit protocol is not supported. ' 'Please specify one purpose only.') elif '-spoof' in protocol: protocol=protocol.replace('-spoof', '') if 'probe' in purposes: purposes.remove('probe') purposes.append('attack') objects=self._db.objects(groups=groups, protocol=protocol, cls=purposes, clients=model_ids, **kwargs) retval=[] for f in objects: if f.is_real(): retval.append(ReplayBioFile(f)) else: temp=ReplayBioFile(f) temp.client_id='attack' retval.append(temp) return retval def arrange_by_client(self, files): client_files={} for file in files: if str(file.client_id) not in client_files: client_files[str(file.client_id)]=[] client_files[str(file.client_id)].append(file) files_by_clients=[] for client in sorted(client_files.keys()): files_by_clients.append(client_files[client]) return files_by_clients ","sourceWithComments":"#!\/usr\/bin\/env python\n# vim: set fileencoding=utf-8 :\n# Pavel Korshunov <pavel.korshunov@idiap.ch>\n# Mon 12 Oct 14:43:22 CEST 2015\n\n\"\"\"\n  Replay attack database implementation of bob.bio.base.database.BioDatabase interface.\n  It is an extension of an SQL-based database interface, which directly talks to Replay database, for\n  verification experiments (good to use in bob.bio.base framework).\n  It also implements a kind of hack so that you can run vulnerability analysis with it.\n\"\"\"\n\nfrom .database import FaceBioFile\nfrom bob.bio.base.database import BioDatabase\n\n\nclass ReplayBioFile(FaceBioFile):\n    \"\"\"BioFile implementation for the bob.db.replay database\"\"\"\n\n    def __init__(self, f):\n        super(ReplayBioFile, self).__init__(client_id=f.client_id, path=f.path, file_id=f.id)\n        self._f = f\n\n    def load(self, directory=None, extension=None):\n        video = self._f.load(directory, extension)\n        # just return the 10th frame.\n        return video[10]\n\n\nclass ReplayBioDatabase(BioDatabase):\n    \"\"\"\n    Replay attack database implementation of bob.bio.base.database.BioDatabase interface.\n    It is an extension of an SQL-based database interface, which directly talks to Replay database, for\n    verification experiments (good to use in bob.bio.base framework).\n    It also implements a kind of hack so that you can run vulnerability analysis with it.\n    \"\"\"\n    __doc__ = __doc__\n\n    def __init__(self, **kwargs):\n        # call base class constructors to open a session to the database\n        super(ReplayBioDatabase, self).__init__(name='replay', **kwargs)\n\n        from bob.db.replay import Database as LowLevelDatabase\n        self._db = LowLevelDatabase()\n\n        self.low_level_group_names = ('train', 'devel', 'test')\n        self.high_level_group_names = ('world', 'dev', 'eval')\n\n    def protocol_names(self):\n        \"\"\"Returns all registered protocol names\n        Here I am going to hack and double the number of protocols\n        with -licit and -spoof. This is done for running vulnerability\n        analysis\"\"\"\n        names = [p.name + '-licit' for p in self._db.protocols()]\n        names += [p.name + '-spoof' for p in self._db.protocols()]\n        return names\n\n    def groups(self):\n        return self.convert_names_to_highlevel(\n            self._db.groups(), self.low_level_group_names, self.high_level_group_names)\n\n    def annotations(self, file):\n        \"\"\"Will return the bounding box annotation of 10th frame of the video.\"\"\"\n        fn = 10  # 10th frame number\n        annots = file._f.bbx(directory=self.original_directory)\n        # bob uses the (y, x) format\n        topleft = (annots[fn][2], annots[fn][1])\n        bottomright = (annots[fn][2] + annots[fn][4], annots[fn][1] + annots[fn][3])\n        annotations = {'topleft': topleft, 'bottomright': bottomright}\n        return annotations\n\n    def model_ids_with_protocol(self, groups=None, protocol=None, **kwargs):\n        # since the low-level API does not support verification straight-forward-ly, we improvise.\n        files = self.objects(groups=groups, protocol=protocol, purposes='enroll', **kwargs)\n        return sorted(set(f.client_id for f in files))\n\n    def objects(self, groups=None, protocol=None, purposes=None, model_ids=None, **kwargs):\n        if protocol == '.':\n            protocol = None\n        protocol = self.check_parameter_for_validity(protocol, \"protocol\", self.protocol_names(), 'grandtest-licit')\n        groups = self.check_parameters_for_validity(groups, \"group\", self.groups(), self.groups())\n        purposes = self.check_parameters_for_validity(purposes, \"purpose\", ('enroll', 'probe'), ('enroll', 'probe'))\n        purposes = list(purposes)\n        groups = self.convert_names_to_lowlevel(\n            groups, self.low_level_group_names, self.high_level_group_names)\n\n        # protocol licit is not defined in the low level API\n        # so do a hack here.\n        if '-licit' in protocol:\n            # for licit we return the grandtest protocol\n            protocol = protocol.replace('-licit', '')\n            # The low-level API has only \"attack\", \"real\", \"enroll\" and \"probe\"\n            # should translate to \"real\" or \"attack\" depending on the protocol.\n            # enroll does not to change.\n            if 'probe' in purposes:\n                purposes.remove('probe')\n                purposes.append('real')\n                if len(purposes) == 1:\n                    # making the model_ids to None will return all clients which make\n                    # the impostor data also available.\n                    model_ids = None\n                elif model_ids:\n                    raise NotImplementedError(\n                       'Currently returning both enroll and probe for specific '\n                       'client(s) in the licit protocol is not supported. '\n                       'Please specify one purpose only.')\n        elif '-spoof' in protocol:\n            protocol = protocol.replace('-spoof', '')\n            # you need to replace probe with attack and real for the spoof protocols.\n            # You can add the real here also to create positives scores also\n            # but usually you get these scores when you run the licit protocol\n            if 'probe' in purposes:\n                purposes.remove('probe')\n                purposes.append('attack')\n\n        # now, query the actual Replay database\n        objects = self._db.objects(groups=groups, protocol=protocol, cls=purposes, clients=model_ids, **kwargs)\n\n        # make sure to return BioFile representation of a file, not the database one\n        # also make sure you replace client ids with spoof\/metatdata1\/metadata2\/...\n        retval = []\n        for f in objects:\n            if f.is_real():\n                retval.append(ReplayBioFile(f))\n            else:\n                temp = ReplayBioFile(f)\n                temp.client_id = 'attack'\n                retval.append(temp)\n        return retval\n\n    def arrange_by_client(self, files):\n        client_files = {}\n        for file in files:\n            if str(file.client_id) not in client_files:\n                client_files[str(file.client_id)] = []\n            client_files[str(file.client_id)].append(file)\n\n        files_by_clients = []\n        for client in sorted(client_files.keys()):\n            files_by_clients.append(client_files[client])\n        return files_by_clients\n"}},"msg":"[replay] improve the score files by adding attack type information"},"89b9cc0f953fbabc8d8069aec93166f0fbc36ee9":{"url":"https:\/\/api.github.com\/repos\/bioidiap\/bob.bio.face\/commits\/89b9cc0f953fbabc8d8069aec93166f0fbc36ee9","html_url":"https:\/\/github.com\/bioidiap\/bob.bio.face\/commit\/89b9cc0f953fbabc8d8069aec93166f0fbc36ee9","sha":"89b9cc0f953fbabc8d8069aec93166f0fbc36ee9","keyword":"replay attack vulnerable","diff":"diff --git a\/bob\/bio\/face\/config\/database\/replay.py b\/bob\/bio\/face\/config\/database\/replay_licit.py\nsimilarity index 62%\nrename from bob\/bio\/face\/config\/database\/replay.py\nrename to bob\/bio\/face\/config\/database\/replay_licit.py\nindex 3a424caa..a200303b 100644\n--- a\/bob\/bio\/face\/config\/database\/replay.py\n+++ b\/bob\/bio\/face\/config\/database\/replay_licit.py\n@@ -7,18 +7,14 @@\n \n replay_attack_directory = rc[\"bob.db.replay.directory\"]\n \n-replay_licit = DatabaseConnector(\n+# Licit\n+database = DatabaseConnector(\n     ReplayBioDatabase(\n         original_directory=replay_attack_directory,\n         original_extension=\".mov\",\n         protocol=\"grandtest-licit\",\n-    )\n+    ),\n+    annotation_type=\"bounding-box\",\n+    fixed_positions=None,\n )\n \n-replay_spoof = DatabaseConnector(\n-    ReplayBioDatabase(\n-        original_directory=replay_attack_directory,\n-        original_extension=\".mov\",\n-        protocol=\"grandtest-spoof\",\n-    )\n-)\ndiff --git a\/bob\/bio\/face\/config\/database\/replay_spoof.py b\/bob\/bio\/face\/config\/database\/replay_spoof.py\nnew file mode 100644\nindex 00000000..2cdab86c\n--- \/dev\/null\n+++ b\/bob\/bio\/face\/config\/database\/replay_spoof.py\n@@ -0,0 +1,21 @@\n+#!\/usr\/bin\/env python\n+\n+from bob.bio.face.database import ReplayBioDatabase\n+from bob.bio.base.pipelines.vanilla_biometrics import DatabaseConnector\n+from bob.extension import rc\n+\n+\n+replay_attack_directory = rc[\"bob.db.replay.directory\"]\n+\n+database = DatabaseConnector(\n+    ReplayBioDatabase(\n+        original_directory=replay_attack_directory,\n+        original_extension=\".mov\",\n+        protocol=\"grandtest-spoof\",\n+    ),\n+    annotation_type=\"bounding-box\",\n+    fixed_positions=None,\n+    # Only compare with spoofs from the same target identity\n+    allow_scoring_with_all_biometric_references=False,\n+)\n+\ndiff --git a\/bob\/bio\/face\/config\/database\/replaymobile.py b\/bob\/bio\/face\/config\/database\/replaymobile_licit.py\nsimilarity index 61%\nrename from bob\/bio\/face\/config\/database\/replaymobile.py\nrename to bob\/bio\/face\/config\/database\/replaymobile_licit.py\nindex 8a030247..1ed52050 100644\n--- a\/bob\/bio\/face\/config\/database\/replaymobile.py\n+++ b\/bob\/bio\/face\/config\/database\/replaymobile_licit.py\n@@ -7,18 +7,12 @@\n \n replay_mobile_directory = rc[\"bob.db.replay_mobile.directory\"]\n \n-replaymobile_licit = DatabaseConnector(\n+database = DatabaseConnector(\n     ReplayMobileBioDatabase(\n         original_directory=replay_mobile_directory,\n         original_extension=\".mov\",\n         protocol=\"grandtest-licit\",\n-    )\n-)\n-\n-replaymobile_spoof = DatabaseConnector(\n-    ReplayMobileBioDatabase(\n-        original_directory=replay_mobile_directory,\n-        original_extension=\".mov\",\n-        protocol=\"grandtest-spoof\",\n-    )\n+    ),\n+    annotation_type=\"bounding-box\",\n+    fixed_positions=None,\n )\ndiff --git a\/bob\/bio\/face\/config\/database\/replaymobile_spoof.py b\/bob\/bio\/face\/config\/database\/replaymobile_spoof.py\nnew file mode 100644\nindex 00000000..3f9d75b7\n--- \/dev\/null\n+++ b\/bob\/bio\/face\/config\/database\/replaymobile_spoof.py\n@@ -0,0 +1,20 @@\n+#!\/usr\/bin\/env python\n+\n+from bob.bio.face.database import ReplayMobileBioDatabase\n+from bob.bio.base.pipelines.vanilla_biometrics import DatabaseConnector\n+from bob.extension import rc\n+\n+\n+replay_mobile_directory = rc[\"bob.db.replay_mobile.directory\"]\n+\n+database = DatabaseConnector(\n+    ReplayMobileBioDatabase(\n+        original_directory=replay_mobile_directory,\n+        original_extension=\".mov\",\n+        protocol=\"grandtest-spoof\",\n+    ),\n+    annotation_type=\"bounding-box\",\n+    fixed_positions=None,\n+    # Only compare with spoofs from the same target identity\n+    allow_scoring_with_all_biometric_references=False,\n+)\ndiff --git a\/setup.py b\/setup.py\nindex b73abd87..16511fd4 100644\n--- a\/setup.py\n+++ b\/setup.py\n@@ -35,7 +35,7 @@\n \n from setuptools import setup, dist\n \n-dist.Distribution(dict(setup_requires=['bob.extension']))\n+dist.Distribution(dict(setup_requires=[\"bob.extension\"]))\n \n from bob.extension.utils import load_requirements, find_packages\n \n@@ -44,35 +44,29 @@\n # The only thing we do in this file is to call the setup() function with all\n # parameters that define our package.\n setup(\n-\n     # This is the basic information about your project. Modify all this\n     # information before releasing code publicly.\n-    name='bob.bio.face',\n+    name=\"bob.bio.face\",\n     version=open(\"version.txt\").read().rstrip(),\n-    description='Tools for running face recognition experiments',\n-\n-    url='https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face',\n-    license='BSD',\n-    author='Manuel Gunther',\n-    author_email='siebenkopf@googlemail.com',\n-    keywords='bob, biometric recognition, evaluation',\n-\n+    description=\"Tools for running face recognition experiments\",\n+    url=\"https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face\",\n+    license=\"BSD\",\n+    author=\"Manuel Gunther\",\n+    author_email=\"siebenkopf@googlemail.com\",\n+    keywords=\"bob, biometric recognition, evaluation\",\n     # If you have a better, long description of your package, place it on the\n     # 'doc' directory and then hook it here\n-    long_description=open('README.rst').read(),\n-\n+    long_description=open(\"README.rst\").read(),\n     # This line is required for any distutils based packaging.\n     packages=find_packages(),\n     include_package_data=True,\n     zip_safe=False,\n-\n     # This line defines which packages should be installed when you \"install\"\n     # this package. All packages that are mentioned here, but are not installed\n     # on the current system will be installed locally and only visible to the\n     # scripts of this package. Don't worry - You won't need administrative\n     # privileges when using buildout.\n     install_requires=install_requires,\n-\n     # Your project should be called something like 'bob.<foo>' or\n     # 'bob.<foo>.<bar>'. To implement this correctly and still get all your\n     # packages to be imported w\/o problems, you need to implement namespaces\n@@ -83,8 +77,6 @@\n     # Our database packages are good examples of namespace implementations\n     # using several layers. You can check them out here:\n     # https:\/\/www.idiap.ch\/software\/bob\/packages\n-\n-\n     # This entry defines which scripts you will have inside the 'bin' directory\n     # once you install the package (or run 'bin\/buildout'). The order of each\n     # entry under 'console_scripts' is like this:\n@@ -100,118 +92,99 @@\n     # In this simple example we will create a single program that will print\n     # the version of bob.\n     entry_points={\n-\n         # scripts should be declared using this entry:\n-        'console_scripts': [\n+        \"console_scripts\": [],\n+        \"bob.bio.database\": [\n+            \"arface            = bob.bio.face.config.database.arface:database\",\n+            \"atnt              = bob.bio.face.config.database.atnt:database\",\n+            \"gbu               = bob.bio.face.config.database.gbu:database\",\n+            \"ijbc-11              = bob.bio.face.config.database.ijbc:database\",\n+            \"lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database\",\n+            \"lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database\",\n+            \"mobio-male       = bob.bio.face.config.database.mobio_male:database\",\n+            \"mobio-all        = bob.bio.face.config.database.mobio_all:database\",\n+            \"multipie          = bob.bio.face.config.database.multipie:database\",\n+            \"multipie-pose     = bob.bio.face.config.database.multipie_pose:database\",\n+            \"replay-img-licit  = bob.bio.face.config.database.replay:replay_licit\",\n+            \"replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof\",\n+            \"replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit\",\n+            \"replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof\",\n+            \"fargo  = bob.bio.face.config.database.fargo:database\",\n         ],\n-\n-        'bob.bio.database': [\n-            'arface            = bob.bio.face.config.database.arface:database',\n-            'atnt              = bob.bio.face.config.database.atnt:database',\n-            'gbu               = bob.bio.face.config.database.gbu:database',\n-\n-            'ijbc-11              = bob.bio.face.config.database.ijbc:database',\n-\n-            'lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database',\n-            'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database',\n-            'mobio-male       = bob.bio.face.config.database.mobio_male:database',\n-            'mobio-all        = bob.bio.face.config.database.mobio_all:database',\n-            'multipie          = bob.bio.face.config.database.multipie:database',\n-            'multipie-pose     = bob.bio.face.config.database.multipie_pose:database',\n-            'replay-img-licit  = bob.bio.face.config.database.replay:replay_licit',\n-            'replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof',\n-            'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit',\n-            'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof',\n-            'fargo  = bob.bio.face.config.database.fargo:database',\n+        \"bob.bio.annotator\": [\n+            \"facedetect               = bob.bio.face.config.annotator.facedetect:annotator\",\n+            \"facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator\",\n+            \"flandmark                = bob.bio.face.config.annotator.flandmark:annotator\",\n+            \"mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator\",\n         ],\n-\n-        'bob.bio.annotator': [\n-            'facedetect               = bob.bio.face.config.annotator.facedetect:annotator',\n-            'facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator',\n-            'flandmark                = bob.bio.face.config.annotator.flandmark:annotator',\n-            'mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator',\n+        \"bob.bio.transformer\": [\n+            \"facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer\",\n+            \"facedetect = bob.bio.face.config.annotator.facedetect:transformer\",\n+            \"flandmark = bob.bio.face.config.annotator.flandmark:annotator\",\n+            \"mtcnn = bob.bio.face.config.annotator.mtcnn:transformer\",\n+            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer\",\n+            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer\",\n+            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer\",\n+            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer\",\n+            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer\",\n+            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer\",\n+            \"gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer\",\n+            \"lgbphs = bob.bio.face.config.baseline.lgbphs:transformer\",\n+            \"dummy = bob.bio.face.config.baseline.dummy:transformer\",\n         ],\n-\n-        'bob.bio.transformer':[\n-          'facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer',\n-          'facedetect = bob.bio.face.config.annotator.facedetect:transformer',\n-          'flandmark = bob.bio.face.config.annotator.flandmark:annotator',\n-          'mtcnn = bob.bio.face.config.annotator.mtcnn:transformer',\n-          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer',\n-          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer',\n-          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer',\n-          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer',\n-          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer',\n-          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer',\n-          'gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer',\n-          'lgbphs = bob.bio.face.config.baseline.lgbphs:transformer',\n-          'dummy = bob.bio.face.config.baseline.dummy:transformer',\n+        # baselines\n+        \"bob.bio.pipeline\": [\n+            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline\",\n+            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline\",\n+            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline\",\n+            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline\",\n+            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline\",\n+            \"gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline\",\n+            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline\",\n+            \"lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline\",\n+            \"lda = bob.bio.face.config.baseline.lda:pipeline\",\n+            \"dummy = bob.bio.face.config.baseline.dummy:pipeline\",\n         ],\n-\n-        #baselines\n-        'bob.bio.pipeline':[\n-          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline',\n-          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline',\n-          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline',\n-          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline',\n-          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline',\n-          'gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline',\n-          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline',\n-          'lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline',\n-          'lda = bob.bio.face.config.baseline.lda:pipeline',\n-          'dummy = bob.bio.face.config.baseline.dummy:pipeline',\n+        \"bob.bio.config\": [\n+            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg\",\n+            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface\",\n+            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface\",\n+            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb\",\n+            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb\",\n+            \"gabor_graph = bob.bio.face.config.baseline.gabor_graph\",\n+            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface\",\n+            \"lgbphs = bob.bio.face.config.baseline.lgbphs\",\n+            \"lda = bob.bio.face.config.baseline.lda\",\n+            \"arface            = bob.bio.face.config.database.arface\",\n+            \"atnt              = bob.bio.face.config.database.atnt\",\n+            \"gbu               = bob.bio.face.config.database.gbu\",\n+            \"ijbc-11              = bob.bio.face.config.database.ijbc\",\n+            \"lfw-restricted    = bob.bio.face.config.database.lfw_restricted\",\n+            \"lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted\",\n+            \"mobio-male       = bob.bio.face.config.database.mobio_male\",\n+            \"mobio-all        = bob.bio.face.config.database.mobio_all\",\n+            \"multipie          = bob.bio.face.config.database.multipie\",\n+            \"multipie-pose     = bob.bio.face.config.database.multipie_pose\",\n+            \"replay-img-licit  = bob.bio.face.config.database.replay_licit\",\n+            \"replay-img-spoof  = bob.bio.face.config.database.replay_spoof\",\n+            \"replaymobile-img-licit  = bob.bio.face.config.database.replaymobile_licit\",\n+            \"replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile_spoof\",\n+            \"fargo  = bob.bio.face.config.database.fargo\",\n         ],\n-\n-        'bob.bio.config': [\n-          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg',\n-          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface',\n-          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface',\n-          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb',\n-          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb',\n-          'gabor_graph = bob.bio.face.config.baseline.gabor_graph',\n-          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface',\n-          'lgbphs = bob.bio.face.config.baseline.lgbphs',\n-          'lda = bob.bio.face.config.baseline.lda',\n-\n-\n-\n-          'arface            = bob.bio.face.config.database.arface',\n-          'atnt              = bob.bio.face.config.database.atnt',\n-          'gbu               = bob.bio.face.config.database.gbu',\n-\n-          'ijbc-11              = bob.bio.face.config.database.ijbc',\n-\n-          'lfw-restricted    = bob.bio.face.config.database.lfw_restricted',\n-          'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted',\n-          'mobio-male       = bob.bio.face.config.database.mobio_male',\n-          'mobio-all        = bob.bio.face.config.database.mobio_all',\n-          'multipie          = bob.bio.face.config.database.multipie',\n-          'multipie-pose     = bob.bio.face.config.database.multipie_pose',\n-          'replay-img-licit  = bob.bio.face.config.database.replay',\n-          'replay-img-spoof  = bob.bio.face.config.database.replay',\n-          'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile',\n-          'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile',\n-\n-          'fargo  = bob.bio.face.config.database.fargo',\n-        ],\n-\n-        'bob.bio.cli': [\n-          'display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations',\n+        \"bob.bio.cli\": [\n+            \"display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations\",\n         ],\n-\n-\n     },\n-\n     # Classifiers are important if you plan to distribute this package through\n     # PyPI. You can find the complete list of classifiers that are valid and\n     # useful here (http:\/\/pypi.python.org\/pypi?%3Aaction=list_classifiers).\n     classifiers=[\n-        'Framework :: Bob',\n-        'Development Status :: 3 - Alpha',\n-        'Intended Audience :: Developers',\n-        'License :: OSI Approved :: BSD License',\n-        'Natural Language :: English',\n-        'Programming Language :: Python',\n-        'Topic :: Scientific\/Engineering :: Artificial Intelligence',\n+        \"Framework :: Bob\",\n+        \"Development Status :: 3 - Alpha\",\n+        \"Intended Audience :: Developers\",\n+        \"License :: OSI Approved :: BSD License\",\n+        \"Natural Language :: English\",\n+        \"Programming Language :: Python\",\n+        \"Topic :: Scientific\/Engineering :: Artificial Intelligence\",\n     ],\n )\n","message":"","files":{"\/bob\/bio\/face\/config\/database\/replay.py":{"changes":[{"diff":"\n \n replay_attack_directory = rc[\"bob.db.replay.directory\"]\n \n-replay_licit = DatabaseConnector(\n+# Licit\n+database = DatabaseConnector(\n     ReplayBioDatabase(\n         original_directory=replay_attack_directory,\n         original_extension=\".mov\",\n         protocol=\"grandtest-licit\",\n-    )\n+    ),\n+    annotation_type=\"bounding-box\",\n+    fixed_positions=None,\n )\n \n-replay_spoof = DatabaseConnector(\n-    ReplayBioDatabase(\n-        original_directory=replay_attack_directory,\n-        original_extension=\".mov\",\n-        protocol=\"grandtest-spoof\",\n-    )\n-)","add":5,"remove":9,"filename":"\/bob\/bio\/face\/config\/database\/replay.py","badparts":["replay_licit = DatabaseConnector(","    )","replay_spoof = DatabaseConnector(","    ReplayBioDatabase(","        original_directory=replay_attack_directory,","        original_extension=\".mov\",","        protocol=\"grandtest-spoof\",","    )",")"],"goodparts":["database = DatabaseConnector(","    ),","    annotation_type=\"bounding-box\",","    fixed_positions=None,"]}],"source":"\n from bob.bio.face.database import ReplayBioDatabase from bob.bio.base.pipelines.vanilla_biometrics import DatabaseConnector from bob.extension import rc replay_attack_directory=rc[\"bob.db.replay.directory\"] replay_licit=DatabaseConnector( ReplayBioDatabase( original_directory=replay_attack_directory, original_extension=\".mov\", protocol=\"grandtest-licit\", ) ) replay_spoof=DatabaseConnector( ReplayBioDatabase( original_directory=replay_attack_directory, original_extension=\".mov\", protocol=\"grandtest-spoof\", ) ) ","sourceWithComments":"#!\/usr\/bin\/env python\n\nfrom bob.bio.face.database import ReplayBioDatabase\nfrom bob.bio.base.pipelines.vanilla_biometrics import DatabaseConnector\nfrom bob.extension import rc\n\n\nreplay_attack_directory = rc[\"bob.db.replay.directory\"]\n\nreplay_licit = DatabaseConnector(\n    ReplayBioDatabase(\n        original_directory=replay_attack_directory,\n        original_extension=\".mov\",\n        protocol=\"grandtest-licit\",\n    )\n)\n\nreplay_spoof = DatabaseConnector(\n    ReplayBioDatabase(\n        original_directory=replay_attack_directory,\n        original_extension=\".mov\",\n        protocol=\"grandtest-spoof\",\n    )\n)\n"},"\/bob\/bio\/face\/config\/database\/replaymobile.py":{"changes":[{"diff":"\n \n replay_mobile_directory = rc[\"bob.db.replay_mobile.directory\"]\n \n-replaymobile_licit = DatabaseConnector(\n+database = DatabaseConnector(\n     ReplayMobileBioDatabase(\n         original_directory=replay_mobile_directory,\n         original_extension=\".mov\",\n         protocol=\"grandtest-licit\",\n-    )\n-)\n-\n-replaymobile_spoof = DatabaseConnector(\n-    ReplayMobileBioDatabase(\n-        original_directory=replay_mobile_directory,\n-        original_extension=\".mov\",\n-        protocol=\"grandtest-spoof\",\n-    )\n+    ),\n+    annotation_type=\"bounding-box\",\n+    fixed_positions=None,\n","add":4,"remove":10,"filename":"\/bob\/bio\/face\/config\/database\/replaymobile.py","badparts":["replaymobile_licit = DatabaseConnector(","    )",")","replaymobile_spoof = DatabaseConnector(","    ReplayMobileBioDatabase(","        original_directory=replay_mobile_directory,","        original_extension=\".mov\",","        protocol=\"grandtest-spoof\",","    )"],"goodparts":["database = DatabaseConnector(","    ),","    annotation_type=\"bounding-box\",","    fixed_positions=None,"]}],"source":"\n from bob.bio.face.database import ReplayMobileBioDatabase from bob.bio.base.pipelines.vanilla_biometrics import DatabaseConnector from bob.extension import rc replay_mobile_directory=rc[\"bob.db.replay_mobile.directory\"] replaymobile_licit=DatabaseConnector( ReplayMobileBioDatabase( original_directory=replay_mobile_directory, original_extension=\".mov\", protocol=\"grandtest-licit\", ) ) replaymobile_spoof=DatabaseConnector( ReplayMobileBioDatabase( original_directory=replay_mobile_directory, original_extension=\".mov\", protocol=\"grandtest-spoof\", ) ) ","sourceWithComments":"#!\/usr\/bin\/env python\n\nfrom bob.bio.face.database import ReplayMobileBioDatabase\nfrom bob.bio.base.pipelines.vanilla_biometrics import DatabaseConnector\nfrom bob.extension import rc\n\n\nreplay_mobile_directory = rc[\"bob.db.replay_mobile.directory\"]\n\nreplaymobile_licit = DatabaseConnector(\n    ReplayMobileBioDatabase(\n        original_directory=replay_mobile_directory,\n        original_extension=\".mov\",\n        protocol=\"grandtest-licit\",\n    )\n)\n\nreplaymobile_spoof = DatabaseConnector(\n    ReplayMobileBioDatabase(\n        original_directory=replay_mobile_directory,\n        original_extension=\".mov\",\n        protocol=\"grandtest-spoof\",\n    )\n)\n"},"\/setup.py":{"changes":[{"diff":"\n \n from setuptools import setup, dist\n \n-dist.Distribution(dict(setup_requires=['bob.extension']))\n+dist.Distribution(dict(setup_requires=[\"bob.extension\"]))\n \n from bob.extension.utils import load_requirements, find_packages\n \n","add":1,"remove":1,"filename":"\/setup.py","badparts":["dist.Distribution(dict(setup_requires=['bob.extension']))"],"goodparts":["dist.Distribution(dict(setup_requires=[\"bob.extension\"]))"]},{"diff":"\n # parameters that define our package.\n setup(\n-\n     # This is the basic information about your project. Modify all this\n     # information before releasing code publicly.\n-    name='bob.bio.face',\n+    name=\"bob.bio.face\",\n     version=open(\"version.txt\").read().rstrip(),\n-    description='Tools for running face recognition experiments',\n-\n-    url='https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face',\n-    license='BSD',\n-    author='Manuel Gunther',\n-    author_email='siebenkopf@googlemail.com',\n-    keywords='bob, biometric recognition, evaluation',\n-\n+    description=\"Tools for running face recognition experiments\",\n+    url=\"https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face\",\n+    license=\"BSD\",\n+    author=\"Manuel Gunther\",\n+    author_email=\"siebenkopf@googlemail.com\",\n+    keywords=\"bob, biometric recognition, evaluation\",\n     # If you have a better, long description of your package, place it on the\n     # 'doc' directory and then hook it here\n-    long_description=open('README.rst').read(),\n-\n+    long_description=open(\"README.rst\").read(),\n     # This line is required for any distutils based packaging.\n     packages=find_packages(),\n     include_package_data=True,\n     zip_safe=False,\n-\n     # This line defines which packages should be installed when you \"install\"\n     # this package. All packages that are mentioned here, but are not installed\n     # on the current system will be installed locally and only visible to the\n     # scripts of this package. Don't worry - You won't need administrative\n     # privileges when using buildout.\n     install_requires=install_requires,\n-\n     # Your project should be called something like 'bob.<foo>' or\n     # 'bob.<foo>.<bar>'. To implement this correctly and still get all your\n     # packages to be imported w\/o problems, you need to implement namespaces\n","add":8,"remove":14,"filename":"\/setup.py","badparts":["    name='bob.bio.face',","    description='Tools for running face recognition experiments',","    url='https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face',","    license='BSD',","    author='Manuel Gunther',","    author_email='siebenkopf@googlemail.com',","    keywords='bob, biometric recognition, evaluation',","    long_description=open('README.rst').read(),"],"goodparts":["    name=\"bob.bio.face\",","    description=\"Tools for running face recognition experiments\",","    url=\"https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face\",","    license=\"BSD\",","    author=\"Manuel Gunther\",","    author_email=\"siebenkopf@googlemail.com\",","    keywords=\"bob, biometric recognition, evaluation\",","    long_description=open(\"README.rst\").read(),"]},{"diff":"\n     # the version of bob.\n     entry_points={\n-\n         # scripts should be declared using this entry:\n-        'console_scripts': [\n+        \"console_scripts\": [],\n+        \"bob.bio.database\": [\n+            \"arface            = bob.bio.face.config.database.arface:database\",\n+            \"atnt              = bob.bio.face.config.database.atnt:database\",\n+            \"gbu               = bob.bio.face.config.database.gbu:database\",\n+            \"ijbc-11              = bob.bio.face.config.database.ijbc:database\",\n+            \"lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database\",\n+            \"lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database\",\n+            \"mobio-male       = bob.bio.face.config.database.mobio_male:database\",\n+            \"mobio-all        = bob.bio.face.config.database.mobio_all:database\",\n+            \"multipie          = bob.bio.face.config.database.multipie:database\",\n+            \"multipie-pose     = bob.bio.face.config.database.multipie_pose:database\",\n+            \"replay-img-licit  = bob.bio.face.config.database.replay:replay_licit\",\n+            \"replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof\",\n+            \"replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit\",\n+            \"replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof\",\n+            \"fargo  = bob.bio.face.config.database.fargo:database\",\n         ],\n-\n-        'bob.bio.database': [\n-            'arface            = bob.bio.face.config.database.arface:database',\n-            'atnt              = bob.bio.face.config.database.atnt:database',\n-            'gbu               = bob.bio.face.config.database.gbu:database',\n-\n-            'ijbc-11              = bob.bio.face.config.database.ijbc:database',\n-\n-            'lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database',\n-            'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database',\n-            'mobio-male       = bob.bio.face.config.database.mobio_male:database',\n-            'mobio-all        = bob.bio.face.config.database.mobio_all:database',\n-            'multipie          = bob.bio.face.config.database.multipie:database',\n-            'multipie-pose     = bob.bio.face.config.database.multipie_pose:database',\n-            'replay-img-licit  = bob.bio.face.config.database.replay:replay_licit',\n-            'replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof',\n-            'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit',\n-            'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof',\n-            'fargo  = bob.bio.face.config.database.fargo:database',\n+        \"bob.bio.annotator\": [\n+            \"facedetect               = bob.bio.face.config.annotator.facedetect:annotator\",\n+            \"facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator\",\n+            \"flandmark                = bob.bio.face.config.annotator.flandmark:annotator\",\n+            \"mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator\",\n         ],\n-\n-        'bob.bio.annotator': [\n-            'facedetect               = bob.bio.face.config.annotator.facedetect:annotator',\n-            'facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator',\n-            'flandmark                = bob.bio.face.config.annotator.flandmark:annotator',\n-            'mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator',\n+        \"bob.bio.transformer\": [\n+            \"facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer\",\n+            \"facedetect = bob.bio.face.config.annotator.facedetect:transformer\",\n+            \"flandmark = bob.bio.face.config.annotator.flandmark:annotator\",\n+            \"mtcnn = bob.bio.face.config.annotator.mtcnn:transformer\",\n+            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer\",\n+            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer\",\n+            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer\",\n+            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer\",\n+            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer\",\n+            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer\",\n+            \"gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer\",\n+            \"lgbphs = bob.bio.face.config.baseline.lgbphs:transformer\",\n+            \"dummy = bob.bio.face.config.baseline.dummy:transformer\",\n         ],\n-\n-        'bob.bio.transformer':[\n-          'facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer',\n-          'facedetect = bob.bio.face.config.annotator.facedetect:transformer',\n-          'flandmark = bob.bio.face.config.annotator.flandmark:annotator',\n-          'mtcnn = bob.bio.face.config.annotator.mtcnn:transformer',\n-          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer',\n-          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer',\n-          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer',\n-          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer',\n-          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer',\n-          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer',\n-          'gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer',\n-          'lgbphs = bob.bio.face.config.baseline.lgbphs:transformer',\n-          'dummy = bob.bio.face.config.baseline.dummy:transformer',\n+        # baselines\n+        \"bob.bio.pipeline\": [\n+            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline\",\n+            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline\",\n+            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline\",\n+            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline\",\n+            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline\",\n+            \"gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline\",\n+            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline\",\n+            \"lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline\",\n+            \"lda = bob.bio.face.config.baseline.lda:pipeline\",\n+            \"dummy = bob.bio.face.config.baseline.dummy:pipeline\",\n         ],\n-\n-        #baselines\n-        'bob.bio.pipeline':[\n-          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline',\n-          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline',\n-          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline',\n-          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline',\n-          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline',\n-          'gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline',\n-          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline',\n-          'lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline',\n-          'lda = bob.bio.face.config.baseline.lda:pipeline',\n-          'dummy = bob.bio.face.config.baseline.dummy:pipeline',\n+        \"bob.bio.config\": [\n+            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg\",\n+            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface\",\n+            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface\",\n+            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb\",\n+            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb\",\n+            \"gabor_graph = bob.bio.face.config.baseline.gabor_graph\",\n+            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface\",\n+            \"lgbphs = bob.bio.face.config.baseline.lgbphs\",\n+            \"lda = bob.bio.face.config.baseline.lda\",\n+            \"arface            = bob.bio.face.config.database.arface\",\n+            \"atnt              = bob.bio.face.config.database.atnt\",\n+            \"gbu               = bob.bio.face.config.database.gbu\",\n+            \"ijbc-11              = bob.bio.face.config.database.ijbc\",\n+            \"lfw-restricted    = bob.bio.face.config.database.lfw_restricted\",\n+            \"lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted\",\n+            \"mobio-male       = bob.bio.face.config.database.mobio_male\",\n+            \"mobio-all        = bob.bio.face.config.database.mobio_all\",\n+            \"multipie          = bob.bio.face.config.database.multipie\",\n+            \"multipie-pose     = bob.bio.face.config.database.multipie_pose\",\n+            \"replay-img-licit  = bob.bio.face.config.database.replay_licit\",\n+            \"replay-img-spoof  = bob.bio.face.config.database.replay_spoof\",\n+            \"replaymobile-img-licit  = bob.bio.face.config.database.replaymobile_licit\",\n+            \"replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile_spoof\",\n+            \"fargo  = bob.bio.face.config.database.fargo\",\n         ],\n-\n-        'bob.bio.config': [\n-          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg',\n-          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface',\n-          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface',\n-          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb',\n-          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb',\n-          'gabor_graph = bob.bio.face.config.baseline.gabor_graph',\n-          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface',\n-          'lgbphs = bob.bio.face.config.baseline.lgbphs',\n-          'lda = bob.bio.face.config.baseline.lda',\n-\n-\n-\n-          'arface            = bob.bio.face.config.database.arface',\n-          'atnt              = bob.bio.face.config.database.atnt',\n-          'gbu               = bob.bio.face.config.database.gbu',\n-\n-          'ijbc-11              = bob.bio.face.config.database.ijbc',\n-\n-          'lfw-restricted    = bob.bio.face.config.database.lfw_restricted',\n-          'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted',\n-          'mobio-male       = bob.bio.face.config.database.mobio_male',\n-          'mobio-all        = bob.bio.face.config.database.mobio_all',\n-          'multipie          = bob.bio.face.config.database.multipie',\n-          'multipie-pose     = bob.bio.face.config.database.multipie_pose',\n-          'replay-img-licit  = bob.bio.face.config.database.replay',\n-          'replay-img-spoof  = bob.bio.face.config.database.replay',\n-          'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile',\n-          'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile',\n-\n-          'fargo  = bob.bio.face.config.database.fargo',\n-        ],\n-\n-        'bob.bio.cli': [\n-          'display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations',\n+        \"bob.bio.cli\": [\n+            \"display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations\",\n         ],\n-\n-\n     },\n-\n     # Classifiers are important if you plan to distribute this package through\n     # PyPI. You can find the complete list of classifiers that are valid and\n     # useful here (http:\/\/pypi.python.org\/pypi?%3Aaction=list_classifiers).\n     classifiers=[\n-        'Framework :: Bob',\n-        'Development Status :: 3 - Alpha',\n-        'Intended Audience :: Developers',\n-        'License :: OSI Approved :: BSD License',\n-        'Natural Language :: English',\n-        'Programming Language :: Python',\n-        'Topic :: Scientific\/Engineering :: Artificial Intelligence',\n+        \"Framework :: Bob\",\n+        \"Development Status :: 3 - Alpha\",\n+        \"Intended Audience :: Developers\",\n+        \"License :: OSI Approved :: BSD License\",\n+        \"Natural Language :: English\",\n+        \"Programming Language :: Python\",\n+        \"Topic :: Scientific\/Engineering :: Artificial Intelligence\",\n     ],\n )\n","add":82,"remove":101,"filename":"\/setup.py","badparts":["        'console_scripts': [","        'bob.bio.database': [","            'arface            = bob.bio.face.config.database.arface:database',","            'atnt              = bob.bio.face.config.database.atnt:database',","            'gbu               = bob.bio.face.config.database.gbu:database',","            'ijbc-11              = bob.bio.face.config.database.ijbc:database',","            'lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database',","            'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database',","            'mobio-male       = bob.bio.face.config.database.mobio_male:database',","            'mobio-all        = bob.bio.face.config.database.mobio_all:database',","            'multipie          = bob.bio.face.config.database.multipie:database',","            'multipie-pose     = bob.bio.face.config.database.multipie_pose:database',","            'replay-img-licit  = bob.bio.face.config.database.replay:replay_licit',","            'replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof',","            'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit',","            'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof',","            'fargo  = bob.bio.face.config.database.fargo:database',","        'bob.bio.annotator': [","            'facedetect               = bob.bio.face.config.annotator.facedetect:annotator',","            'facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator',","            'flandmark                = bob.bio.face.config.annotator.flandmark:annotator',","            'mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator',","        'bob.bio.transformer':[","          'facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer',","          'facedetect = bob.bio.face.config.annotator.facedetect:transformer',","          'flandmark = bob.bio.face.config.annotator.flandmark:annotator',","          'mtcnn = bob.bio.face.config.annotator.mtcnn:transformer',","          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer',","          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer',","          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer',","          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer',","          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer',","          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer',","          'gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer',","          'lgbphs = bob.bio.face.config.baseline.lgbphs:transformer',","          'dummy = bob.bio.face.config.baseline.dummy:transformer',","        'bob.bio.pipeline':[","          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline',","          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline',","          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline',","          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline',","          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline',","          'gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline',","          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline',","          'lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline',","          'lda = bob.bio.face.config.baseline.lda:pipeline',","          'dummy = bob.bio.face.config.baseline.dummy:pipeline',","        'bob.bio.config': [","          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg',","          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface',","          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface',","          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb',","          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb',","          'gabor_graph = bob.bio.face.config.baseline.gabor_graph',","          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface',","          'lgbphs = bob.bio.face.config.baseline.lgbphs',","          'lda = bob.bio.face.config.baseline.lda',","          'arface            = bob.bio.face.config.database.arface',","          'atnt              = bob.bio.face.config.database.atnt',","          'gbu               = bob.bio.face.config.database.gbu',","          'ijbc-11              = bob.bio.face.config.database.ijbc',","          'lfw-restricted    = bob.bio.face.config.database.lfw_restricted',","          'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted',","          'mobio-male       = bob.bio.face.config.database.mobio_male',","          'mobio-all        = bob.bio.face.config.database.mobio_all',","          'multipie          = bob.bio.face.config.database.multipie',","          'multipie-pose     = bob.bio.face.config.database.multipie_pose',","          'replay-img-licit  = bob.bio.face.config.database.replay',","          'replay-img-spoof  = bob.bio.face.config.database.replay',","          'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile',","          'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile',","          'fargo  = bob.bio.face.config.database.fargo',","        ],","        'bob.bio.cli': [","          'display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations',","        'Framework :: Bob',","        'Development Status :: 3 - Alpha',","        'Intended Audience :: Developers',","        'License :: OSI Approved :: BSD License',","        'Natural Language :: English',","        'Programming Language :: Python',","        'Topic :: Scientific\/Engineering :: Artificial Intelligence',"],"goodparts":["        \"console_scripts\": [],","        \"bob.bio.database\": [","            \"arface            = bob.bio.face.config.database.arface:database\",","            \"atnt              = bob.bio.face.config.database.atnt:database\",","            \"gbu               = bob.bio.face.config.database.gbu:database\",","            \"ijbc-11              = bob.bio.face.config.database.ijbc:database\",","            \"lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database\",","            \"lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database\",","            \"mobio-male       = bob.bio.face.config.database.mobio_male:database\",","            \"mobio-all        = bob.bio.face.config.database.mobio_all:database\",","            \"multipie          = bob.bio.face.config.database.multipie:database\",","            \"multipie-pose     = bob.bio.face.config.database.multipie_pose:database\",","            \"replay-img-licit  = bob.bio.face.config.database.replay:replay_licit\",","            \"replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof\",","            \"replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit\",","            \"replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof\",","            \"fargo  = bob.bio.face.config.database.fargo:database\",","        \"bob.bio.annotator\": [","            \"facedetect               = bob.bio.face.config.annotator.facedetect:annotator\",","            \"facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator\",","            \"flandmark                = bob.bio.face.config.annotator.flandmark:annotator\",","            \"mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator\",","        \"bob.bio.transformer\": [","            \"facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer\",","            \"facedetect = bob.bio.face.config.annotator.facedetect:transformer\",","            \"flandmark = bob.bio.face.config.annotator.flandmark:annotator\",","            \"mtcnn = bob.bio.face.config.annotator.mtcnn:transformer\",","            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer\",","            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer\",","            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer\",","            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer\",","            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer\",","            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer\",","            \"gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer\",","            \"lgbphs = bob.bio.face.config.baseline.lgbphs:transformer\",","            \"dummy = bob.bio.face.config.baseline.dummy:transformer\",","        \"bob.bio.pipeline\": [","            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline\",","            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline\",","            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline\",","            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline\",","            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline\",","            \"gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline\",","            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline\",","            \"lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline\",","            \"lda = bob.bio.face.config.baseline.lda:pipeline\",","            \"dummy = bob.bio.face.config.baseline.dummy:pipeline\",","        \"bob.bio.config\": [","            \"facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg\",","            \"inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface\",","            \"inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface\",","            \"inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb\",","            \"inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb\",","            \"gabor_graph = bob.bio.face.config.baseline.gabor_graph\",","            \"arcface-insightface = bob.bio.face.config.baseline.arcface_insightface\",","            \"lgbphs = bob.bio.face.config.baseline.lgbphs\",","            \"lda = bob.bio.face.config.baseline.lda\",","            \"arface            = bob.bio.face.config.database.arface\",","            \"atnt              = bob.bio.face.config.database.atnt\",","            \"gbu               = bob.bio.face.config.database.gbu\",","            \"ijbc-11              = bob.bio.face.config.database.ijbc\",","            \"lfw-restricted    = bob.bio.face.config.database.lfw_restricted\",","            \"lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted\",","            \"mobio-male       = bob.bio.face.config.database.mobio_male\",","            \"mobio-all        = bob.bio.face.config.database.mobio_all\",","            \"multipie          = bob.bio.face.config.database.multipie\",","            \"multipie-pose     = bob.bio.face.config.database.multipie_pose\",","            \"replay-img-licit  = bob.bio.face.config.database.replay_licit\",","            \"replay-img-spoof  = bob.bio.face.config.database.replay_spoof\",","            \"replaymobile-img-licit  = bob.bio.face.config.database.replaymobile_licit\",","            \"replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile_spoof\",","            \"fargo  = bob.bio.face.config.database.fargo\",","        \"bob.bio.cli\": [","            \"display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations\",","        \"Framework :: Bob\",","        \"Development Status :: 3 - Alpha\",","        \"Intended Audience :: Developers\",","        \"License :: OSI Approved :: BSD License\",","        \"Natural Language :: English\",","        \"Programming Language :: Python\",","        \"Topic :: Scientific\/Engineering :: Artificial Intelligence\","]}],"source":"\n from setuptools import setup, dist dist.Distribution(dict(setup_requires=['bob.extension'])) from bob.extension.utils import load_requirements, find_packages install_requires=load_requirements() setup( name='bob.bio.face', version=open(\"version.txt\").read().rstrip(), description='Tools for running face recognition experiments', url='https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face', license='BSD', author='Manuel Gunther', author_email='siebenkopf@googlemail.com', keywords='bob, biometric recognition, evaluation', long_description=open('README.rst').read(), packages=find_packages(), include_package_data=True, zip_safe=False, install_requires=install_requires, entry_points={ 'console_scripts':[ ], 'bob.bio.database':[ 'arface =bob.bio.face.config.database.arface:database', 'atnt =bob.bio.face.config.database.atnt:database', 'gbu =bob.bio.face.config.database.gbu:database', 'ijbc-11 =bob.bio.face.config.database.ijbc:database', 'lfw-restricted =bob.bio.face.config.database.lfw_restricted:database', 'lfw-unrestricted =bob.bio.face.config.database.lfw_unrestricted:database', 'mobio-male =bob.bio.face.config.database.mobio_male:database', 'mobio-all =bob.bio.face.config.database.mobio_all:database', 'multipie =bob.bio.face.config.database.multipie:database', 'multipie-pose =bob.bio.face.config.database.multipie_pose:database', 'replay-img-licit =bob.bio.face.config.database.replay:replay_licit', 'replay-img-spoof =bob.bio.face.config.database.replay:replay_spoof', 'replaymobile-img-licit =bob.bio.face.config.database.replaymobile:replaymobile_licit', 'replaymobile-img-spoof =bob.bio.face.config.database.replaymobile:replaymobile_spoof', 'fargo =bob.bio.face.config.database.fargo:database', ], 'bob.bio.annotator':[ 'facedetect =bob.bio.face.config.annotator.facedetect:annotator', 'facedetect-eye-estimate =bob.bio.face.config.annotator.facedetect_eye_estimate:annotator', 'flandmark =bob.bio.face.config.annotator.flandmark:annotator', 'mtcnn =bob.bio.face.config.annotator.mtcnn:annotator', ], 'bob.bio.transformer':[ 'facedetect-eye-estimate=bob.bio.face.config.annotator.facedetect_eye_estimate:transformer', 'facedetect=bob.bio.face.config.annotator.facedetect:transformer', 'flandmark=bob.bio.face.config.annotator.flandmark:annotator', 'mtcnn=bob.bio.face.config.annotator.mtcnn:transformer', 'facenet-sanderberg=bob.bio.face.config.baseline.facenet_sanderberg:transformer', 'inception-resnetv1-casiawebface=bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer', 'inception-resnetv2-casiawebface=bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer', 'inception-resnetv1-msceleb=bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer', 'inception-resnetv2-msceleb=bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer', 'arcface-insightface=bob.bio.face.config.baseline.arcface_insightface:transformer', 'gabor-graph=bob.bio.face.config.baseline.gabor_graph:transformer', 'lgbphs=bob.bio.face.config.baseline.lgbphs:transformer', 'dummy=bob.bio.face.config.baseline.dummy:transformer', ], 'bob.bio.pipeline':[ 'facenet-sanderberg=bob.bio.face.config.baseline.facenet_sanderberg:pipeline', 'inception-resnetv1-casiawebface=bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline', 'inception-resnetv2-casiawebface=bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline', 'inception-resnetv1-msceleb=bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline', 'inception-resnetv2-msceleb=bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline', 'gabor_graph=bob.bio.face.config.baseline.gabor_graph:pipeline', 'arcface-insightface=bob.bio.face.config.baseline.arcface_insightface:pipeline', 'lgbphs=bob.bio.face.config.baseline.lgbphs:pipeline', 'lda=bob.bio.face.config.baseline.lda:pipeline', 'dummy=bob.bio.face.config.baseline.dummy:pipeline', ], 'bob.bio.config':[ 'facenet-sanderberg=bob.bio.face.config.baseline.facenet_sanderberg', 'inception-resnetv1-casiawebface=bob.bio.face.config.baseline.inception_resnetv1_casiawebface', 'inception-resnetv2-casiawebface=bob.bio.face.config.baseline.inception_resnetv2_casiawebface', 'inception-resnetv1-msceleb=bob.bio.face.config.baseline.inception_resnetv1_msceleb', 'inception-resnetv2-msceleb=bob.bio.face.config.baseline.inception_resnetv2_msceleb', 'gabor_graph=bob.bio.face.config.baseline.gabor_graph', 'arcface-insightface=bob.bio.face.config.baseline.arcface_insightface', 'lgbphs=bob.bio.face.config.baseline.lgbphs', 'lda=bob.bio.face.config.baseline.lda', 'arface =bob.bio.face.config.database.arface', 'atnt =bob.bio.face.config.database.atnt', 'gbu =bob.bio.face.config.database.gbu', 'ijbc-11 =bob.bio.face.config.database.ijbc', 'lfw-restricted =bob.bio.face.config.database.lfw_restricted', 'lfw-unrestricted =bob.bio.face.config.database.lfw_unrestricted', 'mobio-male =bob.bio.face.config.database.mobio_male', 'mobio-all =bob.bio.face.config.database.mobio_all', 'multipie =bob.bio.face.config.database.multipie', 'multipie-pose =bob.bio.face.config.database.multipie_pose', 'replay-img-licit =bob.bio.face.config.database.replay', 'replay-img-spoof =bob.bio.face.config.database.replay', 'replaymobile-img-licit =bob.bio.face.config.database.replaymobile', 'replaymobile-img-spoof =bob.bio.face.config.database.replaymobile', 'fargo =bob.bio.face.config.database.fargo', ], 'bob.bio.cli':[ 'display-face-annotations =bob.bio.face.script.display_face_annotations:display_face_annotations', ], }, classifiers=[ 'Framework:: Bob', 'Development Status:: 3 -Alpha', 'Intended Audience:: Developers', 'License:: OSI Approved:: BSD License', 'Natural Language:: English', 'Programming Language:: Python', 'Topic:: Scientific\/Engineering:: Artificial Intelligence', ], ) ","sourceWithComments":"#!\/usr\/bin\/env python\n# vim: set fileencoding=utf-8 :\n# Andre Anjos <andre.anjos@idiap.ch>\n# Mon 16 Apr 08:18:08 2012 CEST\n#\n# Copyright (C) Idiap Research Institute, Martigny, Switzerland\n#\n# This program is free software: you can redistribute it and\/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, version 3 of the License.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http:\/\/www.gnu.org\/licenses\/>.\n\n# This file contains the python (distutils\/setuptools) instructions so your\n# package can be installed on **any** host system. It defines some basic\n# information like the package name for instance, or its homepage.\n#\n# It also defines which other packages this python package depends on and that\n# are required for this package's operation. The python subsystem will make\n# sure all dependent packages are installed or will install them for you upon\n# the installation of this package.\n#\n# The 'buildout' system we use here will go further and wrap this package in\n# such a way to create an isolated python working environment. Buildout will\n# make sure that dependencies which are not yet installed do get installed, but\n# **without** requiring administrative privileges on the host system. This\n# allows you to test your package with new python dependencies w\/o requiring\n# administrative interventions.\n\nfrom setuptools import setup, dist\n\ndist.Distribution(dict(setup_requires=['bob.extension']))\n\nfrom bob.extension.utils import load_requirements, find_packages\n\ninstall_requires = load_requirements()\n\n# The only thing we do in this file is to call the setup() function with all\n# parameters that define our package.\nsetup(\n\n    # This is the basic information about your project. Modify all this\n    # information before releasing code publicly.\n    name='bob.bio.face',\n    version=open(\"version.txt\").read().rstrip(),\n    description='Tools for running face recognition experiments',\n\n    url='https:\/\/gitlab.idiap.ch\/bob\/bob.bio.face',\n    license='BSD',\n    author='Manuel Gunther',\n    author_email='siebenkopf@googlemail.com',\n    keywords='bob, biometric recognition, evaluation',\n\n    # If you have a better, long description of your package, place it on the\n    # 'doc' directory and then hook it here\n    long_description=open('README.rst').read(),\n\n    # This line is required for any distutils based packaging.\n    packages=find_packages(),\n    include_package_data=True,\n    zip_safe=False,\n\n    # This line defines which packages should be installed when you \"install\"\n    # this package. All packages that are mentioned here, but are not installed\n    # on the current system will be installed locally and only visible to the\n    # scripts of this package. Don't worry - You won't need administrative\n    # privileges when using buildout.\n    install_requires=install_requires,\n\n    # Your project should be called something like 'bob.<foo>' or\n    # 'bob.<foo>.<bar>'. To implement this correctly and still get all your\n    # packages to be imported w\/o problems, you need to implement namespaces\n    # on the various levels of the package and declare them here. See more\n    # about this here:\n    # http:\/\/peak.telecommunity.com\/DevCenter\/setuptools#namespace-packages\n    #\n    # Our database packages are good examples of namespace implementations\n    # using several layers. You can check them out here:\n    # https:\/\/www.idiap.ch\/software\/bob\/packages\n\n\n    # This entry defines which scripts you will have inside the 'bin' directory\n    # once you install the package (or run 'bin\/buildout'). The order of each\n    # entry under 'console_scripts' is like this:\n    #   script-name-at-bin-directory = module.at.your.library:function\n    #\n    # The module.at.your.library is the python file within your library, using\n    # the python syntax for directories (i.e., a '.' instead of '\/' or '\\').\n    # This syntax also omits the '.py' extension of the filename. So, a file\n    # installed under 'example\/foo.py' that contains a function which\n    # implements the 'main()' function of particular script you want to have\n    # should be referred as 'example.foo:main'.\n    #\n    # In this simple example we will create a single program that will print\n    # the version of bob.\n    entry_points={\n\n        # scripts should be declared using this entry:\n        'console_scripts': [\n        ],\n\n        'bob.bio.database': [\n            'arface            = bob.bio.face.config.database.arface:database',\n            'atnt              = bob.bio.face.config.database.atnt:database',\n            'gbu               = bob.bio.face.config.database.gbu:database',\n\n            'ijbc-11              = bob.bio.face.config.database.ijbc:database',\n\n            'lfw-restricted    = bob.bio.face.config.database.lfw_restricted:database',\n            'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted:database',\n            'mobio-male       = bob.bio.face.config.database.mobio_male:database',\n            'mobio-all        = bob.bio.face.config.database.mobio_all:database',\n            'multipie          = bob.bio.face.config.database.multipie:database',\n            'multipie-pose     = bob.bio.face.config.database.multipie_pose:database',\n            'replay-img-licit  = bob.bio.face.config.database.replay:replay_licit',\n            'replay-img-spoof  = bob.bio.face.config.database.replay:replay_spoof',\n            'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile:replaymobile_licit',\n            'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile:replaymobile_spoof',\n            'fargo  = bob.bio.face.config.database.fargo:database',\n        ],\n\n        'bob.bio.annotator': [\n            'facedetect               = bob.bio.face.config.annotator.facedetect:annotator',\n            'facedetect-eye-estimate  = bob.bio.face.config.annotator.facedetect_eye_estimate:annotator',\n            'flandmark                = bob.bio.face.config.annotator.flandmark:annotator',\n            'mtcnn                    = bob.bio.face.config.annotator.mtcnn:annotator',\n        ],\n\n        'bob.bio.transformer':[\n          'facedetect-eye-estimate = bob.bio.face.config.annotator.facedetect_eye_estimate:transformer',\n          'facedetect = bob.bio.face.config.annotator.facedetect:transformer',\n          'flandmark = bob.bio.face.config.annotator.flandmark:annotator',\n          'mtcnn = bob.bio.face.config.annotator.mtcnn:transformer',\n          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:transformer',\n          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:transformer',\n          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:transformer',\n          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:transformer',\n          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:transformer',\n          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:transformer',\n          'gabor-graph = bob.bio.face.config.baseline.gabor_graph:transformer',\n          'lgbphs = bob.bio.face.config.baseline.lgbphs:transformer',\n          'dummy = bob.bio.face.config.baseline.dummy:transformer',\n        ],\n\n        #baselines\n        'bob.bio.pipeline':[\n          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg:pipeline',\n          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface:pipeline',\n          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface:pipeline',\n          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb:pipeline',\n          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb:pipeline',\n          'gabor_graph = bob.bio.face.config.baseline.gabor_graph:pipeline',\n          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface:pipeline',\n          'lgbphs = bob.bio.face.config.baseline.lgbphs:pipeline',\n          'lda = bob.bio.face.config.baseline.lda:pipeline',\n          'dummy = bob.bio.face.config.baseline.dummy:pipeline',\n        ],\n\n        'bob.bio.config': [\n          'facenet-sanderberg = bob.bio.face.config.baseline.facenet_sanderberg',\n          'inception-resnetv1-casiawebface = bob.bio.face.config.baseline.inception_resnetv1_casiawebface',\n          'inception-resnetv2-casiawebface = bob.bio.face.config.baseline.inception_resnetv2_casiawebface',\n          'inception-resnetv1-msceleb = bob.bio.face.config.baseline.inception_resnetv1_msceleb',\n          'inception-resnetv2-msceleb = bob.bio.face.config.baseline.inception_resnetv2_msceleb',\n          'gabor_graph = bob.bio.face.config.baseline.gabor_graph',\n          'arcface-insightface = bob.bio.face.config.baseline.arcface_insightface',\n          'lgbphs = bob.bio.face.config.baseline.lgbphs',\n          'lda = bob.bio.face.config.baseline.lda',\n\n\n\n          'arface            = bob.bio.face.config.database.arface',\n          'atnt              = bob.bio.face.config.database.atnt',\n          'gbu               = bob.bio.face.config.database.gbu',\n\n          'ijbc-11              = bob.bio.face.config.database.ijbc',\n\n          'lfw-restricted    = bob.bio.face.config.database.lfw_restricted',\n          'lfw-unrestricted  = bob.bio.face.config.database.lfw_unrestricted',\n          'mobio-male       = bob.bio.face.config.database.mobio_male',\n          'mobio-all        = bob.bio.face.config.database.mobio_all',\n          'multipie          = bob.bio.face.config.database.multipie',\n          'multipie-pose     = bob.bio.face.config.database.multipie_pose',\n          'replay-img-licit  = bob.bio.face.config.database.replay',\n          'replay-img-spoof  = bob.bio.face.config.database.replay',\n          'replaymobile-img-licit  = bob.bio.face.config.database.replaymobile',\n          'replaymobile-img-spoof  = bob.bio.face.config.database.replaymobile',\n\n          'fargo  = bob.bio.face.config.database.fargo',\n        ],\n\n        'bob.bio.cli': [\n          'display-face-annotations          = bob.bio.face.script.display_face_annotations:display_face_annotations',\n        ],\n\n\n    },\n\n    # Classifiers are important if you plan to distribute this package through\n    # PyPI. You can find the complete list of classifiers that are valid and\n    # useful here (http:\/\/pypi.python.org\/pypi?%3Aaction=list_classifiers).\n    classifiers=[\n        'Framework :: Bob',\n        'Development Status :: 3 - Alpha',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: BSD License',\n        'Natural Language :: English',\n        'Programming Language :: Python',\n        'Topic :: Scientific\/Engineering :: Artificial Intelligence',\n    ],\n)\n"}},"msg":"Some fixes to allow vulnerability tests with replay-attack and replay-mobile database"}},"https:\/\/github.com\/tamzi\/bungeni-portal":{"fdcd90bde5dd5efb4ff894413df30b18768381e4":{"url":"https:\/\/api.github.com\/repos\/tamzi\/bungeni-portal\/commits\/fdcd90bde5dd5efb4ff894413df30b18768381e4","html_url":"https:\/\/github.com\/tamzi\/bungeni-portal\/commit\/fdcd90bde5dd5efb4ff894413df30b18768381e4","message":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings.","sha":"fdcd90bde5dd5efb4ff894413df30b18768381e4","keyword":"replay attack improve","diff":"diff --git a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\nindex 44ae077ff..2d6b1645d 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n@@ -254,7 +254,7 @@ def permission_type_key(self):\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\nindex e328f6c85..96e0dc6f0 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n@@ -209,7 +209,14 @@ def oauth_authorization_token_expiry_time(self):\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self):\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\nindex 7435b4a3a..28e02aebf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n@@ -300,5 +300,5 @@ def setUp(self):\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"])\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\nindex 4ac3db531..8610d7e73 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n@@ -573,4 +573,11 @@ def title(self):\n         context = _merged(self.context)\n         return component.getUtility(IRole, context.role_id).title\n \n+@register.adapter()\n+class OAuthApplicationDescriptiveProperties(DescriptiveProperties):\n+    component.adapts(interfaces.IOAuthApplication)\n \n+    @property\n+    def title(self):\n+        context = _merged(self.context)\n+        return context.name\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\nindex e747ae61c..7122485b2 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n@@ -578,6 +578,9 @@ class IDebateTake(interface.Interface):\n class IOAuthApplication(interface.Interface):\n     \"\"\"Marker interface for an OAuth Application record\"\"\"\n \n+class IOAuthApplicationContainer(IAlchemistContainer):\n+    \"\"\"Marker interface for an OAuth Applications container\"\"\"\n+\n class IOAuthAuthorization(interface.Interface):\n     \"\"\"Marker interfeace for OAuth authorizations\"\"\"\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\nindex e34a41ef8..3900cbd92 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n@@ -163,8 +163,13 @@\n   <permission id=\"bungeni.debate_takes.View\" title=\"View debate takes\" \/>\n   <permission id=\"bungeni.debate_takes.Edit\" title=\"Edit debate takes\" \/>\n \n-  <permission id=\"bungeni.oauth_application.View\" title=\"View oauth app\" \/>\n-  <permission id=\"bungeni.oauth_application.Delete\" title=\"Delete oauth app\" \/>\n-  <meta:redefinePermission from=\"bungeni.oauth_application.View\" to=\"zope.ManageContent\" \/>\n+  <permission id=\"bungeni.o_auth_application.View\" title=\"View oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Add\" title=\"Add oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Edit\" title=\"Edit oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Delete\" title=\"Delete oauth app\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.View\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Add\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Edit\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Delete\" to=\"zope.ManageContent\" \/>\n   <permission id=\"bungeni.oauth.View\" title=\"Use oauth api\" \/>\n <\/configure>\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\nindex 128a2c535..f1d0ed492 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n@@ -1185,7 +1185,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"identifier\", rdb.UnicodeText, nullable=False, \n         unique=True),\n     rdb.Column(\"name\", rdb.UnicodeText, nullable=False),\n-    rdb.Column(\"secret\", rdb.String(32), nullable=False),\n+    rdb.Column(\"secret\", rdb.String(100), nullable=False),\n     rdb.Column(\"redirection_endpoint\", rdb.UnicodeText, nullable=False)\n )\n \n@@ -1195,7 +1195,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n         nullable=False),\n     rdb.Column(\"application_id\", rdb.Integer,\n         rdb.ForeignKey(\"oauth_application.application_id\"), nullable=False),\n-    rdb.Column(\"authorization_code\", rdb.String(32), nullable=False),\n+    rdb.Column(\"authorization_code\", rdb.String(100), nullable=False),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n     rdb.Column(\"active\", rdb.Boolean(), nullable=False)\n )\n@@ -1204,8 +1204,8 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"access_token_id\", rdb.Integer, primary_key=True),\n     rdb.Column(\"authorization_id\", rdb.Integer,\n              rdb.ForeignKey(\"oauth_authorization.authorization_id\")),\n-    rdb.Column(\"access_token\", rdb.String(32)),\n-    rdb.Column(\"refresh_token\", rdb.String(32)),\n+    rdb.Column(\"access_token\", rdb.String(100)),\n+    rdb.Column(\"refresh_token\", rdb.String(100)),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n )\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\nindex 21c811509..bf1568c5e 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n@@ -1,8 +1,10 @@\n import hashlib\n+import hmac\n import random\n import string\n import urllib\n import simplejson\n+import time\n from datetime import datetime, timedelta\n \n from sqlalchemy.orm.exc import NoResultFound\n@@ -30,8 +32,8 @@\n def get_key():\n     \"\"\"Return a randomly generated key\n     \"\"\"\n-    m = hashlib.sha256()\n-    m.update(\"\".join(random.sample(string.letters + string.digits, 32)))\n+    m = hashlib.sha1()\n+    m.update(\"\".join(random.sample(string.letters + string.digits, 20)))\n     return m.hexdigest()\n \n \n@@ -45,10 +47,10 @@ class AddOAuthApplication(forms.common.AddForm):\n     @form.action(_(u\"Create Application\"), name=\"create\")\n     def handle_create_application(self, action, data, validator=\"validateAdd\"):\n         oauth_app = domain.OAuthApplication()\n-        oauth_app.application_identifier = data[\"application_identifier\"]\n-        oauth_app.application_name = data[\"application_name\"]\n+        oauth_app.identifier = data[\"identifier\"]\n+        oauth_app.name = data[\"name\"]\n         oauth_app.redirection_endpoint = data[\"redirection_endpoint\"]\n-        oauth_app.application_key = get_key()\n+        oauth_app.secret = get_key()\n         session = Session()\n         session.add(oauth_app)\n         session.flush()\n@@ -163,41 +165,73 @@ def __call__(self):\n class IOAuthAuthorizeForm(interface.Interface):\n     client_id = schema.TextLine(required=False)\n     state = schema.TextLine(required=False)\n-\n+    time = schema.TextLine(required=False)\n+    nonce = schema.TextLine(required=False)\n \n class OAuthAuthorizeForm(form.FormBase):\n     form_fields = form.Fields(IOAuthAuthorizeForm)\n     form_fields[\"client_id\"].custom_widget = widgets.HiddenTextWidget\n     form_fields[\"state\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"nonce\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"time\"].custom_widget = widgets.HiddenTextWidget\n     template = NamedTemplate(\"alchemist.form\")\n     form_name = _(\"authorise_oauth_application\",\n         default=u\"Authorise OAuth Application\")\n \n     def __init__(self, context, request, parameters={}):\n         self.parameters = parameters\n+        if self.parameters:\n+            self.parameters[\"time\"] = time.time()\n+            self.parameters[\"nonce\"] = self.generate_nonce(\n+                self.parameters[\"time\"])\n         self.action_url = \"\/api\/oauth\/authorize-form\"\n         super(OAuthAuthorizeForm, self).__init__(context, request)\n \n     def setUpWidgets(self, ignore_request=False):\n+        \n         self.widgets = form.setUpWidgets(\n             self.form_fields, self.prefix, self.context, self.request,\n             data=self.parameters if self.parameters else self.request.form,\n             ignore_request=ignore_request\n         )\n \n-    @form.action(_(u\"Authorize application\"), name=\"authorize\")\n+    def generate_nonce(self, auth_time):\n+        data = \"{0}:{1}:{2}\".format(\n+            self.parameters[\"client_id\"], get_db_user().user_id, auth_time)\n+        return hmac.new(capi.oauth_hmac_key, data, hashlib.sha1).hexdigest()\n+\n+    def check_authorization(self, action, data):\n+        errors = []\n+        data = self.request.form\n+        if not data.get(\"form.time\", None) or not data.get(\"form.nonce\", None):\n+            errors.append(InvalidRequest)\n+            return errors\n+        max_time = datetime.fromtimestamp(float(data[\"form.time\"])) + \\\n+            timedelta(seconds=capi.oauth_authorization_token_expiry_time)\n+        if (datetime.now() > max_time):\n+            errors.append(InvalidGrant)\n+        if data[\"form.nonce\"] != self.generate_nonce(data[\"form.time\"]):\n+            errors.append(InvalidGrant)\n+        return errors\n+\n+    def handle_failure(self, action, data, errors):\n+        return ErrorPage(self.context, self.request, errors[0])()\n+\n+    @form.action(_(u\"Authorize application\"), name=\"authorize\",\n+        validator=check_authorization, failure=handle_failure)\n     def handle_authorize_app(self, action, data):\n         session = Session()\n         oauth_authorization = domain.OAuthAuthorization()\n         oauth_authorization.user_id = get_db_user().user_id\n         app = session.query(domain.OAuthApplication\n-            ).filter(domain.OAuthApplication.application_identifier ==\n+            ).filter(domain.OAuthApplication.identifier ==\n                 data[\"client_id\"]\n             ).one()\n         oauth_authorization.application_id = app.application_id\n         oauth_authorization.authorization_code = get_key()\n         oauth_authorization.expiry = datetime.now() + timedelta(\n-            seconds=capi.oauth_auth_expiry_time)\n+            seconds=capi.oauth_authorization_token_expiry_time)\n+        oauth_authorization.active = True\n         session.add(oauth_authorization)\n         redirect_uri = \"{0}?code={1}\".format(\n             app.redirection_endpoint, oauth_authorization.authorization_code)\n@@ -213,10 +247,10 @@ def handle_cancel(self, action, data):\n                      == data[\"client_id\"]\n             ).one()\n         error = UnauthorizedClient(app.redirection_endpoint, data[\"state\"])\n-        redirect_error(self.request, error)\n+        redirect_error(self.context, self.request, error)\n \n \n-def redirect_error(request, error):\n+def redirect_error(context, request, error):\n     if error.redirect_uri:\n         next_url = \"{0}?error={1}&error_description={2}\".format(\n             error.redirect_uri, error.error, error.error_description)\n@@ -224,10 +258,10 @@ def redirect_error(request, error):\n             next_url = \"{0}&state={1}\".format(next_url, error.state)\n         return request.response.redirect(next_url, trusted=True)\n     else:\n-        bad_request(request, error)\n+        return ErrorPage(context, request, error)()\n \n \n-def bad_request(request, error):\n+def bad_request(context, request, error):\n     request.response.setStatus(400)\n     data = {\"error\": error.error, \"error_description\": error.error_description}\n     return simplejson.dumps(data)\n@@ -277,7 +311,7 @@ def __call__(self):\n         except UnauthorizedClient as e:\n             return ErrorPage(self.context, self.request, e)()\n         except OAuthException as e:\n-            return redirect_error(self.request, e)\n+            return redirect_error(self.context, self.request, e)\n \n         if not IUnauthenticatedPrincipal.providedBy(self.request.principal):\n             # authorize form\n@@ -345,7 +379,7 @@ def __call__(self):\n         try:\n             parameters = self.parameters()\n         except OAuthException as e:\n-            return bad_request(self.request, e)\n+            return bad_request(self.context, self.request, e)\n         assert (self.authorization is not None,\n             \"Authorization object not initalized\")\n         self.authorization.expiry = datetime.now()\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\nindex 18c6363b5..1372b42bf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n@@ -1718,13 +1718,13 @@ class ItemScheduleVoteDescriptor(ModelDescriptor):\n class OAuthApplicationDescriptor(ModelDescriptor):\n     localisable = False\n     fields = [\n-        F(name=\"application_identifier\",\n+        F(name=\"identifier\",\n           label=\"Unique Application Identifier\",\n           required=True,\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_name\",\n+        F(name=\"name\",\n           label=\"Application Name\",\n           required=True,\n           value_type=\"text\",\n@@ -1736,8 +1736,8 @@ class OAuthApplicationDescriptor(ModelDescriptor):\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_key\",\n-          label=\"Application Key\",\n+        F(name=\"secret\",\n+          label=\"Application Secret\",\n           localizable=[show(\"view\"), hide(\"add\")],\n           required=True,\n           value_type=\"text\",\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\nindex 57deb7ee2..66b0dbd7b 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n@@ -1265,5 +1265,14 @@\n      viewName=\"\"\n      weight=\"30\"\n      \/-->\n+   <!--OAuth-->\n+   <browser:menuItem menu=\"plone_contentmenu\"\n+        for=\"bungeni.models.interfaces.IOAuthApplicationContainer\"\n+        title=\"Add OAuth Application\"\n+        action=\"add\"\n+        permission=\"bungeni.o_auth_application.Add\"\n+        layer=\".interfaces.IAdminSectionLayer\"\n+        order=\"62\"\n+    \/>\n <\/configure>\n \n","files":{"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py":{"changes":[{"diff":"\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),","add":1,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py","badparts":["    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),"],"goodparts":["    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),"]}],"source":"\n \"\"\"Aggregation of information about loaded domain types. No public methods here --all available methods from this are those exposed via bungeni.capi. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\") from zope.interface.interfaces import IInterface from zope.security.proxy import removeSecurityProxy from zope.dottedname.resolve import resolve from bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface from bungeni.alchemist.model import( new_custom_domain_interface, new_custom_domain_model, ) from bungeni.alchemist.catalyst import( INTERFACE_MODULE, MODEL_MODULE ) from bungeni.models import interfaces from bungeni.models import domain from bungeni.core.workflow.interfaces import IWorkflow from bungeni.utils import naming __all__=[] def _iter(): \"\"\"Return iterator on all(key, TypeInfo) entries in TYPE_REGISTRY. Usage: capi.iter_type_info() \"\"\" for type_key, ti in TYPE_REGISTRY: yield type_key, ti def _get(discriminator): \"\"\"Get the TypeInfo instance for discriminator, that may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: provides IBungeniContent domain model instance: type provides IBungeniContent descriptor: provides IModelDescriptor Raise KeyError if no entry matched. Usage: capi.get_type_info(discriminator) \"\"\" if discriminator is None: m=\"type_info._get discriminator is None\" log.error(m) raise ValueError(m) discri=removeSecurityProxy(discriminator) getter=None if IIModelInterface.providedBy(discri): discri=naming.type_key(\"table_schema_interface_name\", discri.__name__) elif IInterface.providedBy(discri): discri=naming.type_key(\"model_interface_name\", discri.__name__) elif type(discri) is type and issubclass(discri, domain.Entity): discri=naming.polymorphic_identity(discri) elif isinstance(discri, domain.Entity): discri=naming.polymorphic_identity(type(discri)) if isinstance(discri, basestring): getter=_get_by_type_key elif IWorkflow.providedBy(discri): getter=_get_by_workflow elif IModelDescriptor.implementedBy(discri): getter=_get_by_descriptor_model if getter is not None: ti=getter(discri) if ti is not None: return ti else: m=\"No type registered for discriminator: %r\" %(discriminator) else: m=\"Invalid type info lookup discriminator: %r\" %(discriminator) from bungeni.ui.utils import debug log.debug(debug.interfaces(discriminator)) log.debug(m) raise KeyError(m) def _get_by_type_key(key): for type_key, ti in _iter(): if type_key==key: return ti ''' !+IALCHEMISTCONTENT fails on different interfaces with same name! (Pdb) ti.interface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) ti.interface.__bases__ (<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>) (Pdb) iface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) iface.__bases__ (<InterfaceClass zope.interface.Interface>,) ''' def _get_by_model(model): for type_key, ti in _iter(): if model is ti.domain_model: return ti def _get_by_instance(instance): return _get_by_model(type(instance)) def _get_by_workflow(wf): for type_key, ti in _iter(): if wf is ti.workflow: return ti def _get_by_descriptor_model(descriptor_model): for type_key, ti in _iter(): if descriptor_model is ti.descriptor_model: return ti class TI(object): \"\"\"TypeInfo, associates together the following attributes for a given type: workflow_key the workflow file name defaults to the type_key for workflowed types that DO NOT specify is None for non-workflowed types workflow same workflow insatnce may be used by multiple types is None for non-workflowed types interface the manually applied application-dedicated model interface (if any) for the type derived_table_schema auto-generated db schema interface, provides IIModelInterface domain_model the domain class descriptor_model the descriptor model for UI views for the type container_class container class for domain_model container_interface interface for the container class for domain_model \"\"\" def __init__(self, workflow_key, iface, domain_model=None): self.workflow_key=workflow_key self.interface=iface self.derived_table_schema=None self.workflow=None self.domain_model=domain_model self.descriptor_model=None self.container_class=None self.container_interface=None self.custom=False def __str__(self): return str(self.__dict__) @property def scope(self): if self.custom: return \"custom\" if self.descriptor_model is not None: return self.descriptor_model.scope @property def permission_type_key(self): if self.custom: return self.workflow.name return(self.workflow_key or naming.type_key(\"model_name\", self.domain_model.__name__) ) ''' !+TYPE_REGISTRY externalize further to bungeni_custom, currently: -association of type key and dedicated interface are hard-wired here -ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when loading workflows and descriptors -type_key IS the underscore-separated lowercase of the domain cls name i.e. utils.naming.polymorphic_identity(domain_model) -!+ti.workflow_key SHOULD always be equal to type_key -!+corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated -!+dedicated interfaces for archetype incantations should be auto-generated, from specific workflow name\/attr... e.g. via: zope.interface.interface.InterfaceClass(iname, bases, __module__) -!+should ti.interface be automatically generated also for system types? Usage: from bungeni.capi import capi capi.get_type_info(discriminator) -> TypeInfo capi.iter_type_info() -> iterator of all registered(key, TypeInfo) ''' TYPE_REGISTRY=[ (\"user_address\", TI(\"address\", interfaces.IUserAddress)), (\"group_address\", TI(\"address\", interfaces.IGroupAddress)), (\"attachment\", TI(\"attachment\", interfaces.IAttachment)), (\"event\", TI(\"event\", interfaces.IEvent)), (\"sitting\", TI(\"sitting\", interfaces.ISitting)), (\"heading\", TI(\"heading\", interfaces.IHeading)), (\"user\", TI(\"user\", interfaces.IBungeniUser)), (\"signatory\", TI(\"signatory\", interfaces.ISignatory)), (\"group\", TI(\"group\", interfaces.IBungeniGroup)), (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)), (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)), (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)), (\"oauth_application\", TI(None, interfaces.IOAuthApplication)), (\"debate_media\", TI(None, interfaces.IDebateMedia)), (\"user_delegation\", TI(None, interfaces.IUserDelegation)), (\"title_type\", TI(None, interfaces.ITitleType)), (\"member_title\", TI(None, interfaces.IMemberTitle)), (\"change\", TI(None, interfaces.IChange)), (\"doc\", TI(None, interfaces.IDoc)), (\"doc_version\", TI(None, None)), (\"attachment_version\", TI(None, None)), (\"venue\", TI(None, interfaces.IVenue)), (\"session\", TI(None, interfaces.ISession)), (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)), (\"country\", TI(None, interfaces.ICountry)), (\"item_schedule\", TI(None, interfaces.IItemSchedule)), (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)), (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)), (\"editorial_note\", TI(None, interfaces.IEditorialNote)), (\"sitting_report\", TI(None, interfaces.ISittingReport)), (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)), ] def register_new_custom_type(type_key, workflow_key, archetype_key): \"\"\"Retrieve(create if needed) a domain interface and model for type_key, and register as new entry on TYPE_REGISTER. \"\"\" domain_iface_name=naming.model_interface_name(type_key) try: domain_iface=resolve(\"%s.%s\" %(INTERFACE_MODULE.__name__, domain_iface_name)) log.warn(\"Custom interface ALREADY EXISTS: %s\" %(domain_iface)) except ImportError: domain_iface=new_custom_domain_interface(type_key, domain_iface_name) domain_model_name=naming.model_name(type_key) try: domain_model=resolve(\"%s.%s\" %(MODEL_MODULE.__name__, domain_model_name)) log.warn(\"Custom domain model ALREADY EXISTS: %s\" %(domain_model)) except ImportError: domain_model=new_custom_domain_model(type_key, domain_iface, archetype_key) ti=TI(workflow_key, domain_iface, domain_model) ti.custom=True TYPE_REGISTRY.append((type_key, ti)) log.info(\"Registered custom type[%s]: %s\" %(archetype_key, type_key)) return type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Aggregation of information about loaded domain types.\n\nNo public methods here -- all available methods from this are those exposed \nvia bungeni.capi.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\")\n\nfrom zope.interface.interfaces import IInterface\nfrom zope.security.proxy import removeSecurityProxy\nfrom zope.dottedname.resolve import resolve\n\nfrom bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface\nfrom bungeni.alchemist.model import (\n    new_custom_domain_interface,\n    new_custom_domain_model,\n)\nfrom bungeni.alchemist.catalyst import (\n    INTERFACE_MODULE, \n    MODEL_MODULE\n)\nfrom bungeni.models import interfaces\nfrom bungeni.models import domain\nfrom bungeni.core.workflow.interfaces import IWorkflow\nfrom bungeni.utils import naming\n\n__all__ = []\n\n\n# acessors exposed via capi\n\ndef _iter():\n    \"\"\"Return iterator on all (key, TypeInfo) entries in TYPE_REGISTRY.\n    \n    Usage: capi.iter_type_info()\n    \"\"\"\n    for type_key, ti in TYPE_REGISTRY:\n        yield type_key, ti\n\ndef _get(discriminator):\n    \"\"\"Get the TypeInfo instance for discriminator, that may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: provides IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor: provides IModelDescriptor\n    \n    Raise KeyError if no entry matched.\n    \n    Usage: capi.get_type_info(discriminator)\n    \"\"\"\n    if discriminator is None:\n        m = \"type_info._get discriminator is None\"\n        log.error(m)\n        raise ValueError(m)\n    discri = removeSecurityProxy(discriminator)\n    getter = None\n    \n    # !+IALCHEMISTCONTENT normalize trickier discriminator cases to type_key\n    if IIModelInterface.providedBy(discri):\n        discri = naming.type_key(\"table_schema_interface_name\", discri.__name__)\n    elif IInterface.providedBy(discri):\n        discri = naming.type_key(\"model_interface_name\", discri.__name__)\n    elif type(discri) is type and issubclass(discri, domain.Entity):\n        discri = naming.polymorphic_identity(discri)\n    elif isinstance(discri, domain.Entity):\n        discri = naming.polymorphic_identity(type(discri))\n    \n    if isinstance(discri, basestring):\n        getter = _get_by_type_key\n    #elif IInterface.providedBy(discri):\n    #    getter = _get_by_interface\n    #!+elif interfaces.IBungeniContent.implementedBy(discri):\n    #elif issubclass(discri, domain.Entity):\n    #    getter = _get_by_model\n    #!+elif interfaces.IBungeniContent.providedBy(discri):\n    #elif isinstance(discri, domain.Entity):\n    #    getter = _get_by_instance\n    elif IWorkflow.providedBy(discri):\n        getter = _get_by_workflow\n    elif IModelDescriptor.implementedBy(discri):\n        getter = _get_by_descriptor_model\n    \n    if getter is not None:\n        ti = getter(discri)\n        if ti is not None:\n            return ti\n        else:\n            m = \"No type registered for discriminator: %r\" % (discriminator)\n    else: \n        m = \"Invalid type info lookup discriminator: %r\" % (discriminator)\n    from bungeni.ui.utils import debug\n    log.debug(debug.interfaces(discriminator))\n    log.debug(m)\n    raise KeyError(m)\n\n\n# following getters return \"first matching\" TypeInfo instance in registry\n    \ndef _get_by_type_key(key):\n    for type_key, ti in _iter():\n        if type_key == key:\n            return ti\n#def _get_by_interface(iface):\n''' !+IALCHEMISTCONTENT fails on different interfaces with same name!\n(Pdb) ti.interface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) ti.interface.__bases__\n(<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>)\n(Pdb) iface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) iface.__bases__\n(<InterfaceClass zope.interface.Interface>,)\n'''\n#    for type_key, ti in _iter():\n#        if iface is ti.interface: #!+issubclass(iface, ti.interface)?\n#            return ti\ndef _get_by_model(model):\n    for type_key, ti in _iter():\n        if model is ti.domain_model: #!+issubclass(model, ti.domain_model)?\n            return ti\ndef _get_by_instance(instance):\n    return _get_by_model(type(instance))\ndef _get_by_workflow(wf):\n    for type_key, ti in _iter():\n        if wf is ti.workflow:\n            return ti\ndef _get_by_descriptor_model(descriptor_model):\n    for type_key, ti in _iter():\n        if descriptor_model is ti.descriptor_model:\n            return ti\n\n# \n\nclass TI(object):\n    \"\"\"TypeInfo, associates together the following attributes for a given type:\n            workflow_key \n                the workflow file name\n                defaults to the type_key for workflowed types that DO NOT specify\n                is None for non-workflowed types\n            workflow \n                same workflow insatnce may be used by multiple types\n                is None for non-workflowed types\n            interface\n                the manually applied application-dedicated model interface \n                (if any) for the type\n            derived_table_schema\n                auto-generated db schema interface, provides IIModelInterface\n            domain_model\n                the domain class\n            descriptor_model\n                the descriptor model for UI views for the type\n            container_class\n                container class for domain_model\n            container_interface\n                interface for the container class for domain_model\n    \"\"\"\n    def __init__(self, workflow_key, iface, domain_model=None):\n        self.workflow_key = workflow_key\n        self.interface = iface\n        self.derived_table_schema = None # provides IIModelInterface\n        self.workflow = None\n        self.domain_model = domain_model\n        self.descriptor_model = None\n        self.container_class = None\n        self.container_interface = None\n        self.custom = False # type loaded from custom configuration \n        # NOTE: only needed temporarily (until descriptor_model is set), \n        # then ti.custom not be inconsistent descriptor_model.scope i.e.\n        #if self.custom: assert self.descriptor_model.scope == \"custom\"\n        # !+ archetype_key?\n    def __str__(self):\n        return str(self.__dict__)\n    \n    @property\n    def scope(self):\n        # !+CUSTOM_TYPE_DESCRIPTOR the self.custom check below MUST precede the\n        # check on self.descriptor_model.scope as otherwise the \"in-transit\" \n        # custom types will not be picked up as custom types -- as during\n        # loading the descriptors for all custom types may not yet have been \n        # autogenerated (and would therefore correctly have \n        # descriptor_model.scope=\"custom\" set).\n        if self.custom:\n            return \"custom\"\n        if self.descriptor_model is not None:\n            return self.descriptor_model.scope\n    \n    @property\n    def permission_type_key(self):\n        if self.custom:\n            # custom types ALWAYS have a type_key-bound workflow instance - that\n            # may therefore have a different name than workflow_key e.g. Office\n            # uses the \"group\" workflow, that is type-relative reloaded as the\n            # \"office\" workflow instance.\n            return self.workflow.name\n        # system types ALWAYS use workflow_key - even if multiple types use the \n        # same workflow e.g. UserAddress & GroupAddress. \n        # if no workflow, compute type_key from domain_model\n        # #!+REDUNDANT(mb, 2012) This type key is already known during type\n        # setup i.e. TYPE_REGISTRY\n        return (self.workflow_key or \n            naming.type_key(\"model_name\", self.domain_model.__name__)\n        )\n\n'''\n!+TYPE_REGISTRY externalize further to bungeni_custom, currently:\n- association of type key and dedicated interface are hard-wired here\n- ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when \n  loading workflows and descriptors\n- type_key IS the underscore-separated lowercase of the domain cls name \n  i.e. utils.naming.polymorphic_identity(domain_model)\n- !+ ti.workflow_key SHOULD always be equal to type_key\n- !+ corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated\n- !+ dedicated interfaces for archetype incantations should be auto-generated, \n    from specific workflow name\/attr... e.g. via:\n    zope.interface.interface.InterfaceClass(iname, bases, __module__)\n- !+ should ti.interface be automatically generated also for system types?\n\nUsage:\n    from bungeni.capi import capi\n    capi.get_type_info(discriminator) -> TypeInfo\n    capi.iter_type_info() -> iterator of all registered (key, TypeInfo)\n'''\nTYPE_REGISTRY = [\n    # (key, ti)\n    # - the type key, unique for each type, is the underscore-separated \n    #   lowercase name of the domain_model (the domain class)\n    # - order is relevant (dictates workflow loading order)\n    \n    # feature \"support\" types, system types, required\n    \n    # workflowed\n    (\"user_address\", TI(\"address\", interfaces.IUserAddress)),\n    (\"group_address\", TI(\"address\", interfaces.IGroupAddress)),\n    # !+Attachment (mr, jul-2011)\n    # a) must be loaded before any other type that *may* support attachments!\n    # b) MUST support versions\n    (\"attachment\", TI(\"attachment\", interfaces.IAttachment)),\n    (\"event\", TI(\"event\", interfaces.IEvent)),\n    (\"sitting\", TI(\"sitting\", interfaces.ISitting)),\n    (\"heading\", TI(\"heading\", interfaces.IHeading)),\n    (\"user\", TI(\"user\", interfaces.IBungeniUser)),\n    (\"signatory\", TI(\"signatory\", interfaces.ISignatory)),\n    \n    # !+NAMING: member-related -> Group name + \"Member\" (no + \"ship\")\n    (\"group\", TI(\"group\", interfaces.IBungeniGroup)),\n    (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)),\n    (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n    (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n        # non-workflowed\n    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n    (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n    (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n    (\"title_type\", TI(None, interfaces.ITitleType)),\n    (\"member_title\", TI(None, interfaces.IMemberTitle)),\n    (\"change\", TI(None, interfaces.IChange)),\n    (\"doc\", TI(None, interfaces.IDoc)),\n    (\"doc_version\", TI(None, None)), #interfaces.IDocVersion)), #!+IVERSION\n    (\"attachment_version\", TI(None, None)), #interfaces.IAttachmentVersion)), #!+IVERSION\n    (\"venue\", TI(None, interfaces.IVenue)),\n    (\"session\", TI(None, interfaces.ISession)),\n    (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)),\n    (\"country\", TI(None, interfaces.ICountry)),\n    (\"item_schedule\", TI(None, interfaces.IItemSchedule)),\n    (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)),\n    (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)),\n    (\"editorial_note\", TI(None, interfaces.IEditorialNote)),\n    (\"sitting_report\", TI(None, interfaces.ISittingReport)),\n    (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)),\n    \n    # additional custom types are loaded dynamically from bungeni_custom\/types.xml\n]\n\n\n\n\n# register custom types\n\ndef register_new_custom_type(type_key, workflow_key, archetype_key):\n    \"\"\"Retrieve (create if needed) a domain interface and model for type_key,\n    and register as new entry on TYPE_REGISTER.\n    \"\"\"\n    \n    # generate custom domain interface\n    domain_iface_name = naming.model_interface_name(type_key)\n    try:\n        domain_iface = resolve(\"%s.%s\" % (INTERFACE_MODULE.__name__, domain_iface_name))\n        log.warn(\"Custom interface ALREADY EXISTS: %s\" % (domain_iface))\n    except ImportError:\n        domain_iface = new_custom_domain_interface(type_key, domain_iface_name)\n    \n    # generate custom domain_model\n    domain_model_name = naming.model_name(type_key)\n    try:\n        domain_model = resolve(\"%s.%s\" % (MODEL_MODULE.__name__, domain_model_name))\n        log.warn(\"Custom domain model ALREADY EXISTS: %s\" % (domain_model))\n    except ImportError:\n        domain_model = new_custom_domain_model(type_key, domain_iface, archetype_key)\n    \n    # type_info entry\n    ti = TI(workflow_key, domain_iface, domain_model)\n    ti.custom = True\n    TYPE_REGISTRY.append((type_key, ti))\n    \n    log.info(\"Registered custom type [%s]: %s\" % (archetype_key, type_key))\n    return type_key, ti\n\n\n\n\n\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py":{"changes":[{"diff":"\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self)","add":8,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py","badparts":["        return int(bc.oauth_auth_expiry_time)"],"goodparts":["        return int(bc.oauth_authorization_token_expiry_time)","    @cached_property.cachedIn(\"__oauth_hmac_key__\")","    @bungeni_custom_errors","    def oauth_hmac_key(self):","        \"\"\"String used to to generate nonces. KEEP SECRET.","        \"\"\"","        return bc.oauth_hmac_key"]}],"source":"\n \"\"\"Defines the accessor class for Bungeni Custom parameters. See bungeni.capi __init__.py for usage. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.capi\") import sys import time import os from zope.dottedname.resolve import resolve from zope.cachedescriptors import property as cached_property from bungeni.utils import error from bungeni.alchemist import type_info import bungeni_custom as bc class BungeniCustomError(Exception): \"\"\"A configuration error during loading of configuration. \"\"\" class BungeniCustomRuntimeError(BungeniCustomError): \"\"\"Internal error while executing a callable determined from configuration. \"\"\" def bungeni_custom_errors(f): \"\"\"Decorator to intercept any error raised by function f and re-raise it as a BungeniCustomError. To be used to decorate any function involved in reading\/validating\/processing any bungeni_custom parameters. \"\"\" return error.exceptions_as(BungeniCustomError)(f) def wrapped_callable(unwrapped): assert callable(unwrapped), unwrapped def wrapped(*args): log.debug(\"Calling %s with args: %s\" %(unwrapped, args)) try: return unwrapped(*args) except: exc=sys.exc_info()[1] log.debug(\"BungeniCustomRuntimeError[%r] in wrapped_callable: %s %s\", exc, wrapped, args) raise wrapped._unwrapped=unwrapped wrapped.__name__=unwrapped.__name__ return wrapped class CAPI(object): \"\"\"Accessor class for Bungeni Custom parameters. \"\"\" def __init__(self): self.validate_properties() def validate_properties(self): \"\"\"Validate this capi instance. Ensure valid setup of properties at instantiation of CAPI instance \"\"\" self.default_language self.country_code self.right_to_left_languages @property @bungeni_custom_errors def zope_i18n_allowed_languages(self): return tuple(bc.zope_i18n_allowed_languages.split()) @property @bungeni_custom_errors def zope_i18n_compile_mo_files(self): return bool( bc.zope_i18n_compile_mo_files is True or bc.zope_i18n_compile_mo_files==\"1\") @property @bungeni_custom_errors def country_code(self): \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this bungeni instance. \"\"\" return bc.country_code @property @bungeni_custom_errors def default_language(self): assert bc.default_language in self.zope_i18n_allowed_languages, \\ \"Default language[%s] not in allowed languages[%s]\" %( bc.default_language, self.zope_i18n_allowed_languages,) return bc.default_language @property @bungeni_custom_errors def right_to_left_languages(self): rtl_langs=tuple(bc.right_to_left_languages.split()) assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\ \"Right to left languages[%s] not in allowed languages[%s]\" %( bc.right_to_left_languages, self.zope_i18n_allowed_languages) return rtl_langs @property @bungeni_custom_errors def check_auto_reload_localization(self): \"\"\"() -> int minimum number of seconds to wait between checks for whether a localization file needs reloading; 0 means never check(deployment) \"\"\" int(bc.check_auto_reload_localization) return bc.check_auto_reload_localization @bungeni_custom_errors def get_workflow_condition(self, condition): condition_module=resolve(\"._conditions\", \"bungeni_custom.workflows\") condition=getattr(condition_module, condition) return wrapped_callable(condition) @bungeni_custom_errors def get_workflow_action(self, action): action_module=resolve(\"._actions\", \"bungeni_custom.workflows\") action=getattr(action_module, action) return wrapped_callable(action) @bungeni_custom_errors def get_form_constraint(self, constraint): constraint_module=resolve(\"._constraints\", \"bungeni_custom.forms\") constraint=getattr(constraint_module, constraint) return wrapped_callable(constraint) @bungeni_custom_errors def get_form_validator(self, validation): validator_module=resolve(\"._validations\", \"bungeni_custom.forms\") validator=getattr(validator_module, validation) return wrapped_callable(validator) @bungeni_custom_errors def get_form_derived(self, derived): derived_module=resolve(\"._derived\", \"bungeni_custom.forms\") derived_def=getattr(derived_module, derived) return wrapped_callable(derived_def) @property @bungeni_custom_errors def default_number_of_listing_items(self): \"\"\"This is the max number of items that are displayed in a listing by default. Returns an integer \"\"\" return int(bc.default_number_of_listing_items) @property @bungeni_custom_errors def long_text_column_listings_truncate_at(self): \"\"\"When listing text columns, only display first so many characters.\"\"\" return int(bc.long_text_column_listings_truncate_at) def xml_workspace_tabs_file(self): \"\"\"helper function used by workspace tab info APIs\"\"\" TABS_FILE=\"tabs.xml\" from lxml import etree ws_path=self.get_path_for(\"workspace\") file_path=os.path.join(ws_path, TABS_FILE) tabs=etree.fromstring(open(file_path).read()) return tabs @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\") @bungeni_custom_errors def workspace_tab_count_cache_refresh_time(self): \"\"\"The duration in seconds between tab count refresh operations\"\"\" tabs=self.xml_workspace_tabs_file() tabs_count_refresh=tabs.attrib[\"tab_count_cache_refresh_time\"] return int(tabs_count_refresh) @cached_property.cachedIn(\"__workspace_tabs__\") @bungeni_custom_errors def workspace_tabs(self): \"\"\"The tabs in the workspace\"\"\" ws_tabs=[] tabs=self.xml_workspace_tabs_file() for tab in tabs.iterchildren(tag=\"tab\"): ws_tabs.append(tab.attrib[\"id\"]) return ws_tabs @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\") @bungeni_custom_errors def oauth_access_token_expiry_time(self): \"\"\"time in seconds before an access token expires\"\"\" return(bc.oauth_access_token_expiry_time) @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\") @bungeni_custom_errors def oauth_authorization_token_expiry_time(self): \"\"\"time in seconds before an oauth authorization code expires max recommended time is 10min \"\"\" return int(bc.oauth_auth_expiry_time) def get_root_path(self): \"\"\"Get absolute physical path location for currently active bungeni_custom package folder. \"\"\" return os.path.dirname(os.path.abspath(bc.__file__)) def get_path_for(self, *path_components): \"\"\"Get absolute path, under bungeni_custom, for path_components. \"\"\" return os.path.join(*(self.get_root_path(),)+path_components) def put_env(self, key): \"\"\"Set capi value for{key} as the environment variable{key} i.e. use to set os.environ[key]. Wrapper on os.put_env(key, string_value) --to take care of the value string-casting required by os.put_env while still allowing the liberty of data-typing values of capi attributes as needed. \"\"\" value=getattr(self, key) try: os.environ[key]=value except TypeError: try: os.environ[key]=\" \".join(value) except TypeError: os.environ[key]=repr(value) assert eval(os.environ[key])==value _is_modified_since_last_times={} def is_modified_since(self, abspath, modified_on_first_check=True): \"\"\"(abspath:str, modified_on_first_check:bool) -> bool Checks file path st_mtime to see if file has been modified since last check. Updates entry per path, with last(check, modified) times. \"\"\" check_auto_reload_localization=self.check_auto_reload_localization now=time.time() last_checked, old_last_modified=\\ self._is_modified_since_last_times.get(abspath) or(0, 0) if not check_auto_reload_localization: if last_checked or not modified_on_first_check: return False if not now-last_checked > check_auto_reload_localization: return False last_modified=os.stat(abspath).st_mtime self._is_modified_since_last_times[abspath]=(now, last_modified) if not last_checked: return modified_on_first_check return(old_last_modified < last_modified) def get_type_info(self, discriminator): \"\"\"Get the TypeInfo instance for discriminator(see core.type_info). The discriminator may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: implements IBungeniContent domain model instance: type provides IBungeniContent descriptor_model: implements IModelDescriptor Raise KeyError if no entry matched. \"\"\" return type_info._get(discriminator) def iter_type_info(self, scope=None): \"\"\"Return iterator on all registered(key, TypeInfo) entries. scope:either(None, \"system\", \"archetype\", \"custom\") \"\"\" for type_key, ti in type_info._iter(): if(scope is None or ti.scope==scope): yield type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Defines the accessor class for Bungeni Custom parameters.\n\nSee bungeni.capi __init__.py for usage.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.capi\")\n\nimport sys\nimport time\nimport os\nfrom zope.dottedname.resolve import resolve\nfrom zope.cachedescriptors import property as cached_property\nfrom bungeni.utils import error\nfrom bungeni.alchemist import type_info\nimport bungeni_custom as bc\n\n\n# utils \n\nclass BungeniCustomError(Exception):\n    \"\"\"A configuration error during loading of configuration.\n    \"\"\"\nclass BungeniCustomRuntimeError(BungeniCustomError): \n    \"\"\"Internal error while executing a callable determined from configuration.\n    \"\"\" \n\ndef bungeni_custom_errors(f):\n    \"\"\"Decorator to intercept any error raised by function f and re-raise it\n    as a BungeniCustomError. To be used to decorate any function involved \n    in reading\/validating\/processing any bungeni_custom parameters. \n    \"\"\"\n    return error.exceptions_as(BungeniCustomError)(f)\n\n\ndef wrapped_callable(unwrapped):\n    assert callable(unwrapped), unwrapped\n    def wrapped(*args):\n        log.debug(\"Calling %s with args: %s\" % (unwrapped, args))\n        try:\n            return unwrapped(*args)\n        except:\n            # intercept exc, to re-raise it *unchanged*, only for debugging\n            # e.g. constraints raise numerous (expected?) NoInputData errors\n            exc = sys.exc_info()[1]\n            log.debug(\"BungeniCustomRuntimeError [%r] in wrapped_callable: %s %s\",\n                    exc, wrapped, args)\n            raise\n    # remember original unwrapped callable\n    wrapped._unwrapped = unwrapped\n    wrapped.__name__ = unwrapped.__name__\n    return wrapped\n\n\n# capi (singleton)\n\nclass CAPI(object):\n    \"\"\"Accessor class for Bungeni Custom parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.validate_properties()\n    \n    def validate_properties(self):\n        \"\"\"Validate this capi instance.\n        Ensure valid setup of properties at instantiation of CAPI instance\n        \"\"\"\n        self.default_language\n        self.country_code\n        self.right_to_left_languages\n        \n    # bungeni_custom parameter properties\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_allowed_languages(self):\n        # NOTE: zope.i18n.config.ALLOWED_LANGUAGES expects the value of the \n        # env variable for this to be a COMMA or SPACE separated STRING\n        return tuple(bc.zope_i18n_allowed_languages.split())\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_compile_mo_files(self):\n        return bool(\n            bc.zope_i18n_compile_mo_files is True or \n            bc.zope_i18n_compile_mo_files == \"1\")\n   \n    @property\n    @bungeni_custom_errors\n    def country_code(self):\n        \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this \n        bungeni instance.\n        \"\"\"\n        return bc.country_code\n\n    @property\n    @bungeni_custom_errors\n    def default_language(self):\n        assert bc.default_language in self.zope_i18n_allowed_languages, \\\n            \"Default language [%s] not in allowed languages [%s]\" % (\n                bc.default_language, self.zope_i18n_allowed_languages,)\n        return bc.default_language\n        \n    @property\n    @bungeni_custom_errors\n    def right_to_left_languages(self):\n        rtl_langs = tuple(bc.right_to_left_languages.split())\n        assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\\n            \"Right to left languages [%s] not in allowed languages [%s]\" % (\n                bc.right_to_left_languages, self.zope_i18n_allowed_languages)\n        return rtl_langs\n    \n    @property\n    @bungeni_custom_errors\n    def check_auto_reload_localization(self):\n        \"\"\" () -> int\n        minimum number of seconds to wait between checks for whether a \n        localization file needs reloading; 0 means never check (deployment)\n        \"\"\"\n        int(bc.check_auto_reload_localization) # TypeError if not an int\n        return bc.check_auto_reload_localization\n    \n    \n    @bungeni_custom_errors\n    def get_workflow_condition(self, condition):\n        condition_module = resolve(\"._conditions\", \"bungeni_custom.workflows\")\n        condition = getattr(condition_module, condition) # raises AttributeError\n        return wrapped_callable(condition)\n    \n    @bungeni_custom_errors\n    def get_workflow_action(self, action):\n        action_module = resolve(\"._actions\", \"bungeni_custom.workflows\")\n        action = getattr(action_module, action) # raises AttributeError\n        return wrapped_callable(action)\n    \n    @bungeni_custom_errors\n    def get_form_constraint(self, constraint):\n        constraint_module = resolve(\"._constraints\", \"bungeni_custom.forms\")\n        constraint = getattr(constraint_module, constraint) # raises AttributeError\n        return wrapped_callable(constraint)\n    \n    @bungeni_custom_errors\n    def get_form_validator(self, validation):\n        validator_module = resolve(\"._validations\", \"bungeni_custom.forms\")\n        validator = getattr(validator_module, validation) # raises AttributeError\n        return wrapped_callable(validator)\n    \n    @bungeni_custom_errors\n    def get_form_derived(self, derived):\n        derived_module = resolve(\"._derived\", \"bungeni_custom.forms\")\n        derived_def = getattr(derived_module, derived) # raises AttributeError\n        return wrapped_callable(derived_def)\n    \n    \n    @property\n    @bungeni_custom_errors\n    def default_number_of_listing_items(self):\n        \"\"\"This is the max number of items that are displayed in a listing by\n        default. Returns an integer\n        \"\"\"\n        return int(bc.default_number_of_listing_items)\n    \n    @property\n    @bungeni_custom_errors\n    def long_text_column_listings_truncate_at(self):\n        \"\"\"When listing text columns, only display first so many characters.\"\"\"\n        return int(bc.long_text_column_listings_truncate_at)\n    \n    def xml_workspace_tabs_file(self):\n        \"\"\"helper function used by workspace tab info APIs\"\"\"\n        TABS_FILE = \"tabs.xml\"    \n        from lxml import etree\n        ws_path = self.get_path_for(\"workspace\")\n        file_path = os.path.join(ws_path, TABS_FILE)\n        tabs = etree.fromstring(open(file_path).read()) \n        return tabs                \n    \n    @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\")\n    @bungeni_custom_errors\n    def workspace_tab_count_cache_refresh_time(self):\n        \"\"\"The duration in seconds between tab count refresh operations\"\"\"\n        tabs = self.xml_workspace_tabs_file()\n        tabs_count_refresh = tabs.attrib[\"tab_count_cache_refresh_time\"]\n        return int(tabs_count_refresh)\n    \n    @cached_property.cachedIn(\"__workspace_tabs__\")\n    @bungeni_custom_errors\n    def workspace_tabs(self):\n        \"\"\"The tabs in the workspace\"\"\"\n        ws_tabs = []\n        tabs = self.xml_workspace_tabs_file()\n        for tab in tabs.iterchildren(tag=\"tab\"):\n            ws_tabs.append(tab.attrib[\"id\"])\n        return ws_tabs    \n\n    @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_access_token_expiry_time(self):\n        \"\"\"time in seconds before an access token expires\"\"\"\n        return (bc.oauth_access_token_expiry_time)\n\n    @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_authorization_token_expiry_time(self):\n        \"\"\"time in seconds before an oauth authorization code expires\n        max recommended time is 10min\n        \"\"\"\n        return int(bc.oauth_auth_expiry_time)\n    # utility methods\n    \n    def get_root_path(self):\n        \"\"\"Get absolute physical path location for currently active \n        bungeni_custom package folder.\n        \"\"\"\n        return os.path.dirname(os.path.abspath(bc.__file__)) \n    \n    def get_path_for(self, *path_components):\n        \"\"\"Get absolute path, under bungeni_custom, for path_components.\n        \"\"\"\n        return os.path.join(*(self.get_root_path(),)+path_components)\n    \n    def put_env(self, key):\n        \"\"\"Set capi value for {key} as the environment variable {key}\n        i.e. use to set os.environ[key].\n        \n        Wrapper on os.put_env(key, string_value) -- to take care of\n        the value string-casting required by os.put_env while still \n        allowing the liberty of data-typing values of capi attributes \n        as needed.\n        \"\"\"\n        value = getattr(self, key)\n        try:\n            os.environ[key] = value\n            # OK, value is a string... done.\n        except TypeError:\n            # putenv() argument 2 must be string, not <...>\n            # i.e. value is NOT a string... try string-casting:\n            try:\n                # some zope code expects sequences to be specified as a \n                # COMMA or SPACE separated STRING, so we first try the value \n                # as a sequence, and serialize it to an environment variable \n                # value as expected by zope\n                os.environ[key] = \" \".join(value)\n            except TypeError:\n                # not a sequence, just fallback on repr(value)\n                os.environ[key] = repr(value)\n                # ensure that the original object value defines a __repr__ \n                # that can correctly re-instantiate the original object\n                assert eval(os.environ[key]) == value\n    \n    _is_modified_since_last_times = {} # {path: (last_checked, last_modified)}\n    def is_modified_since(self, abspath, modified_on_first_check=True):\n        \"\"\" (abspath:str, modified_on_first_check:bool) -> bool\n        Checks file path st_mtime to see if file has been modified since last \n        check. Updates entry per path, with last (check, modified) times.\n        \"\"\"\n        check_auto_reload_localization = self.check_auto_reload_localization\n        now = time.time()\n        last_checked, old_last_modified = \\\n            self._is_modified_since_last_times.get(abspath) or (0, 0)\n        if not check_auto_reload_localization:\n            # 0 =>> never check (unless this is the first check...)\n            if last_checked or not modified_on_first_check:\n                return False\n        if not now-last_checked > check_auto_reload_localization:\n            # last check too recent, avoid doing os.stat\n            return False\n        last_modified = os.stat(abspath).st_mtime\n        self._is_modified_since_last_times[abspath] = (now, last_modified)\n        if not last_checked:\n            # last_checked==0, this is the first check\n            return modified_on_first_check\n        return (old_last_modified < last_modified)\n    \n    # type registry\n    \n    def get_type_info(self, discriminator):\n        \"\"\"Get the TypeInfo instance for discriminator (see core.type_info). \n        \n        The discriminator may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: implements IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor_model: implements IModelDescriptor\n        \n        Raise KeyError if no entry matched.\n        \"\"\"\n        return type_info._get(discriminator)\n    \n    def iter_type_info(self, scope=None):\n        \"\"\"Return iterator on all registered (key, TypeInfo) entries.\n        scope:either(None, \"system\", \"archetype\", \"custom\")\n        \"\"\"\n        for type_key, ti in type_info._iter():\n            if (scope is None or ti.scope == scope):\n                yield type_key, ti\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py":{"changes":[{"diff":"\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"","add":2,"remove":2,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py","badparts":["        api[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])"],"goodparts":["        admin[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, admin[u\"applications\""]}],"source":"\n \"\"\"The Bungeni Application $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.core.app\") from zope.interface import implements from zope.interface import implementedBy from zope import component from zope.interface.declarations import alsoProvides from zope.app.appsetup.appsetup import getConfigContext from zope.app.component import site from zope.location.interfaces import ILocation from ore.wsgiapp.app import Application from ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent from bungeni.models import domain from bungeni.models import interfaces as model_interfaces from bungeni.models.utils import get_current_parliament from bungeni.models.utils import container_getter from bungeni.core import interfaces from bungeni.core import location from bungeni.core.content import(Section, AdminSection, AkomaNtosoSection, WorkspaceSection, APISection, OAuthSection) from bungeni.core.content import QueryContent from bungeni.core.i18n import _ from bungeni.core.workspace import(WorkspaceContainer, WorkspaceUnderConsiderationContainer, WorkspaceTrackedDocumentsContainer, WorkspaceGroupsContainer, WorkspaceSchedulableContainer, load_workspaces) from bungeni.core.notifications import load_notifications from bungeni.core.emailnotifications import load_email from bungeni.core.serialize import serialization_notifications from bungeni.ui.utils import url, common from bungeni.capi import capi from bungeni.utils import register @register.handler( (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent)) def on_wsgi_application_created_event(application, event): \"\"\"Additional setup on IWSGIApplicationCreatedEvent. \"\"\" log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) for type_key, ti in capi.iter_type_info(): if ti.workflow: ti.workflow.validate_permissions_roles() import bungeni.core.workflows.events load_workspaces() load_notifications() load_email() serialization_notifications() import bungeni.core.events app_setup=model_interfaces.IBungeniSetup(application) app_setup.setUp() try: import bungeni.utils.xmlconfexport as confexp confexp.write_all() except: log.debug((\"on_wsgi_application_created:\" \"error while exporting config parameters to xml\")) log.debug(\"on_wsgi_application_created_event: _features: %s\" %( getConfigContext()._features)) def to_locatable_container(domain_class, *domain_containers): component.provideAdapter(location.ContainerLocation(*domain_containers), (implementedBy(domain_class), ILocation)) class BungeniApp(Application): implements(model_interfaces.IBungeniApplication) class AppSetup(object): implements(model_interfaces.IBungeniSetup) def __init__(self, application): self.context=application def setUp(self): from zope.configuration import xmlconfig xmlconfig.string(\"\"\" <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\" xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\"> <include package=\"zope.i18n\" file=\"meta.zcml\" \/> <i18n:registerTranslations directory=\"%s\" \/> <\/configure> \"\"\" %(capi.get_path_for(\"translations\", \"bungeni\"))) import index index.setupFieldDefinitions(index.indexer) sm=site.LocalSiteManager(self.context) self.context.setSiteManager(sm) from bungeni.core import language from bungeni.ui import z3evoque z3evoque.set_get_gettext() z3evoque.setup_evoque() z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\")) z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL) z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name) z3evoque.domain.set_on_globals(\"get_base_direction\", language.get_base_direction) z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl) self.context[\"bungeni\"]=AkomaNtosoSection( title=_(u\"Bungeni\"), description=_(u\"Current parliamentary activity\"), default_name=\"bung\", ) workspace=self.context[\"workspace\"]=WorkspaceSection( title=_(\"section_workspace\", default=u\"Workspace\"), description=_(u\"Current parliamentary activity\"), default_name=\"my-documents\", ) alsoProvides(workspace, interfaces.ISearchableSection) workspace[\"my-documents\"]=WorkspaceSection( title=_(\"section_workspace_documents\", default=u\"my documents\"), description=_(u\"my documents workspace section\"), default_name=\"inbox\", marker=interfaces.IWorkspaceDocuments, ) for tab in capi.workspace_tabs: workspace[\"my-documents\"][tab]=WorkspaceContainer( tab_type=tab, title=_(\"section_workspace_%s\" % tab, default=tab), marker=interfaces.IWorkspaceTab ) ws_uc=workspace[\"under-consideration\"]=WorkspaceSection( title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), default_name=\"documents\", marker=interfaces.IWorkspaceUnderConsideration) ws_uc[\"documents\"]=WorkspaceUnderConsiderationContainer( name=\"documents\", title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), marker=interfaces.IWorkspaceTrackedDocuments) ws_uc[\"tracked-documents\"]=WorkspaceTrackedDocumentsContainer( name=\"tracked documents\", title=_(u\"tracked documents\"), description=_(u\"tracked documents\")) ws_sched=workspace[\"scheduling\"]=Section( title=_(\"section_scheduling\", default=u\"Scheduling\"), description=_(u\"Workspace Scheduling\"), default_name=\"index\", marker=interfaces.IWorkspaceScheduling) ws_sched[\"committees\"]=QueryContent( container_getter(get_current_parliament, \"committees\"), title=_(\"section_scheduling_committees\", default=u\"Committees\"), description=_(u\"Committee schedules\")) ws_sched[\"documents\"]=WorkspaceSchedulableContainer( name=_(u\"schedulable items\"), title=_(u\"schedulable items\"), description=_(u\"documents available for scheduling\")) ws_sched[\"sittings\"]=QueryContent( container_getter(get_current_parliament, \"sittings\"), title=_(\"section_scheduling_sittings\", default=u\"Sittings\"), description=_(u\"Plenary Sittings\")) ws_sched[\"agendaitems\"]=QueryContent( container_getter(get_current_parliament, \"agendaitems\"), title=_(\"section_scheduling_agenda_items\", default=u\"Agenda items\"), description=_(u\"Manage agenda items\")) workspace[\"groups\"]=WorkspaceSection( title=_(\"section_groups\", default=u\"Groups\"), description=_(u\"Bungeni Groups\"), default_name=\"my-groups\", marker=interfaces.IWorkspaceGroups) workspace[\"groups\"][\"my-groups\"]=WorkspaceGroupsContainer( name=\"my-groups\", title=_(u\"My Groups\"), description=_(u\"Groups that the user is a member of\")) for key, info in capi.iter_type_info(): if model_interfaces.IScheduleContent.implementedBy(info.domain_model): container_name=\"%ss\" % key container=\"%sContainer\" % info.domain_model.__name__ ws_sched[container_name]=getattr(domain, container)() to_locatable_container(info.domain_model, ws_sched[container_name]) admin=self.context[\"admin\"]=AdminSection( title=_(u\"Administration\"), description=_(u\"Manage bungeni settings\"), default_name=\"admin-index\", marker=model_interfaces.IBungeniAdmin) alsoProvides(admin, interfaces.ISearchableSection) content=admin[\"content\"]=Section( title=_(u\"Content\"), description=_(u\"browse bungeni content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"browse-admin\") admin[\"email-settings\"]=Section( title=_(u\"email settings\"), description=_(u\"manage email settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"email-settings\") admin[\"xapian-settings\"]=Section( title=_(u\"search index settings\"), description=_(u\"manage search index settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"xapian-settings\") admin[\"registry-settings\"]=Section( title=_(u\"registry settings\"), description=_(u\"manage registry settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"registry-settings\") admin[\"serialization-manager\"]=Section( title=_(u\"serialization manager\"), description=_(u\"batch serialization of content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"serialization-manager\") content[u\"parliaments\"]=domain.ParliamentContainer() to_locatable_container(domain.Parliament, content[u\"parliaments\"]) content[u\"users\"]=domain.UserContainer() to_locatable_container(domain.User, content[u\"users\"]) api=self.context[\"api\"]=APISection( title=_(u\"Bungeni API\"), description=_(u\"Bungeni REST API\"), default_name=\"index.html\", ) api[\"oauth\"]=OAuthSection( title=_(u\"Bungeni OAuth API\"), description=_(u\"Bungeni OAuth API\"), default_name=\"index.html\", ) api[u\"applications\"]=domain.OAuthApplicationContainer() to_locatable_container(domain.OAuthApplication, api[u\"applications\"]) ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"The Bungeni Application \n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.core.app\")\n\nfrom zope.interface import implements\nfrom zope.interface import implementedBy\nfrom zope import component\nfrom zope.interface.declarations import alsoProvides\n\nfrom zope.app.appsetup.appsetup import getConfigContext\nfrom zope.app.component import site\nfrom zope.location.interfaces import ILocation\n\nfrom ore.wsgiapp.app import Application\nfrom ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent\n\nfrom bungeni.models import domain\nfrom bungeni.models import interfaces as model_interfaces\nfrom bungeni.models.utils import get_current_parliament\nfrom bungeni.models.utils import container_getter\n\nfrom bungeni.core import interfaces\nfrom bungeni.core import location\nfrom bungeni.core.content import (Section, AdminSection, AkomaNtosoSection,\n    WorkspaceSection, APISection, OAuthSection)\nfrom bungeni.core.content import QueryContent\nfrom bungeni.core.i18n import _\nfrom bungeni.core.workspace import (WorkspaceContainer,\n    WorkspaceUnderConsiderationContainer,\n    WorkspaceTrackedDocumentsContainer,\n    WorkspaceGroupsContainer,\n    WorkspaceSchedulableContainer,\n    load_workspaces)\nfrom bungeni.core.notifications import load_notifications\nfrom bungeni.core.emailnotifications import load_email\nfrom bungeni.core.serialize import serialization_notifications\nfrom bungeni.ui.utils import url, common # !+ core dependency on ui\nfrom bungeni.capi import capi\nfrom bungeni.utils import register\n\n\n\n@register.handler(\n    (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent))\ndef on_wsgi_application_created_event(application, event):\n    \"\"\"Additional setup on IWSGIApplicationCreatedEvent.\n    \"\"\"\n    # !+ui.app.on_wsgi_application_created_event ALWAYS gets called prior to this\n    log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) \n    \n    # additional workflow validation\n    for type_key, ti in capi.iter_type_info():\n        if ti.workflow:\n            ti.workflow.validate_permissions_roles()\n    \n    # import events module, registering handlers\n    import bungeni.core.workflows.events\n    \n    # load workspaces\n    load_workspaces()\n    \n    # load notifications\n    load_notifications()\n\n    # load email notifications\n    load_email()\n\n    # set up serialization notifications\n    serialization_notifications()\n    \n    # import events modules, registering handlers\n    import bungeni.core.events\n    \n    app_setup = model_interfaces.IBungeniSetup(application)\n    app_setup.setUp()\n    \n    # write configuration parameters to xml\n    try:\n        import bungeni.utils.xmlconfexport as confexp\n        confexp.write_all()\n    except:\n        log.debug((\"on_wsgi_application_created :\"\n            \"error while exporting config parameters to xml\"))\n    \n    log.debug(\"on_wsgi_application_created_event: _features: %s\" % (\n        getConfigContext()._features))\n\n\ndef to_locatable_container(domain_class, *domain_containers):\n    component.provideAdapter(location.ContainerLocation(*domain_containers),\n               (implementedBy(domain_class), ILocation))\n\n\nclass BungeniApp(Application):\n    implements(model_interfaces.IBungeniApplication)\n\nclass AppSetup(object):\n    \n    implements(model_interfaces.IBungeniSetup)\n    \n    def __init__(self, application):\n        self.context = application\n    \n    def setUp(self):\n        \n        # register translations\n        #import zope.i18n.zcml\n        #zope.i18n.zcml.registerTranslations(getConfigContext(),\n        #    capi.get_path_for(\"translations\", \"bungeni\"))\n        # !+ZCML_PYTHON(mr, apr-2011) above registerTranslations() in python \n        # does not work, as subsequent utility lookup fails. We workaround it \n        # by executing the following parametrized bit of ZCML:\n        from zope.configuration import xmlconfig\n        xmlconfig.string(\"\"\"\n            <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\"\n                xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\">\n                <include package=\"zope.i18n\" file=\"meta.zcml\" \/>\n                <i18n:registerTranslations directory=\"%s\" \/>\n            <\/configure>\n            \"\"\" % (capi.get_path_for(\"translations\", \"bungeni\")))\n        \n        # ensure indexing facilities are setup(lazy)\n        import index\n        index.setupFieldDefinitions(index.indexer)\n        \n        sm = site.LocalSiteManager(self.context)\n        self.context.setSiteManager(sm)\n        \n        from bungeni.core import language\n        from bungeni.ui import z3evoque\n        z3evoque.set_get_gettext()\n        z3evoque.setup_evoque()\n        z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\"))\n        z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL)\n        z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name)\n        z3evoque.domain.set_on_globals(\"get_base_direction\", \n            language.get_base_direction)\n        z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl)          \n        \n        # !+ where is the view name for the app root (slash) set?\n        \n        # CONVENTION: the action of each site top-section is made to point \n        # directly the primary sub-section (the INDEX) that it contains.\n        # EXCEPTION: the \"\/\", when logged in, is redirected to \"\/workspace\/pi\"\n        \n        self.context[\"bungeni\"] = AkomaNtosoSection(\n            title=_(u\"Bungeni\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"bung\", # !+NAMING(mr, jul-2011) bung?!?\n        )\n        \n        # top-level sections\n        workspace = self.context[\"workspace\"] = WorkspaceSection(\n            title=_(\"section_workspace\", default=u\"Workspace\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"my-documents\",\n        )\n        alsoProvides(workspace, interfaces.ISearchableSection)\n        \n        workspace[\"my-documents\"] = WorkspaceSection(\n            title=_(\"section_workspace_documents\", default=u\"my documents\"),\n            description=_(u\"my documents workspace section\"),\n            default_name=\"inbox\",\n            marker=interfaces.IWorkspaceDocuments,\n        )\n        \n        for tab in capi.workspace_tabs:\n            workspace[\"my-documents\"][tab] = WorkspaceContainer(\n                tab_type=tab,\n                title=_(\"section_workspace_%s\" % tab, default=tab),\n                marker=interfaces.IWorkspaceTab\n            )\n\n        ws_uc = workspace[\"under-consideration\"] = WorkspaceSection(\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            default_name=\"documents\",\n            marker=interfaces.IWorkspaceUnderConsideration)\n        ws_uc[\"documents\"] = WorkspaceUnderConsiderationContainer(\n            name=\"documents\",\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            marker=interfaces.IWorkspaceTrackedDocuments)\n        ws_uc[\"tracked-documents\"] = WorkspaceTrackedDocumentsContainer(\n            name=\"tracked documents\",\n            title=_(u\"tracked documents\"),\n            description=_(u\"tracked documents\"))\n        \n        ws_sched = workspace[\"scheduling\"] = Section(\n            title=_(\"section_scheduling\", default=u\"Scheduling\"),\n            description=_(u\"Workspace Scheduling\"),\n            default_name=\"index\",\n            marker=interfaces.IWorkspaceScheduling)\n        ws_sched[\"committees\"] = QueryContent(\n            container_getter(get_current_parliament, \"committees\"),\n            title=_(\"section_scheduling_committees\", default=u\"Committees\"),\n            #!+marker=interfaces.ICommitteeAddContext,\n            description=_(u\"Committee schedules\"))\n        ws_sched[\"documents\"] = WorkspaceSchedulableContainer(\n            name=_(u\"schedulable items\"),\n            title=_(u\"schedulable items\"),\n            description=_(u\"documents available for scheduling\"))\n        ws_sched[\"sittings\"] = QueryContent(\n            container_getter(get_current_parliament, \"sittings\"),\n            title=_(\"section_scheduling_sittings\", default=u\"Sittings\"),\n            description=_(u\"Plenary Sittings\"))\n        ws_sched[\"agendaitems\"] = QueryContent(\n            container_getter(get_current_parliament, \"agendaitems\"),\n            title=_(\"section_scheduling_agenda_items\", \n                default=u\"Agenda items\"),\n            #marker=interfaces.IAgendaItemAddContext,\n            description=_(u\"Manage agenda items\"))\n        \n        workspace[\"groups\"] = WorkspaceSection(\n            title=_(\"section_groups\", default=u\"Groups\"),\n            description=_(u\"Bungeni Groups\"),\n            default_name=\"my-groups\",\n            marker=interfaces.IWorkspaceGroups)\n        workspace[\"groups\"][\"my-groups\"] = WorkspaceGroupsContainer(\n            name=\"my-groups\",\n            title=_(u\"My Groups\"),\n            description=_(u\"Groups that the user is a member of\"))\n        \n        #!+TIMING\n        #!+AUTO CONTAINERS SCHEDULING(mb, April-2012)\n        # type_info missing container name\n        for key, info in capi.iter_type_info():\n            if model_interfaces.IScheduleContent.implementedBy(info.domain_model):\n                container_name = \"%ss\" % key\n                container = \"%sContainer\" % info.domain_model.__name__\n                ws_sched[container_name] = getattr(domain, container)()\n                to_locatable_container(info.domain_model, ws_sched[container_name])\n        \n        \n        ##########\n        # Admin User Interface\n        # Administration section\n        \n        #!+SECURITY(miano. nov-2010) Admin section now uses AdminSection\n        # container that is identical to Section, only difference is that\n        # traversing though it requires zope.ManageSite permission as defined\n        # in core\/configure.zcml\n        \n        admin = self.context[\"admin\"] = AdminSection(\n            title=_(u\"Administration\"),\n            description=_(u\"Manage bungeni settings\"),\n            default_name=\"admin-index\",\n            marker=model_interfaces.IBungeniAdmin)\n        alsoProvides(admin, interfaces.ISearchableSection)\n        \n        content = admin[\"content\"] = Section(\n            title=_(u\"Content\"),\n            description=_(u\"browse bungeni content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"browse-admin\")\n        \n        admin[\"email-settings\"] = Section(\n            title=_(u\"email settings\"),\n            description=_(u\"manage email settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"email-settings\")\n        \n        admin[\"xapian-settings\"] = Section(\n            title=_(u\"search index settings\"),\n            description=_(u\"manage search index settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"xapian-settings\")\n        \n        admin[\"registry-settings\"] = Section(\n            title=_(u\"registry settings\"),\n            description=_(u\"manage registry settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"registry-settings\")\n        \n        admin[\"serialization-manager\"] = Section(\n            title=_(u\"serialization manager\"),\n            description=_(u\"batch serialization of content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"serialization-manager\")\n        \n        content[u\"parliaments\"] = domain.ParliamentContainer()\n        to_locatable_container(domain.Parliament, content[u\"parliaments\"])\n        \n        content[u\"users\"] = domain.UserContainer()\n        to_locatable_container(domain.User, content[u\"users\"])\n\n        api = self.context[\"api\"] = APISection(\n            title=_(u\"Bungeni API\"),\n            description=_(u\"Bungeni REST API\"),\n            default_name=\"index.html\",\n        )\n        api[\"oauth\"] = OAuthSection(\n            title=_(u\"Bungeni OAuth API\"),\n            description=_(u\"Bungeni OAuth API\"),\n            default_name=\"index.html\",\n        )\n        api[u\"applications\"] = domain.OAuthApplicationContainer()\n        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n"}},"msg":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings."}},"https:\/\/github.com\/BenoitTalbot\/bungeni-portal":{"1aa46cd5b0df5108f00e711037f07645a9c1f6de":{"url":"https:\/\/api.github.com\/repos\/BenoitTalbot\/bungeni-portal\/commits\/1aa46cd5b0df5108f00e711037f07645a9c1f6de","html_url":"https:\/\/github.com\/BenoitTalbot\/bungeni-portal\/commit\/1aa46cd5b0df5108f00e711037f07645a9c1f6de","message":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings.","sha":"1aa46cd5b0df5108f00e711037f07645a9c1f6de","keyword":"replay attack improve","diff":"diff --git a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\nindex 44ae077ff..2d6b1645d 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n@@ -254,7 +254,7 @@ def permission_type_key(self):\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\nindex e328f6c85..96e0dc6f0 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n@@ -209,7 +209,14 @@ def oauth_authorization_token_expiry_time(self):\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self):\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\nindex 7435b4a3a..28e02aebf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n@@ -300,5 +300,5 @@ def setUp(self):\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"])\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\nindex 4ac3db531..8610d7e73 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n@@ -573,4 +573,11 @@ def title(self):\n         context = _merged(self.context)\n         return component.getUtility(IRole, context.role_id).title\n \n+@register.adapter()\n+class OAuthApplicationDescriptiveProperties(DescriptiveProperties):\n+    component.adapts(interfaces.IOAuthApplication)\n \n+    @property\n+    def title(self):\n+        context = _merged(self.context)\n+        return context.name\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\nindex e747ae61c..7122485b2 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n@@ -578,6 +578,9 @@ class IDebateTake(interface.Interface):\n class IOAuthApplication(interface.Interface):\n     \"\"\"Marker interface for an OAuth Application record\"\"\"\n \n+class IOAuthApplicationContainer(IAlchemistContainer):\n+    \"\"\"Marker interface for an OAuth Applications container\"\"\"\n+\n class IOAuthAuthorization(interface.Interface):\n     \"\"\"Marker interfeace for OAuth authorizations\"\"\"\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\nindex e34a41ef8..3900cbd92 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n@@ -163,8 +163,13 @@\n   <permission id=\"bungeni.debate_takes.View\" title=\"View debate takes\" \/>\n   <permission id=\"bungeni.debate_takes.Edit\" title=\"Edit debate takes\" \/>\n \n-  <permission id=\"bungeni.oauth_application.View\" title=\"View oauth app\" \/>\n-  <permission id=\"bungeni.oauth_application.Delete\" title=\"Delete oauth app\" \/>\n-  <meta:redefinePermission from=\"bungeni.oauth_application.View\" to=\"zope.ManageContent\" \/>\n+  <permission id=\"bungeni.o_auth_application.View\" title=\"View oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Add\" title=\"Add oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Edit\" title=\"Edit oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Delete\" title=\"Delete oauth app\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.View\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Add\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Edit\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Delete\" to=\"zope.ManageContent\" \/>\n   <permission id=\"bungeni.oauth.View\" title=\"Use oauth api\" \/>\n <\/configure>\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\nindex 128a2c535..f1d0ed492 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n@@ -1185,7 +1185,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"identifier\", rdb.UnicodeText, nullable=False, \n         unique=True),\n     rdb.Column(\"name\", rdb.UnicodeText, nullable=False),\n-    rdb.Column(\"secret\", rdb.String(32), nullable=False),\n+    rdb.Column(\"secret\", rdb.String(100), nullable=False),\n     rdb.Column(\"redirection_endpoint\", rdb.UnicodeText, nullable=False)\n )\n \n@@ -1195,7 +1195,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n         nullable=False),\n     rdb.Column(\"application_id\", rdb.Integer,\n         rdb.ForeignKey(\"oauth_application.application_id\"), nullable=False),\n-    rdb.Column(\"authorization_code\", rdb.String(32), nullable=False),\n+    rdb.Column(\"authorization_code\", rdb.String(100), nullable=False),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n     rdb.Column(\"active\", rdb.Boolean(), nullable=False)\n )\n@@ -1204,8 +1204,8 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"access_token_id\", rdb.Integer, primary_key=True),\n     rdb.Column(\"authorization_id\", rdb.Integer,\n              rdb.ForeignKey(\"oauth_authorization.authorization_id\")),\n-    rdb.Column(\"access_token\", rdb.String(32)),\n-    rdb.Column(\"refresh_token\", rdb.String(32)),\n+    rdb.Column(\"access_token\", rdb.String(100)),\n+    rdb.Column(\"refresh_token\", rdb.String(100)),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n )\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\nindex 21c811509..bf1568c5e 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n@@ -1,8 +1,10 @@\n import hashlib\n+import hmac\n import random\n import string\n import urllib\n import simplejson\n+import time\n from datetime import datetime, timedelta\n \n from sqlalchemy.orm.exc import NoResultFound\n@@ -30,8 +32,8 @@\n def get_key():\n     \"\"\"Return a randomly generated key\n     \"\"\"\n-    m = hashlib.sha256()\n-    m.update(\"\".join(random.sample(string.letters + string.digits, 32)))\n+    m = hashlib.sha1()\n+    m.update(\"\".join(random.sample(string.letters + string.digits, 20)))\n     return m.hexdigest()\n \n \n@@ -45,10 +47,10 @@ class AddOAuthApplication(forms.common.AddForm):\n     @form.action(_(u\"Create Application\"), name=\"create\")\n     def handle_create_application(self, action, data, validator=\"validateAdd\"):\n         oauth_app = domain.OAuthApplication()\n-        oauth_app.application_identifier = data[\"application_identifier\"]\n-        oauth_app.application_name = data[\"application_name\"]\n+        oauth_app.identifier = data[\"identifier\"]\n+        oauth_app.name = data[\"name\"]\n         oauth_app.redirection_endpoint = data[\"redirection_endpoint\"]\n-        oauth_app.application_key = get_key()\n+        oauth_app.secret = get_key()\n         session = Session()\n         session.add(oauth_app)\n         session.flush()\n@@ -163,41 +165,73 @@ def __call__(self):\n class IOAuthAuthorizeForm(interface.Interface):\n     client_id = schema.TextLine(required=False)\n     state = schema.TextLine(required=False)\n-\n+    time = schema.TextLine(required=False)\n+    nonce = schema.TextLine(required=False)\n \n class OAuthAuthorizeForm(form.FormBase):\n     form_fields = form.Fields(IOAuthAuthorizeForm)\n     form_fields[\"client_id\"].custom_widget = widgets.HiddenTextWidget\n     form_fields[\"state\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"nonce\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"time\"].custom_widget = widgets.HiddenTextWidget\n     template = NamedTemplate(\"alchemist.form\")\n     form_name = _(\"authorise_oauth_application\",\n         default=u\"Authorise OAuth Application\")\n \n     def __init__(self, context, request, parameters={}):\n         self.parameters = parameters\n+        if self.parameters:\n+            self.parameters[\"time\"] = time.time()\n+            self.parameters[\"nonce\"] = self.generate_nonce(\n+                self.parameters[\"time\"])\n         self.action_url = \"\/api\/oauth\/authorize-form\"\n         super(OAuthAuthorizeForm, self).__init__(context, request)\n \n     def setUpWidgets(self, ignore_request=False):\n+        \n         self.widgets = form.setUpWidgets(\n             self.form_fields, self.prefix, self.context, self.request,\n             data=self.parameters if self.parameters else self.request.form,\n             ignore_request=ignore_request\n         )\n \n-    @form.action(_(u\"Authorize application\"), name=\"authorize\")\n+    def generate_nonce(self, auth_time):\n+        data = \"{0}:{1}:{2}\".format(\n+            self.parameters[\"client_id\"], get_db_user().user_id, auth_time)\n+        return hmac.new(capi.oauth_hmac_key, data, hashlib.sha1).hexdigest()\n+\n+    def check_authorization(self, action, data):\n+        errors = []\n+        data = self.request.form\n+        if not data.get(\"form.time\", None) or not data.get(\"form.nonce\", None):\n+            errors.append(InvalidRequest)\n+            return errors\n+        max_time = datetime.fromtimestamp(float(data[\"form.time\"])) + \\\n+            timedelta(seconds=capi.oauth_authorization_token_expiry_time)\n+        if (datetime.now() > max_time):\n+            errors.append(InvalidGrant)\n+        if data[\"form.nonce\"] != self.generate_nonce(data[\"form.time\"]):\n+            errors.append(InvalidGrant)\n+        return errors\n+\n+    def handle_failure(self, action, data, errors):\n+        return ErrorPage(self.context, self.request, errors[0])()\n+\n+    @form.action(_(u\"Authorize application\"), name=\"authorize\",\n+        validator=check_authorization, failure=handle_failure)\n     def handle_authorize_app(self, action, data):\n         session = Session()\n         oauth_authorization = domain.OAuthAuthorization()\n         oauth_authorization.user_id = get_db_user().user_id\n         app = session.query(domain.OAuthApplication\n-            ).filter(domain.OAuthApplication.application_identifier ==\n+            ).filter(domain.OAuthApplication.identifier ==\n                 data[\"client_id\"]\n             ).one()\n         oauth_authorization.application_id = app.application_id\n         oauth_authorization.authorization_code = get_key()\n         oauth_authorization.expiry = datetime.now() + timedelta(\n-            seconds=capi.oauth_auth_expiry_time)\n+            seconds=capi.oauth_authorization_token_expiry_time)\n+        oauth_authorization.active = True\n         session.add(oauth_authorization)\n         redirect_uri = \"{0}?code={1}\".format(\n             app.redirection_endpoint, oauth_authorization.authorization_code)\n@@ -213,10 +247,10 @@ def handle_cancel(self, action, data):\n                      == data[\"client_id\"]\n             ).one()\n         error = UnauthorizedClient(app.redirection_endpoint, data[\"state\"])\n-        redirect_error(self.request, error)\n+        redirect_error(self.context, self.request, error)\n \n \n-def redirect_error(request, error):\n+def redirect_error(context, request, error):\n     if error.redirect_uri:\n         next_url = \"{0}?error={1}&error_description={2}\".format(\n             error.redirect_uri, error.error, error.error_description)\n@@ -224,10 +258,10 @@ def redirect_error(request, error):\n             next_url = \"{0}&state={1}\".format(next_url, error.state)\n         return request.response.redirect(next_url, trusted=True)\n     else:\n-        bad_request(request, error)\n+        return ErrorPage(context, request, error)()\n \n \n-def bad_request(request, error):\n+def bad_request(context, request, error):\n     request.response.setStatus(400)\n     data = {\"error\": error.error, \"error_description\": error.error_description}\n     return simplejson.dumps(data)\n@@ -277,7 +311,7 @@ def __call__(self):\n         except UnauthorizedClient as e:\n             return ErrorPage(self.context, self.request, e)()\n         except OAuthException as e:\n-            return redirect_error(self.request, e)\n+            return redirect_error(self.context, self.request, e)\n \n         if not IUnauthenticatedPrincipal.providedBy(self.request.principal):\n             # authorize form\n@@ -345,7 +379,7 @@ def __call__(self):\n         try:\n             parameters = self.parameters()\n         except OAuthException as e:\n-            return bad_request(self.request, e)\n+            return bad_request(self.context, self.request, e)\n         assert (self.authorization is not None,\n             \"Authorization object not initalized\")\n         self.authorization.expiry = datetime.now()\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\nindex 18c6363b5..1372b42bf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n@@ -1718,13 +1718,13 @@ class ItemScheduleVoteDescriptor(ModelDescriptor):\n class OAuthApplicationDescriptor(ModelDescriptor):\n     localisable = False\n     fields = [\n-        F(name=\"application_identifier\",\n+        F(name=\"identifier\",\n           label=\"Unique Application Identifier\",\n           required=True,\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_name\",\n+        F(name=\"name\",\n           label=\"Application Name\",\n           required=True,\n           value_type=\"text\",\n@@ -1736,8 +1736,8 @@ class OAuthApplicationDescriptor(ModelDescriptor):\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_key\",\n-          label=\"Application Key\",\n+        F(name=\"secret\",\n+          label=\"Application Secret\",\n           localizable=[show(\"view\"), hide(\"add\")],\n           required=True,\n           value_type=\"text\",\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\nindex 57deb7ee2..66b0dbd7b 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n@@ -1265,5 +1265,14 @@\n      viewName=\"\"\n      weight=\"30\"\n      \/-->\n+   <!--OAuth-->\n+   <browser:menuItem menu=\"plone_contentmenu\"\n+        for=\"bungeni.models.interfaces.IOAuthApplicationContainer\"\n+        title=\"Add OAuth Application\"\n+        action=\"add\"\n+        permission=\"bungeni.o_auth_application.Add\"\n+        layer=\".interfaces.IAdminSectionLayer\"\n+        order=\"62\"\n+    \/>\n <\/configure>\n \n","files":{"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py":{"changes":[{"diff":"\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),","add":1,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py","badparts":["    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),"],"goodparts":["    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),"]}],"source":"\n \"\"\"Aggregation of information about loaded domain types. No public methods here --all available methods from this are those exposed via bungeni.capi. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\") from zope.interface.interfaces import IInterface from zope.security.proxy import removeSecurityProxy from zope.dottedname.resolve import resolve from bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface from bungeni.alchemist.model import( new_custom_domain_interface, new_custom_domain_model, ) from bungeni.alchemist.catalyst import( INTERFACE_MODULE, MODEL_MODULE ) from bungeni.models import interfaces from bungeni.models import domain from bungeni.core.workflow.interfaces import IWorkflow from bungeni.utils import naming __all__=[] def _iter(): \"\"\"Return iterator on all(key, TypeInfo) entries in TYPE_REGISTRY. Usage: capi.iter_type_info() \"\"\" for type_key, ti in TYPE_REGISTRY: yield type_key, ti def _get(discriminator): \"\"\"Get the TypeInfo instance for discriminator, that may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: provides IBungeniContent domain model instance: type provides IBungeniContent descriptor: provides IModelDescriptor Raise KeyError if no entry matched. Usage: capi.get_type_info(discriminator) \"\"\" if discriminator is None: m=\"type_info._get discriminator is None\" log.error(m) raise ValueError(m) discri=removeSecurityProxy(discriminator) getter=None if IIModelInterface.providedBy(discri): discri=naming.type_key(\"table_schema_interface_name\", discri.__name__) elif IInterface.providedBy(discri): discri=naming.type_key(\"model_interface_name\", discri.__name__) elif type(discri) is type and issubclass(discri, domain.Entity): discri=naming.polymorphic_identity(discri) elif isinstance(discri, domain.Entity): discri=naming.polymorphic_identity(type(discri)) if isinstance(discri, basestring): getter=_get_by_type_key elif IWorkflow.providedBy(discri): getter=_get_by_workflow elif IModelDescriptor.implementedBy(discri): getter=_get_by_descriptor_model if getter is not None: ti=getter(discri) if ti is not None: return ti else: m=\"No type registered for discriminator: %r\" %(discriminator) else: m=\"Invalid type info lookup discriminator: %r\" %(discriminator) from bungeni.ui.utils import debug log.debug(debug.interfaces(discriminator)) log.debug(m) raise KeyError(m) def _get_by_type_key(key): for type_key, ti in _iter(): if type_key==key: return ti ''' !+IALCHEMISTCONTENT fails on different interfaces with same name! (Pdb) ti.interface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) ti.interface.__bases__ (<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>) (Pdb) iface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) iface.__bases__ (<InterfaceClass zope.interface.Interface>,) ''' def _get_by_model(model): for type_key, ti in _iter(): if model is ti.domain_model: return ti def _get_by_instance(instance): return _get_by_model(type(instance)) def _get_by_workflow(wf): for type_key, ti in _iter(): if wf is ti.workflow: return ti def _get_by_descriptor_model(descriptor_model): for type_key, ti in _iter(): if descriptor_model is ti.descriptor_model: return ti class TI(object): \"\"\"TypeInfo, associates together the following attributes for a given type: workflow_key the workflow file name defaults to the type_key for workflowed types that DO NOT specify is None for non-workflowed types workflow same workflow insatnce may be used by multiple types is None for non-workflowed types interface the manually applied application-dedicated model interface (if any) for the type derived_table_schema auto-generated db schema interface, provides IIModelInterface domain_model the domain class descriptor_model the descriptor model for UI views for the type container_class container class for domain_model container_interface interface for the container class for domain_model \"\"\" def __init__(self, workflow_key, iface, domain_model=None): self.workflow_key=workflow_key self.interface=iface self.derived_table_schema=None self.workflow=None self.domain_model=domain_model self.descriptor_model=None self.container_class=None self.container_interface=None self.custom=False def __str__(self): return str(self.__dict__) @property def scope(self): if self.custom: return \"custom\" if self.descriptor_model is not None: return self.descriptor_model.scope @property def permission_type_key(self): if self.custom: return self.workflow.name return(self.workflow_key or naming.type_key(\"model_name\", self.domain_model.__name__) ) ''' !+TYPE_REGISTRY externalize further to bungeni_custom, currently: -association of type key and dedicated interface are hard-wired here -ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when loading workflows and descriptors -type_key IS the underscore-separated lowercase of the domain cls name i.e. utils.naming.polymorphic_identity(domain_model) -!+ti.workflow_key SHOULD always be equal to type_key -!+corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated -!+dedicated interfaces for archetype incantations should be auto-generated, from specific workflow name\/attr... e.g. via: zope.interface.interface.InterfaceClass(iname, bases, __module__) -!+should ti.interface be automatically generated also for system types? Usage: from bungeni.capi import capi capi.get_type_info(discriminator) -> TypeInfo capi.iter_type_info() -> iterator of all registered(key, TypeInfo) ''' TYPE_REGISTRY=[ (\"user_address\", TI(\"address\", interfaces.IUserAddress)), (\"group_address\", TI(\"address\", interfaces.IGroupAddress)), (\"attachment\", TI(\"attachment\", interfaces.IAttachment)), (\"event\", TI(\"event\", interfaces.IEvent)), (\"sitting\", TI(\"sitting\", interfaces.ISitting)), (\"heading\", TI(\"heading\", interfaces.IHeading)), (\"user\", TI(\"user\", interfaces.IBungeniUser)), (\"signatory\", TI(\"signatory\", interfaces.ISignatory)), (\"group\", TI(\"group\", interfaces.IBungeniGroup)), (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)), (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)), (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)), (\"oauth_application\", TI(None, interfaces.IOAuthApplication)), (\"debate_media\", TI(None, interfaces.IDebateMedia)), (\"user_delegation\", TI(None, interfaces.IUserDelegation)), (\"title_type\", TI(None, interfaces.ITitleType)), (\"member_title\", TI(None, interfaces.IMemberTitle)), (\"change\", TI(None, interfaces.IChange)), (\"doc\", TI(None, interfaces.IDoc)), (\"doc_version\", TI(None, None)), (\"attachment_version\", TI(None, None)), (\"venue\", TI(None, interfaces.IVenue)), (\"session\", TI(None, interfaces.ISession)), (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)), (\"country\", TI(None, interfaces.ICountry)), (\"item_schedule\", TI(None, interfaces.IItemSchedule)), (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)), (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)), (\"editorial_note\", TI(None, interfaces.IEditorialNote)), (\"sitting_report\", TI(None, interfaces.ISittingReport)), (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)), ] def register_new_custom_type(type_key, workflow_key, archetype_key): \"\"\"Retrieve(create if needed) a domain interface and model for type_key, and register as new entry on TYPE_REGISTER. \"\"\" domain_iface_name=naming.model_interface_name(type_key) try: domain_iface=resolve(\"%s.%s\" %(INTERFACE_MODULE.__name__, domain_iface_name)) log.warn(\"Custom interface ALREADY EXISTS: %s\" %(domain_iface)) except ImportError: domain_iface=new_custom_domain_interface(type_key, domain_iface_name) domain_model_name=naming.model_name(type_key) try: domain_model=resolve(\"%s.%s\" %(MODEL_MODULE.__name__, domain_model_name)) log.warn(\"Custom domain model ALREADY EXISTS: %s\" %(domain_model)) except ImportError: domain_model=new_custom_domain_model(type_key, domain_iface, archetype_key) ti=TI(workflow_key, domain_iface, domain_model) ti.custom=True TYPE_REGISTRY.append((type_key, ti)) log.info(\"Registered custom type[%s]: %s\" %(archetype_key, type_key)) return type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Aggregation of information about loaded domain types.\n\nNo public methods here -- all available methods from this are those exposed \nvia bungeni.capi.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\")\n\nfrom zope.interface.interfaces import IInterface\nfrom zope.security.proxy import removeSecurityProxy\nfrom zope.dottedname.resolve import resolve\n\nfrom bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface\nfrom bungeni.alchemist.model import (\n    new_custom_domain_interface,\n    new_custom_domain_model,\n)\nfrom bungeni.alchemist.catalyst import (\n    INTERFACE_MODULE, \n    MODEL_MODULE\n)\nfrom bungeni.models import interfaces\nfrom bungeni.models import domain\nfrom bungeni.core.workflow.interfaces import IWorkflow\nfrom bungeni.utils import naming\n\n__all__ = []\n\n\n# acessors exposed via capi\n\ndef _iter():\n    \"\"\"Return iterator on all (key, TypeInfo) entries in TYPE_REGISTRY.\n    \n    Usage: capi.iter_type_info()\n    \"\"\"\n    for type_key, ti in TYPE_REGISTRY:\n        yield type_key, ti\n\ndef _get(discriminator):\n    \"\"\"Get the TypeInfo instance for discriminator, that may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: provides IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor: provides IModelDescriptor\n    \n    Raise KeyError if no entry matched.\n    \n    Usage: capi.get_type_info(discriminator)\n    \"\"\"\n    if discriminator is None:\n        m = \"type_info._get discriminator is None\"\n        log.error(m)\n        raise ValueError(m)\n    discri = removeSecurityProxy(discriminator)\n    getter = None\n    \n    # !+IALCHEMISTCONTENT normalize trickier discriminator cases to type_key\n    if IIModelInterface.providedBy(discri):\n        discri = naming.type_key(\"table_schema_interface_name\", discri.__name__)\n    elif IInterface.providedBy(discri):\n        discri = naming.type_key(\"model_interface_name\", discri.__name__)\n    elif type(discri) is type and issubclass(discri, domain.Entity):\n        discri = naming.polymorphic_identity(discri)\n    elif isinstance(discri, domain.Entity):\n        discri = naming.polymorphic_identity(type(discri))\n    \n    if isinstance(discri, basestring):\n        getter = _get_by_type_key\n    #elif IInterface.providedBy(discri):\n    #    getter = _get_by_interface\n    #!+elif interfaces.IBungeniContent.implementedBy(discri):\n    #elif issubclass(discri, domain.Entity):\n    #    getter = _get_by_model\n    #!+elif interfaces.IBungeniContent.providedBy(discri):\n    #elif isinstance(discri, domain.Entity):\n    #    getter = _get_by_instance\n    elif IWorkflow.providedBy(discri):\n        getter = _get_by_workflow\n    elif IModelDescriptor.implementedBy(discri):\n        getter = _get_by_descriptor_model\n    \n    if getter is not None:\n        ti = getter(discri)\n        if ti is not None:\n            return ti\n        else:\n            m = \"No type registered for discriminator: %r\" % (discriminator)\n    else: \n        m = \"Invalid type info lookup discriminator: %r\" % (discriminator)\n    from bungeni.ui.utils import debug\n    log.debug(debug.interfaces(discriminator))\n    log.debug(m)\n    raise KeyError(m)\n\n\n# following getters return \"first matching\" TypeInfo instance in registry\n    \ndef _get_by_type_key(key):\n    for type_key, ti in _iter():\n        if type_key == key:\n            return ti\n#def _get_by_interface(iface):\n''' !+IALCHEMISTCONTENT fails on different interfaces with same name!\n(Pdb) ti.interface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) ti.interface.__bases__\n(<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>)\n(Pdb) iface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) iface.__bases__\n(<InterfaceClass zope.interface.Interface>,)\n'''\n#    for type_key, ti in _iter():\n#        if iface is ti.interface: #!+issubclass(iface, ti.interface)?\n#            return ti\ndef _get_by_model(model):\n    for type_key, ti in _iter():\n        if model is ti.domain_model: #!+issubclass(model, ti.domain_model)?\n            return ti\ndef _get_by_instance(instance):\n    return _get_by_model(type(instance))\ndef _get_by_workflow(wf):\n    for type_key, ti in _iter():\n        if wf is ti.workflow:\n            return ti\ndef _get_by_descriptor_model(descriptor_model):\n    for type_key, ti in _iter():\n        if descriptor_model is ti.descriptor_model:\n            return ti\n\n# \n\nclass TI(object):\n    \"\"\"TypeInfo, associates together the following attributes for a given type:\n            workflow_key \n                the workflow file name\n                defaults to the type_key for workflowed types that DO NOT specify\n                is None for non-workflowed types\n            workflow \n                same workflow insatnce may be used by multiple types\n                is None for non-workflowed types\n            interface\n                the manually applied application-dedicated model interface \n                (if any) for the type\n            derived_table_schema\n                auto-generated db schema interface, provides IIModelInterface\n            domain_model\n                the domain class\n            descriptor_model\n                the descriptor model for UI views for the type\n            container_class\n                container class for domain_model\n            container_interface\n                interface for the container class for domain_model\n    \"\"\"\n    def __init__(self, workflow_key, iface, domain_model=None):\n        self.workflow_key = workflow_key\n        self.interface = iface\n        self.derived_table_schema = None # provides IIModelInterface\n        self.workflow = None\n        self.domain_model = domain_model\n        self.descriptor_model = None\n        self.container_class = None\n        self.container_interface = None\n        self.custom = False # type loaded from custom configuration \n        # NOTE: only needed temporarily (until descriptor_model is set), \n        # then ti.custom not be inconsistent descriptor_model.scope i.e.\n        #if self.custom: assert self.descriptor_model.scope == \"custom\"\n        # !+ archetype_key?\n    def __str__(self):\n        return str(self.__dict__)\n    \n    @property\n    def scope(self):\n        # !+CUSTOM_TYPE_DESCRIPTOR the self.custom check below MUST precede the\n        # check on self.descriptor_model.scope as otherwise the \"in-transit\" \n        # custom types will not be picked up as custom types -- as during\n        # loading the descriptors for all custom types may not yet have been \n        # autogenerated (and would therefore correctly have \n        # descriptor_model.scope=\"custom\" set).\n        if self.custom:\n            return \"custom\"\n        if self.descriptor_model is not None:\n            return self.descriptor_model.scope\n    \n    @property\n    def permission_type_key(self):\n        if self.custom:\n            # custom types ALWAYS have a type_key-bound workflow instance - that\n            # may therefore have a different name than workflow_key e.g. Office\n            # uses the \"group\" workflow, that is type-relative reloaded as the\n            # \"office\" workflow instance.\n            return self.workflow.name\n        # system types ALWAYS use workflow_key - even if multiple types use the \n        # same workflow e.g. UserAddress & GroupAddress. \n        # if no workflow, compute type_key from domain_model\n        # #!+REDUNDANT(mb, 2012) This type key is already known during type\n        # setup i.e. TYPE_REGISTRY\n        return (self.workflow_key or \n            naming.type_key(\"model_name\", self.domain_model.__name__)\n        )\n\n'''\n!+TYPE_REGISTRY externalize further to bungeni_custom, currently:\n- association of type key and dedicated interface are hard-wired here\n- ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when \n  loading workflows and descriptors\n- type_key IS the underscore-separated lowercase of the domain cls name \n  i.e. utils.naming.polymorphic_identity(domain_model)\n- !+ ti.workflow_key SHOULD always be equal to type_key\n- !+ corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated\n- !+ dedicated interfaces for archetype incantations should be auto-generated, \n    from specific workflow name\/attr... e.g. via:\n    zope.interface.interface.InterfaceClass(iname, bases, __module__)\n- !+ should ti.interface be automatically generated also for system types?\n\nUsage:\n    from bungeni.capi import capi\n    capi.get_type_info(discriminator) -> TypeInfo\n    capi.iter_type_info() -> iterator of all registered (key, TypeInfo)\n'''\nTYPE_REGISTRY = [\n    # (key, ti)\n    # - the type key, unique for each type, is the underscore-separated \n    #   lowercase name of the domain_model (the domain class)\n    # - order is relevant (dictates workflow loading order)\n    \n    # feature \"support\" types, system types, required\n    \n    # workflowed\n    (\"user_address\", TI(\"address\", interfaces.IUserAddress)),\n    (\"group_address\", TI(\"address\", interfaces.IGroupAddress)),\n    # !+Attachment (mr, jul-2011)\n    # a) must be loaded before any other type that *may* support attachments!\n    # b) MUST support versions\n    (\"attachment\", TI(\"attachment\", interfaces.IAttachment)),\n    (\"event\", TI(\"event\", interfaces.IEvent)),\n    (\"sitting\", TI(\"sitting\", interfaces.ISitting)),\n    (\"heading\", TI(\"heading\", interfaces.IHeading)),\n    (\"user\", TI(\"user\", interfaces.IBungeniUser)),\n    (\"signatory\", TI(\"signatory\", interfaces.ISignatory)),\n    \n    # !+NAMING: member-related -> Group name + \"Member\" (no + \"ship\")\n    (\"group\", TI(\"group\", interfaces.IBungeniGroup)),\n    (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)),\n    (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n    (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n        # non-workflowed\n    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n    (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n    (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n    (\"title_type\", TI(None, interfaces.ITitleType)),\n    (\"member_title\", TI(None, interfaces.IMemberTitle)),\n    (\"change\", TI(None, interfaces.IChange)),\n    (\"doc\", TI(None, interfaces.IDoc)),\n    (\"doc_version\", TI(None, None)), #interfaces.IDocVersion)), #!+IVERSION\n    (\"attachment_version\", TI(None, None)), #interfaces.IAttachmentVersion)), #!+IVERSION\n    (\"venue\", TI(None, interfaces.IVenue)),\n    (\"session\", TI(None, interfaces.ISession)),\n    (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)),\n    (\"country\", TI(None, interfaces.ICountry)),\n    (\"item_schedule\", TI(None, interfaces.IItemSchedule)),\n    (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)),\n    (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)),\n    (\"editorial_note\", TI(None, interfaces.IEditorialNote)),\n    (\"sitting_report\", TI(None, interfaces.ISittingReport)),\n    (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)),\n    \n    # additional custom types are loaded dynamically from bungeni_custom\/types.xml\n]\n\n\n\n\n# register custom types\n\ndef register_new_custom_type(type_key, workflow_key, archetype_key):\n    \"\"\"Retrieve (create if needed) a domain interface and model for type_key,\n    and register as new entry on TYPE_REGISTER.\n    \"\"\"\n    \n    # generate custom domain interface\n    domain_iface_name = naming.model_interface_name(type_key)\n    try:\n        domain_iface = resolve(\"%s.%s\" % (INTERFACE_MODULE.__name__, domain_iface_name))\n        log.warn(\"Custom interface ALREADY EXISTS: %s\" % (domain_iface))\n    except ImportError:\n        domain_iface = new_custom_domain_interface(type_key, domain_iface_name)\n    \n    # generate custom domain_model\n    domain_model_name = naming.model_name(type_key)\n    try:\n        domain_model = resolve(\"%s.%s\" % (MODEL_MODULE.__name__, domain_model_name))\n        log.warn(\"Custom domain model ALREADY EXISTS: %s\" % (domain_model))\n    except ImportError:\n        domain_model = new_custom_domain_model(type_key, domain_iface, archetype_key)\n    \n    # type_info entry\n    ti = TI(workflow_key, domain_iface, domain_model)\n    ti.custom = True\n    TYPE_REGISTRY.append((type_key, ti))\n    \n    log.info(\"Registered custom type [%s]: %s\" % (archetype_key, type_key))\n    return type_key, ti\n\n\n\n\n\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py":{"changes":[{"diff":"\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self)","add":8,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py","badparts":["        return int(bc.oauth_auth_expiry_time)"],"goodparts":["        return int(bc.oauth_authorization_token_expiry_time)","    @cached_property.cachedIn(\"__oauth_hmac_key__\")","    @bungeni_custom_errors","    def oauth_hmac_key(self):","        \"\"\"String used to to generate nonces. KEEP SECRET.","        \"\"\"","        return bc.oauth_hmac_key"]}],"source":"\n \"\"\"Defines the accessor class for Bungeni Custom parameters. See bungeni.capi __init__.py for usage. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.capi\") import sys import time import os from zope.dottedname.resolve import resolve from zope.cachedescriptors import property as cached_property from bungeni.utils import error from bungeni.alchemist import type_info import bungeni_custom as bc class BungeniCustomError(Exception): \"\"\"A configuration error during loading of configuration. \"\"\" class BungeniCustomRuntimeError(BungeniCustomError): \"\"\"Internal error while executing a callable determined from configuration. \"\"\" def bungeni_custom_errors(f): \"\"\"Decorator to intercept any error raised by function f and re-raise it as a BungeniCustomError. To be used to decorate any function involved in reading\/validating\/processing any bungeni_custom parameters. \"\"\" return error.exceptions_as(BungeniCustomError)(f) def wrapped_callable(unwrapped): assert callable(unwrapped), unwrapped def wrapped(*args): log.debug(\"Calling %s with args: %s\" %(unwrapped, args)) try: return unwrapped(*args) except: exc=sys.exc_info()[1] log.debug(\"BungeniCustomRuntimeError[%r] in wrapped_callable: %s %s\", exc, wrapped, args) raise wrapped._unwrapped=unwrapped wrapped.__name__=unwrapped.__name__ return wrapped class CAPI(object): \"\"\"Accessor class for Bungeni Custom parameters. \"\"\" def __init__(self): self.validate_properties() def validate_properties(self): \"\"\"Validate this capi instance. Ensure valid setup of properties at instantiation of CAPI instance \"\"\" self.default_language self.country_code self.right_to_left_languages @property @bungeni_custom_errors def zope_i18n_allowed_languages(self): return tuple(bc.zope_i18n_allowed_languages.split()) @property @bungeni_custom_errors def zope_i18n_compile_mo_files(self): return bool( bc.zope_i18n_compile_mo_files is True or bc.zope_i18n_compile_mo_files==\"1\") @property @bungeni_custom_errors def country_code(self): \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this bungeni instance. \"\"\" return bc.country_code @property @bungeni_custom_errors def default_language(self): assert bc.default_language in self.zope_i18n_allowed_languages, \\ \"Default language[%s] not in allowed languages[%s]\" %( bc.default_language, self.zope_i18n_allowed_languages,) return bc.default_language @property @bungeni_custom_errors def right_to_left_languages(self): rtl_langs=tuple(bc.right_to_left_languages.split()) assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\ \"Right to left languages[%s] not in allowed languages[%s]\" %( bc.right_to_left_languages, self.zope_i18n_allowed_languages) return rtl_langs @property @bungeni_custom_errors def check_auto_reload_localization(self): \"\"\"() -> int minimum number of seconds to wait between checks for whether a localization file needs reloading; 0 means never check(deployment) \"\"\" int(bc.check_auto_reload_localization) return bc.check_auto_reload_localization @bungeni_custom_errors def get_workflow_condition(self, condition): condition_module=resolve(\"._conditions\", \"bungeni_custom.workflows\") condition=getattr(condition_module, condition) return wrapped_callable(condition) @bungeni_custom_errors def get_workflow_action(self, action): action_module=resolve(\"._actions\", \"bungeni_custom.workflows\") action=getattr(action_module, action) return wrapped_callable(action) @bungeni_custom_errors def get_form_constraint(self, constraint): constraint_module=resolve(\"._constraints\", \"bungeni_custom.forms\") constraint=getattr(constraint_module, constraint) return wrapped_callable(constraint) @bungeni_custom_errors def get_form_validator(self, validation): validator_module=resolve(\"._validations\", \"bungeni_custom.forms\") validator=getattr(validator_module, validation) return wrapped_callable(validator) @bungeni_custom_errors def get_form_derived(self, derived): derived_module=resolve(\"._derived\", \"bungeni_custom.forms\") derived_def=getattr(derived_module, derived) return wrapped_callable(derived_def) @property @bungeni_custom_errors def default_number_of_listing_items(self): \"\"\"This is the max number of items that are displayed in a listing by default. Returns an integer \"\"\" return int(bc.default_number_of_listing_items) @property @bungeni_custom_errors def long_text_column_listings_truncate_at(self): \"\"\"When listing text columns, only display first so many characters.\"\"\" return int(bc.long_text_column_listings_truncate_at) def xml_workspace_tabs_file(self): \"\"\"helper function used by workspace tab info APIs\"\"\" TABS_FILE=\"tabs.xml\" from lxml import etree ws_path=self.get_path_for(\"workspace\") file_path=os.path.join(ws_path, TABS_FILE) tabs=etree.fromstring(open(file_path).read()) return tabs @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\") @bungeni_custom_errors def workspace_tab_count_cache_refresh_time(self): \"\"\"The duration in seconds between tab count refresh operations\"\"\" tabs=self.xml_workspace_tabs_file() tabs_count_refresh=tabs.attrib[\"tab_count_cache_refresh_time\"] return int(tabs_count_refresh) @cached_property.cachedIn(\"__workspace_tabs__\") @bungeni_custom_errors def workspace_tabs(self): \"\"\"The tabs in the workspace\"\"\" ws_tabs=[] tabs=self.xml_workspace_tabs_file() for tab in tabs.iterchildren(tag=\"tab\"): ws_tabs.append(tab.attrib[\"id\"]) return ws_tabs @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\") @bungeni_custom_errors def oauth_access_token_expiry_time(self): \"\"\"time in seconds before an access token expires\"\"\" return(bc.oauth_access_token_expiry_time) @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\") @bungeni_custom_errors def oauth_authorization_token_expiry_time(self): \"\"\"time in seconds before an oauth authorization code expires max recommended time is 10min \"\"\" return int(bc.oauth_auth_expiry_time) def get_root_path(self): \"\"\"Get absolute physical path location for currently active bungeni_custom package folder. \"\"\" return os.path.dirname(os.path.abspath(bc.__file__)) def get_path_for(self, *path_components): \"\"\"Get absolute path, under bungeni_custom, for path_components. \"\"\" return os.path.join(*(self.get_root_path(),)+path_components) def put_env(self, key): \"\"\"Set capi value for{key} as the environment variable{key} i.e. use to set os.environ[key]. Wrapper on os.put_env(key, string_value) --to take care of the value string-casting required by os.put_env while still allowing the liberty of data-typing values of capi attributes as needed. \"\"\" value=getattr(self, key) try: os.environ[key]=value except TypeError: try: os.environ[key]=\" \".join(value) except TypeError: os.environ[key]=repr(value) assert eval(os.environ[key])==value _is_modified_since_last_times={} def is_modified_since(self, abspath, modified_on_first_check=True): \"\"\"(abspath:str, modified_on_first_check:bool) -> bool Checks file path st_mtime to see if file has been modified since last check. Updates entry per path, with last(check, modified) times. \"\"\" check_auto_reload_localization=self.check_auto_reload_localization now=time.time() last_checked, old_last_modified=\\ self._is_modified_since_last_times.get(abspath) or(0, 0) if not check_auto_reload_localization: if last_checked or not modified_on_first_check: return False if not now-last_checked > check_auto_reload_localization: return False last_modified=os.stat(abspath).st_mtime self._is_modified_since_last_times[abspath]=(now, last_modified) if not last_checked: return modified_on_first_check return(old_last_modified < last_modified) def get_type_info(self, discriminator): \"\"\"Get the TypeInfo instance for discriminator(see core.type_info). The discriminator may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: implements IBungeniContent domain model instance: type provides IBungeniContent descriptor_model: implements IModelDescriptor Raise KeyError if no entry matched. \"\"\" return type_info._get(discriminator) def iter_type_info(self, scope=None): \"\"\"Return iterator on all registered(key, TypeInfo) entries. scope:either(None, \"system\", \"archetype\", \"custom\") \"\"\" for type_key, ti in type_info._iter(): if(scope is None or ti.scope==scope): yield type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Defines the accessor class for Bungeni Custom parameters.\n\nSee bungeni.capi __init__.py for usage.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.capi\")\n\nimport sys\nimport time\nimport os\nfrom zope.dottedname.resolve import resolve\nfrom zope.cachedescriptors import property as cached_property\nfrom bungeni.utils import error\nfrom bungeni.alchemist import type_info\nimport bungeni_custom as bc\n\n\n# utils \n\nclass BungeniCustomError(Exception):\n    \"\"\"A configuration error during loading of configuration.\n    \"\"\"\nclass BungeniCustomRuntimeError(BungeniCustomError): \n    \"\"\"Internal error while executing a callable determined from configuration.\n    \"\"\" \n\ndef bungeni_custom_errors(f):\n    \"\"\"Decorator to intercept any error raised by function f and re-raise it\n    as a BungeniCustomError. To be used to decorate any function involved \n    in reading\/validating\/processing any bungeni_custom parameters. \n    \"\"\"\n    return error.exceptions_as(BungeniCustomError)(f)\n\n\ndef wrapped_callable(unwrapped):\n    assert callable(unwrapped), unwrapped\n    def wrapped(*args):\n        log.debug(\"Calling %s with args: %s\" % (unwrapped, args))\n        try:\n            return unwrapped(*args)\n        except:\n            # intercept exc, to re-raise it *unchanged*, only for debugging\n            # e.g. constraints raise numerous (expected?) NoInputData errors\n            exc = sys.exc_info()[1]\n            log.debug(\"BungeniCustomRuntimeError [%r] in wrapped_callable: %s %s\",\n                    exc, wrapped, args)\n            raise\n    # remember original unwrapped callable\n    wrapped._unwrapped = unwrapped\n    wrapped.__name__ = unwrapped.__name__\n    return wrapped\n\n\n# capi (singleton)\n\nclass CAPI(object):\n    \"\"\"Accessor class for Bungeni Custom parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.validate_properties()\n    \n    def validate_properties(self):\n        \"\"\"Validate this capi instance.\n        Ensure valid setup of properties at instantiation of CAPI instance\n        \"\"\"\n        self.default_language\n        self.country_code\n        self.right_to_left_languages\n        \n    # bungeni_custom parameter properties\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_allowed_languages(self):\n        # NOTE: zope.i18n.config.ALLOWED_LANGUAGES expects the value of the \n        # env variable for this to be a COMMA or SPACE separated STRING\n        return tuple(bc.zope_i18n_allowed_languages.split())\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_compile_mo_files(self):\n        return bool(\n            bc.zope_i18n_compile_mo_files is True or \n            bc.zope_i18n_compile_mo_files == \"1\")\n   \n    @property\n    @bungeni_custom_errors\n    def country_code(self):\n        \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this \n        bungeni instance.\n        \"\"\"\n        return bc.country_code\n\n    @property\n    @bungeni_custom_errors\n    def default_language(self):\n        assert bc.default_language in self.zope_i18n_allowed_languages, \\\n            \"Default language [%s] not in allowed languages [%s]\" % (\n                bc.default_language, self.zope_i18n_allowed_languages,)\n        return bc.default_language\n        \n    @property\n    @bungeni_custom_errors\n    def right_to_left_languages(self):\n        rtl_langs = tuple(bc.right_to_left_languages.split())\n        assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\\n            \"Right to left languages [%s] not in allowed languages [%s]\" % (\n                bc.right_to_left_languages, self.zope_i18n_allowed_languages)\n        return rtl_langs\n    \n    @property\n    @bungeni_custom_errors\n    def check_auto_reload_localization(self):\n        \"\"\" () -> int\n        minimum number of seconds to wait between checks for whether a \n        localization file needs reloading; 0 means never check (deployment)\n        \"\"\"\n        int(bc.check_auto_reload_localization) # TypeError if not an int\n        return bc.check_auto_reload_localization\n    \n    \n    @bungeni_custom_errors\n    def get_workflow_condition(self, condition):\n        condition_module = resolve(\"._conditions\", \"bungeni_custom.workflows\")\n        condition = getattr(condition_module, condition) # raises AttributeError\n        return wrapped_callable(condition)\n    \n    @bungeni_custom_errors\n    def get_workflow_action(self, action):\n        action_module = resolve(\"._actions\", \"bungeni_custom.workflows\")\n        action = getattr(action_module, action) # raises AttributeError\n        return wrapped_callable(action)\n    \n    @bungeni_custom_errors\n    def get_form_constraint(self, constraint):\n        constraint_module = resolve(\"._constraints\", \"bungeni_custom.forms\")\n        constraint = getattr(constraint_module, constraint) # raises AttributeError\n        return wrapped_callable(constraint)\n    \n    @bungeni_custom_errors\n    def get_form_validator(self, validation):\n        validator_module = resolve(\"._validations\", \"bungeni_custom.forms\")\n        validator = getattr(validator_module, validation) # raises AttributeError\n        return wrapped_callable(validator)\n    \n    @bungeni_custom_errors\n    def get_form_derived(self, derived):\n        derived_module = resolve(\"._derived\", \"bungeni_custom.forms\")\n        derived_def = getattr(derived_module, derived) # raises AttributeError\n        return wrapped_callable(derived_def)\n    \n    \n    @property\n    @bungeni_custom_errors\n    def default_number_of_listing_items(self):\n        \"\"\"This is the max number of items that are displayed in a listing by\n        default. Returns an integer\n        \"\"\"\n        return int(bc.default_number_of_listing_items)\n    \n    @property\n    @bungeni_custom_errors\n    def long_text_column_listings_truncate_at(self):\n        \"\"\"When listing text columns, only display first so many characters.\"\"\"\n        return int(bc.long_text_column_listings_truncate_at)\n    \n    def xml_workspace_tabs_file(self):\n        \"\"\"helper function used by workspace tab info APIs\"\"\"\n        TABS_FILE = \"tabs.xml\"    \n        from lxml import etree\n        ws_path = self.get_path_for(\"workspace\")\n        file_path = os.path.join(ws_path, TABS_FILE)\n        tabs = etree.fromstring(open(file_path).read()) \n        return tabs                \n    \n    @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\")\n    @bungeni_custom_errors\n    def workspace_tab_count_cache_refresh_time(self):\n        \"\"\"The duration in seconds between tab count refresh operations\"\"\"\n        tabs = self.xml_workspace_tabs_file()\n        tabs_count_refresh = tabs.attrib[\"tab_count_cache_refresh_time\"]\n        return int(tabs_count_refresh)\n    \n    @cached_property.cachedIn(\"__workspace_tabs__\")\n    @bungeni_custom_errors\n    def workspace_tabs(self):\n        \"\"\"The tabs in the workspace\"\"\"\n        ws_tabs = []\n        tabs = self.xml_workspace_tabs_file()\n        for tab in tabs.iterchildren(tag=\"tab\"):\n            ws_tabs.append(tab.attrib[\"id\"])\n        return ws_tabs    \n\n    @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_access_token_expiry_time(self):\n        \"\"\"time in seconds before an access token expires\"\"\"\n        return (bc.oauth_access_token_expiry_time)\n\n    @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_authorization_token_expiry_time(self):\n        \"\"\"time in seconds before an oauth authorization code expires\n        max recommended time is 10min\n        \"\"\"\n        return int(bc.oauth_auth_expiry_time)\n    # utility methods\n    \n    def get_root_path(self):\n        \"\"\"Get absolute physical path location for currently active \n        bungeni_custom package folder.\n        \"\"\"\n        return os.path.dirname(os.path.abspath(bc.__file__)) \n    \n    def get_path_for(self, *path_components):\n        \"\"\"Get absolute path, under bungeni_custom, for path_components.\n        \"\"\"\n        return os.path.join(*(self.get_root_path(),)+path_components)\n    \n    def put_env(self, key):\n        \"\"\"Set capi value for {key} as the environment variable {key}\n        i.e. use to set os.environ[key].\n        \n        Wrapper on os.put_env(key, string_value) -- to take care of\n        the value string-casting required by os.put_env while still \n        allowing the liberty of data-typing values of capi attributes \n        as needed.\n        \"\"\"\n        value = getattr(self, key)\n        try:\n            os.environ[key] = value\n            # OK, value is a string... done.\n        except TypeError:\n            # putenv() argument 2 must be string, not <...>\n            # i.e. value is NOT a string... try string-casting:\n            try:\n                # some zope code expects sequences to be specified as a \n                # COMMA or SPACE separated STRING, so we first try the value \n                # as a sequence, and serialize it to an environment variable \n                # value as expected by zope\n                os.environ[key] = \" \".join(value)\n            except TypeError:\n                # not a sequence, just fallback on repr(value)\n                os.environ[key] = repr(value)\n                # ensure that the original object value defines a __repr__ \n                # that can correctly re-instantiate the original object\n                assert eval(os.environ[key]) == value\n    \n    _is_modified_since_last_times = {} # {path: (last_checked, last_modified)}\n    def is_modified_since(self, abspath, modified_on_first_check=True):\n        \"\"\" (abspath:str, modified_on_first_check:bool) -> bool\n        Checks file path st_mtime to see if file has been modified since last \n        check. Updates entry per path, with last (check, modified) times.\n        \"\"\"\n        check_auto_reload_localization = self.check_auto_reload_localization\n        now = time.time()\n        last_checked, old_last_modified = \\\n            self._is_modified_since_last_times.get(abspath) or (0, 0)\n        if not check_auto_reload_localization:\n            # 0 =>> never check (unless this is the first check...)\n            if last_checked or not modified_on_first_check:\n                return False\n        if not now-last_checked > check_auto_reload_localization:\n            # last check too recent, avoid doing os.stat\n            return False\n        last_modified = os.stat(abspath).st_mtime\n        self._is_modified_since_last_times[abspath] = (now, last_modified)\n        if not last_checked:\n            # last_checked==0, this is the first check\n            return modified_on_first_check\n        return (old_last_modified < last_modified)\n    \n    # type registry\n    \n    def get_type_info(self, discriminator):\n        \"\"\"Get the TypeInfo instance for discriminator (see core.type_info). \n        \n        The discriminator may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: implements IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor_model: implements IModelDescriptor\n        \n        Raise KeyError if no entry matched.\n        \"\"\"\n        return type_info._get(discriminator)\n    \n    def iter_type_info(self, scope=None):\n        \"\"\"Return iterator on all registered (key, TypeInfo) entries.\n        scope:either(None, \"system\", \"archetype\", \"custom\")\n        \"\"\"\n        for type_key, ti in type_info._iter():\n            if (scope is None or ti.scope == scope):\n                yield type_key, ti\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py":{"changes":[{"diff":"\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"","add":2,"remove":2,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py","badparts":["        api[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])"],"goodparts":["        admin[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, admin[u\"applications\""]}],"source":"\n \"\"\"The Bungeni Application $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.core.app\") from zope.interface import implements from zope.interface import implementedBy from zope import component from zope.interface.declarations import alsoProvides from zope.app.appsetup.appsetup import getConfigContext from zope.app.component import site from zope.location.interfaces import ILocation from ore.wsgiapp.app import Application from ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent from bungeni.models import domain from bungeni.models import interfaces as model_interfaces from bungeni.models.utils import get_current_parliament from bungeni.models.utils import container_getter from bungeni.core import interfaces from bungeni.core import location from bungeni.core.content import(Section, AdminSection, AkomaNtosoSection, WorkspaceSection, APISection, OAuthSection) from bungeni.core.content import QueryContent from bungeni.core.i18n import _ from bungeni.core.workspace import(WorkspaceContainer, WorkspaceUnderConsiderationContainer, WorkspaceTrackedDocumentsContainer, WorkspaceGroupsContainer, WorkspaceSchedulableContainer, load_workspaces) from bungeni.core.notifications import load_notifications from bungeni.core.emailnotifications import load_email from bungeni.core.serialize import serialization_notifications from bungeni.ui.utils import url, common from bungeni.capi import capi from bungeni.utils import register @register.handler( (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent)) def on_wsgi_application_created_event(application, event): \"\"\"Additional setup on IWSGIApplicationCreatedEvent. \"\"\" log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) for type_key, ti in capi.iter_type_info(): if ti.workflow: ti.workflow.validate_permissions_roles() import bungeni.core.workflows.events load_workspaces() load_notifications() load_email() serialization_notifications() import bungeni.core.events app_setup=model_interfaces.IBungeniSetup(application) app_setup.setUp() try: import bungeni.utils.xmlconfexport as confexp confexp.write_all() except: log.debug((\"on_wsgi_application_created:\" \"error while exporting config parameters to xml\")) log.debug(\"on_wsgi_application_created_event: _features: %s\" %( getConfigContext()._features)) def to_locatable_container(domain_class, *domain_containers): component.provideAdapter(location.ContainerLocation(*domain_containers), (implementedBy(domain_class), ILocation)) class BungeniApp(Application): implements(model_interfaces.IBungeniApplication) class AppSetup(object): implements(model_interfaces.IBungeniSetup) def __init__(self, application): self.context=application def setUp(self): from zope.configuration import xmlconfig xmlconfig.string(\"\"\" <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\" xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\"> <include package=\"zope.i18n\" file=\"meta.zcml\" \/> <i18n:registerTranslations directory=\"%s\" \/> <\/configure> \"\"\" %(capi.get_path_for(\"translations\", \"bungeni\"))) import index index.setupFieldDefinitions(index.indexer) sm=site.LocalSiteManager(self.context) self.context.setSiteManager(sm) from bungeni.core import language from bungeni.ui import z3evoque z3evoque.set_get_gettext() z3evoque.setup_evoque() z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\")) z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL) z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name) z3evoque.domain.set_on_globals(\"get_base_direction\", language.get_base_direction) z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl) self.context[\"bungeni\"]=AkomaNtosoSection( title=_(u\"Bungeni\"), description=_(u\"Current parliamentary activity\"), default_name=\"bung\", ) workspace=self.context[\"workspace\"]=WorkspaceSection( title=_(\"section_workspace\", default=u\"Workspace\"), description=_(u\"Current parliamentary activity\"), default_name=\"my-documents\", ) alsoProvides(workspace, interfaces.ISearchableSection) workspace[\"my-documents\"]=WorkspaceSection( title=_(\"section_workspace_documents\", default=u\"my documents\"), description=_(u\"my documents workspace section\"), default_name=\"inbox\", marker=interfaces.IWorkspaceDocuments, ) for tab in capi.workspace_tabs: workspace[\"my-documents\"][tab]=WorkspaceContainer( tab_type=tab, title=_(\"section_workspace_%s\" % tab, default=tab), marker=interfaces.IWorkspaceTab ) ws_uc=workspace[\"under-consideration\"]=WorkspaceSection( title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), default_name=\"documents\", marker=interfaces.IWorkspaceUnderConsideration) ws_uc[\"documents\"]=WorkspaceUnderConsiderationContainer( name=\"documents\", title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), marker=interfaces.IWorkspaceTrackedDocuments) ws_uc[\"tracked-documents\"]=WorkspaceTrackedDocumentsContainer( name=\"tracked documents\", title=_(u\"tracked documents\"), description=_(u\"tracked documents\")) ws_sched=workspace[\"scheduling\"]=Section( title=_(\"section_scheduling\", default=u\"Scheduling\"), description=_(u\"Workspace Scheduling\"), default_name=\"index\", marker=interfaces.IWorkspaceScheduling) ws_sched[\"committees\"]=QueryContent( container_getter(get_current_parliament, \"committees\"), title=_(\"section_scheduling_committees\", default=u\"Committees\"), description=_(u\"Committee schedules\")) ws_sched[\"documents\"]=WorkspaceSchedulableContainer( name=_(u\"schedulable items\"), title=_(u\"schedulable items\"), description=_(u\"documents available for scheduling\")) ws_sched[\"sittings\"]=QueryContent( container_getter(get_current_parliament, \"sittings\"), title=_(\"section_scheduling_sittings\", default=u\"Sittings\"), description=_(u\"Plenary Sittings\")) ws_sched[\"agendaitems\"]=QueryContent( container_getter(get_current_parliament, \"agendaitems\"), title=_(\"section_scheduling_agenda_items\", default=u\"Agenda items\"), description=_(u\"Manage agenda items\")) workspace[\"groups\"]=WorkspaceSection( title=_(\"section_groups\", default=u\"Groups\"), description=_(u\"Bungeni Groups\"), default_name=\"my-groups\", marker=interfaces.IWorkspaceGroups) workspace[\"groups\"][\"my-groups\"]=WorkspaceGroupsContainer( name=\"my-groups\", title=_(u\"My Groups\"), description=_(u\"Groups that the user is a member of\")) for key, info in capi.iter_type_info(): if model_interfaces.IScheduleContent.implementedBy(info.domain_model): container_name=\"%ss\" % key container=\"%sContainer\" % info.domain_model.__name__ ws_sched[container_name]=getattr(domain, container)() to_locatable_container(info.domain_model, ws_sched[container_name]) admin=self.context[\"admin\"]=AdminSection( title=_(u\"Administration\"), description=_(u\"Manage bungeni settings\"), default_name=\"admin-index\", marker=model_interfaces.IBungeniAdmin) alsoProvides(admin, interfaces.ISearchableSection) content=admin[\"content\"]=Section( title=_(u\"Content\"), description=_(u\"browse bungeni content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"browse-admin\") admin[\"email-settings\"]=Section( title=_(u\"email settings\"), description=_(u\"manage email settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"email-settings\") admin[\"xapian-settings\"]=Section( title=_(u\"search index settings\"), description=_(u\"manage search index settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"xapian-settings\") admin[\"registry-settings\"]=Section( title=_(u\"registry settings\"), description=_(u\"manage registry settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"registry-settings\") admin[\"serialization-manager\"]=Section( title=_(u\"serialization manager\"), description=_(u\"batch serialization of content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"serialization-manager\") content[u\"parliaments\"]=domain.ParliamentContainer() to_locatable_container(domain.Parliament, content[u\"parliaments\"]) content[u\"users\"]=domain.UserContainer() to_locatable_container(domain.User, content[u\"users\"]) api=self.context[\"api\"]=APISection( title=_(u\"Bungeni API\"), description=_(u\"Bungeni REST API\"), default_name=\"index.html\", ) api[\"oauth\"]=OAuthSection( title=_(u\"Bungeni OAuth API\"), description=_(u\"Bungeni OAuth API\"), default_name=\"index.html\", ) api[u\"applications\"]=domain.OAuthApplicationContainer() to_locatable_container(domain.OAuthApplication, api[u\"applications\"]) ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"The Bungeni Application \n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.core.app\")\n\nfrom zope.interface import implements\nfrom zope.interface import implementedBy\nfrom zope import component\nfrom zope.interface.declarations import alsoProvides\n\nfrom zope.app.appsetup.appsetup import getConfigContext\nfrom zope.app.component import site\nfrom zope.location.interfaces import ILocation\n\nfrom ore.wsgiapp.app import Application\nfrom ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent\n\nfrom bungeni.models import domain\nfrom bungeni.models import interfaces as model_interfaces\nfrom bungeni.models.utils import get_current_parliament\nfrom bungeni.models.utils import container_getter\n\nfrom bungeni.core import interfaces\nfrom bungeni.core import location\nfrom bungeni.core.content import (Section, AdminSection, AkomaNtosoSection,\n    WorkspaceSection, APISection, OAuthSection)\nfrom bungeni.core.content import QueryContent\nfrom bungeni.core.i18n import _\nfrom bungeni.core.workspace import (WorkspaceContainer,\n    WorkspaceUnderConsiderationContainer,\n    WorkspaceTrackedDocumentsContainer,\n    WorkspaceGroupsContainer,\n    WorkspaceSchedulableContainer,\n    load_workspaces)\nfrom bungeni.core.notifications import load_notifications\nfrom bungeni.core.emailnotifications import load_email\nfrom bungeni.core.serialize import serialization_notifications\nfrom bungeni.ui.utils import url, common # !+ core dependency on ui\nfrom bungeni.capi import capi\nfrom bungeni.utils import register\n\n\n\n@register.handler(\n    (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent))\ndef on_wsgi_application_created_event(application, event):\n    \"\"\"Additional setup on IWSGIApplicationCreatedEvent.\n    \"\"\"\n    # !+ui.app.on_wsgi_application_created_event ALWAYS gets called prior to this\n    log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) \n    \n    # additional workflow validation\n    for type_key, ti in capi.iter_type_info():\n        if ti.workflow:\n            ti.workflow.validate_permissions_roles()\n    \n    # import events module, registering handlers\n    import bungeni.core.workflows.events\n    \n    # load workspaces\n    load_workspaces()\n    \n    # load notifications\n    load_notifications()\n\n    # load email notifications\n    load_email()\n\n    # set up serialization notifications\n    serialization_notifications()\n    \n    # import events modules, registering handlers\n    import bungeni.core.events\n    \n    app_setup = model_interfaces.IBungeniSetup(application)\n    app_setup.setUp()\n    \n    # write configuration parameters to xml\n    try:\n        import bungeni.utils.xmlconfexport as confexp\n        confexp.write_all()\n    except:\n        log.debug((\"on_wsgi_application_created :\"\n            \"error while exporting config parameters to xml\"))\n    \n    log.debug(\"on_wsgi_application_created_event: _features: %s\" % (\n        getConfigContext()._features))\n\n\ndef to_locatable_container(domain_class, *domain_containers):\n    component.provideAdapter(location.ContainerLocation(*domain_containers),\n               (implementedBy(domain_class), ILocation))\n\n\nclass BungeniApp(Application):\n    implements(model_interfaces.IBungeniApplication)\n\nclass AppSetup(object):\n    \n    implements(model_interfaces.IBungeniSetup)\n    \n    def __init__(self, application):\n        self.context = application\n    \n    def setUp(self):\n        \n        # register translations\n        #import zope.i18n.zcml\n        #zope.i18n.zcml.registerTranslations(getConfigContext(),\n        #    capi.get_path_for(\"translations\", \"bungeni\"))\n        # !+ZCML_PYTHON(mr, apr-2011) above registerTranslations() in python \n        # does not work, as subsequent utility lookup fails. We workaround it \n        # by executing the following parametrized bit of ZCML:\n        from zope.configuration import xmlconfig\n        xmlconfig.string(\"\"\"\n            <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\"\n                xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\">\n                <include package=\"zope.i18n\" file=\"meta.zcml\" \/>\n                <i18n:registerTranslations directory=\"%s\" \/>\n            <\/configure>\n            \"\"\" % (capi.get_path_for(\"translations\", \"bungeni\")))\n        \n        # ensure indexing facilities are setup(lazy)\n        import index\n        index.setupFieldDefinitions(index.indexer)\n        \n        sm = site.LocalSiteManager(self.context)\n        self.context.setSiteManager(sm)\n        \n        from bungeni.core import language\n        from bungeni.ui import z3evoque\n        z3evoque.set_get_gettext()\n        z3evoque.setup_evoque()\n        z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\"))\n        z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL)\n        z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name)\n        z3evoque.domain.set_on_globals(\"get_base_direction\", \n            language.get_base_direction)\n        z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl)          \n        \n        # !+ where is the view name for the app root (slash) set?\n        \n        # CONVENTION: the action of each site top-section is made to point \n        # directly the primary sub-section (the INDEX) that it contains.\n        # EXCEPTION: the \"\/\", when logged in, is redirected to \"\/workspace\/pi\"\n        \n        self.context[\"bungeni\"] = AkomaNtosoSection(\n            title=_(u\"Bungeni\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"bung\", # !+NAMING(mr, jul-2011) bung?!?\n        )\n        \n        # top-level sections\n        workspace = self.context[\"workspace\"] = WorkspaceSection(\n            title=_(\"section_workspace\", default=u\"Workspace\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"my-documents\",\n        )\n        alsoProvides(workspace, interfaces.ISearchableSection)\n        \n        workspace[\"my-documents\"] = WorkspaceSection(\n            title=_(\"section_workspace_documents\", default=u\"my documents\"),\n            description=_(u\"my documents workspace section\"),\n            default_name=\"inbox\",\n            marker=interfaces.IWorkspaceDocuments,\n        )\n        \n        for tab in capi.workspace_tabs:\n            workspace[\"my-documents\"][tab] = WorkspaceContainer(\n                tab_type=tab,\n                title=_(\"section_workspace_%s\" % tab, default=tab),\n                marker=interfaces.IWorkspaceTab\n            )\n\n        ws_uc = workspace[\"under-consideration\"] = WorkspaceSection(\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            default_name=\"documents\",\n            marker=interfaces.IWorkspaceUnderConsideration)\n        ws_uc[\"documents\"] = WorkspaceUnderConsiderationContainer(\n            name=\"documents\",\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            marker=interfaces.IWorkspaceTrackedDocuments)\n        ws_uc[\"tracked-documents\"] = WorkspaceTrackedDocumentsContainer(\n            name=\"tracked documents\",\n            title=_(u\"tracked documents\"),\n            description=_(u\"tracked documents\"))\n        \n        ws_sched = workspace[\"scheduling\"] = Section(\n            title=_(\"section_scheduling\", default=u\"Scheduling\"),\n            description=_(u\"Workspace Scheduling\"),\n            default_name=\"index\",\n            marker=interfaces.IWorkspaceScheduling)\n        ws_sched[\"committees\"] = QueryContent(\n            container_getter(get_current_parliament, \"committees\"),\n            title=_(\"section_scheduling_committees\", default=u\"Committees\"),\n            #!+marker=interfaces.ICommitteeAddContext,\n            description=_(u\"Committee schedules\"))\n        ws_sched[\"documents\"] = WorkspaceSchedulableContainer(\n            name=_(u\"schedulable items\"),\n            title=_(u\"schedulable items\"),\n            description=_(u\"documents available for scheduling\"))\n        ws_sched[\"sittings\"] = QueryContent(\n            container_getter(get_current_parliament, \"sittings\"),\n            title=_(\"section_scheduling_sittings\", default=u\"Sittings\"),\n            description=_(u\"Plenary Sittings\"))\n        ws_sched[\"agendaitems\"] = QueryContent(\n            container_getter(get_current_parliament, \"agendaitems\"),\n            title=_(\"section_scheduling_agenda_items\", \n                default=u\"Agenda items\"),\n            #marker=interfaces.IAgendaItemAddContext,\n            description=_(u\"Manage agenda items\"))\n        \n        workspace[\"groups\"] = WorkspaceSection(\n            title=_(\"section_groups\", default=u\"Groups\"),\n            description=_(u\"Bungeni Groups\"),\n            default_name=\"my-groups\",\n            marker=interfaces.IWorkspaceGroups)\n        workspace[\"groups\"][\"my-groups\"] = WorkspaceGroupsContainer(\n            name=\"my-groups\",\n            title=_(u\"My Groups\"),\n            description=_(u\"Groups that the user is a member of\"))\n        \n        #!+TIMING\n        #!+AUTO CONTAINERS SCHEDULING(mb, April-2012)\n        # type_info missing container name\n        for key, info in capi.iter_type_info():\n            if model_interfaces.IScheduleContent.implementedBy(info.domain_model):\n                container_name = \"%ss\" % key\n                container = \"%sContainer\" % info.domain_model.__name__\n                ws_sched[container_name] = getattr(domain, container)()\n                to_locatable_container(info.domain_model, ws_sched[container_name])\n        \n        \n        ##########\n        # Admin User Interface\n        # Administration section\n        \n        #!+SECURITY(miano. nov-2010) Admin section now uses AdminSection\n        # container that is identical to Section, only difference is that\n        # traversing though it requires zope.ManageSite permission as defined\n        # in core\/configure.zcml\n        \n        admin = self.context[\"admin\"] = AdminSection(\n            title=_(u\"Administration\"),\n            description=_(u\"Manage bungeni settings\"),\n            default_name=\"admin-index\",\n            marker=model_interfaces.IBungeniAdmin)\n        alsoProvides(admin, interfaces.ISearchableSection)\n        \n        content = admin[\"content\"] = Section(\n            title=_(u\"Content\"),\n            description=_(u\"browse bungeni content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"browse-admin\")\n        \n        admin[\"email-settings\"] = Section(\n            title=_(u\"email settings\"),\n            description=_(u\"manage email settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"email-settings\")\n        \n        admin[\"xapian-settings\"] = Section(\n            title=_(u\"search index settings\"),\n            description=_(u\"manage search index settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"xapian-settings\")\n        \n        admin[\"registry-settings\"] = Section(\n            title=_(u\"registry settings\"),\n            description=_(u\"manage registry settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"registry-settings\")\n        \n        admin[\"serialization-manager\"] = Section(\n            title=_(u\"serialization manager\"),\n            description=_(u\"batch serialization of content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"serialization-manager\")\n        \n        content[u\"parliaments\"] = domain.ParliamentContainer()\n        to_locatable_container(domain.Parliament, content[u\"parliaments\"])\n        \n        content[u\"users\"] = domain.UserContainer()\n        to_locatable_container(domain.User, content[u\"users\"])\n\n        api = self.context[\"api\"] = APISection(\n            title=_(u\"Bungeni API\"),\n            description=_(u\"Bungeni REST API\"),\n            default_name=\"index.html\",\n        )\n        api[\"oauth\"] = OAuthSection(\n            title=_(u\"Bungeni OAuth API\"),\n            description=_(u\"Bungeni OAuth API\"),\n            default_name=\"index.html\",\n        )\n        api[u\"applications\"] = domain.OAuthApplicationContainer()\n        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n"}},"msg":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings."}},"https:\/\/github.com\/kohsah\/bungeni-portal":{"b010337746758f1455f032fa513d3ffab0b0b7f4":{"url":"https:\/\/api.github.com\/repos\/kohsah\/bungeni-portal\/commits\/b010337746758f1455f032fa513d3ffab0b0b7f4","html_url":"https:\/\/github.com\/kohsah\/bungeni-portal\/commit\/b010337746758f1455f032fa513d3ffab0b0b7f4","message":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings.","sha":"b010337746758f1455f032fa513d3ffab0b0b7f4","keyword":"replay attack improve","diff":"diff --git a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\nindex 44ae077ff..2d6b1645d 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n@@ -254,7 +254,7 @@ def permission_type_key(self):\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\nindex e328f6c85..96e0dc6f0 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n@@ -209,7 +209,14 @@ def oauth_authorization_token_expiry_time(self):\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self):\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\nindex 7435b4a3a..28e02aebf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n@@ -300,5 +300,5 @@ def setUp(self):\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"])\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\nindex 4ac3db531..8610d7e73 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n@@ -573,4 +573,11 @@ def title(self):\n         context = _merged(self.context)\n         return component.getUtility(IRole, context.role_id).title\n \n+@register.adapter()\n+class OAuthApplicationDescriptiveProperties(DescriptiveProperties):\n+    component.adapts(interfaces.IOAuthApplication)\n \n+    @property\n+    def title(self):\n+        context = _merged(self.context)\n+        return context.name\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\nindex e747ae61c..7122485b2 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n@@ -578,6 +578,9 @@ class IDebateTake(interface.Interface):\n class IOAuthApplication(interface.Interface):\n     \"\"\"Marker interface for an OAuth Application record\"\"\"\n \n+class IOAuthApplicationContainer(IAlchemistContainer):\n+    \"\"\"Marker interface for an OAuth Applications container\"\"\"\n+\n class IOAuthAuthorization(interface.Interface):\n     \"\"\"Marker interfeace for OAuth authorizations\"\"\"\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\nindex e34a41ef8..3900cbd92 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n@@ -163,8 +163,13 @@\n   <permission id=\"bungeni.debate_takes.View\" title=\"View debate takes\" \/>\n   <permission id=\"bungeni.debate_takes.Edit\" title=\"Edit debate takes\" \/>\n \n-  <permission id=\"bungeni.oauth_application.View\" title=\"View oauth app\" \/>\n-  <permission id=\"bungeni.oauth_application.Delete\" title=\"Delete oauth app\" \/>\n-  <meta:redefinePermission from=\"bungeni.oauth_application.View\" to=\"zope.ManageContent\" \/>\n+  <permission id=\"bungeni.o_auth_application.View\" title=\"View oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Add\" title=\"Add oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Edit\" title=\"Edit oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Delete\" title=\"Delete oauth app\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.View\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Add\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Edit\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Delete\" to=\"zope.ManageContent\" \/>\n   <permission id=\"bungeni.oauth.View\" title=\"Use oauth api\" \/>\n <\/configure>\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\nindex 128a2c535..f1d0ed492 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n@@ -1185,7 +1185,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"identifier\", rdb.UnicodeText, nullable=False, \n         unique=True),\n     rdb.Column(\"name\", rdb.UnicodeText, nullable=False),\n-    rdb.Column(\"secret\", rdb.String(32), nullable=False),\n+    rdb.Column(\"secret\", rdb.String(100), nullable=False),\n     rdb.Column(\"redirection_endpoint\", rdb.UnicodeText, nullable=False)\n )\n \n@@ -1195,7 +1195,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n         nullable=False),\n     rdb.Column(\"application_id\", rdb.Integer,\n         rdb.ForeignKey(\"oauth_application.application_id\"), nullable=False),\n-    rdb.Column(\"authorization_code\", rdb.String(32), nullable=False),\n+    rdb.Column(\"authorization_code\", rdb.String(100), nullable=False),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n     rdb.Column(\"active\", rdb.Boolean(), nullable=False)\n )\n@@ -1204,8 +1204,8 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"access_token_id\", rdb.Integer, primary_key=True),\n     rdb.Column(\"authorization_id\", rdb.Integer,\n              rdb.ForeignKey(\"oauth_authorization.authorization_id\")),\n-    rdb.Column(\"access_token\", rdb.String(32)),\n-    rdb.Column(\"refresh_token\", rdb.String(32)),\n+    rdb.Column(\"access_token\", rdb.String(100)),\n+    rdb.Column(\"refresh_token\", rdb.String(100)),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n )\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\nindex 21c811509..bf1568c5e 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n@@ -1,8 +1,10 @@\n import hashlib\n+import hmac\n import random\n import string\n import urllib\n import simplejson\n+import time\n from datetime import datetime, timedelta\n \n from sqlalchemy.orm.exc import NoResultFound\n@@ -30,8 +32,8 @@\n def get_key():\n     \"\"\"Return a randomly generated key\n     \"\"\"\n-    m = hashlib.sha256()\n-    m.update(\"\".join(random.sample(string.letters + string.digits, 32)))\n+    m = hashlib.sha1()\n+    m.update(\"\".join(random.sample(string.letters + string.digits, 20)))\n     return m.hexdigest()\n \n \n@@ -45,10 +47,10 @@ class AddOAuthApplication(forms.common.AddForm):\n     @form.action(_(u\"Create Application\"), name=\"create\")\n     def handle_create_application(self, action, data, validator=\"validateAdd\"):\n         oauth_app = domain.OAuthApplication()\n-        oauth_app.application_identifier = data[\"application_identifier\"]\n-        oauth_app.application_name = data[\"application_name\"]\n+        oauth_app.identifier = data[\"identifier\"]\n+        oauth_app.name = data[\"name\"]\n         oauth_app.redirection_endpoint = data[\"redirection_endpoint\"]\n-        oauth_app.application_key = get_key()\n+        oauth_app.secret = get_key()\n         session = Session()\n         session.add(oauth_app)\n         session.flush()\n@@ -163,41 +165,73 @@ def __call__(self):\n class IOAuthAuthorizeForm(interface.Interface):\n     client_id = schema.TextLine(required=False)\n     state = schema.TextLine(required=False)\n-\n+    time = schema.TextLine(required=False)\n+    nonce = schema.TextLine(required=False)\n \n class OAuthAuthorizeForm(form.FormBase):\n     form_fields = form.Fields(IOAuthAuthorizeForm)\n     form_fields[\"client_id\"].custom_widget = widgets.HiddenTextWidget\n     form_fields[\"state\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"nonce\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"time\"].custom_widget = widgets.HiddenTextWidget\n     template = NamedTemplate(\"alchemist.form\")\n     form_name = _(\"authorise_oauth_application\",\n         default=u\"Authorise OAuth Application\")\n \n     def __init__(self, context, request, parameters={}):\n         self.parameters = parameters\n+        if self.parameters:\n+            self.parameters[\"time\"] = time.time()\n+            self.parameters[\"nonce\"] = self.generate_nonce(\n+                self.parameters[\"time\"])\n         self.action_url = \"\/api\/oauth\/authorize-form\"\n         super(OAuthAuthorizeForm, self).__init__(context, request)\n \n     def setUpWidgets(self, ignore_request=False):\n+        \n         self.widgets = form.setUpWidgets(\n             self.form_fields, self.prefix, self.context, self.request,\n             data=self.parameters if self.parameters else self.request.form,\n             ignore_request=ignore_request\n         )\n \n-    @form.action(_(u\"Authorize application\"), name=\"authorize\")\n+    def generate_nonce(self, auth_time):\n+        data = \"{0}:{1}:{2}\".format(\n+            self.parameters[\"client_id\"], get_db_user().user_id, auth_time)\n+        return hmac.new(capi.oauth_hmac_key, data, hashlib.sha1).hexdigest()\n+\n+    def check_authorization(self, action, data):\n+        errors = []\n+        data = self.request.form\n+        if not data.get(\"form.time\", None) or not data.get(\"form.nonce\", None):\n+            errors.append(InvalidRequest)\n+            return errors\n+        max_time = datetime.fromtimestamp(float(data[\"form.time\"])) + \\\n+            timedelta(seconds=capi.oauth_authorization_token_expiry_time)\n+        if (datetime.now() > max_time):\n+            errors.append(InvalidGrant)\n+        if data[\"form.nonce\"] != self.generate_nonce(data[\"form.time\"]):\n+            errors.append(InvalidGrant)\n+        return errors\n+\n+    def handle_failure(self, action, data, errors):\n+        return ErrorPage(self.context, self.request, errors[0])()\n+\n+    @form.action(_(u\"Authorize application\"), name=\"authorize\",\n+        validator=check_authorization, failure=handle_failure)\n     def handle_authorize_app(self, action, data):\n         session = Session()\n         oauth_authorization = domain.OAuthAuthorization()\n         oauth_authorization.user_id = get_db_user().user_id\n         app = session.query(domain.OAuthApplication\n-            ).filter(domain.OAuthApplication.application_identifier ==\n+            ).filter(domain.OAuthApplication.identifier ==\n                 data[\"client_id\"]\n             ).one()\n         oauth_authorization.application_id = app.application_id\n         oauth_authorization.authorization_code = get_key()\n         oauth_authorization.expiry = datetime.now() + timedelta(\n-            seconds=capi.oauth_auth_expiry_time)\n+            seconds=capi.oauth_authorization_token_expiry_time)\n+        oauth_authorization.active = True\n         session.add(oauth_authorization)\n         redirect_uri = \"{0}?code={1}\".format(\n             app.redirection_endpoint, oauth_authorization.authorization_code)\n@@ -213,10 +247,10 @@ def handle_cancel(self, action, data):\n                      == data[\"client_id\"]\n             ).one()\n         error = UnauthorizedClient(app.redirection_endpoint, data[\"state\"])\n-        redirect_error(self.request, error)\n+        redirect_error(self.context, self.request, error)\n \n \n-def redirect_error(request, error):\n+def redirect_error(context, request, error):\n     if error.redirect_uri:\n         next_url = \"{0}?error={1}&error_description={2}\".format(\n             error.redirect_uri, error.error, error.error_description)\n@@ -224,10 +258,10 @@ def redirect_error(request, error):\n             next_url = \"{0}&state={1}\".format(next_url, error.state)\n         return request.response.redirect(next_url, trusted=True)\n     else:\n-        bad_request(request, error)\n+        return ErrorPage(context, request, error)()\n \n \n-def bad_request(request, error):\n+def bad_request(context, request, error):\n     request.response.setStatus(400)\n     data = {\"error\": error.error, \"error_description\": error.error_description}\n     return simplejson.dumps(data)\n@@ -277,7 +311,7 @@ def __call__(self):\n         except UnauthorizedClient as e:\n             return ErrorPage(self.context, self.request, e)()\n         except OAuthException as e:\n-            return redirect_error(self.request, e)\n+            return redirect_error(self.context, self.request, e)\n \n         if not IUnauthenticatedPrincipal.providedBy(self.request.principal):\n             # authorize form\n@@ -345,7 +379,7 @@ def __call__(self):\n         try:\n             parameters = self.parameters()\n         except OAuthException as e:\n-            return bad_request(self.request, e)\n+            return bad_request(self.context, self.request, e)\n         assert (self.authorization is not None,\n             \"Authorization object not initalized\")\n         self.authorization.expiry = datetime.now()\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\nindex 18c6363b5..1372b42bf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n@@ -1718,13 +1718,13 @@ class ItemScheduleVoteDescriptor(ModelDescriptor):\n class OAuthApplicationDescriptor(ModelDescriptor):\n     localisable = False\n     fields = [\n-        F(name=\"application_identifier\",\n+        F(name=\"identifier\",\n           label=\"Unique Application Identifier\",\n           required=True,\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_name\",\n+        F(name=\"name\",\n           label=\"Application Name\",\n           required=True,\n           value_type=\"text\",\n@@ -1736,8 +1736,8 @@ class OAuthApplicationDescriptor(ModelDescriptor):\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_key\",\n-          label=\"Application Key\",\n+        F(name=\"secret\",\n+          label=\"Application Secret\",\n           localizable=[show(\"view\"), hide(\"add\")],\n           required=True,\n           value_type=\"text\",\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\nindex 57deb7ee2..66b0dbd7b 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n@@ -1265,5 +1265,14 @@\n      viewName=\"\"\n      weight=\"30\"\n      \/-->\n+   <!--OAuth-->\n+   <browser:menuItem menu=\"plone_contentmenu\"\n+        for=\"bungeni.models.interfaces.IOAuthApplicationContainer\"\n+        title=\"Add OAuth Application\"\n+        action=\"add\"\n+        permission=\"bungeni.o_auth_application.Add\"\n+        layer=\".interfaces.IAdminSectionLayer\"\n+        order=\"62\"\n+    \/>\n <\/configure>\n \n","files":{"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py":{"changes":[{"diff":"\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),","add":1,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py","badparts":["    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),"],"goodparts":["    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),"]}],"source":"\n \"\"\"Aggregation of information about loaded domain types. No public methods here --all available methods from this are those exposed via bungeni.capi. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\") from zope.interface.interfaces import IInterface from zope.security.proxy import removeSecurityProxy from zope.dottedname.resolve import resolve from bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface from bungeni.alchemist.model import( new_custom_domain_interface, new_custom_domain_model, ) from bungeni.alchemist.catalyst import( INTERFACE_MODULE, MODEL_MODULE ) from bungeni.models import interfaces from bungeni.models import domain from bungeni.core.workflow.interfaces import IWorkflow from bungeni.utils import naming __all__=[] def _iter(): \"\"\"Return iterator on all(key, TypeInfo) entries in TYPE_REGISTRY. Usage: capi.iter_type_info() \"\"\" for type_key, ti in TYPE_REGISTRY: yield type_key, ti def _get(discriminator): \"\"\"Get the TypeInfo instance for discriminator, that may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: provides IBungeniContent domain model instance: type provides IBungeniContent descriptor: provides IModelDescriptor Raise KeyError if no entry matched. Usage: capi.get_type_info(discriminator) \"\"\" if discriminator is None: m=\"type_info._get discriminator is None\" log.error(m) raise ValueError(m) discri=removeSecurityProxy(discriminator) getter=None if IIModelInterface.providedBy(discri): discri=naming.type_key(\"table_schema_interface_name\", discri.__name__) elif IInterface.providedBy(discri): discri=naming.type_key(\"model_interface_name\", discri.__name__) elif type(discri) is type and issubclass(discri, domain.Entity): discri=naming.polymorphic_identity(discri) elif isinstance(discri, domain.Entity): discri=naming.polymorphic_identity(type(discri)) if isinstance(discri, basestring): getter=_get_by_type_key elif IWorkflow.providedBy(discri): getter=_get_by_workflow elif IModelDescriptor.implementedBy(discri): getter=_get_by_descriptor_model if getter is not None: ti=getter(discri) if ti is not None: return ti else: m=\"No type registered for discriminator: %r\" %(discriminator) else: m=\"Invalid type info lookup discriminator: %r\" %(discriminator) from bungeni.ui.utils import debug log.debug(debug.interfaces(discriminator)) log.debug(m) raise KeyError(m) def _get_by_type_key(key): for type_key, ti in _iter(): if type_key==key: return ti ''' !+IALCHEMISTCONTENT fails on different interfaces with same name! (Pdb) ti.interface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) ti.interface.__bases__ (<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>) (Pdb) iface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) iface.__bases__ (<InterfaceClass zope.interface.Interface>,) ''' def _get_by_model(model): for type_key, ti in _iter(): if model is ti.domain_model: return ti def _get_by_instance(instance): return _get_by_model(type(instance)) def _get_by_workflow(wf): for type_key, ti in _iter(): if wf is ti.workflow: return ti def _get_by_descriptor_model(descriptor_model): for type_key, ti in _iter(): if descriptor_model is ti.descriptor_model: return ti class TI(object): \"\"\"TypeInfo, associates together the following attributes for a given type: workflow_key the workflow file name defaults to the type_key for workflowed types that DO NOT specify is None for non-workflowed types workflow same workflow insatnce may be used by multiple types is None for non-workflowed types interface the manually applied application-dedicated model interface (if any) for the type derived_table_schema auto-generated db schema interface, provides IIModelInterface domain_model the domain class descriptor_model the descriptor model for UI views for the type container_class container class for domain_model container_interface interface for the container class for domain_model \"\"\" def __init__(self, workflow_key, iface, domain_model=None): self.workflow_key=workflow_key self.interface=iface self.derived_table_schema=None self.workflow=None self.domain_model=domain_model self.descriptor_model=None self.container_class=None self.container_interface=None self.custom=False def __str__(self): return str(self.__dict__) @property def scope(self): if self.custom: return \"custom\" if self.descriptor_model is not None: return self.descriptor_model.scope @property def permission_type_key(self): if self.custom: return self.workflow.name return(self.workflow_key or naming.type_key(\"model_name\", self.domain_model.__name__) ) ''' !+TYPE_REGISTRY externalize further to bungeni_custom, currently: -association of type key and dedicated interface are hard-wired here -ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when loading workflows and descriptors -type_key IS the underscore-separated lowercase of the domain cls name i.e. utils.naming.polymorphic_identity(domain_model) -!+ti.workflow_key SHOULD always be equal to type_key -!+corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated -!+dedicated interfaces for archetype incantations should be auto-generated, from specific workflow name\/attr... e.g. via: zope.interface.interface.InterfaceClass(iname, bases, __module__) -!+should ti.interface be automatically generated also for system types? Usage: from bungeni.capi import capi capi.get_type_info(discriminator) -> TypeInfo capi.iter_type_info() -> iterator of all registered(key, TypeInfo) ''' TYPE_REGISTRY=[ (\"user_address\", TI(\"address\", interfaces.IUserAddress)), (\"group_address\", TI(\"address\", interfaces.IGroupAddress)), (\"attachment\", TI(\"attachment\", interfaces.IAttachment)), (\"event\", TI(\"event\", interfaces.IEvent)), (\"sitting\", TI(\"sitting\", interfaces.ISitting)), (\"heading\", TI(\"heading\", interfaces.IHeading)), (\"user\", TI(\"user\", interfaces.IBungeniUser)), (\"signatory\", TI(\"signatory\", interfaces.ISignatory)), (\"group\", TI(\"group\", interfaces.IBungeniGroup)), (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)), (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)), (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)), (\"oauth_application\", TI(None, interfaces.IOAuthApplication)), (\"debate_media\", TI(None, interfaces.IDebateMedia)), (\"user_delegation\", TI(None, interfaces.IUserDelegation)), (\"title_type\", TI(None, interfaces.ITitleType)), (\"member_title\", TI(None, interfaces.IMemberTitle)), (\"change\", TI(None, interfaces.IChange)), (\"doc\", TI(None, interfaces.IDoc)), (\"doc_version\", TI(None, None)), (\"attachment_version\", TI(None, None)), (\"venue\", TI(None, interfaces.IVenue)), (\"session\", TI(None, interfaces.ISession)), (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)), (\"country\", TI(None, interfaces.ICountry)), (\"item_schedule\", TI(None, interfaces.IItemSchedule)), (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)), (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)), (\"editorial_note\", TI(None, interfaces.IEditorialNote)), (\"sitting_report\", TI(None, interfaces.ISittingReport)), (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)), ] def register_new_custom_type(type_key, workflow_key, archetype_key): \"\"\"Retrieve(create if needed) a domain interface and model for type_key, and register as new entry on TYPE_REGISTER. \"\"\" domain_iface_name=naming.model_interface_name(type_key) try: domain_iface=resolve(\"%s.%s\" %(INTERFACE_MODULE.__name__, domain_iface_name)) log.warn(\"Custom interface ALREADY EXISTS: %s\" %(domain_iface)) except ImportError: domain_iface=new_custom_domain_interface(type_key, domain_iface_name) domain_model_name=naming.model_name(type_key) try: domain_model=resolve(\"%s.%s\" %(MODEL_MODULE.__name__, domain_model_name)) log.warn(\"Custom domain model ALREADY EXISTS: %s\" %(domain_model)) except ImportError: domain_model=new_custom_domain_model(type_key, domain_iface, archetype_key) ti=TI(workflow_key, domain_iface, domain_model) ti.custom=True TYPE_REGISTRY.append((type_key, ti)) log.info(\"Registered custom type[%s]: %s\" %(archetype_key, type_key)) return type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Aggregation of information about loaded domain types.\n\nNo public methods here -- all available methods from this are those exposed \nvia bungeni.capi.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\")\n\nfrom zope.interface.interfaces import IInterface\nfrom zope.security.proxy import removeSecurityProxy\nfrom zope.dottedname.resolve import resolve\n\nfrom bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface\nfrom bungeni.alchemist.model import (\n    new_custom_domain_interface,\n    new_custom_domain_model,\n)\nfrom bungeni.alchemist.catalyst import (\n    INTERFACE_MODULE, \n    MODEL_MODULE\n)\nfrom bungeni.models import interfaces\nfrom bungeni.models import domain\nfrom bungeni.core.workflow.interfaces import IWorkflow\nfrom bungeni.utils import naming\n\n__all__ = []\n\n\n# acessors exposed via capi\n\ndef _iter():\n    \"\"\"Return iterator on all (key, TypeInfo) entries in TYPE_REGISTRY.\n    \n    Usage: capi.iter_type_info()\n    \"\"\"\n    for type_key, ti in TYPE_REGISTRY:\n        yield type_key, ti\n\ndef _get(discriminator):\n    \"\"\"Get the TypeInfo instance for discriminator, that may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: provides IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor: provides IModelDescriptor\n    \n    Raise KeyError if no entry matched.\n    \n    Usage: capi.get_type_info(discriminator)\n    \"\"\"\n    if discriminator is None:\n        m = \"type_info._get discriminator is None\"\n        log.error(m)\n        raise ValueError(m)\n    discri = removeSecurityProxy(discriminator)\n    getter = None\n    \n    # !+IALCHEMISTCONTENT normalize trickier discriminator cases to type_key\n    if IIModelInterface.providedBy(discri):\n        discri = naming.type_key(\"table_schema_interface_name\", discri.__name__)\n    elif IInterface.providedBy(discri):\n        discri = naming.type_key(\"model_interface_name\", discri.__name__)\n    elif type(discri) is type and issubclass(discri, domain.Entity):\n        discri = naming.polymorphic_identity(discri)\n    elif isinstance(discri, domain.Entity):\n        discri = naming.polymorphic_identity(type(discri))\n    \n    if isinstance(discri, basestring):\n        getter = _get_by_type_key\n    #elif IInterface.providedBy(discri):\n    #    getter = _get_by_interface\n    #!+elif interfaces.IBungeniContent.implementedBy(discri):\n    #elif issubclass(discri, domain.Entity):\n    #    getter = _get_by_model\n    #!+elif interfaces.IBungeniContent.providedBy(discri):\n    #elif isinstance(discri, domain.Entity):\n    #    getter = _get_by_instance\n    elif IWorkflow.providedBy(discri):\n        getter = _get_by_workflow\n    elif IModelDescriptor.implementedBy(discri):\n        getter = _get_by_descriptor_model\n    \n    if getter is not None:\n        ti = getter(discri)\n        if ti is not None:\n            return ti\n        else:\n            m = \"No type registered for discriminator: %r\" % (discriminator)\n    else: \n        m = \"Invalid type info lookup discriminator: %r\" % (discriminator)\n    from bungeni.ui.utils import debug\n    log.debug(debug.interfaces(discriminator))\n    log.debug(m)\n    raise KeyError(m)\n\n\n# following getters return \"first matching\" TypeInfo instance in registry\n    \ndef _get_by_type_key(key):\n    for type_key, ti in _iter():\n        if type_key == key:\n            return ti\n#def _get_by_interface(iface):\n''' !+IALCHEMISTCONTENT fails on different interfaces with same name!\n(Pdb) ti.interface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) ti.interface.__bases__\n(<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>)\n(Pdb) iface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) iface.__bases__\n(<InterfaceClass zope.interface.Interface>,)\n'''\n#    for type_key, ti in _iter():\n#        if iface is ti.interface: #!+issubclass(iface, ti.interface)?\n#            return ti\ndef _get_by_model(model):\n    for type_key, ti in _iter():\n        if model is ti.domain_model: #!+issubclass(model, ti.domain_model)?\n            return ti\ndef _get_by_instance(instance):\n    return _get_by_model(type(instance))\ndef _get_by_workflow(wf):\n    for type_key, ti in _iter():\n        if wf is ti.workflow:\n            return ti\ndef _get_by_descriptor_model(descriptor_model):\n    for type_key, ti in _iter():\n        if descriptor_model is ti.descriptor_model:\n            return ti\n\n# \n\nclass TI(object):\n    \"\"\"TypeInfo, associates together the following attributes for a given type:\n            workflow_key \n                the workflow file name\n                defaults to the type_key for workflowed types that DO NOT specify\n                is None for non-workflowed types\n            workflow \n                same workflow insatnce may be used by multiple types\n                is None for non-workflowed types\n            interface\n                the manually applied application-dedicated model interface \n                (if any) for the type\n            derived_table_schema\n                auto-generated db schema interface, provides IIModelInterface\n            domain_model\n                the domain class\n            descriptor_model\n                the descriptor model for UI views for the type\n            container_class\n                container class for domain_model\n            container_interface\n                interface for the container class for domain_model\n    \"\"\"\n    def __init__(self, workflow_key, iface, domain_model=None):\n        self.workflow_key = workflow_key\n        self.interface = iface\n        self.derived_table_schema = None # provides IIModelInterface\n        self.workflow = None\n        self.domain_model = domain_model\n        self.descriptor_model = None\n        self.container_class = None\n        self.container_interface = None\n        self.custom = False # type loaded from custom configuration \n        # NOTE: only needed temporarily (until descriptor_model is set), \n        # then ti.custom not be inconsistent descriptor_model.scope i.e.\n        #if self.custom: assert self.descriptor_model.scope == \"custom\"\n        # !+ archetype_key?\n    def __str__(self):\n        return str(self.__dict__)\n    \n    @property\n    def scope(self):\n        # !+CUSTOM_TYPE_DESCRIPTOR the self.custom check below MUST precede the\n        # check on self.descriptor_model.scope as otherwise the \"in-transit\" \n        # custom types will not be picked up as custom types -- as during\n        # loading the descriptors for all custom types may not yet have been \n        # autogenerated (and would therefore correctly have \n        # descriptor_model.scope=\"custom\" set).\n        if self.custom:\n            return \"custom\"\n        if self.descriptor_model is not None:\n            return self.descriptor_model.scope\n    \n    @property\n    def permission_type_key(self):\n        if self.custom:\n            # custom types ALWAYS have a type_key-bound workflow instance - that\n            # may therefore have a different name than workflow_key e.g. Office\n            # uses the \"group\" workflow, that is type-relative reloaded as the\n            # \"office\" workflow instance.\n            return self.workflow.name\n        # system types ALWAYS use workflow_key - even if multiple types use the \n        # same workflow e.g. UserAddress & GroupAddress. \n        # if no workflow, compute type_key from domain_model\n        # #!+REDUNDANT(mb, 2012) This type key is already known during type\n        # setup i.e. TYPE_REGISTRY\n        return (self.workflow_key or \n            naming.type_key(\"model_name\", self.domain_model.__name__)\n        )\n\n'''\n!+TYPE_REGISTRY externalize further to bungeni_custom, currently:\n- association of type key and dedicated interface are hard-wired here\n- ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when \n  loading workflows and descriptors\n- type_key IS the underscore-separated lowercase of the domain cls name \n  i.e. utils.naming.polymorphic_identity(domain_model)\n- !+ ti.workflow_key SHOULD always be equal to type_key\n- !+ corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated\n- !+ dedicated interfaces for archetype incantations should be auto-generated, \n    from specific workflow name\/attr... e.g. via:\n    zope.interface.interface.InterfaceClass(iname, bases, __module__)\n- !+ should ti.interface be automatically generated also for system types?\n\nUsage:\n    from bungeni.capi import capi\n    capi.get_type_info(discriminator) -> TypeInfo\n    capi.iter_type_info() -> iterator of all registered (key, TypeInfo)\n'''\nTYPE_REGISTRY = [\n    # (key, ti)\n    # - the type key, unique for each type, is the underscore-separated \n    #   lowercase name of the domain_model (the domain class)\n    # - order is relevant (dictates workflow loading order)\n    \n    # feature \"support\" types, system types, required\n    \n    # workflowed\n    (\"user_address\", TI(\"address\", interfaces.IUserAddress)),\n    (\"group_address\", TI(\"address\", interfaces.IGroupAddress)),\n    # !+Attachment (mr, jul-2011)\n    # a) must be loaded before any other type that *may* support attachments!\n    # b) MUST support versions\n    (\"attachment\", TI(\"attachment\", interfaces.IAttachment)),\n    (\"event\", TI(\"event\", interfaces.IEvent)),\n    (\"sitting\", TI(\"sitting\", interfaces.ISitting)),\n    (\"heading\", TI(\"heading\", interfaces.IHeading)),\n    (\"user\", TI(\"user\", interfaces.IBungeniUser)),\n    (\"signatory\", TI(\"signatory\", interfaces.ISignatory)),\n    \n    # !+NAMING: member-related -> Group name + \"Member\" (no + \"ship\")\n    (\"group\", TI(\"group\", interfaces.IBungeniGroup)),\n    (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)),\n    (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n    (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n        # non-workflowed\n    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n    (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n    (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n    (\"title_type\", TI(None, interfaces.ITitleType)),\n    (\"member_title\", TI(None, interfaces.IMemberTitle)),\n    (\"change\", TI(None, interfaces.IChange)),\n    (\"doc\", TI(None, interfaces.IDoc)),\n    (\"doc_version\", TI(None, None)), #interfaces.IDocVersion)), #!+IVERSION\n    (\"attachment_version\", TI(None, None)), #interfaces.IAttachmentVersion)), #!+IVERSION\n    (\"venue\", TI(None, interfaces.IVenue)),\n    (\"session\", TI(None, interfaces.ISession)),\n    (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)),\n    (\"country\", TI(None, interfaces.ICountry)),\n    (\"item_schedule\", TI(None, interfaces.IItemSchedule)),\n    (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)),\n    (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)),\n    (\"editorial_note\", TI(None, interfaces.IEditorialNote)),\n    (\"sitting_report\", TI(None, interfaces.ISittingReport)),\n    (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)),\n    \n    # additional custom types are loaded dynamically from bungeni_custom\/types.xml\n]\n\n\n\n\n# register custom types\n\ndef register_new_custom_type(type_key, workflow_key, archetype_key):\n    \"\"\"Retrieve (create if needed) a domain interface and model for type_key,\n    and register as new entry on TYPE_REGISTER.\n    \"\"\"\n    \n    # generate custom domain interface\n    domain_iface_name = naming.model_interface_name(type_key)\n    try:\n        domain_iface = resolve(\"%s.%s\" % (INTERFACE_MODULE.__name__, domain_iface_name))\n        log.warn(\"Custom interface ALREADY EXISTS: %s\" % (domain_iface))\n    except ImportError:\n        domain_iface = new_custom_domain_interface(type_key, domain_iface_name)\n    \n    # generate custom domain_model\n    domain_model_name = naming.model_name(type_key)\n    try:\n        domain_model = resolve(\"%s.%s\" % (MODEL_MODULE.__name__, domain_model_name))\n        log.warn(\"Custom domain model ALREADY EXISTS: %s\" % (domain_model))\n    except ImportError:\n        domain_model = new_custom_domain_model(type_key, domain_iface, archetype_key)\n    \n    # type_info entry\n    ti = TI(workflow_key, domain_iface, domain_model)\n    ti.custom = True\n    TYPE_REGISTRY.append((type_key, ti))\n    \n    log.info(\"Registered custom type [%s]: %s\" % (archetype_key, type_key))\n    return type_key, ti\n\n\n\n\n\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py":{"changes":[{"diff":"\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self)","add":8,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py","badparts":["        return int(bc.oauth_auth_expiry_time)"],"goodparts":["        return int(bc.oauth_authorization_token_expiry_time)","    @cached_property.cachedIn(\"__oauth_hmac_key__\")","    @bungeni_custom_errors","    def oauth_hmac_key(self):","        \"\"\"String used to to generate nonces. KEEP SECRET.","        \"\"\"","        return bc.oauth_hmac_key"]}],"source":"\n \"\"\"Defines the accessor class for Bungeni Custom parameters. See bungeni.capi __init__.py for usage. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.capi\") import sys import time import os from zope.dottedname.resolve import resolve from zope.cachedescriptors import property as cached_property from bungeni.utils import error from bungeni.alchemist import type_info import bungeni_custom as bc class BungeniCustomError(Exception): \"\"\"A configuration error during loading of configuration. \"\"\" class BungeniCustomRuntimeError(BungeniCustomError): \"\"\"Internal error while executing a callable determined from configuration. \"\"\" def bungeni_custom_errors(f): \"\"\"Decorator to intercept any error raised by function f and re-raise it as a BungeniCustomError. To be used to decorate any function involved in reading\/validating\/processing any bungeni_custom parameters. \"\"\" return error.exceptions_as(BungeniCustomError)(f) def wrapped_callable(unwrapped): assert callable(unwrapped), unwrapped def wrapped(*args): log.debug(\"Calling %s with args: %s\" %(unwrapped, args)) try: return unwrapped(*args) except: exc=sys.exc_info()[1] log.debug(\"BungeniCustomRuntimeError[%r] in wrapped_callable: %s %s\", exc, wrapped, args) raise wrapped._unwrapped=unwrapped wrapped.__name__=unwrapped.__name__ return wrapped class CAPI(object): \"\"\"Accessor class for Bungeni Custom parameters. \"\"\" def __init__(self): self.validate_properties() def validate_properties(self): \"\"\"Validate this capi instance. Ensure valid setup of properties at instantiation of CAPI instance \"\"\" self.default_language self.country_code self.right_to_left_languages @property @bungeni_custom_errors def zope_i18n_allowed_languages(self): return tuple(bc.zope_i18n_allowed_languages.split()) @property @bungeni_custom_errors def zope_i18n_compile_mo_files(self): return bool( bc.zope_i18n_compile_mo_files is True or bc.zope_i18n_compile_mo_files==\"1\") @property @bungeni_custom_errors def country_code(self): \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this bungeni instance. \"\"\" return bc.country_code @property @bungeni_custom_errors def default_language(self): assert bc.default_language in self.zope_i18n_allowed_languages, \\ \"Default language[%s] not in allowed languages[%s]\" %( bc.default_language, self.zope_i18n_allowed_languages,) return bc.default_language @property @bungeni_custom_errors def right_to_left_languages(self): rtl_langs=tuple(bc.right_to_left_languages.split()) assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\ \"Right to left languages[%s] not in allowed languages[%s]\" %( bc.right_to_left_languages, self.zope_i18n_allowed_languages) return rtl_langs @property @bungeni_custom_errors def check_auto_reload_localization(self): \"\"\"() -> int minimum number of seconds to wait between checks for whether a localization file needs reloading; 0 means never check(deployment) \"\"\" int(bc.check_auto_reload_localization) return bc.check_auto_reload_localization @bungeni_custom_errors def get_workflow_condition(self, condition): condition_module=resolve(\"._conditions\", \"bungeni_custom.workflows\") condition=getattr(condition_module, condition) return wrapped_callable(condition) @bungeni_custom_errors def get_workflow_action(self, action): action_module=resolve(\"._actions\", \"bungeni_custom.workflows\") action=getattr(action_module, action) return wrapped_callable(action) @bungeni_custom_errors def get_form_constraint(self, constraint): constraint_module=resolve(\"._constraints\", \"bungeni_custom.forms\") constraint=getattr(constraint_module, constraint) return wrapped_callable(constraint) @bungeni_custom_errors def get_form_validator(self, validation): validator_module=resolve(\"._validations\", \"bungeni_custom.forms\") validator=getattr(validator_module, validation) return wrapped_callable(validator) @bungeni_custom_errors def get_form_derived(self, derived): derived_module=resolve(\"._derived\", \"bungeni_custom.forms\") derived_def=getattr(derived_module, derived) return wrapped_callable(derived_def) @property @bungeni_custom_errors def default_number_of_listing_items(self): \"\"\"This is the max number of items that are displayed in a listing by default. Returns an integer \"\"\" return int(bc.default_number_of_listing_items) @property @bungeni_custom_errors def long_text_column_listings_truncate_at(self): \"\"\"When listing text columns, only display first so many characters.\"\"\" return int(bc.long_text_column_listings_truncate_at) def xml_workspace_tabs_file(self): \"\"\"helper function used by workspace tab info APIs\"\"\" TABS_FILE=\"tabs.xml\" from lxml import etree ws_path=self.get_path_for(\"workspace\") file_path=os.path.join(ws_path, TABS_FILE) tabs=etree.fromstring(open(file_path).read()) return tabs @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\") @bungeni_custom_errors def workspace_tab_count_cache_refresh_time(self): \"\"\"The duration in seconds between tab count refresh operations\"\"\" tabs=self.xml_workspace_tabs_file() tabs_count_refresh=tabs.attrib[\"tab_count_cache_refresh_time\"] return int(tabs_count_refresh) @cached_property.cachedIn(\"__workspace_tabs__\") @bungeni_custom_errors def workspace_tabs(self): \"\"\"The tabs in the workspace\"\"\" ws_tabs=[] tabs=self.xml_workspace_tabs_file() for tab in tabs.iterchildren(tag=\"tab\"): ws_tabs.append(tab.attrib[\"id\"]) return ws_tabs @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\") @bungeni_custom_errors def oauth_access_token_expiry_time(self): \"\"\"time in seconds before an access token expires\"\"\" return(bc.oauth_access_token_expiry_time) @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\") @bungeni_custom_errors def oauth_authorization_token_expiry_time(self): \"\"\"time in seconds before an oauth authorization code expires max recommended time is 10min \"\"\" return int(bc.oauth_auth_expiry_time) def get_root_path(self): \"\"\"Get absolute physical path location for currently active bungeni_custom package folder. \"\"\" return os.path.dirname(os.path.abspath(bc.__file__)) def get_path_for(self, *path_components): \"\"\"Get absolute path, under bungeni_custom, for path_components. \"\"\" return os.path.join(*(self.get_root_path(),)+path_components) def put_env(self, key): \"\"\"Set capi value for{key} as the environment variable{key} i.e. use to set os.environ[key]. Wrapper on os.put_env(key, string_value) --to take care of the value string-casting required by os.put_env while still allowing the liberty of data-typing values of capi attributes as needed. \"\"\" value=getattr(self, key) try: os.environ[key]=value except TypeError: try: os.environ[key]=\" \".join(value) except TypeError: os.environ[key]=repr(value) assert eval(os.environ[key])==value _is_modified_since_last_times={} def is_modified_since(self, abspath, modified_on_first_check=True): \"\"\"(abspath:str, modified_on_first_check:bool) -> bool Checks file path st_mtime to see if file has been modified since last check. Updates entry per path, with last(check, modified) times. \"\"\" check_auto_reload_localization=self.check_auto_reload_localization now=time.time() last_checked, old_last_modified=\\ self._is_modified_since_last_times.get(abspath) or(0, 0) if not check_auto_reload_localization: if last_checked or not modified_on_first_check: return False if not now-last_checked > check_auto_reload_localization: return False last_modified=os.stat(abspath).st_mtime self._is_modified_since_last_times[abspath]=(now, last_modified) if not last_checked: return modified_on_first_check return(old_last_modified < last_modified) def get_type_info(self, discriminator): \"\"\"Get the TypeInfo instance for discriminator(see core.type_info). The discriminator may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: implements IBungeniContent domain model instance: type provides IBungeniContent descriptor_model: implements IModelDescriptor Raise KeyError if no entry matched. \"\"\" return type_info._get(discriminator) def iter_type_info(self, scope=None): \"\"\"Return iterator on all registered(key, TypeInfo) entries. scope:either(None, \"system\", \"archetype\", \"custom\") \"\"\" for type_key, ti in type_info._iter(): if(scope is None or ti.scope==scope): yield type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Defines the accessor class for Bungeni Custom parameters.\n\nSee bungeni.capi __init__.py for usage.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.capi\")\n\nimport sys\nimport time\nimport os\nfrom zope.dottedname.resolve import resolve\nfrom zope.cachedescriptors import property as cached_property\nfrom bungeni.utils import error\nfrom bungeni.alchemist import type_info\nimport bungeni_custom as bc\n\n\n# utils \n\nclass BungeniCustomError(Exception):\n    \"\"\"A configuration error during loading of configuration.\n    \"\"\"\nclass BungeniCustomRuntimeError(BungeniCustomError): \n    \"\"\"Internal error while executing a callable determined from configuration.\n    \"\"\" \n\ndef bungeni_custom_errors(f):\n    \"\"\"Decorator to intercept any error raised by function f and re-raise it\n    as a BungeniCustomError. To be used to decorate any function involved \n    in reading\/validating\/processing any bungeni_custom parameters. \n    \"\"\"\n    return error.exceptions_as(BungeniCustomError)(f)\n\n\ndef wrapped_callable(unwrapped):\n    assert callable(unwrapped), unwrapped\n    def wrapped(*args):\n        log.debug(\"Calling %s with args: %s\" % (unwrapped, args))\n        try:\n            return unwrapped(*args)\n        except:\n            # intercept exc, to re-raise it *unchanged*, only for debugging\n            # e.g. constraints raise numerous (expected?) NoInputData errors\n            exc = sys.exc_info()[1]\n            log.debug(\"BungeniCustomRuntimeError [%r] in wrapped_callable: %s %s\",\n                    exc, wrapped, args)\n            raise\n    # remember original unwrapped callable\n    wrapped._unwrapped = unwrapped\n    wrapped.__name__ = unwrapped.__name__\n    return wrapped\n\n\n# capi (singleton)\n\nclass CAPI(object):\n    \"\"\"Accessor class for Bungeni Custom parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.validate_properties()\n    \n    def validate_properties(self):\n        \"\"\"Validate this capi instance.\n        Ensure valid setup of properties at instantiation of CAPI instance\n        \"\"\"\n        self.default_language\n        self.country_code\n        self.right_to_left_languages\n        \n    # bungeni_custom parameter properties\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_allowed_languages(self):\n        # NOTE: zope.i18n.config.ALLOWED_LANGUAGES expects the value of the \n        # env variable for this to be a COMMA or SPACE separated STRING\n        return tuple(bc.zope_i18n_allowed_languages.split())\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_compile_mo_files(self):\n        return bool(\n            bc.zope_i18n_compile_mo_files is True or \n            bc.zope_i18n_compile_mo_files == \"1\")\n   \n    @property\n    @bungeni_custom_errors\n    def country_code(self):\n        \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this \n        bungeni instance.\n        \"\"\"\n        return bc.country_code\n\n    @property\n    @bungeni_custom_errors\n    def default_language(self):\n        assert bc.default_language in self.zope_i18n_allowed_languages, \\\n            \"Default language [%s] not in allowed languages [%s]\" % (\n                bc.default_language, self.zope_i18n_allowed_languages,)\n        return bc.default_language\n        \n    @property\n    @bungeni_custom_errors\n    def right_to_left_languages(self):\n        rtl_langs = tuple(bc.right_to_left_languages.split())\n        assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\\n            \"Right to left languages [%s] not in allowed languages [%s]\" % (\n                bc.right_to_left_languages, self.zope_i18n_allowed_languages)\n        return rtl_langs\n    \n    @property\n    @bungeni_custom_errors\n    def check_auto_reload_localization(self):\n        \"\"\" () -> int\n        minimum number of seconds to wait between checks for whether a \n        localization file needs reloading; 0 means never check (deployment)\n        \"\"\"\n        int(bc.check_auto_reload_localization) # TypeError if not an int\n        return bc.check_auto_reload_localization\n    \n    \n    @bungeni_custom_errors\n    def get_workflow_condition(self, condition):\n        condition_module = resolve(\"._conditions\", \"bungeni_custom.workflows\")\n        condition = getattr(condition_module, condition) # raises AttributeError\n        return wrapped_callable(condition)\n    \n    @bungeni_custom_errors\n    def get_workflow_action(self, action):\n        action_module = resolve(\"._actions\", \"bungeni_custom.workflows\")\n        action = getattr(action_module, action) # raises AttributeError\n        return wrapped_callable(action)\n    \n    @bungeni_custom_errors\n    def get_form_constraint(self, constraint):\n        constraint_module = resolve(\"._constraints\", \"bungeni_custom.forms\")\n        constraint = getattr(constraint_module, constraint) # raises AttributeError\n        return wrapped_callable(constraint)\n    \n    @bungeni_custom_errors\n    def get_form_validator(self, validation):\n        validator_module = resolve(\"._validations\", \"bungeni_custom.forms\")\n        validator = getattr(validator_module, validation) # raises AttributeError\n        return wrapped_callable(validator)\n    \n    @bungeni_custom_errors\n    def get_form_derived(self, derived):\n        derived_module = resolve(\"._derived\", \"bungeni_custom.forms\")\n        derived_def = getattr(derived_module, derived) # raises AttributeError\n        return wrapped_callable(derived_def)\n    \n    \n    @property\n    @bungeni_custom_errors\n    def default_number_of_listing_items(self):\n        \"\"\"This is the max number of items that are displayed in a listing by\n        default. Returns an integer\n        \"\"\"\n        return int(bc.default_number_of_listing_items)\n    \n    @property\n    @bungeni_custom_errors\n    def long_text_column_listings_truncate_at(self):\n        \"\"\"When listing text columns, only display first so many characters.\"\"\"\n        return int(bc.long_text_column_listings_truncate_at)\n    \n    def xml_workspace_tabs_file(self):\n        \"\"\"helper function used by workspace tab info APIs\"\"\"\n        TABS_FILE = \"tabs.xml\"    \n        from lxml import etree\n        ws_path = self.get_path_for(\"workspace\")\n        file_path = os.path.join(ws_path, TABS_FILE)\n        tabs = etree.fromstring(open(file_path).read()) \n        return tabs                \n    \n    @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\")\n    @bungeni_custom_errors\n    def workspace_tab_count_cache_refresh_time(self):\n        \"\"\"The duration in seconds between tab count refresh operations\"\"\"\n        tabs = self.xml_workspace_tabs_file()\n        tabs_count_refresh = tabs.attrib[\"tab_count_cache_refresh_time\"]\n        return int(tabs_count_refresh)\n    \n    @cached_property.cachedIn(\"__workspace_tabs__\")\n    @bungeni_custom_errors\n    def workspace_tabs(self):\n        \"\"\"The tabs in the workspace\"\"\"\n        ws_tabs = []\n        tabs = self.xml_workspace_tabs_file()\n        for tab in tabs.iterchildren(tag=\"tab\"):\n            ws_tabs.append(tab.attrib[\"id\"])\n        return ws_tabs    \n\n    @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_access_token_expiry_time(self):\n        \"\"\"time in seconds before an access token expires\"\"\"\n        return (bc.oauth_access_token_expiry_time)\n\n    @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_authorization_token_expiry_time(self):\n        \"\"\"time in seconds before an oauth authorization code expires\n        max recommended time is 10min\n        \"\"\"\n        return int(bc.oauth_auth_expiry_time)\n    # utility methods\n    \n    def get_root_path(self):\n        \"\"\"Get absolute physical path location for currently active \n        bungeni_custom package folder.\n        \"\"\"\n        return os.path.dirname(os.path.abspath(bc.__file__)) \n    \n    def get_path_for(self, *path_components):\n        \"\"\"Get absolute path, under bungeni_custom, for path_components.\n        \"\"\"\n        return os.path.join(*(self.get_root_path(),)+path_components)\n    \n    def put_env(self, key):\n        \"\"\"Set capi value for {key} as the environment variable {key}\n        i.e. use to set os.environ[key].\n        \n        Wrapper on os.put_env(key, string_value) -- to take care of\n        the value string-casting required by os.put_env while still \n        allowing the liberty of data-typing values of capi attributes \n        as needed.\n        \"\"\"\n        value = getattr(self, key)\n        try:\n            os.environ[key] = value\n            # OK, value is a string... done.\n        except TypeError:\n            # putenv() argument 2 must be string, not <...>\n            # i.e. value is NOT a string... try string-casting:\n            try:\n                # some zope code expects sequences to be specified as a \n                # COMMA or SPACE separated STRING, so we first try the value \n                # as a sequence, and serialize it to an environment variable \n                # value as expected by zope\n                os.environ[key] = \" \".join(value)\n            except TypeError:\n                # not a sequence, just fallback on repr(value)\n                os.environ[key] = repr(value)\n                # ensure that the original object value defines a __repr__ \n                # that can correctly re-instantiate the original object\n                assert eval(os.environ[key]) == value\n    \n    _is_modified_since_last_times = {} # {path: (last_checked, last_modified)}\n    def is_modified_since(self, abspath, modified_on_first_check=True):\n        \"\"\" (abspath:str, modified_on_first_check:bool) -> bool\n        Checks file path st_mtime to see if file has been modified since last \n        check. Updates entry per path, with last (check, modified) times.\n        \"\"\"\n        check_auto_reload_localization = self.check_auto_reload_localization\n        now = time.time()\n        last_checked, old_last_modified = \\\n            self._is_modified_since_last_times.get(abspath) or (0, 0)\n        if not check_auto_reload_localization:\n            # 0 =>> never check (unless this is the first check...)\n            if last_checked or not modified_on_first_check:\n                return False\n        if not now-last_checked > check_auto_reload_localization:\n            # last check too recent, avoid doing os.stat\n            return False\n        last_modified = os.stat(abspath).st_mtime\n        self._is_modified_since_last_times[abspath] = (now, last_modified)\n        if not last_checked:\n            # last_checked==0, this is the first check\n            return modified_on_first_check\n        return (old_last_modified < last_modified)\n    \n    # type registry\n    \n    def get_type_info(self, discriminator):\n        \"\"\"Get the TypeInfo instance for discriminator (see core.type_info). \n        \n        The discriminator may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: implements IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor_model: implements IModelDescriptor\n        \n        Raise KeyError if no entry matched.\n        \"\"\"\n        return type_info._get(discriminator)\n    \n    def iter_type_info(self, scope=None):\n        \"\"\"Return iterator on all registered (key, TypeInfo) entries.\n        scope:either(None, \"system\", \"archetype\", \"custom\")\n        \"\"\"\n        for type_key, ti in type_info._iter():\n            if (scope is None or ti.scope == scope):\n                yield type_key, ti\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py":{"changes":[{"diff":"\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"","add":2,"remove":2,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py","badparts":["        api[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])"],"goodparts":["        admin[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, admin[u\"applications\""]}],"source":"\n \"\"\"The Bungeni Application $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.core.app\") from zope.interface import implements from zope.interface import implementedBy from zope import component from zope.interface.declarations import alsoProvides from zope.app.appsetup.appsetup import getConfigContext from zope.app.component import site from zope.location.interfaces import ILocation from ore.wsgiapp.app import Application from ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent from bungeni.models import domain from bungeni.models import interfaces as model_interfaces from bungeni.models.utils import get_current_parliament from bungeni.models.utils import container_getter from bungeni.core import interfaces from bungeni.core import location from bungeni.core.content import(Section, AdminSection, AkomaNtosoSection, WorkspaceSection, APISection, OAuthSection) from bungeni.core.content import QueryContent from bungeni.core.i18n import _ from bungeni.core.workspace import(WorkspaceContainer, WorkspaceUnderConsiderationContainer, WorkspaceTrackedDocumentsContainer, WorkspaceGroupsContainer, WorkspaceSchedulableContainer, load_workspaces) from bungeni.core.notifications import load_notifications from bungeni.core.emailnotifications import load_email from bungeni.core.serialize import serialization_notifications from bungeni.ui.utils import url, common from bungeni.capi import capi from bungeni.utils import register @register.handler( (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent)) def on_wsgi_application_created_event(application, event): \"\"\"Additional setup on IWSGIApplicationCreatedEvent. \"\"\" log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) for type_key, ti in capi.iter_type_info(): if ti.workflow: ti.workflow.validate_permissions_roles() import bungeni.core.workflows.events load_workspaces() load_notifications() load_email() serialization_notifications() import bungeni.core.events app_setup=model_interfaces.IBungeniSetup(application) app_setup.setUp() try: import bungeni.utils.xmlconfexport as confexp confexp.write_all() except: log.debug((\"on_wsgi_application_created:\" \"error while exporting config parameters to xml\")) log.debug(\"on_wsgi_application_created_event: _features: %s\" %( getConfigContext()._features)) def to_locatable_container(domain_class, *domain_containers): component.provideAdapter(location.ContainerLocation(*domain_containers), (implementedBy(domain_class), ILocation)) class BungeniApp(Application): implements(model_interfaces.IBungeniApplication) class AppSetup(object): implements(model_interfaces.IBungeniSetup) def __init__(self, application): self.context=application def setUp(self): from zope.configuration import xmlconfig xmlconfig.string(\"\"\" <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\" xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\"> <include package=\"zope.i18n\" file=\"meta.zcml\" \/> <i18n:registerTranslations directory=\"%s\" \/> <\/configure> \"\"\" %(capi.get_path_for(\"translations\", \"bungeni\"))) import index index.setupFieldDefinitions(index.indexer) sm=site.LocalSiteManager(self.context) self.context.setSiteManager(sm) from bungeni.core import language from bungeni.ui import z3evoque z3evoque.set_get_gettext() z3evoque.setup_evoque() z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\")) z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL) z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name) z3evoque.domain.set_on_globals(\"get_base_direction\", language.get_base_direction) z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl) self.context[\"bungeni\"]=AkomaNtosoSection( title=_(u\"Bungeni\"), description=_(u\"Current parliamentary activity\"), default_name=\"bung\", ) workspace=self.context[\"workspace\"]=WorkspaceSection( title=_(\"section_workspace\", default=u\"Workspace\"), description=_(u\"Current parliamentary activity\"), default_name=\"my-documents\", ) alsoProvides(workspace, interfaces.ISearchableSection) workspace[\"my-documents\"]=WorkspaceSection( title=_(\"section_workspace_documents\", default=u\"my documents\"), description=_(u\"my documents workspace section\"), default_name=\"inbox\", marker=interfaces.IWorkspaceDocuments, ) for tab in capi.workspace_tabs: workspace[\"my-documents\"][tab]=WorkspaceContainer( tab_type=tab, title=_(\"section_workspace_%s\" % tab, default=tab), marker=interfaces.IWorkspaceTab ) ws_uc=workspace[\"under-consideration\"]=WorkspaceSection( title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), default_name=\"documents\", marker=interfaces.IWorkspaceUnderConsideration) ws_uc[\"documents\"]=WorkspaceUnderConsiderationContainer( name=\"documents\", title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), marker=interfaces.IWorkspaceTrackedDocuments) ws_uc[\"tracked-documents\"]=WorkspaceTrackedDocumentsContainer( name=\"tracked documents\", title=_(u\"tracked documents\"), description=_(u\"tracked documents\")) ws_sched=workspace[\"scheduling\"]=Section( title=_(\"section_scheduling\", default=u\"Scheduling\"), description=_(u\"Workspace Scheduling\"), default_name=\"index\", marker=interfaces.IWorkspaceScheduling) ws_sched[\"committees\"]=QueryContent( container_getter(get_current_parliament, \"committees\"), title=_(\"section_scheduling_committees\", default=u\"Committees\"), description=_(u\"Committee schedules\")) ws_sched[\"documents\"]=WorkspaceSchedulableContainer( name=_(u\"schedulable items\"), title=_(u\"schedulable items\"), description=_(u\"documents available for scheduling\")) ws_sched[\"sittings\"]=QueryContent( container_getter(get_current_parliament, \"sittings\"), title=_(\"section_scheduling_sittings\", default=u\"Sittings\"), description=_(u\"Plenary Sittings\")) ws_sched[\"agendaitems\"]=QueryContent( container_getter(get_current_parliament, \"agendaitems\"), title=_(\"section_scheduling_agenda_items\", default=u\"Agenda items\"), description=_(u\"Manage agenda items\")) workspace[\"groups\"]=WorkspaceSection( title=_(\"section_groups\", default=u\"Groups\"), description=_(u\"Bungeni Groups\"), default_name=\"my-groups\", marker=interfaces.IWorkspaceGroups) workspace[\"groups\"][\"my-groups\"]=WorkspaceGroupsContainer( name=\"my-groups\", title=_(u\"My Groups\"), description=_(u\"Groups that the user is a member of\")) for key, info in capi.iter_type_info(): if model_interfaces.IScheduleContent.implementedBy(info.domain_model): container_name=\"%ss\" % key container=\"%sContainer\" % info.domain_model.__name__ ws_sched[container_name]=getattr(domain, container)() to_locatable_container(info.domain_model, ws_sched[container_name]) admin=self.context[\"admin\"]=AdminSection( title=_(u\"Administration\"), description=_(u\"Manage bungeni settings\"), default_name=\"admin-index\", marker=model_interfaces.IBungeniAdmin) alsoProvides(admin, interfaces.ISearchableSection) content=admin[\"content\"]=Section( title=_(u\"Content\"), description=_(u\"browse bungeni content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"browse-admin\") admin[\"email-settings\"]=Section( title=_(u\"email settings\"), description=_(u\"manage email settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"email-settings\") admin[\"xapian-settings\"]=Section( title=_(u\"search index settings\"), description=_(u\"manage search index settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"xapian-settings\") admin[\"registry-settings\"]=Section( title=_(u\"registry settings\"), description=_(u\"manage registry settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"registry-settings\") admin[\"serialization-manager\"]=Section( title=_(u\"serialization manager\"), description=_(u\"batch serialization of content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"serialization-manager\") content[u\"parliaments\"]=domain.ParliamentContainer() to_locatable_container(domain.Parliament, content[u\"parliaments\"]) content[u\"users\"]=domain.UserContainer() to_locatable_container(domain.User, content[u\"users\"]) api=self.context[\"api\"]=APISection( title=_(u\"Bungeni API\"), description=_(u\"Bungeni REST API\"), default_name=\"index.html\", ) api[\"oauth\"]=OAuthSection( title=_(u\"Bungeni OAuth API\"), description=_(u\"Bungeni OAuth API\"), default_name=\"index.html\", ) api[u\"applications\"]=domain.OAuthApplicationContainer() to_locatable_container(domain.OAuthApplication, api[u\"applications\"]) ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"The Bungeni Application \n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.core.app\")\n\nfrom zope.interface import implements\nfrom zope.interface import implementedBy\nfrom zope import component\nfrom zope.interface.declarations import alsoProvides\n\nfrom zope.app.appsetup.appsetup import getConfigContext\nfrom zope.app.component import site\nfrom zope.location.interfaces import ILocation\n\nfrom ore.wsgiapp.app import Application\nfrom ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent\n\nfrom bungeni.models import domain\nfrom bungeni.models import interfaces as model_interfaces\nfrom bungeni.models.utils import get_current_parliament\nfrom bungeni.models.utils import container_getter\n\nfrom bungeni.core import interfaces\nfrom bungeni.core import location\nfrom bungeni.core.content import (Section, AdminSection, AkomaNtosoSection,\n    WorkspaceSection, APISection, OAuthSection)\nfrom bungeni.core.content import QueryContent\nfrom bungeni.core.i18n import _\nfrom bungeni.core.workspace import (WorkspaceContainer,\n    WorkspaceUnderConsiderationContainer,\n    WorkspaceTrackedDocumentsContainer,\n    WorkspaceGroupsContainer,\n    WorkspaceSchedulableContainer,\n    load_workspaces)\nfrom bungeni.core.notifications import load_notifications\nfrom bungeni.core.emailnotifications import load_email\nfrom bungeni.core.serialize import serialization_notifications\nfrom bungeni.ui.utils import url, common # !+ core dependency on ui\nfrom bungeni.capi import capi\nfrom bungeni.utils import register\n\n\n\n@register.handler(\n    (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent))\ndef on_wsgi_application_created_event(application, event):\n    \"\"\"Additional setup on IWSGIApplicationCreatedEvent.\n    \"\"\"\n    # !+ui.app.on_wsgi_application_created_event ALWAYS gets called prior to this\n    log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) \n    \n    # additional workflow validation\n    for type_key, ti in capi.iter_type_info():\n        if ti.workflow:\n            ti.workflow.validate_permissions_roles()\n    \n    # import events module, registering handlers\n    import bungeni.core.workflows.events\n    \n    # load workspaces\n    load_workspaces()\n    \n    # load notifications\n    load_notifications()\n\n    # load email notifications\n    load_email()\n\n    # set up serialization notifications\n    serialization_notifications()\n    \n    # import events modules, registering handlers\n    import bungeni.core.events\n    \n    app_setup = model_interfaces.IBungeniSetup(application)\n    app_setup.setUp()\n    \n    # write configuration parameters to xml\n    try:\n        import bungeni.utils.xmlconfexport as confexp\n        confexp.write_all()\n    except:\n        log.debug((\"on_wsgi_application_created :\"\n            \"error while exporting config parameters to xml\"))\n    \n    log.debug(\"on_wsgi_application_created_event: _features: %s\" % (\n        getConfigContext()._features))\n\n\ndef to_locatable_container(domain_class, *domain_containers):\n    component.provideAdapter(location.ContainerLocation(*domain_containers),\n               (implementedBy(domain_class), ILocation))\n\n\nclass BungeniApp(Application):\n    implements(model_interfaces.IBungeniApplication)\n\nclass AppSetup(object):\n    \n    implements(model_interfaces.IBungeniSetup)\n    \n    def __init__(self, application):\n        self.context = application\n    \n    def setUp(self):\n        \n        # register translations\n        #import zope.i18n.zcml\n        #zope.i18n.zcml.registerTranslations(getConfigContext(),\n        #    capi.get_path_for(\"translations\", \"bungeni\"))\n        # !+ZCML_PYTHON(mr, apr-2011) above registerTranslations() in python \n        # does not work, as subsequent utility lookup fails. We workaround it \n        # by executing the following parametrized bit of ZCML:\n        from zope.configuration import xmlconfig\n        xmlconfig.string(\"\"\"\n            <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\"\n                xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\">\n                <include package=\"zope.i18n\" file=\"meta.zcml\" \/>\n                <i18n:registerTranslations directory=\"%s\" \/>\n            <\/configure>\n            \"\"\" % (capi.get_path_for(\"translations\", \"bungeni\")))\n        \n        # ensure indexing facilities are setup(lazy)\n        import index\n        index.setupFieldDefinitions(index.indexer)\n        \n        sm = site.LocalSiteManager(self.context)\n        self.context.setSiteManager(sm)\n        \n        from bungeni.core import language\n        from bungeni.ui import z3evoque\n        z3evoque.set_get_gettext()\n        z3evoque.setup_evoque()\n        z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\"))\n        z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL)\n        z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name)\n        z3evoque.domain.set_on_globals(\"get_base_direction\", \n            language.get_base_direction)\n        z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl)          \n        \n        # !+ where is the view name for the app root (slash) set?\n        \n        # CONVENTION: the action of each site top-section is made to point \n        # directly the primary sub-section (the INDEX) that it contains.\n        # EXCEPTION: the \"\/\", when logged in, is redirected to \"\/workspace\/pi\"\n        \n        self.context[\"bungeni\"] = AkomaNtosoSection(\n            title=_(u\"Bungeni\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"bung\", # !+NAMING(mr, jul-2011) bung?!?\n        )\n        \n        # top-level sections\n        workspace = self.context[\"workspace\"] = WorkspaceSection(\n            title=_(\"section_workspace\", default=u\"Workspace\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"my-documents\",\n        )\n        alsoProvides(workspace, interfaces.ISearchableSection)\n        \n        workspace[\"my-documents\"] = WorkspaceSection(\n            title=_(\"section_workspace_documents\", default=u\"my documents\"),\n            description=_(u\"my documents workspace section\"),\n            default_name=\"inbox\",\n            marker=interfaces.IWorkspaceDocuments,\n        )\n        \n        for tab in capi.workspace_tabs:\n            workspace[\"my-documents\"][tab] = WorkspaceContainer(\n                tab_type=tab,\n                title=_(\"section_workspace_%s\" % tab, default=tab),\n                marker=interfaces.IWorkspaceTab\n            )\n\n        ws_uc = workspace[\"under-consideration\"] = WorkspaceSection(\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            default_name=\"documents\",\n            marker=interfaces.IWorkspaceUnderConsideration)\n        ws_uc[\"documents\"] = WorkspaceUnderConsiderationContainer(\n            name=\"documents\",\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            marker=interfaces.IWorkspaceTrackedDocuments)\n        ws_uc[\"tracked-documents\"] = WorkspaceTrackedDocumentsContainer(\n            name=\"tracked documents\",\n            title=_(u\"tracked documents\"),\n            description=_(u\"tracked documents\"))\n        \n        ws_sched = workspace[\"scheduling\"] = Section(\n            title=_(\"section_scheduling\", default=u\"Scheduling\"),\n            description=_(u\"Workspace Scheduling\"),\n            default_name=\"index\",\n            marker=interfaces.IWorkspaceScheduling)\n        ws_sched[\"committees\"] = QueryContent(\n            container_getter(get_current_parliament, \"committees\"),\n            title=_(\"section_scheduling_committees\", default=u\"Committees\"),\n            #!+marker=interfaces.ICommitteeAddContext,\n            description=_(u\"Committee schedules\"))\n        ws_sched[\"documents\"] = WorkspaceSchedulableContainer(\n            name=_(u\"schedulable items\"),\n            title=_(u\"schedulable items\"),\n            description=_(u\"documents available for scheduling\"))\n        ws_sched[\"sittings\"] = QueryContent(\n            container_getter(get_current_parliament, \"sittings\"),\n            title=_(\"section_scheduling_sittings\", default=u\"Sittings\"),\n            description=_(u\"Plenary Sittings\"))\n        ws_sched[\"agendaitems\"] = QueryContent(\n            container_getter(get_current_parliament, \"agendaitems\"),\n            title=_(\"section_scheduling_agenda_items\", \n                default=u\"Agenda items\"),\n            #marker=interfaces.IAgendaItemAddContext,\n            description=_(u\"Manage agenda items\"))\n        \n        workspace[\"groups\"] = WorkspaceSection(\n            title=_(\"section_groups\", default=u\"Groups\"),\n            description=_(u\"Bungeni Groups\"),\n            default_name=\"my-groups\",\n            marker=interfaces.IWorkspaceGroups)\n        workspace[\"groups\"][\"my-groups\"] = WorkspaceGroupsContainer(\n            name=\"my-groups\",\n            title=_(u\"My Groups\"),\n            description=_(u\"Groups that the user is a member of\"))\n        \n        #!+TIMING\n        #!+AUTO CONTAINERS SCHEDULING(mb, April-2012)\n        # type_info missing container name\n        for key, info in capi.iter_type_info():\n            if model_interfaces.IScheduleContent.implementedBy(info.domain_model):\n                container_name = \"%ss\" % key\n                container = \"%sContainer\" % info.domain_model.__name__\n                ws_sched[container_name] = getattr(domain, container)()\n                to_locatable_container(info.domain_model, ws_sched[container_name])\n        \n        \n        ##########\n        # Admin User Interface\n        # Administration section\n        \n        #!+SECURITY(miano. nov-2010) Admin section now uses AdminSection\n        # container that is identical to Section, only difference is that\n        # traversing though it requires zope.ManageSite permission as defined\n        # in core\/configure.zcml\n        \n        admin = self.context[\"admin\"] = AdminSection(\n            title=_(u\"Administration\"),\n            description=_(u\"Manage bungeni settings\"),\n            default_name=\"admin-index\",\n            marker=model_interfaces.IBungeniAdmin)\n        alsoProvides(admin, interfaces.ISearchableSection)\n        \n        content = admin[\"content\"] = Section(\n            title=_(u\"Content\"),\n            description=_(u\"browse bungeni content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"browse-admin\")\n        \n        admin[\"email-settings\"] = Section(\n            title=_(u\"email settings\"),\n            description=_(u\"manage email settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"email-settings\")\n        \n        admin[\"xapian-settings\"] = Section(\n            title=_(u\"search index settings\"),\n            description=_(u\"manage search index settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"xapian-settings\")\n        \n        admin[\"registry-settings\"] = Section(\n            title=_(u\"registry settings\"),\n            description=_(u\"manage registry settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"registry-settings\")\n        \n        admin[\"serialization-manager\"] = Section(\n            title=_(u\"serialization manager\"),\n            description=_(u\"batch serialization of content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"serialization-manager\")\n        \n        content[u\"parliaments\"] = domain.ParliamentContainer()\n        to_locatable_container(domain.Parliament, content[u\"parliaments\"])\n        \n        content[u\"users\"] = domain.UserContainer()\n        to_locatable_container(domain.User, content[u\"users\"])\n\n        api = self.context[\"api\"] = APISection(\n            title=_(u\"Bungeni API\"),\n            description=_(u\"Bungeni REST API\"),\n            default_name=\"index.html\",\n        )\n        api[\"oauth\"] = OAuthSection(\n            title=_(u\"Bungeni OAuth API\"),\n            description=_(u\"Bungeni OAuth API\"),\n            default_name=\"index.html\",\n        )\n        api[u\"applications\"] = domain.OAuthApplicationContainer()\n        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n"}},"msg":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings."}},"https:\/\/github.com\/mohalfaki\/bungeni-portal":{"fdcd90bde5dd5efb4ff894413df30b18768381e4":{"url":"https:\/\/api.github.com\/repos\/mohalfaki\/bungeni-portal\/commits\/fdcd90bde5dd5efb4ff894413df30b18768381e4","html_url":"https:\/\/github.com\/mohalfaki\/bungeni-portal\/commit\/fdcd90bde5dd5efb4ff894413df30b18768381e4","message":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings.","sha":"fdcd90bde5dd5efb4ff894413df30b18768381e4","keyword":"replay attack improve","diff":"diff --git a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\nindex 44ae077ff..2d6b1645d 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n@@ -254,7 +254,7 @@ def permission_type_key(self):\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\nindex e328f6c85..96e0dc6f0 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n@@ -209,7 +209,14 @@ def oauth_authorization_token_expiry_time(self):\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self):\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\nindex 7435b4a3a..28e02aebf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n@@ -300,5 +300,5 @@ def setUp(self):\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"])\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\nindex 4ac3db531..8610d7e73 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n@@ -573,4 +573,11 @@ def title(self):\n         context = _merged(self.context)\n         return component.getUtility(IRole, context.role_id).title\n \n+@register.adapter()\n+class OAuthApplicationDescriptiveProperties(DescriptiveProperties):\n+    component.adapts(interfaces.IOAuthApplication)\n \n+    @property\n+    def title(self):\n+        context = _merged(self.context)\n+        return context.name\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\nindex e747ae61c..7122485b2 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n@@ -578,6 +578,9 @@ class IDebateTake(interface.Interface):\n class IOAuthApplication(interface.Interface):\n     \"\"\"Marker interface for an OAuth Application record\"\"\"\n \n+class IOAuthApplicationContainer(IAlchemistContainer):\n+    \"\"\"Marker interface for an OAuth Applications container\"\"\"\n+\n class IOAuthAuthorization(interface.Interface):\n     \"\"\"Marker interfeace for OAuth authorizations\"\"\"\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\nindex e34a41ef8..3900cbd92 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n@@ -163,8 +163,13 @@\n   <permission id=\"bungeni.debate_takes.View\" title=\"View debate takes\" \/>\n   <permission id=\"bungeni.debate_takes.Edit\" title=\"Edit debate takes\" \/>\n \n-  <permission id=\"bungeni.oauth_application.View\" title=\"View oauth app\" \/>\n-  <permission id=\"bungeni.oauth_application.Delete\" title=\"Delete oauth app\" \/>\n-  <meta:redefinePermission from=\"bungeni.oauth_application.View\" to=\"zope.ManageContent\" \/>\n+  <permission id=\"bungeni.o_auth_application.View\" title=\"View oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Add\" title=\"Add oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Edit\" title=\"Edit oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Delete\" title=\"Delete oauth app\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.View\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Add\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Edit\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Delete\" to=\"zope.ManageContent\" \/>\n   <permission id=\"bungeni.oauth.View\" title=\"Use oauth api\" \/>\n <\/configure>\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\nindex 128a2c535..f1d0ed492 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n@@ -1185,7 +1185,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"identifier\", rdb.UnicodeText, nullable=False, \n         unique=True),\n     rdb.Column(\"name\", rdb.UnicodeText, nullable=False),\n-    rdb.Column(\"secret\", rdb.String(32), nullable=False),\n+    rdb.Column(\"secret\", rdb.String(100), nullable=False),\n     rdb.Column(\"redirection_endpoint\", rdb.UnicodeText, nullable=False)\n )\n \n@@ -1195,7 +1195,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n         nullable=False),\n     rdb.Column(\"application_id\", rdb.Integer,\n         rdb.ForeignKey(\"oauth_application.application_id\"), nullable=False),\n-    rdb.Column(\"authorization_code\", rdb.String(32), nullable=False),\n+    rdb.Column(\"authorization_code\", rdb.String(100), nullable=False),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n     rdb.Column(\"active\", rdb.Boolean(), nullable=False)\n )\n@@ -1204,8 +1204,8 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"access_token_id\", rdb.Integer, primary_key=True),\n     rdb.Column(\"authorization_id\", rdb.Integer,\n              rdb.ForeignKey(\"oauth_authorization.authorization_id\")),\n-    rdb.Column(\"access_token\", rdb.String(32)),\n-    rdb.Column(\"refresh_token\", rdb.String(32)),\n+    rdb.Column(\"access_token\", rdb.String(100)),\n+    rdb.Column(\"refresh_token\", rdb.String(100)),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n )\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\nindex 21c811509..bf1568c5e 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n@@ -1,8 +1,10 @@\n import hashlib\n+import hmac\n import random\n import string\n import urllib\n import simplejson\n+import time\n from datetime import datetime, timedelta\n \n from sqlalchemy.orm.exc import NoResultFound\n@@ -30,8 +32,8 @@\n def get_key():\n     \"\"\"Return a randomly generated key\n     \"\"\"\n-    m = hashlib.sha256()\n-    m.update(\"\".join(random.sample(string.letters + string.digits, 32)))\n+    m = hashlib.sha1()\n+    m.update(\"\".join(random.sample(string.letters + string.digits, 20)))\n     return m.hexdigest()\n \n \n@@ -45,10 +47,10 @@ class AddOAuthApplication(forms.common.AddForm):\n     @form.action(_(u\"Create Application\"), name=\"create\")\n     def handle_create_application(self, action, data, validator=\"validateAdd\"):\n         oauth_app = domain.OAuthApplication()\n-        oauth_app.application_identifier = data[\"application_identifier\"]\n-        oauth_app.application_name = data[\"application_name\"]\n+        oauth_app.identifier = data[\"identifier\"]\n+        oauth_app.name = data[\"name\"]\n         oauth_app.redirection_endpoint = data[\"redirection_endpoint\"]\n-        oauth_app.application_key = get_key()\n+        oauth_app.secret = get_key()\n         session = Session()\n         session.add(oauth_app)\n         session.flush()\n@@ -163,41 +165,73 @@ def __call__(self):\n class IOAuthAuthorizeForm(interface.Interface):\n     client_id = schema.TextLine(required=False)\n     state = schema.TextLine(required=False)\n-\n+    time = schema.TextLine(required=False)\n+    nonce = schema.TextLine(required=False)\n \n class OAuthAuthorizeForm(form.FormBase):\n     form_fields = form.Fields(IOAuthAuthorizeForm)\n     form_fields[\"client_id\"].custom_widget = widgets.HiddenTextWidget\n     form_fields[\"state\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"nonce\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"time\"].custom_widget = widgets.HiddenTextWidget\n     template = NamedTemplate(\"alchemist.form\")\n     form_name = _(\"authorise_oauth_application\",\n         default=u\"Authorise OAuth Application\")\n \n     def __init__(self, context, request, parameters={}):\n         self.parameters = parameters\n+        if self.parameters:\n+            self.parameters[\"time\"] = time.time()\n+            self.parameters[\"nonce\"] = self.generate_nonce(\n+                self.parameters[\"time\"])\n         self.action_url = \"\/api\/oauth\/authorize-form\"\n         super(OAuthAuthorizeForm, self).__init__(context, request)\n \n     def setUpWidgets(self, ignore_request=False):\n+        \n         self.widgets = form.setUpWidgets(\n             self.form_fields, self.prefix, self.context, self.request,\n             data=self.parameters if self.parameters else self.request.form,\n             ignore_request=ignore_request\n         )\n \n-    @form.action(_(u\"Authorize application\"), name=\"authorize\")\n+    def generate_nonce(self, auth_time):\n+        data = \"{0}:{1}:{2}\".format(\n+            self.parameters[\"client_id\"], get_db_user().user_id, auth_time)\n+        return hmac.new(capi.oauth_hmac_key, data, hashlib.sha1).hexdigest()\n+\n+    def check_authorization(self, action, data):\n+        errors = []\n+        data = self.request.form\n+        if not data.get(\"form.time\", None) or not data.get(\"form.nonce\", None):\n+            errors.append(InvalidRequest)\n+            return errors\n+        max_time = datetime.fromtimestamp(float(data[\"form.time\"])) + \\\n+            timedelta(seconds=capi.oauth_authorization_token_expiry_time)\n+        if (datetime.now() > max_time):\n+            errors.append(InvalidGrant)\n+        if data[\"form.nonce\"] != self.generate_nonce(data[\"form.time\"]):\n+            errors.append(InvalidGrant)\n+        return errors\n+\n+    def handle_failure(self, action, data, errors):\n+        return ErrorPage(self.context, self.request, errors[0])()\n+\n+    @form.action(_(u\"Authorize application\"), name=\"authorize\",\n+        validator=check_authorization, failure=handle_failure)\n     def handle_authorize_app(self, action, data):\n         session = Session()\n         oauth_authorization = domain.OAuthAuthorization()\n         oauth_authorization.user_id = get_db_user().user_id\n         app = session.query(domain.OAuthApplication\n-            ).filter(domain.OAuthApplication.application_identifier ==\n+            ).filter(domain.OAuthApplication.identifier ==\n                 data[\"client_id\"]\n             ).one()\n         oauth_authorization.application_id = app.application_id\n         oauth_authorization.authorization_code = get_key()\n         oauth_authorization.expiry = datetime.now() + timedelta(\n-            seconds=capi.oauth_auth_expiry_time)\n+            seconds=capi.oauth_authorization_token_expiry_time)\n+        oauth_authorization.active = True\n         session.add(oauth_authorization)\n         redirect_uri = \"{0}?code={1}\".format(\n             app.redirection_endpoint, oauth_authorization.authorization_code)\n@@ -213,10 +247,10 @@ def handle_cancel(self, action, data):\n                      == data[\"client_id\"]\n             ).one()\n         error = UnauthorizedClient(app.redirection_endpoint, data[\"state\"])\n-        redirect_error(self.request, error)\n+        redirect_error(self.context, self.request, error)\n \n \n-def redirect_error(request, error):\n+def redirect_error(context, request, error):\n     if error.redirect_uri:\n         next_url = \"{0}?error={1}&error_description={2}\".format(\n             error.redirect_uri, error.error, error.error_description)\n@@ -224,10 +258,10 @@ def redirect_error(request, error):\n             next_url = \"{0}&state={1}\".format(next_url, error.state)\n         return request.response.redirect(next_url, trusted=True)\n     else:\n-        bad_request(request, error)\n+        return ErrorPage(context, request, error)()\n \n \n-def bad_request(request, error):\n+def bad_request(context, request, error):\n     request.response.setStatus(400)\n     data = {\"error\": error.error, \"error_description\": error.error_description}\n     return simplejson.dumps(data)\n@@ -277,7 +311,7 @@ def __call__(self):\n         except UnauthorizedClient as e:\n             return ErrorPage(self.context, self.request, e)()\n         except OAuthException as e:\n-            return redirect_error(self.request, e)\n+            return redirect_error(self.context, self.request, e)\n \n         if not IUnauthenticatedPrincipal.providedBy(self.request.principal):\n             # authorize form\n@@ -345,7 +379,7 @@ def __call__(self):\n         try:\n             parameters = self.parameters()\n         except OAuthException as e:\n-            return bad_request(self.request, e)\n+            return bad_request(self.context, self.request, e)\n         assert (self.authorization is not None,\n             \"Authorization object not initalized\")\n         self.authorization.expiry = datetime.now()\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\nindex 18c6363b5..1372b42bf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n@@ -1718,13 +1718,13 @@ class ItemScheduleVoteDescriptor(ModelDescriptor):\n class OAuthApplicationDescriptor(ModelDescriptor):\n     localisable = False\n     fields = [\n-        F(name=\"application_identifier\",\n+        F(name=\"identifier\",\n           label=\"Unique Application Identifier\",\n           required=True,\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_name\",\n+        F(name=\"name\",\n           label=\"Application Name\",\n           required=True,\n           value_type=\"text\",\n@@ -1736,8 +1736,8 @@ class OAuthApplicationDescriptor(ModelDescriptor):\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_key\",\n-          label=\"Application Key\",\n+        F(name=\"secret\",\n+          label=\"Application Secret\",\n           localizable=[show(\"view\"), hide(\"add\")],\n           required=True,\n           value_type=\"text\",\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\nindex 57deb7ee2..66b0dbd7b 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n@@ -1265,5 +1265,14 @@\n      viewName=\"\"\n      weight=\"30\"\n      \/-->\n+   <!--OAuth-->\n+   <browser:menuItem menu=\"plone_contentmenu\"\n+        for=\"bungeni.models.interfaces.IOAuthApplicationContainer\"\n+        title=\"Add OAuth Application\"\n+        action=\"add\"\n+        permission=\"bungeni.o_auth_application.Add\"\n+        layer=\".interfaces.IAdminSectionLayer\"\n+        order=\"62\"\n+    \/>\n <\/configure>\n \n","files":{"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py":{"changes":[{"diff":"\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),","add":1,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py","badparts":["    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),"],"goodparts":["    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),"]}],"source":"\n \"\"\"Aggregation of information about loaded domain types. No public methods here --all available methods from this are those exposed via bungeni.capi. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\") from zope.interface.interfaces import IInterface from zope.security.proxy import removeSecurityProxy from zope.dottedname.resolve import resolve from bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface from bungeni.alchemist.model import( new_custom_domain_interface, new_custom_domain_model, ) from bungeni.alchemist.catalyst import( INTERFACE_MODULE, MODEL_MODULE ) from bungeni.models import interfaces from bungeni.models import domain from bungeni.core.workflow.interfaces import IWorkflow from bungeni.utils import naming __all__=[] def _iter(): \"\"\"Return iterator on all(key, TypeInfo) entries in TYPE_REGISTRY. Usage: capi.iter_type_info() \"\"\" for type_key, ti in TYPE_REGISTRY: yield type_key, ti def _get(discriminator): \"\"\"Get the TypeInfo instance for discriminator, that may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: provides IBungeniContent domain model instance: type provides IBungeniContent descriptor: provides IModelDescriptor Raise KeyError if no entry matched. Usage: capi.get_type_info(discriminator) \"\"\" if discriminator is None: m=\"type_info._get discriminator is None\" log.error(m) raise ValueError(m) discri=removeSecurityProxy(discriminator) getter=None if IIModelInterface.providedBy(discri): discri=naming.type_key(\"table_schema_interface_name\", discri.__name__) elif IInterface.providedBy(discri): discri=naming.type_key(\"model_interface_name\", discri.__name__) elif type(discri) is type and issubclass(discri, domain.Entity): discri=naming.polymorphic_identity(discri) elif isinstance(discri, domain.Entity): discri=naming.polymorphic_identity(type(discri)) if isinstance(discri, basestring): getter=_get_by_type_key elif IWorkflow.providedBy(discri): getter=_get_by_workflow elif IModelDescriptor.implementedBy(discri): getter=_get_by_descriptor_model if getter is not None: ti=getter(discri) if ti is not None: return ti else: m=\"No type registered for discriminator: %r\" %(discriminator) else: m=\"Invalid type info lookup discriminator: %r\" %(discriminator) from bungeni.ui.utils import debug log.debug(debug.interfaces(discriminator)) log.debug(m) raise KeyError(m) def _get_by_type_key(key): for type_key, ti in _iter(): if type_key==key: return ti ''' !+IALCHEMISTCONTENT fails on different interfaces with same name! (Pdb) ti.interface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) ti.interface.__bases__ (<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>) (Pdb) iface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) iface.__bases__ (<InterfaceClass zope.interface.Interface>,) ''' def _get_by_model(model): for type_key, ti in _iter(): if model is ti.domain_model: return ti def _get_by_instance(instance): return _get_by_model(type(instance)) def _get_by_workflow(wf): for type_key, ti in _iter(): if wf is ti.workflow: return ti def _get_by_descriptor_model(descriptor_model): for type_key, ti in _iter(): if descriptor_model is ti.descriptor_model: return ti class TI(object): \"\"\"TypeInfo, associates together the following attributes for a given type: workflow_key the workflow file name defaults to the type_key for workflowed types that DO NOT specify is None for non-workflowed types workflow same workflow insatnce may be used by multiple types is None for non-workflowed types interface the manually applied application-dedicated model interface (if any) for the type derived_table_schema auto-generated db schema interface, provides IIModelInterface domain_model the domain class descriptor_model the descriptor model for UI views for the type container_class container class for domain_model container_interface interface for the container class for domain_model \"\"\" def __init__(self, workflow_key, iface, domain_model=None): self.workflow_key=workflow_key self.interface=iface self.derived_table_schema=None self.workflow=None self.domain_model=domain_model self.descriptor_model=None self.container_class=None self.container_interface=None self.custom=False def __str__(self): return str(self.__dict__) @property def scope(self): if self.custom: return \"custom\" if self.descriptor_model is not None: return self.descriptor_model.scope @property def permission_type_key(self): if self.custom: return self.workflow.name return(self.workflow_key or naming.type_key(\"model_name\", self.domain_model.__name__) ) ''' !+TYPE_REGISTRY externalize further to bungeni_custom, currently: -association of type key and dedicated interface are hard-wired here -ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when loading workflows and descriptors -type_key IS the underscore-separated lowercase of the domain cls name i.e. utils.naming.polymorphic_identity(domain_model) -!+ti.workflow_key SHOULD always be equal to type_key -!+corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated -!+dedicated interfaces for archetype incantations should be auto-generated, from specific workflow name\/attr... e.g. via: zope.interface.interface.InterfaceClass(iname, bases, __module__) -!+should ti.interface be automatically generated also for system types? Usage: from bungeni.capi import capi capi.get_type_info(discriminator) -> TypeInfo capi.iter_type_info() -> iterator of all registered(key, TypeInfo) ''' TYPE_REGISTRY=[ (\"user_address\", TI(\"address\", interfaces.IUserAddress)), (\"group_address\", TI(\"address\", interfaces.IGroupAddress)), (\"attachment\", TI(\"attachment\", interfaces.IAttachment)), (\"event\", TI(\"event\", interfaces.IEvent)), (\"sitting\", TI(\"sitting\", interfaces.ISitting)), (\"heading\", TI(\"heading\", interfaces.IHeading)), (\"user\", TI(\"user\", interfaces.IBungeniUser)), (\"signatory\", TI(\"signatory\", interfaces.ISignatory)), (\"group\", TI(\"group\", interfaces.IBungeniGroup)), (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)), (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)), (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)), (\"oauth_application\", TI(None, interfaces.IOAuthApplication)), (\"debate_media\", TI(None, interfaces.IDebateMedia)), (\"user_delegation\", TI(None, interfaces.IUserDelegation)), (\"title_type\", TI(None, interfaces.ITitleType)), (\"member_title\", TI(None, interfaces.IMemberTitle)), (\"change\", TI(None, interfaces.IChange)), (\"doc\", TI(None, interfaces.IDoc)), (\"doc_version\", TI(None, None)), (\"attachment_version\", TI(None, None)), (\"venue\", TI(None, interfaces.IVenue)), (\"session\", TI(None, interfaces.ISession)), (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)), (\"country\", TI(None, interfaces.ICountry)), (\"item_schedule\", TI(None, interfaces.IItemSchedule)), (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)), (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)), (\"editorial_note\", TI(None, interfaces.IEditorialNote)), (\"sitting_report\", TI(None, interfaces.ISittingReport)), (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)), ] def register_new_custom_type(type_key, workflow_key, archetype_key): \"\"\"Retrieve(create if needed) a domain interface and model for type_key, and register as new entry on TYPE_REGISTER. \"\"\" domain_iface_name=naming.model_interface_name(type_key) try: domain_iface=resolve(\"%s.%s\" %(INTERFACE_MODULE.__name__, domain_iface_name)) log.warn(\"Custom interface ALREADY EXISTS: %s\" %(domain_iface)) except ImportError: domain_iface=new_custom_domain_interface(type_key, domain_iface_name) domain_model_name=naming.model_name(type_key) try: domain_model=resolve(\"%s.%s\" %(MODEL_MODULE.__name__, domain_model_name)) log.warn(\"Custom domain model ALREADY EXISTS: %s\" %(domain_model)) except ImportError: domain_model=new_custom_domain_model(type_key, domain_iface, archetype_key) ti=TI(workflow_key, domain_iface, domain_model) ti.custom=True TYPE_REGISTRY.append((type_key, ti)) log.info(\"Registered custom type[%s]: %s\" %(archetype_key, type_key)) return type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Aggregation of information about loaded domain types.\n\nNo public methods here -- all available methods from this are those exposed \nvia bungeni.capi.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\")\n\nfrom zope.interface.interfaces import IInterface\nfrom zope.security.proxy import removeSecurityProxy\nfrom zope.dottedname.resolve import resolve\n\nfrom bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface\nfrom bungeni.alchemist.model import (\n    new_custom_domain_interface,\n    new_custom_domain_model,\n)\nfrom bungeni.alchemist.catalyst import (\n    INTERFACE_MODULE, \n    MODEL_MODULE\n)\nfrom bungeni.models import interfaces\nfrom bungeni.models import domain\nfrom bungeni.core.workflow.interfaces import IWorkflow\nfrom bungeni.utils import naming\n\n__all__ = []\n\n\n# acessors exposed via capi\n\ndef _iter():\n    \"\"\"Return iterator on all (key, TypeInfo) entries in TYPE_REGISTRY.\n    \n    Usage: capi.iter_type_info()\n    \"\"\"\n    for type_key, ti in TYPE_REGISTRY:\n        yield type_key, ti\n\ndef _get(discriminator):\n    \"\"\"Get the TypeInfo instance for discriminator, that may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: provides IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor: provides IModelDescriptor\n    \n    Raise KeyError if no entry matched.\n    \n    Usage: capi.get_type_info(discriminator)\n    \"\"\"\n    if discriminator is None:\n        m = \"type_info._get discriminator is None\"\n        log.error(m)\n        raise ValueError(m)\n    discri = removeSecurityProxy(discriminator)\n    getter = None\n    \n    # !+IALCHEMISTCONTENT normalize trickier discriminator cases to type_key\n    if IIModelInterface.providedBy(discri):\n        discri = naming.type_key(\"table_schema_interface_name\", discri.__name__)\n    elif IInterface.providedBy(discri):\n        discri = naming.type_key(\"model_interface_name\", discri.__name__)\n    elif type(discri) is type and issubclass(discri, domain.Entity):\n        discri = naming.polymorphic_identity(discri)\n    elif isinstance(discri, domain.Entity):\n        discri = naming.polymorphic_identity(type(discri))\n    \n    if isinstance(discri, basestring):\n        getter = _get_by_type_key\n    #elif IInterface.providedBy(discri):\n    #    getter = _get_by_interface\n    #!+elif interfaces.IBungeniContent.implementedBy(discri):\n    #elif issubclass(discri, domain.Entity):\n    #    getter = _get_by_model\n    #!+elif interfaces.IBungeniContent.providedBy(discri):\n    #elif isinstance(discri, domain.Entity):\n    #    getter = _get_by_instance\n    elif IWorkflow.providedBy(discri):\n        getter = _get_by_workflow\n    elif IModelDescriptor.implementedBy(discri):\n        getter = _get_by_descriptor_model\n    \n    if getter is not None:\n        ti = getter(discri)\n        if ti is not None:\n            return ti\n        else:\n            m = \"No type registered for discriminator: %r\" % (discriminator)\n    else: \n        m = \"Invalid type info lookup discriminator: %r\" % (discriminator)\n    from bungeni.ui.utils import debug\n    log.debug(debug.interfaces(discriminator))\n    log.debug(m)\n    raise KeyError(m)\n\n\n# following getters return \"first matching\" TypeInfo instance in registry\n    \ndef _get_by_type_key(key):\n    for type_key, ti in _iter():\n        if type_key == key:\n            return ti\n#def _get_by_interface(iface):\n''' !+IALCHEMISTCONTENT fails on different interfaces with same name!\n(Pdb) ti.interface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) ti.interface.__bases__\n(<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>)\n(Pdb) iface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) iface.__bases__\n(<InterfaceClass zope.interface.Interface>,)\n'''\n#    for type_key, ti in _iter():\n#        if iface is ti.interface: #!+issubclass(iface, ti.interface)?\n#            return ti\ndef _get_by_model(model):\n    for type_key, ti in _iter():\n        if model is ti.domain_model: #!+issubclass(model, ti.domain_model)?\n            return ti\ndef _get_by_instance(instance):\n    return _get_by_model(type(instance))\ndef _get_by_workflow(wf):\n    for type_key, ti in _iter():\n        if wf is ti.workflow:\n            return ti\ndef _get_by_descriptor_model(descriptor_model):\n    for type_key, ti in _iter():\n        if descriptor_model is ti.descriptor_model:\n            return ti\n\n# \n\nclass TI(object):\n    \"\"\"TypeInfo, associates together the following attributes for a given type:\n            workflow_key \n                the workflow file name\n                defaults to the type_key for workflowed types that DO NOT specify\n                is None for non-workflowed types\n            workflow \n                same workflow insatnce may be used by multiple types\n                is None for non-workflowed types\n            interface\n                the manually applied application-dedicated model interface \n                (if any) for the type\n            derived_table_schema\n                auto-generated db schema interface, provides IIModelInterface\n            domain_model\n                the domain class\n            descriptor_model\n                the descriptor model for UI views for the type\n            container_class\n                container class for domain_model\n            container_interface\n                interface for the container class for domain_model\n    \"\"\"\n    def __init__(self, workflow_key, iface, domain_model=None):\n        self.workflow_key = workflow_key\n        self.interface = iface\n        self.derived_table_schema = None # provides IIModelInterface\n        self.workflow = None\n        self.domain_model = domain_model\n        self.descriptor_model = None\n        self.container_class = None\n        self.container_interface = None\n        self.custom = False # type loaded from custom configuration \n        # NOTE: only needed temporarily (until descriptor_model is set), \n        # then ti.custom not be inconsistent descriptor_model.scope i.e.\n        #if self.custom: assert self.descriptor_model.scope == \"custom\"\n        # !+ archetype_key?\n    def __str__(self):\n        return str(self.__dict__)\n    \n    @property\n    def scope(self):\n        # !+CUSTOM_TYPE_DESCRIPTOR the self.custom check below MUST precede the\n        # check on self.descriptor_model.scope as otherwise the \"in-transit\" \n        # custom types will not be picked up as custom types -- as during\n        # loading the descriptors for all custom types may not yet have been \n        # autogenerated (and would therefore correctly have \n        # descriptor_model.scope=\"custom\" set).\n        if self.custom:\n            return \"custom\"\n        if self.descriptor_model is not None:\n            return self.descriptor_model.scope\n    \n    @property\n    def permission_type_key(self):\n        if self.custom:\n            # custom types ALWAYS have a type_key-bound workflow instance - that\n            # may therefore have a different name than workflow_key e.g. Office\n            # uses the \"group\" workflow, that is type-relative reloaded as the\n            # \"office\" workflow instance.\n            return self.workflow.name\n        # system types ALWAYS use workflow_key - even if multiple types use the \n        # same workflow e.g. UserAddress & GroupAddress. \n        # if no workflow, compute type_key from domain_model\n        # #!+REDUNDANT(mb, 2012) This type key is already known during type\n        # setup i.e. TYPE_REGISTRY\n        return (self.workflow_key or \n            naming.type_key(\"model_name\", self.domain_model.__name__)\n        )\n\n'''\n!+TYPE_REGISTRY externalize further to bungeni_custom, currently:\n- association of type key and dedicated interface are hard-wired here\n- ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when \n  loading workflows and descriptors\n- type_key IS the underscore-separated lowercase of the domain cls name \n  i.e. utils.naming.polymorphic_identity(domain_model)\n- !+ ti.workflow_key SHOULD always be equal to type_key\n- !+ corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated\n- !+ dedicated interfaces for archetype incantations should be auto-generated, \n    from specific workflow name\/attr... e.g. via:\n    zope.interface.interface.InterfaceClass(iname, bases, __module__)\n- !+ should ti.interface be automatically generated also for system types?\n\nUsage:\n    from bungeni.capi import capi\n    capi.get_type_info(discriminator) -> TypeInfo\n    capi.iter_type_info() -> iterator of all registered (key, TypeInfo)\n'''\nTYPE_REGISTRY = [\n    # (key, ti)\n    # - the type key, unique for each type, is the underscore-separated \n    #   lowercase name of the domain_model (the domain class)\n    # - order is relevant (dictates workflow loading order)\n    \n    # feature \"support\" types, system types, required\n    \n    # workflowed\n    (\"user_address\", TI(\"address\", interfaces.IUserAddress)),\n    (\"group_address\", TI(\"address\", interfaces.IGroupAddress)),\n    # !+Attachment (mr, jul-2011)\n    # a) must be loaded before any other type that *may* support attachments!\n    # b) MUST support versions\n    (\"attachment\", TI(\"attachment\", interfaces.IAttachment)),\n    (\"event\", TI(\"event\", interfaces.IEvent)),\n    (\"sitting\", TI(\"sitting\", interfaces.ISitting)),\n    (\"heading\", TI(\"heading\", interfaces.IHeading)),\n    (\"user\", TI(\"user\", interfaces.IBungeniUser)),\n    (\"signatory\", TI(\"signatory\", interfaces.ISignatory)),\n    \n    # !+NAMING: member-related -> Group name + \"Member\" (no + \"ship\")\n    (\"group\", TI(\"group\", interfaces.IBungeniGroup)),\n    (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)),\n    (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n    (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n        # non-workflowed\n    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n    (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n    (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n    (\"title_type\", TI(None, interfaces.ITitleType)),\n    (\"member_title\", TI(None, interfaces.IMemberTitle)),\n    (\"change\", TI(None, interfaces.IChange)),\n    (\"doc\", TI(None, interfaces.IDoc)),\n    (\"doc_version\", TI(None, None)), #interfaces.IDocVersion)), #!+IVERSION\n    (\"attachment_version\", TI(None, None)), #interfaces.IAttachmentVersion)), #!+IVERSION\n    (\"venue\", TI(None, interfaces.IVenue)),\n    (\"session\", TI(None, interfaces.ISession)),\n    (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)),\n    (\"country\", TI(None, interfaces.ICountry)),\n    (\"item_schedule\", TI(None, interfaces.IItemSchedule)),\n    (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)),\n    (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)),\n    (\"editorial_note\", TI(None, interfaces.IEditorialNote)),\n    (\"sitting_report\", TI(None, interfaces.ISittingReport)),\n    (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)),\n    \n    # additional custom types are loaded dynamically from bungeni_custom\/types.xml\n]\n\n\n\n\n# register custom types\n\ndef register_new_custom_type(type_key, workflow_key, archetype_key):\n    \"\"\"Retrieve (create if needed) a domain interface and model for type_key,\n    and register as new entry on TYPE_REGISTER.\n    \"\"\"\n    \n    # generate custom domain interface\n    domain_iface_name = naming.model_interface_name(type_key)\n    try:\n        domain_iface = resolve(\"%s.%s\" % (INTERFACE_MODULE.__name__, domain_iface_name))\n        log.warn(\"Custom interface ALREADY EXISTS: %s\" % (domain_iface))\n    except ImportError:\n        domain_iface = new_custom_domain_interface(type_key, domain_iface_name)\n    \n    # generate custom domain_model\n    domain_model_name = naming.model_name(type_key)\n    try:\n        domain_model = resolve(\"%s.%s\" % (MODEL_MODULE.__name__, domain_model_name))\n        log.warn(\"Custom domain model ALREADY EXISTS: %s\" % (domain_model))\n    except ImportError:\n        domain_model = new_custom_domain_model(type_key, domain_iface, archetype_key)\n    \n    # type_info entry\n    ti = TI(workflow_key, domain_iface, domain_model)\n    ti.custom = True\n    TYPE_REGISTRY.append((type_key, ti))\n    \n    log.info(\"Registered custom type [%s]: %s\" % (archetype_key, type_key))\n    return type_key, ti\n\n\n\n\n\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py":{"changes":[{"diff":"\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self)","add":8,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py","badparts":["        return int(bc.oauth_auth_expiry_time)"],"goodparts":["        return int(bc.oauth_authorization_token_expiry_time)","    @cached_property.cachedIn(\"__oauth_hmac_key__\")","    @bungeni_custom_errors","    def oauth_hmac_key(self):","        \"\"\"String used to to generate nonces. KEEP SECRET.","        \"\"\"","        return bc.oauth_hmac_key"]}],"source":"\n \"\"\"Defines the accessor class for Bungeni Custom parameters. See bungeni.capi __init__.py for usage. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.capi\") import sys import time import os from zope.dottedname.resolve import resolve from zope.cachedescriptors import property as cached_property from bungeni.utils import error from bungeni.alchemist import type_info import bungeni_custom as bc class BungeniCustomError(Exception): \"\"\"A configuration error during loading of configuration. \"\"\" class BungeniCustomRuntimeError(BungeniCustomError): \"\"\"Internal error while executing a callable determined from configuration. \"\"\" def bungeni_custom_errors(f): \"\"\"Decorator to intercept any error raised by function f and re-raise it as a BungeniCustomError. To be used to decorate any function involved in reading\/validating\/processing any bungeni_custom parameters. \"\"\" return error.exceptions_as(BungeniCustomError)(f) def wrapped_callable(unwrapped): assert callable(unwrapped), unwrapped def wrapped(*args): log.debug(\"Calling %s with args: %s\" %(unwrapped, args)) try: return unwrapped(*args) except: exc=sys.exc_info()[1] log.debug(\"BungeniCustomRuntimeError[%r] in wrapped_callable: %s %s\", exc, wrapped, args) raise wrapped._unwrapped=unwrapped wrapped.__name__=unwrapped.__name__ return wrapped class CAPI(object): \"\"\"Accessor class for Bungeni Custom parameters. \"\"\" def __init__(self): self.validate_properties() def validate_properties(self): \"\"\"Validate this capi instance. Ensure valid setup of properties at instantiation of CAPI instance \"\"\" self.default_language self.country_code self.right_to_left_languages @property @bungeni_custom_errors def zope_i18n_allowed_languages(self): return tuple(bc.zope_i18n_allowed_languages.split()) @property @bungeni_custom_errors def zope_i18n_compile_mo_files(self): return bool( bc.zope_i18n_compile_mo_files is True or bc.zope_i18n_compile_mo_files==\"1\") @property @bungeni_custom_errors def country_code(self): \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this bungeni instance. \"\"\" return bc.country_code @property @bungeni_custom_errors def default_language(self): assert bc.default_language in self.zope_i18n_allowed_languages, \\ \"Default language[%s] not in allowed languages[%s]\" %( bc.default_language, self.zope_i18n_allowed_languages,) return bc.default_language @property @bungeni_custom_errors def right_to_left_languages(self): rtl_langs=tuple(bc.right_to_left_languages.split()) assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\ \"Right to left languages[%s] not in allowed languages[%s]\" %( bc.right_to_left_languages, self.zope_i18n_allowed_languages) return rtl_langs @property @bungeni_custom_errors def check_auto_reload_localization(self): \"\"\"() -> int minimum number of seconds to wait between checks for whether a localization file needs reloading; 0 means never check(deployment) \"\"\" int(bc.check_auto_reload_localization) return bc.check_auto_reload_localization @bungeni_custom_errors def get_workflow_condition(self, condition): condition_module=resolve(\"._conditions\", \"bungeni_custom.workflows\") condition=getattr(condition_module, condition) return wrapped_callable(condition) @bungeni_custom_errors def get_workflow_action(self, action): action_module=resolve(\"._actions\", \"bungeni_custom.workflows\") action=getattr(action_module, action) return wrapped_callable(action) @bungeni_custom_errors def get_form_constraint(self, constraint): constraint_module=resolve(\"._constraints\", \"bungeni_custom.forms\") constraint=getattr(constraint_module, constraint) return wrapped_callable(constraint) @bungeni_custom_errors def get_form_validator(self, validation): validator_module=resolve(\"._validations\", \"bungeni_custom.forms\") validator=getattr(validator_module, validation) return wrapped_callable(validator) @bungeni_custom_errors def get_form_derived(self, derived): derived_module=resolve(\"._derived\", \"bungeni_custom.forms\") derived_def=getattr(derived_module, derived) return wrapped_callable(derived_def) @property @bungeni_custom_errors def default_number_of_listing_items(self): \"\"\"This is the max number of items that are displayed in a listing by default. Returns an integer \"\"\" return int(bc.default_number_of_listing_items) @property @bungeni_custom_errors def long_text_column_listings_truncate_at(self): \"\"\"When listing text columns, only display first so many characters.\"\"\" return int(bc.long_text_column_listings_truncate_at) def xml_workspace_tabs_file(self): \"\"\"helper function used by workspace tab info APIs\"\"\" TABS_FILE=\"tabs.xml\" from lxml import etree ws_path=self.get_path_for(\"workspace\") file_path=os.path.join(ws_path, TABS_FILE) tabs=etree.fromstring(open(file_path).read()) return tabs @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\") @bungeni_custom_errors def workspace_tab_count_cache_refresh_time(self): \"\"\"The duration in seconds between tab count refresh operations\"\"\" tabs=self.xml_workspace_tabs_file() tabs_count_refresh=tabs.attrib[\"tab_count_cache_refresh_time\"] return int(tabs_count_refresh) @cached_property.cachedIn(\"__workspace_tabs__\") @bungeni_custom_errors def workspace_tabs(self): \"\"\"The tabs in the workspace\"\"\" ws_tabs=[] tabs=self.xml_workspace_tabs_file() for tab in tabs.iterchildren(tag=\"tab\"): ws_tabs.append(tab.attrib[\"id\"]) return ws_tabs @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\") @bungeni_custom_errors def oauth_access_token_expiry_time(self): \"\"\"time in seconds before an access token expires\"\"\" return(bc.oauth_access_token_expiry_time) @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\") @bungeni_custom_errors def oauth_authorization_token_expiry_time(self): \"\"\"time in seconds before an oauth authorization code expires max recommended time is 10min \"\"\" return int(bc.oauth_auth_expiry_time) def get_root_path(self): \"\"\"Get absolute physical path location for currently active bungeni_custom package folder. \"\"\" return os.path.dirname(os.path.abspath(bc.__file__)) def get_path_for(self, *path_components): \"\"\"Get absolute path, under bungeni_custom, for path_components. \"\"\" return os.path.join(*(self.get_root_path(),)+path_components) def put_env(self, key): \"\"\"Set capi value for{key} as the environment variable{key} i.e. use to set os.environ[key]. Wrapper on os.put_env(key, string_value) --to take care of the value string-casting required by os.put_env while still allowing the liberty of data-typing values of capi attributes as needed. \"\"\" value=getattr(self, key) try: os.environ[key]=value except TypeError: try: os.environ[key]=\" \".join(value) except TypeError: os.environ[key]=repr(value) assert eval(os.environ[key])==value _is_modified_since_last_times={} def is_modified_since(self, abspath, modified_on_first_check=True): \"\"\"(abspath:str, modified_on_first_check:bool) -> bool Checks file path st_mtime to see if file has been modified since last check. Updates entry per path, with last(check, modified) times. \"\"\" check_auto_reload_localization=self.check_auto_reload_localization now=time.time() last_checked, old_last_modified=\\ self._is_modified_since_last_times.get(abspath) or(0, 0) if not check_auto_reload_localization: if last_checked or not modified_on_first_check: return False if not now-last_checked > check_auto_reload_localization: return False last_modified=os.stat(abspath).st_mtime self._is_modified_since_last_times[abspath]=(now, last_modified) if not last_checked: return modified_on_first_check return(old_last_modified < last_modified) def get_type_info(self, discriminator): \"\"\"Get the TypeInfo instance for discriminator(see core.type_info). The discriminator may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: implements IBungeniContent domain model instance: type provides IBungeniContent descriptor_model: implements IModelDescriptor Raise KeyError if no entry matched. \"\"\" return type_info._get(discriminator) def iter_type_info(self, scope=None): \"\"\"Return iterator on all registered(key, TypeInfo) entries. scope:either(None, \"system\", \"archetype\", \"custom\") \"\"\" for type_key, ti in type_info._iter(): if(scope is None or ti.scope==scope): yield type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Defines the accessor class for Bungeni Custom parameters.\n\nSee bungeni.capi __init__.py for usage.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.capi\")\n\nimport sys\nimport time\nimport os\nfrom zope.dottedname.resolve import resolve\nfrom zope.cachedescriptors import property as cached_property\nfrom bungeni.utils import error\nfrom bungeni.alchemist import type_info\nimport bungeni_custom as bc\n\n\n# utils \n\nclass BungeniCustomError(Exception):\n    \"\"\"A configuration error during loading of configuration.\n    \"\"\"\nclass BungeniCustomRuntimeError(BungeniCustomError): \n    \"\"\"Internal error while executing a callable determined from configuration.\n    \"\"\" \n\ndef bungeni_custom_errors(f):\n    \"\"\"Decorator to intercept any error raised by function f and re-raise it\n    as a BungeniCustomError. To be used to decorate any function involved \n    in reading\/validating\/processing any bungeni_custom parameters. \n    \"\"\"\n    return error.exceptions_as(BungeniCustomError)(f)\n\n\ndef wrapped_callable(unwrapped):\n    assert callable(unwrapped), unwrapped\n    def wrapped(*args):\n        log.debug(\"Calling %s with args: %s\" % (unwrapped, args))\n        try:\n            return unwrapped(*args)\n        except:\n            # intercept exc, to re-raise it *unchanged*, only for debugging\n            # e.g. constraints raise numerous (expected?) NoInputData errors\n            exc = sys.exc_info()[1]\n            log.debug(\"BungeniCustomRuntimeError [%r] in wrapped_callable: %s %s\",\n                    exc, wrapped, args)\n            raise\n    # remember original unwrapped callable\n    wrapped._unwrapped = unwrapped\n    wrapped.__name__ = unwrapped.__name__\n    return wrapped\n\n\n# capi (singleton)\n\nclass CAPI(object):\n    \"\"\"Accessor class for Bungeni Custom parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.validate_properties()\n    \n    def validate_properties(self):\n        \"\"\"Validate this capi instance.\n        Ensure valid setup of properties at instantiation of CAPI instance\n        \"\"\"\n        self.default_language\n        self.country_code\n        self.right_to_left_languages\n        \n    # bungeni_custom parameter properties\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_allowed_languages(self):\n        # NOTE: zope.i18n.config.ALLOWED_LANGUAGES expects the value of the \n        # env variable for this to be a COMMA or SPACE separated STRING\n        return tuple(bc.zope_i18n_allowed_languages.split())\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_compile_mo_files(self):\n        return bool(\n            bc.zope_i18n_compile_mo_files is True or \n            bc.zope_i18n_compile_mo_files == \"1\")\n   \n    @property\n    @bungeni_custom_errors\n    def country_code(self):\n        \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this \n        bungeni instance.\n        \"\"\"\n        return bc.country_code\n\n    @property\n    @bungeni_custom_errors\n    def default_language(self):\n        assert bc.default_language in self.zope_i18n_allowed_languages, \\\n            \"Default language [%s] not in allowed languages [%s]\" % (\n                bc.default_language, self.zope_i18n_allowed_languages,)\n        return bc.default_language\n        \n    @property\n    @bungeni_custom_errors\n    def right_to_left_languages(self):\n        rtl_langs = tuple(bc.right_to_left_languages.split())\n        assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\\n            \"Right to left languages [%s] not in allowed languages [%s]\" % (\n                bc.right_to_left_languages, self.zope_i18n_allowed_languages)\n        return rtl_langs\n    \n    @property\n    @bungeni_custom_errors\n    def check_auto_reload_localization(self):\n        \"\"\" () -> int\n        minimum number of seconds to wait between checks for whether a \n        localization file needs reloading; 0 means never check (deployment)\n        \"\"\"\n        int(bc.check_auto_reload_localization) # TypeError if not an int\n        return bc.check_auto_reload_localization\n    \n    \n    @bungeni_custom_errors\n    def get_workflow_condition(self, condition):\n        condition_module = resolve(\"._conditions\", \"bungeni_custom.workflows\")\n        condition = getattr(condition_module, condition) # raises AttributeError\n        return wrapped_callable(condition)\n    \n    @bungeni_custom_errors\n    def get_workflow_action(self, action):\n        action_module = resolve(\"._actions\", \"bungeni_custom.workflows\")\n        action = getattr(action_module, action) # raises AttributeError\n        return wrapped_callable(action)\n    \n    @bungeni_custom_errors\n    def get_form_constraint(self, constraint):\n        constraint_module = resolve(\"._constraints\", \"bungeni_custom.forms\")\n        constraint = getattr(constraint_module, constraint) # raises AttributeError\n        return wrapped_callable(constraint)\n    \n    @bungeni_custom_errors\n    def get_form_validator(self, validation):\n        validator_module = resolve(\"._validations\", \"bungeni_custom.forms\")\n        validator = getattr(validator_module, validation) # raises AttributeError\n        return wrapped_callable(validator)\n    \n    @bungeni_custom_errors\n    def get_form_derived(self, derived):\n        derived_module = resolve(\"._derived\", \"bungeni_custom.forms\")\n        derived_def = getattr(derived_module, derived) # raises AttributeError\n        return wrapped_callable(derived_def)\n    \n    \n    @property\n    @bungeni_custom_errors\n    def default_number_of_listing_items(self):\n        \"\"\"This is the max number of items that are displayed in a listing by\n        default. Returns an integer\n        \"\"\"\n        return int(bc.default_number_of_listing_items)\n    \n    @property\n    @bungeni_custom_errors\n    def long_text_column_listings_truncate_at(self):\n        \"\"\"When listing text columns, only display first so many characters.\"\"\"\n        return int(bc.long_text_column_listings_truncate_at)\n    \n    def xml_workspace_tabs_file(self):\n        \"\"\"helper function used by workspace tab info APIs\"\"\"\n        TABS_FILE = \"tabs.xml\"    \n        from lxml import etree\n        ws_path = self.get_path_for(\"workspace\")\n        file_path = os.path.join(ws_path, TABS_FILE)\n        tabs = etree.fromstring(open(file_path).read()) \n        return tabs                \n    \n    @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\")\n    @bungeni_custom_errors\n    def workspace_tab_count_cache_refresh_time(self):\n        \"\"\"The duration in seconds between tab count refresh operations\"\"\"\n        tabs = self.xml_workspace_tabs_file()\n        tabs_count_refresh = tabs.attrib[\"tab_count_cache_refresh_time\"]\n        return int(tabs_count_refresh)\n    \n    @cached_property.cachedIn(\"__workspace_tabs__\")\n    @bungeni_custom_errors\n    def workspace_tabs(self):\n        \"\"\"The tabs in the workspace\"\"\"\n        ws_tabs = []\n        tabs = self.xml_workspace_tabs_file()\n        for tab in tabs.iterchildren(tag=\"tab\"):\n            ws_tabs.append(tab.attrib[\"id\"])\n        return ws_tabs    \n\n    @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_access_token_expiry_time(self):\n        \"\"\"time in seconds before an access token expires\"\"\"\n        return (bc.oauth_access_token_expiry_time)\n\n    @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_authorization_token_expiry_time(self):\n        \"\"\"time in seconds before an oauth authorization code expires\n        max recommended time is 10min\n        \"\"\"\n        return int(bc.oauth_auth_expiry_time)\n    # utility methods\n    \n    def get_root_path(self):\n        \"\"\"Get absolute physical path location for currently active \n        bungeni_custom package folder.\n        \"\"\"\n        return os.path.dirname(os.path.abspath(bc.__file__)) \n    \n    def get_path_for(self, *path_components):\n        \"\"\"Get absolute path, under bungeni_custom, for path_components.\n        \"\"\"\n        return os.path.join(*(self.get_root_path(),)+path_components)\n    \n    def put_env(self, key):\n        \"\"\"Set capi value for {key} as the environment variable {key}\n        i.e. use to set os.environ[key].\n        \n        Wrapper on os.put_env(key, string_value) -- to take care of\n        the value string-casting required by os.put_env while still \n        allowing the liberty of data-typing values of capi attributes \n        as needed.\n        \"\"\"\n        value = getattr(self, key)\n        try:\n            os.environ[key] = value\n            # OK, value is a string... done.\n        except TypeError:\n            # putenv() argument 2 must be string, not <...>\n            # i.e. value is NOT a string... try string-casting:\n            try:\n                # some zope code expects sequences to be specified as a \n                # COMMA or SPACE separated STRING, so we first try the value \n                # as a sequence, and serialize it to an environment variable \n                # value as expected by zope\n                os.environ[key] = \" \".join(value)\n            except TypeError:\n                # not a sequence, just fallback on repr(value)\n                os.environ[key] = repr(value)\n                # ensure that the original object value defines a __repr__ \n                # that can correctly re-instantiate the original object\n                assert eval(os.environ[key]) == value\n    \n    _is_modified_since_last_times = {} # {path: (last_checked, last_modified)}\n    def is_modified_since(self, abspath, modified_on_first_check=True):\n        \"\"\" (abspath:str, modified_on_first_check:bool) -> bool\n        Checks file path st_mtime to see if file has been modified since last \n        check. Updates entry per path, with last (check, modified) times.\n        \"\"\"\n        check_auto_reload_localization = self.check_auto_reload_localization\n        now = time.time()\n        last_checked, old_last_modified = \\\n            self._is_modified_since_last_times.get(abspath) or (0, 0)\n        if not check_auto_reload_localization:\n            # 0 =>> never check (unless this is the first check...)\n            if last_checked or not modified_on_first_check:\n                return False\n        if not now-last_checked > check_auto_reload_localization:\n            # last check too recent, avoid doing os.stat\n            return False\n        last_modified = os.stat(abspath).st_mtime\n        self._is_modified_since_last_times[abspath] = (now, last_modified)\n        if not last_checked:\n            # last_checked==0, this is the first check\n            return modified_on_first_check\n        return (old_last_modified < last_modified)\n    \n    # type registry\n    \n    def get_type_info(self, discriminator):\n        \"\"\"Get the TypeInfo instance for discriminator (see core.type_info). \n        \n        The discriminator may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: implements IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor_model: implements IModelDescriptor\n        \n        Raise KeyError if no entry matched.\n        \"\"\"\n        return type_info._get(discriminator)\n    \n    def iter_type_info(self, scope=None):\n        \"\"\"Return iterator on all registered (key, TypeInfo) entries.\n        scope:either(None, \"system\", \"archetype\", \"custom\")\n        \"\"\"\n        for type_key, ti in type_info._iter():\n            if (scope is None or ti.scope == scope):\n                yield type_key, ti\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py":{"changes":[{"diff":"\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"","add":2,"remove":2,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py","badparts":["        api[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])"],"goodparts":["        admin[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, admin[u\"applications\""]}],"source":"\n \"\"\"The Bungeni Application $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.core.app\") from zope.interface import implements from zope.interface import implementedBy from zope import component from zope.interface.declarations import alsoProvides from zope.app.appsetup.appsetup import getConfigContext from zope.app.component import site from zope.location.interfaces import ILocation from ore.wsgiapp.app import Application from ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent from bungeni.models import domain from bungeni.models import interfaces as model_interfaces from bungeni.models.utils import get_current_parliament from bungeni.models.utils import container_getter from bungeni.core import interfaces from bungeni.core import location from bungeni.core.content import(Section, AdminSection, AkomaNtosoSection, WorkspaceSection, APISection, OAuthSection) from bungeni.core.content import QueryContent from bungeni.core.i18n import _ from bungeni.core.workspace import(WorkspaceContainer, WorkspaceUnderConsiderationContainer, WorkspaceTrackedDocumentsContainer, WorkspaceGroupsContainer, WorkspaceSchedulableContainer, load_workspaces) from bungeni.core.notifications import load_notifications from bungeni.core.emailnotifications import load_email from bungeni.core.serialize import serialization_notifications from bungeni.ui.utils import url, common from bungeni.capi import capi from bungeni.utils import register @register.handler( (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent)) def on_wsgi_application_created_event(application, event): \"\"\"Additional setup on IWSGIApplicationCreatedEvent. \"\"\" log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) for type_key, ti in capi.iter_type_info(): if ti.workflow: ti.workflow.validate_permissions_roles() import bungeni.core.workflows.events load_workspaces() load_notifications() load_email() serialization_notifications() import bungeni.core.events app_setup=model_interfaces.IBungeniSetup(application) app_setup.setUp() try: import bungeni.utils.xmlconfexport as confexp confexp.write_all() except: log.debug((\"on_wsgi_application_created:\" \"error while exporting config parameters to xml\")) log.debug(\"on_wsgi_application_created_event: _features: %s\" %( getConfigContext()._features)) def to_locatable_container(domain_class, *domain_containers): component.provideAdapter(location.ContainerLocation(*domain_containers), (implementedBy(domain_class), ILocation)) class BungeniApp(Application): implements(model_interfaces.IBungeniApplication) class AppSetup(object): implements(model_interfaces.IBungeniSetup) def __init__(self, application): self.context=application def setUp(self): from zope.configuration import xmlconfig xmlconfig.string(\"\"\" <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\" xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\"> <include package=\"zope.i18n\" file=\"meta.zcml\" \/> <i18n:registerTranslations directory=\"%s\" \/> <\/configure> \"\"\" %(capi.get_path_for(\"translations\", \"bungeni\"))) import index index.setupFieldDefinitions(index.indexer) sm=site.LocalSiteManager(self.context) self.context.setSiteManager(sm) from bungeni.core import language from bungeni.ui import z3evoque z3evoque.set_get_gettext() z3evoque.setup_evoque() z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\")) z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL) z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name) z3evoque.domain.set_on_globals(\"get_base_direction\", language.get_base_direction) z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl) self.context[\"bungeni\"]=AkomaNtosoSection( title=_(u\"Bungeni\"), description=_(u\"Current parliamentary activity\"), default_name=\"bung\", ) workspace=self.context[\"workspace\"]=WorkspaceSection( title=_(\"section_workspace\", default=u\"Workspace\"), description=_(u\"Current parliamentary activity\"), default_name=\"my-documents\", ) alsoProvides(workspace, interfaces.ISearchableSection) workspace[\"my-documents\"]=WorkspaceSection( title=_(\"section_workspace_documents\", default=u\"my documents\"), description=_(u\"my documents workspace section\"), default_name=\"inbox\", marker=interfaces.IWorkspaceDocuments, ) for tab in capi.workspace_tabs: workspace[\"my-documents\"][tab]=WorkspaceContainer( tab_type=tab, title=_(\"section_workspace_%s\" % tab, default=tab), marker=interfaces.IWorkspaceTab ) ws_uc=workspace[\"under-consideration\"]=WorkspaceSection( title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), default_name=\"documents\", marker=interfaces.IWorkspaceUnderConsideration) ws_uc[\"documents\"]=WorkspaceUnderConsiderationContainer( name=\"documents\", title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), marker=interfaces.IWorkspaceTrackedDocuments) ws_uc[\"tracked-documents\"]=WorkspaceTrackedDocumentsContainer( name=\"tracked documents\", title=_(u\"tracked documents\"), description=_(u\"tracked documents\")) ws_sched=workspace[\"scheduling\"]=Section( title=_(\"section_scheduling\", default=u\"Scheduling\"), description=_(u\"Workspace Scheduling\"), default_name=\"index\", marker=interfaces.IWorkspaceScheduling) ws_sched[\"committees\"]=QueryContent( container_getter(get_current_parliament, \"committees\"), title=_(\"section_scheduling_committees\", default=u\"Committees\"), description=_(u\"Committee schedules\")) ws_sched[\"documents\"]=WorkspaceSchedulableContainer( name=_(u\"schedulable items\"), title=_(u\"schedulable items\"), description=_(u\"documents available for scheduling\")) ws_sched[\"sittings\"]=QueryContent( container_getter(get_current_parliament, \"sittings\"), title=_(\"section_scheduling_sittings\", default=u\"Sittings\"), description=_(u\"Plenary Sittings\")) ws_sched[\"agendaitems\"]=QueryContent( container_getter(get_current_parliament, \"agendaitems\"), title=_(\"section_scheduling_agenda_items\", default=u\"Agenda items\"), description=_(u\"Manage agenda items\")) workspace[\"groups\"]=WorkspaceSection( title=_(\"section_groups\", default=u\"Groups\"), description=_(u\"Bungeni Groups\"), default_name=\"my-groups\", marker=interfaces.IWorkspaceGroups) workspace[\"groups\"][\"my-groups\"]=WorkspaceGroupsContainer( name=\"my-groups\", title=_(u\"My Groups\"), description=_(u\"Groups that the user is a member of\")) for key, info in capi.iter_type_info(): if model_interfaces.IScheduleContent.implementedBy(info.domain_model): container_name=\"%ss\" % key container=\"%sContainer\" % info.domain_model.__name__ ws_sched[container_name]=getattr(domain, container)() to_locatable_container(info.domain_model, ws_sched[container_name]) admin=self.context[\"admin\"]=AdminSection( title=_(u\"Administration\"), description=_(u\"Manage bungeni settings\"), default_name=\"admin-index\", marker=model_interfaces.IBungeniAdmin) alsoProvides(admin, interfaces.ISearchableSection) content=admin[\"content\"]=Section( title=_(u\"Content\"), description=_(u\"browse bungeni content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"browse-admin\") admin[\"email-settings\"]=Section( title=_(u\"email settings\"), description=_(u\"manage email settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"email-settings\") admin[\"xapian-settings\"]=Section( title=_(u\"search index settings\"), description=_(u\"manage search index settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"xapian-settings\") admin[\"registry-settings\"]=Section( title=_(u\"registry settings\"), description=_(u\"manage registry settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"registry-settings\") admin[\"serialization-manager\"]=Section( title=_(u\"serialization manager\"), description=_(u\"batch serialization of content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"serialization-manager\") content[u\"parliaments\"]=domain.ParliamentContainer() to_locatable_container(domain.Parliament, content[u\"parliaments\"]) content[u\"users\"]=domain.UserContainer() to_locatable_container(domain.User, content[u\"users\"]) api=self.context[\"api\"]=APISection( title=_(u\"Bungeni API\"), description=_(u\"Bungeni REST API\"), default_name=\"index.html\", ) api[\"oauth\"]=OAuthSection( title=_(u\"Bungeni OAuth API\"), description=_(u\"Bungeni OAuth API\"), default_name=\"index.html\", ) api[u\"applications\"]=domain.OAuthApplicationContainer() to_locatable_container(domain.OAuthApplication, api[u\"applications\"]) ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"The Bungeni Application \n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.core.app\")\n\nfrom zope.interface import implements\nfrom zope.interface import implementedBy\nfrom zope import component\nfrom zope.interface.declarations import alsoProvides\n\nfrom zope.app.appsetup.appsetup import getConfigContext\nfrom zope.app.component import site\nfrom zope.location.interfaces import ILocation\n\nfrom ore.wsgiapp.app import Application\nfrom ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent\n\nfrom bungeni.models import domain\nfrom bungeni.models import interfaces as model_interfaces\nfrom bungeni.models.utils import get_current_parliament\nfrom bungeni.models.utils import container_getter\n\nfrom bungeni.core import interfaces\nfrom bungeni.core import location\nfrom bungeni.core.content import (Section, AdminSection, AkomaNtosoSection,\n    WorkspaceSection, APISection, OAuthSection)\nfrom bungeni.core.content import QueryContent\nfrom bungeni.core.i18n import _\nfrom bungeni.core.workspace import (WorkspaceContainer,\n    WorkspaceUnderConsiderationContainer,\n    WorkspaceTrackedDocumentsContainer,\n    WorkspaceGroupsContainer,\n    WorkspaceSchedulableContainer,\n    load_workspaces)\nfrom bungeni.core.notifications import load_notifications\nfrom bungeni.core.emailnotifications import load_email\nfrom bungeni.core.serialize import serialization_notifications\nfrom bungeni.ui.utils import url, common # !+ core dependency on ui\nfrom bungeni.capi import capi\nfrom bungeni.utils import register\n\n\n\n@register.handler(\n    (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent))\ndef on_wsgi_application_created_event(application, event):\n    \"\"\"Additional setup on IWSGIApplicationCreatedEvent.\n    \"\"\"\n    # !+ui.app.on_wsgi_application_created_event ALWAYS gets called prior to this\n    log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) \n    \n    # additional workflow validation\n    for type_key, ti in capi.iter_type_info():\n        if ti.workflow:\n            ti.workflow.validate_permissions_roles()\n    \n    # import events module, registering handlers\n    import bungeni.core.workflows.events\n    \n    # load workspaces\n    load_workspaces()\n    \n    # load notifications\n    load_notifications()\n\n    # load email notifications\n    load_email()\n\n    # set up serialization notifications\n    serialization_notifications()\n    \n    # import events modules, registering handlers\n    import bungeni.core.events\n    \n    app_setup = model_interfaces.IBungeniSetup(application)\n    app_setup.setUp()\n    \n    # write configuration parameters to xml\n    try:\n        import bungeni.utils.xmlconfexport as confexp\n        confexp.write_all()\n    except:\n        log.debug((\"on_wsgi_application_created :\"\n            \"error while exporting config parameters to xml\"))\n    \n    log.debug(\"on_wsgi_application_created_event: _features: %s\" % (\n        getConfigContext()._features))\n\n\ndef to_locatable_container(domain_class, *domain_containers):\n    component.provideAdapter(location.ContainerLocation(*domain_containers),\n               (implementedBy(domain_class), ILocation))\n\n\nclass BungeniApp(Application):\n    implements(model_interfaces.IBungeniApplication)\n\nclass AppSetup(object):\n    \n    implements(model_interfaces.IBungeniSetup)\n    \n    def __init__(self, application):\n        self.context = application\n    \n    def setUp(self):\n        \n        # register translations\n        #import zope.i18n.zcml\n        #zope.i18n.zcml.registerTranslations(getConfigContext(),\n        #    capi.get_path_for(\"translations\", \"bungeni\"))\n        # !+ZCML_PYTHON(mr, apr-2011) above registerTranslations() in python \n        # does not work, as subsequent utility lookup fails. We workaround it \n        # by executing the following parametrized bit of ZCML:\n        from zope.configuration import xmlconfig\n        xmlconfig.string(\"\"\"\n            <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\"\n                xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\">\n                <include package=\"zope.i18n\" file=\"meta.zcml\" \/>\n                <i18n:registerTranslations directory=\"%s\" \/>\n            <\/configure>\n            \"\"\" % (capi.get_path_for(\"translations\", \"bungeni\")))\n        \n        # ensure indexing facilities are setup(lazy)\n        import index\n        index.setupFieldDefinitions(index.indexer)\n        \n        sm = site.LocalSiteManager(self.context)\n        self.context.setSiteManager(sm)\n        \n        from bungeni.core import language\n        from bungeni.ui import z3evoque\n        z3evoque.set_get_gettext()\n        z3evoque.setup_evoque()\n        z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\"))\n        z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL)\n        z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name)\n        z3evoque.domain.set_on_globals(\"get_base_direction\", \n            language.get_base_direction)\n        z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl)          \n        \n        # !+ where is the view name for the app root (slash) set?\n        \n        # CONVENTION: the action of each site top-section is made to point \n        # directly the primary sub-section (the INDEX) that it contains.\n        # EXCEPTION: the \"\/\", when logged in, is redirected to \"\/workspace\/pi\"\n        \n        self.context[\"bungeni\"] = AkomaNtosoSection(\n            title=_(u\"Bungeni\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"bung\", # !+NAMING(mr, jul-2011) bung?!?\n        )\n        \n        # top-level sections\n        workspace = self.context[\"workspace\"] = WorkspaceSection(\n            title=_(\"section_workspace\", default=u\"Workspace\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"my-documents\",\n        )\n        alsoProvides(workspace, interfaces.ISearchableSection)\n        \n        workspace[\"my-documents\"] = WorkspaceSection(\n            title=_(\"section_workspace_documents\", default=u\"my documents\"),\n            description=_(u\"my documents workspace section\"),\n            default_name=\"inbox\",\n            marker=interfaces.IWorkspaceDocuments,\n        )\n        \n        for tab in capi.workspace_tabs:\n            workspace[\"my-documents\"][tab] = WorkspaceContainer(\n                tab_type=tab,\n                title=_(\"section_workspace_%s\" % tab, default=tab),\n                marker=interfaces.IWorkspaceTab\n            )\n\n        ws_uc = workspace[\"under-consideration\"] = WorkspaceSection(\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            default_name=\"documents\",\n            marker=interfaces.IWorkspaceUnderConsideration)\n        ws_uc[\"documents\"] = WorkspaceUnderConsiderationContainer(\n            name=\"documents\",\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            marker=interfaces.IWorkspaceTrackedDocuments)\n        ws_uc[\"tracked-documents\"] = WorkspaceTrackedDocumentsContainer(\n            name=\"tracked documents\",\n            title=_(u\"tracked documents\"),\n            description=_(u\"tracked documents\"))\n        \n        ws_sched = workspace[\"scheduling\"] = Section(\n            title=_(\"section_scheduling\", default=u\"Scheduling\"),\n            description=_(u\"Workspace Scheduling\"),\n            default_name=\"index\",\n            marker=interfaces.IWorkspaceScheduling)\n        ws_sched[\"committees\"] = QueryContent(\n            container_getter(get_current_parliament, \"committees\"),\n            title=_(\"section_scheduling_committees\", default=u\"Committees\"),\n            #!+marker=interfaces.ICommitteeAddContext,\n            description=_(u\"Committee schedules\"))\n        ws_sched[\"documents\"] = WorkspaceSchedulableContainer(\n            name=_(u\"schedulable items\"),\n            title=_(u\"schedulable items\"),\n            description=_(u\"documents available for scheduling\"))\n        ws_sched[\"sittings\"] = QueryContent(\n            container_getter(get_current_parliament, \"sittings\"),\n            title=_(\"section_scheduling_sittings\", default=u\"Sittings\"),\n            description=_(u\"Plenary Sittings\"))\n        ws_sched[\"agendaitems\"] = QueryContent(\n            container_getter(get_current_parliament, \"agendaitems\"),\n            title=_(\"section_scheduling_agenda_items\", \n                default=u\"Agenda items\"),\n            #marker=interfaces.IAgendaItemAddContext,\n            description=_(u\"Manage agenda items\"))\n        \n        workspace[\"groups\"] = WorkspaceSection(\n            title=_(\"section_groups\", default=u\"Groups\"),\n            description=_(u\"Bungeni Groups\"),\n            default_name=\"my-groups\",\n            marker=interfaces.IWorkspaceGroups)\n        workspace[\"groups\"][\"my-groups\"] = WorkspaceGroupsContainer(\n            name=\"my-groups\",\n            title=_(u\"My Groups\"),\n            description=_(u\"Groups that the user is a member of\"))\n        \n        #!+TIMING\n        #!+AUTO CONTAINERS SCHEDULING(mb, April-2012)\n        # type_info missing container name\n        for key, info in capi.iter_type_info():\n            if model_interfaces.IScheduleContent.implementedBy(info.domain_model):\n                container_name = \"%ss\" % key\n                container = \"%sContainer\" % info.domain_model.__name__\n                ws_sched[container_name] = getattr(domain, container)()\n                to_locatable_container(info.domain_model, ws_sched[container_name])\n        \n        \n        ##########\n        # Admin User Interface\n        # Administration section\n        \n        #!+SECURITY(miano. nov-2010) Admin section now uses AdminSection\n        # container that is identical to Section, only difference is that\n        # traversing though it requires zope.ManageSite permission as defined\n        # in core\/configure.zcml\n        \n        admin = self.context[\"admin\"] = AdminSection(\n            title=_(u\"Administration\"),\n            description=_(u\"Manage bungeni settings\"),\n            default_name=\"admin-index\",\n            marker=model_interfaces.IBungeniAdmin)\n        alsoProvides(admin, interfaces.ISearchableSection)\n        \n        content = admin[\"content\"] = Section(\n            title=_(u\"Content\"),\n            description=_(u\"browse bungeni content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"browse-admin\")\n        \n        admin[\"email-settings\"] = Section(\n            title=_(u\"email settings\"),\n            description=_(u\"manage email settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"email-settings\")\n        \n        admin[\"xapian-settings\"] = Section(\n            title=_(u\"search index settings\"),\n            description=_(u\"manage search index settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"xapian-settings\")\n        \n        admin[\"registry-settings\"] = Section(\n            title=_(u\"registry settings\"),\n            description=_(u\"manage registry settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"registry-settings\")\n        \n        admin[\"serialization-manager\"] = Section(\n            title=_(u\"serialization manager\"),\n            description=_(u\"batch serialization of content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"serialization-manager\")\n        \n        content[u\"parliaments\"] = domain.ParliamentContainer()\n        to_locatable_container(domain.Parliament, content[u\"parliaments\"])\n        \n        content[u\"users\"] = domain.UserContainer()\n        to_locatable_container(domain.User, content[u\"users\"])\n\n        api = self.context[\"api\"] = APISection(\n            title=_(u\"Bungeni API\"),\n            description=_(u\"Bungeni REST API\"),\n            default_name=\"index.html\",\n        )\n        api[\"oauth\"] = OAuthSection(\n            title=_(u\"Bungeni OAuth API\"),\n            description=_(u\"Bungeni OAuth API\"),\n            default_name=\"index.html\",\n        )\n        api[u\"applications\"] = domain.OAuthApplicationContainer()\n        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n"}},"msg":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings."}},"https:\/\/github.com\/ferrumiii\/bungeni-portal":{"fdcd90bde5dd5efb4ff894413df30b18768381e4":{"url":"https:\/\/api.github.com\/repos\/ferrumiii\/bungeni-portal\/commits\/fdcd90bde5dd5efb4ff894413df30b18768381e4","html_url":"https:\/\/github.com\/ferrumiii\/bungeni-portal\/commit\/fdcd90bde5dd5efb4ff894413df30b18768381e4","message":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings.","sha":"fdcd90bde5dd5efb4ff894413df30b18768381e4","keyword":"replay attack improve","diff":"diff --git a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\nindex 44ae077ff..2d6b1645d 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n@@ -254,7 +254,7 @@ def permission_type_key(self):\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\nindex e328f6c85..96e0dc6f0 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n@@ -209,7 +209,14 @@ def oauth_authorization_token_expiry_time(self):\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self):\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\nindex 7435b4a3a..28e02aebf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n@@ -300,5 +300,5 @@ def setUp(self):\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"])\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\nindex 4ac3db531..8610d7e73 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n@@ -573,4 +573,11 @@ def title(self):\n         context = _merged(self.context)\n         return component.getUtility(IRole, context.role_id).title\n \n+@register.adapter()\n+class OAuthApplicationDescriptiveProperties(DescriptiveProperties):\n+    component.adapts(interfaces.IOAuthApplication)\n \n+    @property\n+    def title(self):\n+        context = _merged(self.context)\n+        return context.name\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\nindex e747ae61c..7122485b2 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n@@ -578,6 +578,9 @@ class IDebateTake(interface.Interface):\n class IOAuthApplication(interface.Interface):\n     \"\"\"Marker interface for an OAuth Application record\"\"\"\n \n+class IOAuthApplicationContainer(IAlchemistContainer):\n+    \"\"\"Marker interface for an OAuth Applications container\"\"\"\n+\n class IOAuthAuthorization(interface.Interface):\n     \"\"\"Marker interfeace for OAuth authorizations\"\"\"\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\nindex e34a41ef8..3900cbd92 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n@@ -163,8 +163,13 @@\n   <permission id=\"bungeni.debate_takes.View\" title=\"View debate takes\" \/>\n   <permission id=\"bungeni.debate_takes.Edit\" title=\"Edit debate takes\" \/>\n \n-  <permission id=\"bungeni.oauth_application.View\" title=\"View oauth app\" \/>\n-  <permission id=\"bungeni.oauth_application.Delete\" title=\"Delete oauth app\" \/>\n-  <meta:redefinePermission from=\"bungeni.oauth_application.View\" to=\"zope.ManageContent\" \/>\n+  <permission id=\"bungeni.o_auth_application.View\" title=\"View oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Add\" title=\"Add oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Edit\" title=\"Edit oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Delete\" title=\"Delete oauth app\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.View\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Add\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Edit\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Delete\" to=\"zope.ManageContent\" \/>\n   <permission id=\"bungeni.oauth.View\" title=\"Use oauth api\" \/>\n <\/configure>\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\nindex 128a2c535..f1d0ed492 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n@@ -1185,7 +1185,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"identifier\", rdb.UnicodeText, nullable=False, \n         unique=True),\n     rdb.Column(\"name\", rdb.UnicodeText, nullable=False),\n-    rdb.Column(\"secret\", rdb.String(32), nullable=False),\n+    rdb.Column(\"secret\", rdb.String(100), nullable=False),\n     rdb.Column(\"redirection_endpoint\", rdb.UnicodeText, nullable=False)\n )\n \n@@ -1195,7 +1195,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n         nullable=False),\n     rdb.Column(\"application_id\", rdb.Integer,\n         rdb.ForeignKey(\"oauth_application.application_id\"), nullable=False),\n-    rdb.Column(\"authorization_code\", rdb.String(32), nullable=False),\n+    rdb.Column(\"authorization_code\", rdb.String(100), nullable=False),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n     rdb.Column(\"active\", rdb.Boolean(), nullable=False)\n )\n@@ -1204,8 +1204,8 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"access_token_id\", rdb.Integer, primary_key=True),\n     rdb.Column(\"authorization_id\", rdb.Integer,\n              rdb.ForeignKey(\"oauth_authorization.authorization_id\")),\n-    rdb.Column(\"access_token\", rdb.String(32)),\n-    rdb.Column(\"refresh_token\", rdb.String(32)),\n+    rdb.Column(\"access_token\", rdb.String(100)),\n+    rdb.Column(\"refresh_token\", rdb.String(100)),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n )\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\nindex 21c811509..bf1568c5e 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n@@ -1,8 +1,10 @@\n import hashlib\n+import hmac\n import random\n import string\n import urllib\n import simplejson\n+import time\n from datetime import datetime, timedelta\n \n from sqlalchemy.orm.exc import NoResultFound\n@@ -30,8 +32,8 @@\n def get_key():\n     \"\"\"Return a randomly generated key\n     \"\"\"\n-    m = hashlib.sha256()\n-    m.update(\"\".join(random.sample(string.letters + string.digits, 32)))\n+    m = hashlib.sha1()\n+    m.update(\"\".join(random.sample(string.letters + string.digits, 20)))\n     return m.hexdigest()\n \n \n@@ -45,10 +47,10 @@ class AddOAuthApplication(forms.common.AddForm):\n     @form.action(_(u\"Create Application\"), name=\"create\")\n     def handle_create_application(self, action, data, validator=\"validateAdd\"):\n         oauth_app = domain.OAuthApplication()\n-        oauth_app.application_identifier = data[\"application_identifier\"]\n-        oauth_app.application_name = data[\"application_name\"]\n+        oauth_app.identifier = data[\"identifier\"]\n+        oauth_app.name = data[\"name\"]\n         oauth_app.redirection_endpoint = data[\"redirection_endpoint\"]\n-        oauth_app.application_key = get_key()\n+        oauth_app.secret = get_key()\n         session = Session()\n         session.add(oauth_app)\n         session.flush()\n@@ -163,41 +165,73 @@ def __call__(self):\n class IOAuthAuthorizeForm(interface.Interface):\n     client_id = schema.TextLine(required=False)\n     state = schema.TextLine(required=False)\n-\n+    time = schema.TextLine(required=False)\n+    nonce = schema.TextLine(required=False)\n \n class OAuthAuthorizeForm(form.FormBase):\n     form_fields = form.Fields(IOAuthAuthorizeForm)\n     form_fields[\"client_id\"].custom_widget = widgets.HiddenTextWidget\n     form_fields[\"state\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"nonce\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"time\"].custom_widget = widgets.HiddenTextWidget\n     template = NamedTemplate(\"alchemist.form\")\n     form_name = _(\"authorise_oauth_application\",\n         default=u\"Authorise OAuth Application\")\n \n     def __init__(self, context, request, parameters={}):\n         self.parameters = parameters\n+        if self.parameters:\n+            self.parameters[\"time\"] = time.time()\n+            self.parameters[\"nonce\"] = self.generate_nonce(\n+                self.parameters[\"time\"])\n         self.action_url = \"\/api\/oauth\/authorize-form\"\n         super(OAuthAuthorizeForm, self).__init__(context, request)\n \n     def setUpWidgets(self, ignore_request=False):\n+        \n         self.widgets = form.setUpWidgets(\n             self.form_fields, self.prefix, self.context, self.request,\n             data=self.parameters if self.parameters else self.request.form,\n             ignore_request=ignore_request\n         )\n \n-    @form.action(_(u\"Authorize application\"), name=\"authorize\")\n+    def generate_nonce(self, auth_time):\n+        data = \"{0}:{1}:{2}\".format(\n+            self.parameters[\"client_id\"], get_db_user().user_id, auth_time)\n+        return hmac.new(capi.oauth_hmac_key, data, hashlib.sha1).hexdigest()\n+\n+    def check_authorization(self, action, data):\n+        errors = []\n+        data = self.request.form\n+        if not data.get(\"form.time\", None) or not data.get(\"form.nonce\", None):\n+            errors.append(InvalidRequest)\n+            return errors\n+        max_time = datetime.fromtimestamp(float(data[\"form.time\"])) + \\\n+            timedelta(seconds=capi.oauth_authorization_token_expiry_time)\n+        if (datetime.now() > max_time):\n+            errors.append(InvalidGrant)\n+        if data[\"form.nonce\"] != self.generate_nonce(data[\"form.time\"]):\n+            errors.append(InvalidGrant)\n+        return errors\n+\n+    def handle_failure(self, action, data, errors):\n+        return ErrorPage(self.context, self.request, errors[0])()\n+\n+    @form.action(_(u\"Authorize application\"), name=\"authorize\",\n+        validator=check_authorization, failure=handle_failure)\n     def handle_authorize_app(self, action, data):\n         session = Session()\n         oauth_authorization = domain.OAuthAuthorization()\n         oauth_authorization.user_id = get_db_user().user_id\n         app = session.query(domain.OAuthApplication\n-            ).filter(domain.OAuthApplication.application_identifier ==\n+            ).filter(domain.OAuthApplication.identifier ==\n                 data[\"client_id\"]\n             ).one()\n         oauth_authorization.application_id = app.application_id\n         oauth_authorization.authorization_code = get_key()\n         oauth_authorization.expiry = datetime.now() + timedelta(\n-            seconds=capi.oauth_auth_expiry_time)\n+            seconds=capi.oauth_authorization_token_expiry_time)\n+        oauth_authorization.active = True\n         session.add(oauth_authorization)\n         redirect_uri = \"{0}?code={1}\".format(\n             app.redirection_endpoint, oauth_authorization.authorization_code)\n@@ -213,10 +247,10 @@ def handle_cancel(self, action, data):\n                      == data[\"client_id\"]\n             ).one()\n         error = UnauthorizedClient(app.redirection_endpoint, data[\"state\"])\n-        redirect_error(self.request, error)\n+        redirect_error(self.context, self.request, error)\n \n \n-def redirect_error(request, error):\n+def redirect_error(context, request, error):\n     if error.redirect_uri:\n         next_url = \"{0}?error={1}&error_description={2}\".format(\n             error.redirect_uri, error.error, error.error_description)\n@@ -224,10 +258,10 @@ def redirect_error(request, error):\n             next_url = \"{0}&state={1}\".format(next_url, error.state)\n         return request.response.redirect(next_url, trusted=True)\n     else:\n-        bad_request(request, error)\n+        return ErrorPage(context, request, error)()\n \n \n-def bad_request(request, error):\n+def bad_request(context, request, error):\n     request.response.setStatus(400)\n     data = {\"error\": error.error, \"error_description\": error.error_description}\n     return simplejson.dumps(data)\n@@ -277,7 +311,7 @@ def __call__(self):\n         except UnauthorizedClient as e:\n             return ErrorPage(self.context, self.request, e)()\n         except OAuthException as e:\n-            return redirect_error(self.request, e)\n+            return redirect_error(self.context, self.request, e)\n \n         if not IUnauthenticatedPrincipal.providedBy(self.request.principal):\n             # authorize form\n@@ -345,7 +379,7 @@ def __call__(self):\n         try:\n             parameters = self.parameters()\n         except OAuthException as e:\n-            return bad_request(self.request, e)\n+            return bad_request(self.context, self.request, e)\n         assert (self.authorization is not None,\n             \"Authorization object not initalized\")\n         self.authorization.expiry = datetime.now()\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\nindex 18c6363b5..1372b42bf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n@@ -1718,13 +1718,13 @@ class ItemScheduleVoteDescriptor(ModelDescriptor):\n class OAuthApplicationDescriptor(ModelDescriptor):\n     localisable = False\n     fields = [\n-        F(name=\"application_identifier\",\n+        F(name=\"identifier\",\n           label=\"Unique Application Identifier\",\n           required=True,\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_name\",\n+        F(name=\"name\",\n           label=\"Application Name\",\n           required=True,\n           value_type=\"text\",\n@@ -1736,8 +1736,8 @@ class OAuthApplicationDescriptor(ModelDescriptor):\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_key\",\n-          label=\"Application Key\",\n+        F(name=\"secret\",\n+          label=\"Application Secret\",\n           localizable=[show(\"view\"), hide(\"add\")],\n           required=True,\n           value_type=\"text\",\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\nindex 57deb7ee2..66b0dbd7b 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n@@ -1265,5 +1265,14 @@\n      viewName=\"\"\n      weight=\"30\"\n      \/-->\n+   <!--OAuth-->\n+   <browser:menuItem menu=\"plone_contentmenu\"\n+        for=\"bungeni.models.interfaces.IOAuthApplicationContainer\"\n+        title=\"Add OAuth Application\"\n+        action=\"add\"\n+        permission=\"bungeni.o_auth_application.Add\"\n+        layer=\".interfaces.IAdminSectionLayer\"\n+        order=\"62\"\n+    \/>\n <\/configure>\n \n","files":{"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py":{"changes":[{"diff":"\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),","add":1,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py","badparts":["    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),"],"goodparts":["    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),"]}],"source":"\n \"\"\"Aggregation of information about loaded domain types. No public methods here --all available methods from this are those exposed via bungeni.capi. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\") from zope.interface.interfaces import IInterface from zope.security.proxy import removeSecurityProxy from zope.dottedname.resolve import resolve from bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface from bungeni.alchemist.model import( new_custom_domain_interface, new_custom_domain_model, ) from bungeni.alchemist.catalyst import( INTERFACE_MODULE, MODEL_MODULE ) from bungeni.models import interfaces from bungeni.models import domain from bungeni.core.workflow.interfaces import IWorkflow from bungeni.utils import naming __all__=[] def _iter(): \"\"\"Return iterator on all(key, TypeInfo) entries in TYPE_REGISTRY. Usage: capi.iter_type_info() \"\"\" for type_key, ti in TYPE_REGISTRY: yield type_key, ti def _get(discriminator): \"\"\"Get the TypeInfo instance for discriminator, that may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: provides IBungeniContent domain model instance: type provides IBungeniContent descriptor: provides IModelDescriptor Raise KeyError if no entry matched. Usage: capi.get_type_info(discriminator) \"\"\" if discriminator is None: m=\"type_info._get discriminator is None\" log.error(m) raise ValueError(m) discri=removeSecurityProxy(discriminator) getter=None if IIModelInterface.providedBy(discri): discri=naming.type_key(\"table_schema_interface_name\", discri.__name__) elif IInterface.providedBy(discri): discri=naming.type_key(\"model_interface_name\", discri.__name__) elif type(discri) is type and issubclass(discri, domain.Entity): discri=naming.polymorphic_identity(discri) elif isinstance(discri, domain.Entity): discri=naming.polymorphic_identity(type(discri)) if isinstance(discri, basestring): getter=_get_by_type_key elif IWorkflow.providedBy(discri): getter=_get_by_workflow elif IModelDescriptor.implementedBy(discri): getter=_get_by_descriptor_model if getter is not None: ti=getter(discri) if ti is not None: return ti else: m=\"No type registered for discriminator: %r\" %(discriminator) else: m=\"Invalid type info lookup discriminator: %r\" %(discriminator) from bungeni.ui.utils import debug log.debug(debug.interfaces(discriminator)) log.debug(m) raise KeyError(m) def _get_by_type_key(key): for type_key, ti in _iter(): if type_key==key: return ti ''' !+IALCHEMISTCONTENT fails on different interfaces with same name! (Pdb) ti.interface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) ti.interface.__bases__ (<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>) (Pdb) iface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) iface.__bases__ (<InterfaceClass zope.interface.Interface>,) ''' def _get_by_model(model): for type_key, ti in _iter(): if model is ti.domain_model: return ti def _get_by_instance(instance): return _get_by_model(type(instance)) def _get_by_workflow(wf): for type_key, ti in _iter(): if wf is ti.workflow: return ti def _get_by_descriptor_model(descriptor_model): for type_key, ti in _iter(): if descriptor_model is ti.descriptor_model: return ti class TI(object): \"\"\"TypeInfo, associates together the following attributes for a given type: workflow_key the workflow file name defaults to the type_key for workflowed types that DO NOT specify is None for non-workflowed types workflow same workflow insatnce may be used by multiple types is None for non-workflowed types interface the manually applied application-dedicated model interface (if any) for the type derived_table_schema auto-generated db schema interface, provides IIModelInterface domain_model the domain class descriptor_model the descriptor model for UI views for the type container_class container class for domain_model container_interface interface for the container class for domain_model \"\"\" def __init__(self, workflow_key, iface, domain_model=None): self.workflow_key=workflow_key self.interface=iface self.derived_table_schema=None self.workflow=None self.domain_model=domain_model self.descriptor_model=None self.container_class=None self.container_interface=None self.custom=False def __str__(self): return str(self.__dict__) @property def scope(self): if self.custom: return \"custom\" if self.descriptor_model is not None: return self.descriptor_model.scope @property def permission_type_key(self): if self.custom: return self.workflow.name return(self.workflow_key or naming.type_key(\"model_name\", self.domain_model.__name__) ) ''' !+TYPE_REGISTRY externalize further to bungeni_custom, currently: -association of type key and dedicated interface are hard-wired here -ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when loading workflows and descriptors -type_key IS the underscore-separated lowercase of the domain cls name i.e. utils.naming.polymorphic_identity(domain_model) -!+ti.workflow_key SHOULD always be equal to type_key -!+corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated -!+dedicated interfaces for archetype incantations should be auto-generated, from specific workflow name\/attr... e.g. via: zope.interface.interface.InterfaceClass(iname, bases, __module__) -!+should ti.interface be automatically generated also for system types? Usage: from bungeni.capi import capi capi.get_type_info(discriminator) -> TypeInfo capi.iter_type_info() -> iterator of all registered(key, TypeInfo) ''' TYPE_REGISTRY=[ (\"user_address\", TI(\"address\", interfaces.IUserAddress)), (\"group_address\", TI(\"address\", interfaces.IGroupAddress)), (\"attachment\", TI(\"attachment\", interfaces.IAttachment)), (\"event\", TI(\"event\", interfaces.IEvent)), (\"sitting\", TI(\"sitting\", interfaces.ISitting)), (\"heading\", TI(\"heading\", interfaces.IHeading)), (\"user\", TI(\"user\", interfaces.IBungeniUser)), (\"signatory\", TI(\"signatory\", interfaces.ISignatory)), (\"group\", TI(\"group\", interfaces.IBungeniGroup)), (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)), (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)), (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)), (\"oauth_application\", TI(None, interfaces.IOAuthApplication)), (\"debate_media\", TI(None, interfaces.IDebateMedia)), (\"user_delegation\", TI(None, interfaces.IUserDelegation)), (\"title_type\", TI(None, interfaces.ITitleType)), (\"member_title\", TI(None, interfaces.IMemberTitle)), (\"change\", TI(None, interfaces.IChange)), (\"doc\", TI(None, interfaces.IDoc)), (\"doc_version\", TI(None, None)), (\"attachment_version\", TI(None, None)), (\"venue\", TI(None, interfaces.IVenue)), (\"session\", TI(None, interfaces.ISession)), (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)), (\"country\", TI(None, interfaces.ICountry)), (\"item_schedule\", TI(None, interfaces.IItemSchedule)), (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)), (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)), (\"editorial_note\", TI(None, interfaces.IEditorialNote)), (\"sitting_report\", TI(None, interfaces.ISittingReport)), (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)), ] def register_new_custom_type(type_key, workflow_key, archetype_key): \"\"\"Retrieve(create if needed) a domain interface and model for type_key, and register as new entry on TYPE_REGISTER. \"\"\" domain_iface_name=naming.model_interface_name(type_key) try: domain_iface=resolve(\"%s.%s\" %(INTERFACE_MODULE.__name__, domain_iface_name)) log.warn(\"Custom interface ALREADY EXISTS: %s\" %(domain_iface)) except ImportError: domain_iface=new_custom_domain_interface(type_key, domain_iface_name) domain_model_name=naming.model_name(type_key) try: domain_model=resolve(\"%s.%s\" %(MODEL_MODULE.__name__, domain_model_name)) log.warn(\"Custom domain model ALREADY EXISTS: %s\" %(domain_model)) except ImportError: domain_model=new_custom_domain_model(type_key, domain_iface, archetype_key) ti=TI(workflow_key, domain_iface, domain_model) ti.custom=True TYPE_REGISTRY.append((type_key, ti)) log.info(\"Registered custom type[%s]: %s\" %(archetype_key, type_key)) return type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Aggregation of information about loaded domain types.\n\nNo public methods here -- all available methods from this are those exposed \nvia bungeni.capi.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\")\n\nfrom zope.interface.interfaces import IInterface\nfrom zope.security.proxy import removeSecurityProxy\nfrom zope.dottedname.resolve import resolve\n\nfrom bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface\nfrom bungeni.alchemist.model import (\n    new_custom_domain_interface,\n    new_custom_domain_model,\n)\nfrom bungeni.alchemist.catalyst import (\n    INTERFACE_MODULE, \n    MODEL_MODULE\n)\nfrom bungeni.models import interfaces\nfrom bungeni.models import domain\nfrom bungeni.core.workflow.interfaces import IWorkflow\nfrom bungeni.utils import naming\n\n__all__ = []\n\n\n# acessors exposed via capi\n\ndef _iter():\n    \"\"\"Return iterator on all (key, TypeInfo) entries in TYPE_REGISTRY.\n    \n    Usage: capi.iter_type_info()\n    \"\"\"\n    for type_key, ti in TYPE_REGISTRY:\n        yield type_key, ti\n\ndef _get(discriminator):\n    \"\"\"Get the TypeInfo instance for discriminator, that may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: provides IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor: provides IModelDescriptor\n    \n    Raise KeyError if no entry matched.\n    \n    Usage: capi.get_type_info(discriminator)\n    \"\"\"\n    if discriminator is None:\n        m = \"type_info._get discriminator is None\"\n        log.error(m)\n        raise ValueError(m)\n    discri = removeSecurityProxy(discriminator)\n    getter = None\n    \n    # !+IALCHEMISTCONTENT normalize trickier discriminator cases to type_key\n    if IIModelInterface.providedBy(discri):\n        discri = naming.type_key(\"table_schema_interface_name\", discri.__name__)\n    elif IInterface.providedBy(discri):\n        discri = naming.type_key(\"model_interface_name\", discri.__name__)\n    elif type(discri) is type and issubclass(discri, domain.Entity):\n        discri = naming.polymorphic_identity(discri)\n    elif isinstance(discri, domain.Entity):\n        discri = naming.polymorphic_identity(type(discri))\n    \n    if isinstance(discri, basestring):\n        getter = _get_by_type_key\n    #elif IInterface.providedBy(discri):\n    #    getter = _get_by_interface\n    #!+elif interfaces.IBungeniContent.implementedBy(discri):\n    #elif issubclass(discri, domain.Entity):\n    #    getter = _get_by_model\n    #!+elif interfaces.IBungeniContent.providedBy(discri):\n    #elif isinstance(discri, domain.Entity):\n    #    getter = _get_by_instance\n    elif IWorkflow.providedBy(discri):\n        getter = _get_by_workflow\n    elif IModelDescriptor.implementedBy(discri):\n        getter = _get_by_descriptor_model\n    \n    if getter is not None:\n        ti = getter(discri)\n        if ti is not None:\n            return ti\n        else:\n            m = \"No type registered for discriminator: %r\" % (discriminator)\n    else: \n        m = \"Invalid type info lookup discriminator: %r\" % (discriminator)\n    from bungeni.ui.utils import debug\n    log.debug(debug.interfaces(discriminator))\n    log.debug(m)\n    raise KeyError(m)\n\n\n# following getters return \"first matching\" TypeInfo instance in registry\n    \ndef _get_by_type_key(key):\n    for type_key, ti in _iter():\n        if type_key == key:\n            return ti\n#def _get_by_interface(iface):\n''' !+IALCHEMISTCONTENT fails on different interfaces with same name!\n(Pdb) ti.interface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) ti.interface.__bases__\n(<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>)\n(Pdb) iface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) iface.__bases__\n(<InterfaceClass zope.interface.Interface>,)\n'''\n#    for type_key, ti in _iter():\n#        if iface is ti.interface: #!+issubclass(iface, ti.interface)?\n#            return ti\ndef _get_by_model(model):\n    for type_key, ti in _iter():\n        if model is ti.domain_model: #!+issubclass(model, ti.domain_model)?\n            return ti\ndef _get_by_instance(instance):\n    return _get_by_model(type(instance))\ndef _get_by_workflow(wf):\n    for type_key, ti in _iter():\n        if wf is ti.workflow:\n            return ti\ndef _get_by_descriptor_model(descriptor_model):\n    for type_key, ti in _iter():\n        if descriptor_model is ti.descriptor_model:\n            return ti\n\n# \n\nclass TI(object):\n    \"\"\"TypeInfo, associates together the following attributes for a given type:\n            workflow_key \n                the workflow file name\n                defaults to the type_key for workflowed types that DO NOT specify\n                is None for non-workflowed types\n            workflow \n                same workflow insatnce may be used by multiple types\n                is None for non-workflowed types\n            interface\n                the manually applied application-dedicated model interface \n                (if any) for the type\n            derived_table_schema\n                auto-generated db schema interface, provides IIModelInterface\n            domain_model\n                the domain class\n            descriptor_model\n                the descriptor model for UI views for the type\n            container_class\n                container class for domain_model\n            container_interface\n                interface for the container class for domain_model\n    \"\"\"\n    def __init__(self, workflow_key, iface, domain_model=None):\n        self.workflow_key = workflow_key\n        self.interface = iface\n        self.derived_table_schema = None # provides IIModelInterface\n        self.workflow = None\n        self.domain_model = domain_model\n        self.descriptor_model = None\n        self.container_class = None\n        self.container_interface = None\n        self.custom = False # type loaded from custom configuration \n        # NOTE: only needed temporarily (until descriptor_model is set), \n        # then ti.custom not be inconsistent descriptor_model.scope i.e.\n        #if self.custom: assert self.descriptor_model.scope == \"custom\"\n        # !+ archetype_key?\n    def __str__(self):\n        return str(self.__dict__)\n    \n    @property\n    def scope(self):\n        # !+CUSTOM_TYPE_DESCRIPTOR the self.custom check below MUST precede the\n        # check on self.descriptor_model.scope as otherwise the \"in-transit\" \n        # custom types will not be picked up as custom types -- as during\n        # loading the descriptors for all custom types may not yet have been \n        # autogenerated (and would therefore correctly have \n        # descriptor_model.scope=\"custom\" set).\n        if self.custom:\n            return \"custom\"\n        if self.descriptor_model is not None:\n            return self.descriptor_model.scope\n    \n    @property\n    def permission_type_key(self):\n        if self.custom:\n            # custom types ALWAYS have a type_key-bound workflow instance - that\n            # may therefore have a different name than workflow_key e.g. Office\n            # uses the \"group\" workflow, that is type-relative reloaded as the\n            # \"office\" workflow instance.\n            return self.workflow.name\n        # system types ALWAYS use workflow_key - even if multiple types use the \n        # same workflow e.g. UserAddress & GroupAddress. \n        # if no workflow, compute type_key from domain_model\n        # #!+REDUNDANT(mb, 2012) This type key is already known during type\n        # setup i.e. TYPE_REGISTRY\n        return (self.workflow_key or \n            naming.type_key(\"model_name\", self.domain_model.__name__)\n        )\n\n'''\n!+TYPE_REGISTRY externalize further to bungeni_custom, currently:\n- association of type key and dedicated interface are hard-wired here\n- ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when \n  loading workflows and descriptors\n- type_key IS the underscore-separated lowercase of the domain cls name \n  i.e. utils.naming.polymorphic_identity(domain_model)\n- !+ ti.workflow_key SHOULD always be equal to type_key\n- !+ corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated\n- !+ dedicated interfaces for archetype incantations should be auto-generated, \n    from specific workflow name\/attr... e.g. via:\n    zope.interface.interface.InterfaceClass(iname, bases, __module__)\n- !+ should ti.interface be automatically generated also for system types?\n\nUsage:\n    from bungeni.capi import capi\n    capi.get_type_info(discriminator) -> TypeInfo\n    capi.iter_type_info() -> iterator of all registered (key, TypeInfo)\n'''\nTYPE_REGISTRY = [\n    # (key, ti)\n    # - the type key, unique for each type, is the underscore-separated \n    #   lowercase name of the domain_model (the domain class)\n    # - order is relevant (dictates workflow loading order)\n    \n    # feature \"support\" types, system types, required\n    \n    # workflowed\n    (\"user_address\", TI(\"address\", interfaces.IUserAddress)),\n    (\"group_address\", TI(\"address\", interfaces.IGroupAddress)),\n    # !+Attachment (mr, jul-2011)\n    # a) must be loaded before any other type that *may* support attachments!\n    # b) MUST support versions\n    (\"attachment\", TI(\"attachment\", interfaces.IAttachment)),\n    (\"event\", TI(\"event\", interfaces.IEvent)),\n    (\"sitting\", TI(\"sitting\", interfaces.ISitting)),\n    (\"heading\", TI(\"heading\", interfaces.IHeading)),\n    (\"user\", TI(\"user\", interfaces.IBungeniUser)),\n    (\"signatory\", TI(\"signatory\", interfaces.ISignatory)),\n    \n    # !+NAMING: member-related -> Group name + \"Member\" (no + \"ship\")\n    (\"group\", TI(\"group\", interfaces.IBungeniGroup)),\n    (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)),\n    (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n    (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n        # non-workflowed\n    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n    (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n    (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n    (\"title_type\", TI(None, interfaces.ITitleType)),\n    (\"member_title\", TI(None, interfaces.IMemberTitle)),\n    (\"change\", TI(None, interfaces.IChange)),\n    (\"doc\", TI(None, interfaces.IDoc)),\n    (\"doc_version\", TI(None, None)), #interfaces.IDocVersion)), #!+IVERSION\n    (\"attachment_version\", TI(None, None)), #interfaces.IAttachmentVersion)), #!+IVERSION\n    (\"venue\", TI(None, interfaces.IVenue)),\n    (\"session\", TI(None, interfaces.ISession)),\n    (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)),\n    (\"country\", TI(None, interfaces.ICountry)),\n    (\"item_schedule\", TI(None, interfaces.IItemSchedule)),\n    (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)),\n    (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)),\n    (\"editorial_note\", TI(None, interfaces.IEditorialNote)),\n    (\"sitting_report\", TI(None, interfaces.ISittingReport)),\n    (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)),\n    \n    # additional custom types are loaded dynamically from bungeni_custom\/types.xml\n]\n\n\n\n\n# register custom types\n\ndef register_new_custom_type(type_key, workflow_key, archetype_key):\n    \"\"\"Retrieve (create if needed) a domain interface and model for type_key,\n    and register as new entry on TYPE_REGISTER.\n    \"\"\"\n    \n    # generate custom domain interface\n    domain_iface_name = naming.model_interface_name(type_key)\n    try:\n        domain_iface = resolve(\"%s.%s\" % (INTERFACE_MODULE.__name__, domain_iface_name))\n        log.warn(\"Custom interface ALREADY EXISTS: %s\" % (domain_iface))\n    except ImportError:\n        domain_iface = new_custom_domain_interface(type_key, domain_iface_name)\n    \n    # generate custom domain_model\n    domain_model_name = naming.model_name(type_key)\n    try:\n        domain_model = resolve(\"%s.%s\" % (MODEL_MODULE.__name__, domain_model_name))\n        log.warn(\"Custom domain model ALREADY EXISTS: %s\" % (domain_model))\n    except ImportError:\n        domain_model = new_custom_domain_model(type_key, domain_iface, archetype_key)\n    \n    # type_info entry\n    ti = TI(workflow_key, domain_iface, domain_model)\n    ti.custom = True\n    TYPE_REGISTRY.append((type_key, ti))\n    \n    log.info(\"Registered custom type [%s]: %s\" % (archetype_key, type_key))\n    return type_key, ti\n\n\n\n\n\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py":{"changes":[{"diff":"\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self)","add":8,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py","badparts":["        return int(bc.oauth_auth_expiry_time)"],"goodparts":["        return int(bc.oauth_authorization_token_expiry_time)","    @cached_property.cachedIn(\"__oauth_hmac_key__\")","    @bungeni_custom_errors","    def oauth_hmac_key(self):","        \"\"\"String used to to generate nonces. KEEP SECRET.","        \"\"\"","        return bc.oauth_hmac_key"]}],"source":"\n \"\"\"Defines the accessor class for Bungeni Custom parameters. See bungeni.capi __init__.py for usage. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.capi\") import sys import time import os from zope.dottedname.resolve import resolve from zope.cachedescriptors import property as cached_property from bungeni.utils import error from bungeni.alchemist import type_info import bungeni_custom as bc class BungeniCustomError(Exception): \"\"\"A configuration error during loading of configuration. \"\"\" class BungeniCustomRuntimeError(BungeniCustomError): \"\"\"Internal error while executing a callable determined from configuration. \"\"\" def bungeni_custom_errors(f): \"\"\"Decorator to intercept any error raised by function f and re-raise it as a BungeniCustomError. To be used to decorate any function involved in reading\/validating\/processing any bungeni_custom parameters. \"\"\" return error.exceptions_as(BungeniCustomError)(f) def wrapped_callable(unwrapped): assert callable(unwrapped), unwrapped def wrapped(*args): log.debug(\"Calling %s with args: %s\" %(unwrapped, args)) try: return unwrapped(*args) except: exc=sys.exc_info()[1] log.debug(\"BungeniCustomRuntimeError[%r] in wrapped_callable: %s %s\", exc, wrapped, args) raise wrapped._unwrapped=unwrapped wrapped.__name__=unwrapped.__name__ return wrapped class CAPI(object): \"\"\"Accessor class for Bungeni Custom parameters. \"\"\" def __init__(self): self.validate_properties() def validate_properties(self): \"\"\"Validate this capi instance. Ensure valid setup of properties at instantiation of CAPI instance \"\"\" self.default_language self.country_code self.right_to_left_languages @property @bungeni_custom_errors def zope_i18n_allowed_languages(self): return tuple(bc.zope_i18n_allowed_languages.split()) @property @bungeni_custom_errors def zope_i18n_compile_mo_files(self): return bool( bc.zope_i18n_compile_mo_files is True or bc.zope_i18n_compile_mo_files==\"1\") @property @bungeni_custom_errors def country_code(self): \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this bungeni instance. \"\"\" return bc.country_code @property @bungeni_custom_errors def default_language(self): assert bc.default_language in self.zope_i18n_allowed_languages, \\ \"Default language[%s] not in allowed languages[%s]\" %( bc.default_language, self.zope_i18n_allowed_languages,) return bc.default_language @property @bungeni_custom_errors def right_to_left_languages(self): rtl_langs=tuple(bc.right_to_left_languages.split()) assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\ \"Right to left languages[%s] not in allowed languages[%s]\" %( bc.right_to_left_languages, self.zope_i18n_allowed_languages) return rtl_langs @property @bungeni_custom_errors def check_auto_reload_localization(self): \"\"\"() -> int minimum number of seconds to wait between checks for whether a localization file needs reloading; 0 means never check(deployment) \"\"\" int(bc.check_auto_reload_localization) return bc.check_auto_reload_localization @bungeni_custom_errors def get_workflow_condition(self, condition): condition_module=resolve(\"._conditions\", \"bungeni_custom.workflows\") condition=getattr(condition_module, condition) return wrapped_callable(condition) @bungeni_custom_errors def get_workflow_action(self, action): action_module=resolve(\"._actions\", \"bungeni_custom.workflows\") action=getattr(action_module, action) return wrapped_callable(action) @bungeni_custom_errors def get_form_constraint(self, constraint): constraint_module=resolve(\"._constraints\", \"bungeni_custom.forms\") constraint=getattr(constraint_module, constraint) return wrapped_callable(constraint) @bungeni_custom_errors def get_form_validator(self, validation): validator_module=resolve(\"._validations\", \"bungeni_custom.forms\") validator=getattr(validator_module, validation) return wrapped_callable(validator) @bungeni_custom_errors def get_form_derived(self, derived): derived_module=resolve(\"._derived\", \"bungeni_custom.forms\") derived_def=getattr(derived_module, derived) return wrapped_callable(derived_def) @property @bungeni_custom_errors def default_number_of_listing_items(self): \"\"\"This is the max number of items that are displayed in a listing by default. Returns an integer \"\"\" return int(bc.default_number_of_listing_items) @property @bungeni_custom_errors def long_text_column_listings_truncate_at(self): \"\"\"When listing text columns, only display first so many characters.\"\"\" return int(bc.long_text_column_listings_truncate_at) def xml_workspace_tabs_file(self): \"\"\"helper function used by workspace tab info APIs\"\"\" TABS_FILE=\"tabs.xml\" from lxml import etree ws_path=self.get_path_for(\"workspace\") file_path=os.path.join(ws_path, TABS_FILE) tabs=etree.fromstring(open(file_path).read()) return tabs @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\") @bungeni_custom_errors def workspace_tab_count_cache_refresh_time(self): \"\"\"The duration in seconds between tab count refresh operations\"\"\" tabs=self.xml_workspace_tabs_file() tabs_count_refresh=tabs.attrib[\"tab_count_cache_refresh_time\"] return int(tabs_count_refresh) @cached_property.cachedIn(\"__workspace_tabs__\") @bungeni_custom_errors def workspace_tabs(self): \"\"\"The tabs in the workspace\"\"\" ws_tabs=[] tabs=self.xml_workspace_tabs_file() for tab in tabs.iterchildren(tag=\"tab\"): ws_tabs.append(tab.attrib[\"id\"]) return ws_tabs @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\") @bungeni_custom_errors def oauth_access_token_expiry_time(self): \"\"\"time in seconds before an access token expires\"\"\" return(bc.oauth_access_token_expiry_time) @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\") @bungeni_custom_errors def oauth_authorization_token_expiry_time(self): \"\"\"time in seconds before an oauth authorization code expires max recommended time is 10min \"\"\" return int(bc.oauth_auth_expiry_time) def get_root_path(self): \"\"\"Get absolute physical path location for currently active bungeni_custom package folder. \"\"\" return os.path.dirname(os.path.abspath(bc.__file__)) def get_path_for(self, *path_components): \"\"\"Get absolute path, under bungeni_custom, for path_components. \"\"\" return os.path.join(*(self.get_root_path(),)+path_components) def put_env(self, key): \"\"\"Set capi value for{key} as the environment variable{key} i.e. use to set os.environ[key]. Wrapper on os.put_env(key, string_value) --to take care of the value string-casting required by os.put_env while still allowing the liberty of data-typing values of capi attributes as needed. \"\"\" value=getattr(self, key) try: os.environ[key]=value except TypeError: try: os.environ[key]=\" \".join(value) except TypeError: os.environ[key]=repr(value) assert eval(os.environ[key])==value _is_modified_since_last_times={} def is_modified_since(self, abspath, modified_on_first_check=True): \"\"\"(abspath:str, modified_on_first_check:bool) -> bool Checks file path st_mtime to see if file has been modified since last check. Updates entry per path, with last(check, modified) times. \"\"\" check_auto_reload_localization=self.check_auto_reload_localization now=time.time() last_checked, old_last_modified=\\ self._is_modified_since_last_times.get(abspath) or(0, 0) if not check_auto_reload_localization: if last_checked or not modified_on_first_check: return False if not now-last_checked > check_auto_reload_localization: return False last_modified=os.stat(abspath).st_mtime self._is_modified_since_last_times[abspath]=(now, last_modified) if not last_checked: return modified_on_first_check return(old_last_modified < last_modified) def get_type_info(self, discriminator): \"\"\"Get the TypeInfo instance for discriminator(see core.type_info). The discriminator may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: implements IBungeniContent domain model instance: type provides IBungeniContent descriptor_model: implements IModelDescriptor Raise KeyError if no entry matched. \"\"\" return type_info._get(discriminator) def iter_type_info(self, scope=None): \"\"\"Return iterator on all registered(key, TypeInfo) entries. scope:either(None, \"system\", \"archetype\", \"custom\") \"\"\" for type_key, ti in type_info._iter(): if(scope is None or ti.scope==scope): yield type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Defines the accessor class for Bungeni Custom parameters.\n\nSee bungeni.capi __init__.py for usage.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.capi\")\n\nimport sys\nimport time\nimport os\nfrom zope.dottedname.resolve import resolve\nfrom zope.cachedescriptors import property as cached_property\nfrom bungeni.utils import error\nfrom bungeni.alchemist import type_info\nimport bungeni_custom as bc\n\n\n# utils \n\nclass BungeniCustomError(Exception):\n    \"\"\"A configuration error during loading of configuration.\n    \"\"\"\nclass BungeniCustomRuntimeError(BungeniCustomError): \n    \"\"\"Internal error while executing a callable determined from configuration.\n    \"\"\" \n\ndef bungeni_custom_errors(f):\n    \"\"\"Decorator to intercept any error raised by function f and re-raise it\n    as a BungeniCustomError. To be used to decorate any function involved \n    in reading\/validating\/processing any bungeni_custom parameters. \n    \"\"\"\n    return error.exceptions_as(BungeniCustomError)(f)\n\n\ndef wrapped_callable(unwrapped):\n    assert callable(unwrapped), unwrapped\n    def wrapped(*args):\n        log.debug(\"Calling %s with args: %s\" % (unwrapped, args))\n        try:\n            return unwrapped(*args)\n        except:\n            # intercept exc, to re-raise it *unchanged*, only for debugging\n            # e.g. constraints raise numerous (expected?) NoInputData errors\n            exc = sys.exc_info()[1]\n            log.debug(\"BungeniCustomRuntimeError [%r] in wrapped_callable: %s %s\",\n                    exc, wrapped, args)\n            raise\n    # remember original unwrapped callable\n    wrapped._unwrapped = unwrapped\n    wrapped.__name__ = unwrapped.__name__\n    return wrapped\n\n\n# capi (singleton)\n\nclass CAPI(object):\n    \"\"\"Accessor class for Bungeni Custom parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.validate_properties()\n    \n    def validate_properties(self):\n        \"\"\"Validate this capi instance.\n        Ensure valid setup of properties at instantiation of CAPI instance\n        \"\"\"\n        self.default_language\n        self.country_code\n        self.right_to_left_languages\n        \n    # bungeni_custom parameter properties\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_allowed_languages(self):\n        # NOTE: zope.i18n.config.ALLOWED_LANGUAGES expects the value of the \n        # env variable for this to be a COMMA or SPACE separated STRING\n        return tuple(bc.zope_i18n_allowed_languages.split())\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_compile_mo_files(self):\n        return bool(\n            bc.zope_i18n_compile_mo_files is True or \n            bc.zope_i18n_compile_mo_files == \"1\")\n   \n    @property\n    @bungeni_custom_errors\n    def country_code(self):\n        \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this \n        bungeni instance.\n        \"\"\"\n        return bc.country_code\n\n    @property\n    @bungeni_custom_errors\n    def default_language(self):\n        assert bc.default_language in self.zope_i18n_allowed_languages, \\\n            \"Default language [%s] not in allowed languages [%s]\" % (\n                bc.default_language, self.zope_i18n_allowed_languages,)\n        return bc.default_language\n        \n    @property\n    @bungeni_custom_errors\n    def right_to_left_languages(self):\n        rtl_langs = tuple(bc.right_to_left_languages.split())\n        assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\\n            \"Right to left languages [%s] not in allowed languages [%s]\" % (\n                bc.right_to_left_languages, self.zope_i18n_allowed_languages)\n        return rtl_langs\n    \n    @property\n    @bungeni_custom_errors\n    def check_auto_reload_localization(self):\n        \"\"\" () -> int\n        minimum number of seconds to wait between checks for whether a \n        localization file needs reloading; 0 means never check (deployment)\n        \"\"\"\n        int(bc.check_auto_reload_localization) # TypeError if not an int\n        return bc.check_auto_reload_localization\n    \n    \n    @bungeni_custom_errors\n    def get_workflow_condition(self, condition):\n        condition_module = resolve(\"._conditions\", \"bungeni_custom.workflows\")\n        condition = getattr(condition_module, condition) # raises AttributeError\n        return wrapped_callable(condition)\n    \n    @bungeni_custom_errors\n    def get_workflow_action(self, action):\n        action_module = resolve(\"._actions\", \"bungeni_custom.workflows\")\n        action = getattr(action_module, action) # raises AttributeError\n        return wrapped_callable(action)\n    \n    @bungeni_custom_errors\n    def get_form_constraint(self, constraint):\n        constraint_module = resolve(\"._constraints\", \"bungeni_custom.forms\")\n        constraint = getattr(constraint_module, constraint) # raises AttributeError\n        return wrapped_callable(constraint)\n    \n    @bungeni_custom_errors\n    def get_form_validator(self, validation):\n        validator_module = resolve(\"._validations\", \"bungeni_custom.forms\")\n        validator = getattr(validator_module, validation) # raises AttributeError\n        return wrapped_callable(validator)\n    \n    @bungeni_custom_errors\n    def get_form_derived(self, derived):\n        derived_module = resolve(\"._derived\", \"bungeni_custom.forms\")\n        derived_def = getattr(derived_module, derived) # raises AttributeError\n        return wrapped_callable(derived_def)\n    \n    \n    @property\n    @bungeni_custom_errors\n    def default_number_of_listing_items(self):\n        \"\"\"This is the max number of items that are displayed in a listing by\n        default. Returns an integer\n        \"\"\"\n        return int(bc.default_number_of_listing_items)\n    \n    @property\n    @bungeni_custom_errors\n    def long_text_column_listings_truncate_at(self):\n        \"\"\"When listing text columns, only display first so many characters.\"\"\"\n        return int(bc.long_text_column_listings_truncate_at)\n    \n    def xml_workspace_tabs_file(self):\n        \"\"\"helper function used by workspace tab info APIs\"\"\"\n        TABS_FILE = \"tabs.xml\"    \n        from lxml import etree\n        ws_path = self.get_path_for(\"workspace\")\n        file_path = os.path.join(ws_path, TABS_FILE)\n        tabs = etree.fromstring(open(file_path).read()) \n        return tabs                \n    \n    @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\")\n    @bungeni_custom_errors\n    def workspace_tab_count_cache_refresh_time(self):\n        \"\"\"The duration in seconds between tab count refresh operations\"\"\"\n        tabs = self.xml_workspace_tabs_file()\n        tabs_count_refresh = tabs.attrib[\"tab_count_cache_refresh_time\"]\n        return int(tabs_count_refresh)\n    \n    @cached_property.cachedIn(\"__workspace_tabs__\")\n    @bungeni_custom_errors\n    def workspace_tabs(self):\n        \"\"\"The tabs in the workspace\"\"\"\n        ws_tabs = []\n        tabs = self.xml_workspace_tabs_file()\n        for tab in tabs.iterchildren(tag=\"tab\"):\n            ws_tabs.append(tab.attrib[\"id\"])\n        return ws_tabs    \n\n    @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_access_token_expiry_time(self):\n        \"\"\"time in seconds before an access token expires\"\"\"\n        return (bc.oauth_access_token_expiry_time)\n\n    @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_authorization_token_expiry_time(self):\n        \"\"\"time in seconds before an oauth authorization code expires\n        max recommended time is 10min\n        \"\"\"\n        return int(bc.oauth_auth_expiry_time)\n    # utility methods\n    \n    def get_root_path(self):\n        \"\"\"Get absolute physical path location for currently active \n        bungeni_custom package folder.\n        \"\"\"\n        return os.path.dirname(os.path.abspath(bc.__file__)) \n    \n    def get_path_for(self, *path_components):\n        \"\"\"Get absolute path, under bungeni_custom, for path_components.\n        \"\"\"\n        return os.path.join(*(self.get_root_path(),)+path_components)\n    \n    def put_env(self, key):\n        \"\"\"Set capi value for {key} as the environment variable {key}\n        i.e. use to set os.environ[key].\n        \n        Wrapper on os.put_env(key, string_value) -- to take care of\n        the value string-casting required by os.put_env while still \n        allowing the liberty of data-typing values of capi attributes \n        as needed.\n        \"\"\"\n        value = getattr(self, key)\n        try:\n            os.environ[key] = value\n            # OK, value is a string... done.\n        except TypeError:\n            # putenv() argument 2 must be string, not <...>\n            # i.e. value is NOT a string... try string-casting:\n            try:\n                # some zope code expects sequences to be specified as a \n                # COMMA or SPACE separated STRING, so we first try the value \n                # as a sequence, and serialize it to an environment variable \n                # value as expected by zope\n                os.environ[key] = \" \".join(value)\n            except TypeError:\n                # not a sequence, just fallback on repr(value)\n                os.environ[key] = repr(value)\n                # ensure that the original object value defines a __repr__ \n                # that can correctly re-instantiate the original object\n                assert eval(os.environ[key]) == value\n    \n    _is_modified_since_last_times = {} # {path: (last_checked, last_modified)}\n    def is_modified_since(self, abspath, modified_on_first_check=True):\n        \"\"\" (abspath:str, modified_on_first_check:bool) -> bool\n        Checks file path st_mtime to see if file has been modified since last \n        check. Updates entry per path, with last (check, modified) times.\n        \"\"\"\n        check_auto_reload_localization = self.check_auto_reload_localization\n        now = time.time()\n        last_checked, old_last_modified = \\\n            self._is_modified_since_last_times.get(abspath) or (0, 0)\n        if not check_auto_reload_localization:\n            # 0 =>> never check (unless this is the first check...)\n            if last_checked or not modified_on_first_check:\n                return False\n        if not now-last_checked > check_auto_reload_localization:\n            # last check too recent, avoid doing os.stat\n            return False\n        last_modified = os.stat(abspath).st_mtime\n        self._is_modified_since_last_times[abspath] = (now, last_modified)\n        if not last_checked:\n            # last_checked==0, this is the first check\n            return modified_on_first_check\n        return (old_last_modified < last_modified)\n    \n    # type registry\n    \n    def get_type_info(self, discriminator):\n        \"\"\"Get the TypeInfo instance for discriminator (see core.type_info). \n        \n        The discriminator may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: implements IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor_model: implements IModelDescriptor\n        \n        Raise KeyError if no entry matched.\n        \"\"\"\n        return type_info._get(discriminator)\n    \n    def iter_type_info(self, scope=None):\n        \"\"\"Return iterator on all registered (key, TypeInfo) entries.\n        scope:either(None, \"system\", \"archetype\", \"custom\")\n        \"\"\"\n        for type_key, ti in type_info._iter():\n            if (scope is None or ti.scope == scope):\n                yield type_key, ti\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py":{"changes":[{"diff":"\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"","add":2,"remove":2,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py","badparts":["        api[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])"],"goodparts":["        admin[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, admin[u\"applications\""]}],"source":"\n \"\"\"The Bungeni Application $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.core.app\") from zope.interface import implements from zope.interface import implementedBy from zope import component from zope.interface.declarations import alsoProvides from zope.app.appsetup.appsetup import getConfigContext from zope.app.component import site from zope.location.interfaces import ILocation from ore.wsgiapp.app import Application from ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent from bungeni.models import domain from bungeni.models import interfaces as model_interfaces from bungeni.models.utils import get_current_parliament from bungeni.models.utils import container_getter from bungeni.core import interfaces from bungeni.core import location from bungeni.core.content import(Section, AdminSection, AkomaNtosoSection, WorkspaceSection, APISection, OAuthSection) from bungeni.core.content import QueryContent from bungeni.core.i18n import _ from bungeni.core.workspace import(WorkspaceContainer, WorkspaceUnderConsiderationContainer, WorkspaceTrackedDocumentsContainer, WorkspaceGroupsContainer, WorkspaceSchedulableContainer, load_workspaces) from bungeni.core.notifications import load_notifications from bungeni.core.emailnotifications import load_email from bungeni.core.serialize import serialization_notifications from bungeni.ui.utils import url, common from bungeni.capi import capi from bungeni.utils import register @register.handler( (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent)) def on_wsgi_application_created_event(application, event): \"\"\"Additional setup on IWSGIApplicationCreatedEvent. \"\"\" log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) for type_key, ti in capi.iter_type_info(): if ti.workflow: ti.workflow.validate_permissions_roles() import bungeni.core.workflows.events load_workspaces() load_notifications() load_email() serialization_notifications() import bungeni.core.events app_setup=model_interfaces.IBungeniSetup(application) app_setup.setUp() try: import bungeni.utils.xmlconfexport as confexp confexp.write_all() except: log.debug((\"on_wsgi_application_created:\" \"error while exporting config parameters to xml\")) log.debug(\"on_wsgi_application_created_event: _features: %s\" %( getConfigContext()._features)) def to_locatable_container(domain_class, *domain_containers): component.provideAdapter(location.ContainerLocation(*domain_containers), (implementedBy(domain_class), ILocation)) class BungeniApp(Application): implements(model_interfaces.IBungeniApplication) class AppSetup(object): implements(model_interfaces.IBungeniSetup) def __init__(self, application): self.context=application def setUp(self): from zope.configuration import xmlconfig xmlconfig.string(\"\"\" <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\" xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\"> <include package=\"zope.i18n\" file=\"meta.zcml\" \/> <i18n:registerTranslations directory=\"%s\" \/> <\/configure> \"\"\" %(capi.get_path_for(\"translations\", \"bungeni\"))) import index index.setupFieldDefinitions(index.indexer) sm=site.LocalSiteManager(self.context) self.context.setSiteManager(sm) from bungeni.core import language from bungeni.ui import z3evoque z3evoque.set_get_gettext() z3evoque.setup_evoque() z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\")) z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL) z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name) z3evoque.domain.set_on_globals(\"get_base_direction\", language.get_base_direction) z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl) self.context[\"bungeni\"]=AkomaNtosoSection( title=_(u\"Bungeni\"), description=_(u\"Current parliamentary activity\"), default_name=\"bung\", ) workspace=self.context[\"workspace\"]=WorkspaceSection( title=_(\"section_workspace\", default=u\"Workspace\"), description=_(u\"Current parliamentary activity\"), default_name=\"my-documents\", ) alsoProvides(workspace, interfaces.ISearchableSection) workspace[\"my-documents\"]=WorkspaceSection( title=_(\"section_workspace_documents\", default=u\"my documents\"), description=_(u\"my documents workspace section\"), default_name=\"inbox\", marker=interfaces.IWorkspaceDocuments, ) for tab in capi.workspace_tabs: workspace[\"my-documents\"][tab]=WorkspaceContainer( tab_type=tab, title=_(\"section_workspace_%s\" % tab, default=tab), marker=interfaces.IWorkspaceTab ) ws_uc=workspace[\"under-consideration\"]=WorkspaceSection( title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), default_name=\"documents\", marker=interfaces.IWorkspaceUnderConsideration) ws_uc[\"documents\"]=WorkspaceUnderConsiderationContainer( name=\"documents\", title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), marker=interfaces.IWorkspaceTrackedDocuments) ws_uc[\"tracked-documents\"]=WorkspaceTrackedDocumentsContainer( name=\"tracked documents\", title=_(u\"tracked documents\"), description=_(u\"tracked documents\")) ws_sched=workspace[\"scheduling\"]=Section( title=_(\"section_scheduling\", default=u\"Scheduling\"), description=_(u\"Workspace Scheduling\"), default_name=\"index\", marker=interfaces.IWorkspaceScheduling) ws_sched[\"committees\"]=QueryContent( container_getter(get_current_parliament, \"committees\"), title=_(\"section_scheduling_committees\", default=u\"Committees\"), description=_(u\"Committee schedules\")) ws_sched[\"documents\"]=WorkspaceSchedulableContainer( name=_(u\"schedulable items\"), title=_(u\"schedulable items\"), description=_(u\"documents available for scheduling\")) ws_sched[\"sittings\"]=QueryContent( container_getter(get_current_parliament, \"sittings\"), title=_(\"section_scheduling_sittings\", default=u\"Sittings\"), description=_(u\"Plenary Sittings\")) ws_sched[\"agendaitems\"]=QueryContent( container_getter(get_current_parliament, \"agendaitems\"), title=_(\"section_scheduling_agenda_items\", default=u\"Agenda items\"), description=_(u\"Manage agenda items\")) workspace[\"groups\"]=WorkspaceSection( title=_(\"section_groups\", default=u\"Groups\"), description=_(u\"Bungeni Groups\"), default_name=\"my-groups\", marker=interfaces.IWorkspaceGroups) workspace[\"groups\"][\"my-groups\"]=WorkspaceGroupsContainer( name=\"my-groups\", title=_(u\"My Groups\"), description=_(u\"Groups that the user is a member of\")) for key, info in capi.iter_type_info(): if model_interfaces.IScheduleContent.implementedBy(info.domain_model): container_name=\"%ss\" % key container=\"%sContainer\" % info.domain_model.__name__ ws_sched[container_name]=getattr(domain, container)() to_locatable_container(info.domain_model, ws_sched[container_name]) admin=self.context[\"admin\"]=AdminSection( title=_(u\"Administration\"), description=_(u\"Manage bungeni settings\"), default_name=\"admin-index\", marker=model_interfaces.IBungeniAdmin) alsoProvides(admin, interfaces.ISearchableSection) content=admin[\"content\"]=Section( title=_(u\"Content\"), description=_(u\"browse bungeni content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"browse-admin\") admin[\"email-settings\"]=Section( title=_(u\"email settings\"), description=_(u\"manage email settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"email-settings\") admin[\"xapian-settings\"]=Section( title=_(u\"search index settings\"), description=_(u\"manage search index settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"xapian-settings\") admin[\"registry-settings\"]=Section( title=_(u\"registry settings\"), description=_(u\"manage registry settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"registry-settings\") admin[\"serialization-manager\"]=Section( title=_(u\"serialization manager\"), description=_(u\"batch serialization of content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"serialization-manager\") content[u\"parliaments\"]=domain.ParliamentContainer() to_locatable_container(domain.Parliament, content[u\"parliaments\"]) content[u\"users\"]=domain.UserContainer() to_locatable_container(domain.User, content[u\"users\"]) api=self.context[\"api\"]=APISection( title=_(u\"Bungeni API\"), description=_(u\"Bungeni REST API\"), default_name=\"index.html\", ) api[\"oauth\"]=OAuthSection( title=_(u\"Bungeni OAuth API\"), description=_(u\"Bungeni OAuth API\"), default_name=\"index.html\", ) api[u\"applications\"]=domain.OAuthApplicationContainer() to_locatable_container(domain.OAuthApplication, api[u\"applications\"]) ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"The Bungeni Application \n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.core.app\")\n\nfrom zope.interface import implements\nfrom zope.interface import implementedBy\nfrom zope import component\nfrom zope.interface.declarations import alsoProvides\n\nfrom zope.app.appsetup.appsetup import getConfigContext\nfrom zope.app.component import site\nfrom zope.location.interfaces import ILocation\n\nfrom ore.wsgiapp.app import Application\nfrom ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent\n\nfrom bungeni.models import domain\nfrom bungeni.models import interfaces as model_interfaces\nfrom bungeni.models.utils import get_current_parliament\nfrom bungeni.models.utils import container_getter\n\nfrom bungeni.core import interfaces\nfrom bungeni.core import location\nfrom bungeni.core.content import (Section, AdminSection, AkomaNtosoSection,\n    WorkspaceSection, APISection, OAuthSection)\nfrom bungeni.core.content import QueryContent\nfrom bungeni.core.i18n import _\nfrom bungeni.core.workspace import (WorkspaceContainer,\n    WorkspaceUnderConsiderationContainer,\n    WorkspaceTrackedDocumentsContainer,\n    WorkspaceGroupsContainer,\n    WorkspaceSchedulableContainer,\n    load_workspaces)\nfrom bungeni.core.notifications import load_notifications\nfrom bungeni.core.emailnotifications import load_email\nfrom bungeni.core.serialize import serialization_notifications\nfrom bungeni.ui.utils import url, common # !+ core dependency on ui\nfrom bungeni.capi import capi\nfrom bungeni.utils import register\n\n\n\n@register.handler(\n    (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent))\ndef on_wsgi_application_created_event(application, event):\n    \"\"\"Additional setup on IWSGIApplicationCreatedEvent.\n    \"\"\"\n    # !+ui.app.on_wsgi_application_created_event ALWAYS gets called prior to this\n    log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) \n    \n    # additional workflow validation\n    for type_key, ti in capi.iter_type_info():\n        if ti.workflow:\n            ti.workflow.validate_permissions_roles()\n    \n    # import events module, registering handlers\n    import bungeni.core.workflows.events\n    \n    # load workspaces\n    load_workspaces()\n    \n    # load notifications\n    load_notifications()\n\n    # load email notifications\n    load_email()\n\n    # set up serialization notifications\n    serialization_notifications()\n    \n    # import events modules, registering handlers\n    import bungeni.core.events\n    \n    app_setup = model_interfaces.IBungeniSetup(application)\n    app_setup.setUp()\n    \n    # write configuration parameters to xml\n    try:\n        import bungeni.utils.xmlconfexport as confexp\n        confexp.write_all()\n    except:\n        log.debug((\"on_wsgi_application_created :\"\n            \"error while exporting config parameters to xml\"))\n    \n    log.debug(\"on_wsgi_application_created_event: _features: %s\" % (\n        getConfigContext()._features))\n\n\ndef to_locatable_container(domain_class, *domain_containers):\n    component.provideAdapter(location.ContainerLocation(*domain_containers),\n               (implementedBy(domain_class), ILocation))\n\n\nclass BungeniApp(Application):\n    implements(model_interfaces.IBungeniApplication)\n\nclass AppSetup(object):\n    \n    implements(model_interfaces.IBungeniSetup)\n    \n    def __init__(self, application):\n        self.context = application\n    \n    def setUp(self):\n        \n        # register translations\n        #import zope.i18n.zcml\n        #zope.i18n.zcml.registerTranslations(getConfigContext(),\n        #    capi.get_path_for(\"translations\", \"bungeni\"))\n        # !+ZCML_PYTHON(mr, apr-2011) above registerTranslations() in python \n        # does not work, as subsequent utility lookup fails. We workaround it \n        # by executing the following parametrized bit of ZCML:\n        from zope.configuration import xmlconfig\n        xmlconfig.string(\"\"\"\n            <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\"\n                xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\">\n                <include package=\"zope.i18n\" file=\"meta.zcml\" \/>\n                <i18n:registerTranslations directory=\"%s\" \/>\n            <\/configure>\n            \"\"\" % (capi.get_path_for(\"translations\", \"bungeni\")))\n        \n        # ensure indexing facilities are setup(lazy)\n        import index\n        index.setupFieldDefinitions(index.indexer)\n        \n        sm = site.LocalSiteManager(self.context)\n        self.context.setSiteManager(sm)\n        \n        from bungeni.core import language\n        from bungeni.ui import z3evoque\n        z3evoque.set_get_gettext()\n        z3evoque.setup_evoque()\n        z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\"))\n        z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL)\n        z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name)\n        z3evoque.domain.set_on_globals(\"get_base_direction\", \n            language.get_base_direction)\n        z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl)          \n        \n        # !+ where is the view name for the app root (slash) set?\n        \n        # CONVENTION: the action of each site top-section is made to point \n        # directly the primary sub-section (the INDEX) that it contains.\n        # EXCEPTION: the \"\/\", when logged in, is redirected to \"\/workspace\/pi\"\n        \n        self.context[\"bungeni\"] = AkomaNtosoSection(\n            title=_(u\"Bungeni\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"bung\", # !+NAMING(mr, jul-2011) bung?!?\n        )\n        \n        # top-level sections\n        workspace = self.context[\"workspace\"] = WorkspaceSection(\n            title=_(\"section_workspace\", default=u\"Workspace\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"my-documents\",\n        )\n        alsoProvides(workspace, interfaces.ISearchableSection)\n        \n        workspace[\"my-documents\"] = WorkspaceSection(\n            title=_(\"section_workspace_documents\", default=u\"my documents\"),\n            description=_(u\"my documents workspace section\"),\n            default_name=\"inbox\",\n            marker=interfaces.IWorkspaceDocuments,\n        )\n        \n        for tab in capi.workspace_tabs:\n            workspace[\"my-documents\"][tab] = WorkspaceContainer(\n                tab_type=tab,\n                title=_(\"section_workspace_%s\" % tab, default=tab),\n                marker=interfaces.IWorkspaceTab\n            )\n\n        ws_uc = workspace[\"under-consideration\"] = WorkspaceSection(\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            default_name=\"documents\",\n            marker=interfaces.IWorkspaceUnderConsideration)\n        ws_uc[\"documents\"] = WorkspaceUnderConsiderationContainer(\n            name=\"documents\",\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            marker=interfaces.IWorkspaceTrackedDocuments)\n        ws_uc[\"tracked-documents\"] = WorkspaceTrackedDocumentsContainer(\n            name=\"tracked documents\",\n            title=_(u\"tracked documents\"),\n            description=_(u\"tracked documents\"))\n        \n        ws_sched = workspace[\"scheduling\"] = Section(\n            title=_(\"section_scheduling\", default=u\"Scheduling\"),\n            description=_(u\"Workspace Scheduling\"),\n            default_name=\"index\",\n            marker=interfaces.IWorkspaceScheduling)\n        ws_sched[\"committees\"] = QueryContent(\n            container_getter(get_current_parliament, \"committees\"),\n            title=_(\"section_scheduling_committees\", default=u\"Committees\"),\n            #!+marker=interfaces.ICommitteeAddContext,\n            description=_(u\"Committee schedules\"))\n        ws_sched[\"documents\"] = WorkspaceSchedulableContainer(\n            name=_(u\"schedulable items\"),\n            title=_(u\"schedulable items\"),\n            description=_(u\"documents available for scheduling\"))\n        ws_sched[\"sittings\"] = QueryContent(\n            container_getter(get_current_parliament, \"sittings\"),\n            title=_(\"section_scheduling_sittings\", default=u\"Sittings\"),\n            description=_(u\"Plenary Sittings\"))\n        ws_sched[\"agendaitems\"] = QueryContent(\n            container_getter(get_current_parliament, \"agendaitems\"),\n            title=_(\"section_scheduling_agenda_items\", \n                default=u\"Agenda items\"),\n            #marker=interfaces.IAgendaItemAddContext,\n            description=_(u\"Manage agenda items\"))\n        \n        workspace[\"groups\"] = WorkspaceSection(\n            title=_(\"section_groups\", default=u\"Groups\"),\n            description=_(u\"Bungeni Groups\"),\n            default_name=\"my-groups\",\n            marker=interfaces.IWorkspaceGroups)\n        workspace[\"groups\"][\"my-groups\"] = WorkspaceGroupsContainer(\n            name=\"my-groups\",\n            title=_(u\"My Groups\"),\n            description=_(u\"Groups that the user is a member of\"))\n        \n        #!+TIMING\n        #!+AUTO CONTAINERS SCHEDULING(mb, April-2012)\n        # type_info missing container name\n        for key, info in capi.iter_type_info():\n            if model_interfaces.IScheduleContent.implementedBy(info.domain_model):\n                container_name = \"%ss\" % key\n                container = \"%sContainer\" % info.domain_model.__name__\n                ws_sched[container_name] = getattr(domain, container)()\n                to_locatable_container(info.domain_model, ws_sched[container_name])\n        \n        \n        ##########\n        # Admin User Interface\n        # Administration section\n        \n        #!+SECURITY(miano. nov-2010) Admin section now uses AdminSection\n        # container that is identical to Section, only difference is that\n        # traversing though it requires zope.ManageSite permission as defined\n        # in core\/configure.zcml\n        \n        admin = self.context[\"admin\"] = AdminSection(\n            title=_(u\"Administration\"),\n            description=_(u\"Manage bungeni settings\"),\n            default_name=\"admin-index\",\n            marker=model_interfaces.IBungeniAdmin)\n        alsoProvides(admin, interfaces.ISearchableSection)\n        \n        content = admin[\"content\"] = Section(\n            title=_(u\"Content\"),\n            description=_(u\"browse bungeni content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"browse-admin\")\n        \n        admin[\"email-settings\"] = Section(\n            title=_(u\"email settings\"),\n            description=_(u\"manage email settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"email-settings\")\n        \n        admin[\"xapian-settings\"] = Section(\n            title=_(u\"search index settings\"),\n            description=_(u\"manage search index settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"xapian-settings\")\n        \n        admin[\"registry-settings\"] = Section(\n            title=_(u\"registry settings\"),\n            description=_(u\"manage registry settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"registry-settings\")\n        \n        admin[\"serialization-manager\"] = Section(\n            title=_(u\"serialization manager\"),\n            description=_(u\"batch serialization of content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"serialization-manager\")\n        \n        content[u\"parliaments\"] = domain.ParliamentContainer()\n        to_locatable_container(domain.Parliament, content[u\"parliaments\"])\n        \n        content[u\"users\"] = domain.UserContainer()\n        to_locatable_container(domain.User, content[u\"users\"])\n\n        api = self.context[\"api\"] = APISection(\n            title=_(u\"Bungeni API\"),\n            description=_(u\"Bungeni REST API\"),\n            default_name=\"index.html\",\n        )\n        api[\"oauth\"] = OAuthSection(\n            title=_(u\"Bungeni OAuth API\"),\n            description=_(u\"Bungeni OAuth API\"),\n            default_name=\"index.html\",\n        )\n        api[u\"applications\"] = domain.OAuthApplicationContainer()\n        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n"}},"msg":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings."}},"https:\/\/github.com\/malangalanga\/bungeni-portal":{"65c2f46a64dfa63dcf879c1b98d2cc45d1482415":{"url":"https:\/\/api.github.com\/repos\/malangalanga\/bungeni-portal\/commits\/65c2f46a64dfa63dcf879c1b98d2cc45d1482415","html_url":"https:\/\/github.com\/malangalanga\/bungeni-portal\/commit\/65c2f46a64dfa63dcf879c1b98d2cc45d1482415","message":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings.","sha":"65c2f46a64dfa63dcf879c1b98d2cc45d1482415","keyword":"replay attack improve","diff":"diff --git a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\nindex 44ae077ff..2d6b1645d 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py\n@@ -254,7 +254,7 @@ def permission_type_key(self):\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\nindex e328f6c85..96e0dc6f0 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py\n@@ -209,7 +209,14 @@ def oauth_authorization_token_expiry_time(self):\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self):\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\nindex 7435b4a3a..28e02aebf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py\n@@ -300,5 +300,5 @@ def setUp(self):\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"])\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\nindex 4ac3db531..8610d7e73 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/core\/dc.py\n@@ -573,4 +573,11 @@ def title(self):\n         context = _merged(self.context)\n         return component.getUtility(IRole, context.role_id).title\n \n+@register.adapter()\n+class OAuthApplicationDescriptiveProperties(DescriptiveProperties):\n+    component.adapts(interfaces.IOAuthApplication)\n \n+    @property\n+    def title(self):\n+        context = _merged(self.context)\n+        return context.name\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\nindex e747ae61c..7122485b2 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/interfaces.py\n@@ -578,6 +578,9 @@ class IDebateTake(interface.Interface):\n class IOAuthApplication(interface.Interface):\n     \"\"\"Marker interface for an OAuth Application record\"\"\"\n \n+class IOAuthApplicationContainer(IAlchemistContainer):\n+    \"\"\"Marker interface for an OAuth Applications container\"\"\"\n+\n class IOAuthAuthorization(interface.Interface):\n     \"\"\"Marker interfeace for OAuth authorizations\"\"\"\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\nindex e34a41ef8..3900cbd92 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/permissions.zcml\n@@ -163,8 +163,13 @@\n   <permission id=\"bungeni.debate_takes.View\" title=\"View debate takes\" \/>\n   <permission id=\"bungeni.debate_takes.Edit\" title=\"Edit debate takes\" \/>\n \n-  <permission id=\"bungeni.oauth_application.View\" title=\"View oauth app\" \/>\n-  <permission id=\"bungeni.oauth_application.Delete\" title=\"Delete oauth app\" \/>\n-  <meta:redefinePermission from=\"bungeni.oauth_application.View\" to=\"zope.ManageContent\" \/>\n+  <permission id=\"bungeni.o_auth_application.View\" title=\"View oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Add\" title=\"Add oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Edit\" title=\"Edit oauth app\" \/>\n+  <permission id=\"bungeni.o_auth_application.Delete\" title=\"Delete oauth app\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.View\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Add\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Edit\" to=\"zope.ManageContent\" \/>\n+  <meta:redefinePermission from=\"bungeni.o_auth_application.Delete\" to=\"zope.ManageContent\" \/>\n   <permission id=\"bungeni.oauth.View\" title=\"Use oauth api\" \/>\n <\/configure>\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\nindex 128a2c535..f1d0ed492 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/models\/schema.py\n@@ -1185,7 +1185,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"identifier\", rdb.UnicodeText, nullable=False, \n         unique=True),\n     rdb.Column(\"name\", rdb.UnicodeText, nullable=False),\n-    rdb.Column(\"secret\", rdb.String(32), nullable=False),\n+    rdb.Column(\"secret\", rdb.String(100), nullable=False),\n     rdb.Column(\"redirection_endpoint\", rdb.UnicodeText, nullable=False)\n )\n \n@@ -1195,7 +1195,7 @@ def _make_address_table(metadata, fk_key=\"user\"):\n         nullable=False),\n     rdb.Column(\"application_id\", rdb.Integer,\n         rdb.ForeignKey(\"oauth_application.application_id\"), nullable=False),\n-    rdb.Column(\"authorization_code\", rdb.String(32), nullable=False),\n+    rdb.Column(\"authorization_code\", rdb.String(100), nullable=False),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n     rdb.Column(\"active\", rdb.Boolean(), nullable=False)\n )\n@@ -1204,8 +1204,8 @@ def _make_address_table(metadata, fk_key=\"user\"):\n     rdb.Column(\"access_token_id\", rdb.Integer, primary_key=True),\n     rdb.Column(\"authorization_id\", rdb.Integer,\n              rdb.ForeignKey(\"oauth_authorization.authorization_id\")),\n-    rdb.Column(\"access_token\", rdb.String(32)),\n-    rdb.Column(\"refresh_token\", rdb.String(32)),\n+    rdb.Column(\"access_token\", rdb.String(100)),\n+    rdb.Column(\"refresh_token\", rdb.String(100)),\n     rdb.Column(\"expiry\", rdb.DateTime(timezone=False), nullable=False),\n )\n \ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\nindex 21c811509..bf1568c5e 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/api.py\n@@ -1,8 +1,10 @@\n import hashlib\n+import hmac\n import random\n import string\n import urllib\n import simplejson\n+import time\n from datetime import datetime, timedelta\n \n from sqlalchemy.orm.exc import NoResultFound\n@@ -30,8 +32,8 @@\n def get_key():\n     \"\"\"Return a randomly generated key\n     \"\"\"\n-    m = hashlib.sha256()\n-    m.update(\"\".join(random.sample(string.letters + string.digits, 32)))\n+    m = hashlib.sha1()\n+    m.update(\"\".join(random.sample(string.letters + string.digits, 20)))\n     return m.hexdigest()\n \n \n@@ -45,10 +47,10 @@ class AddOAuthApplication(forms.common.AddForm):\n     @form.action(_(u\"Create Application\"), name=\"create\")\n     def handle_create_application(self, action, data, validator=\"validateAdd\"):\n         oauth_app = domain.OAuthApplication()\n-        oauth_app.application_identifier = data[\"application_identifier\"]\n-        oauth_app.application_name = data[\"application_name\"]\n+        oauth_app.identifier = data[\"identifier\"]\n+        oauth_app.name = data[\"name\"]\n         oauth_app.redirection_endpoint = data[\"redirection_endpoint\"]\n-        oauth_app.application_key = get_key()\n+        oauth_app.secret = get_key()\n         session = Session()\n         session.add(oauth_app)\n         session.flush()\n@@ -163,41 +165,73 @@ def __call__(self):\n class IOAuthAuthorizeForm(interface.Interface):\n     client_id = schema.TextLine(required=False)\n     state = schema.TextLine(required=False)\n-\n+    time = schema.TextLine(required=False)\n+    nonce = schema.TextLine(required=False)\n \n class OAuthAuthorizeForm(form.FormBase):\n     form_fields = form.Fields(IOAuthAuthorizeForm)\n     form_fields[\"client_id\"].custom_widget = widgets.HiddenTextWidget\n     form_fields[\"state\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"nonce\"].custom_widget = widgets.HiddenTextWidget\n+    form_fields[\"time\"].custom_widget = widgets.HiddenTextWidget\n     template = NamedTemplate(\"alchemist.form\")\n     form_name = _(\"authorise_oauth_application\",\n         default=u\"Authorise OAuth Application\")\n \n     def __init__(self, context, request, parameters={}):\n         self.parameters = parameters\n+        if self.parameters:\n+            self.parameters[\"time\"] = time.time()\n+            self.parameters[\"nonce\"] = self.generate_nonce(\n+                self.parameters[\"time\"])\n         self.action_url = \"\/api\/oauth\/authorize-form\"\n         super(OAuthAuthorizeForm, self).__init__(context, request)\n \n     def setUpWidgets(self, ignore_request=False):\n+        \n         self.widgets = form.setUpWidgets(\n             self.form_fields, self.prefix, self.context, self.request,\n             data=self.parameters if self.parameters else self.request.form,\n             ignore_request=ignore_request\n         )\n \n-    @form.action(_(u\"Authorize application\"), name=\"authorize\")\n+    def generate_nonce(self, auth_time):\n+        data = \"{0}:{1}:{2}\".format(\n+            self.parameters[\"client_id\"], get_db_user().user_id, auth_time)\n+        return hmac.new(capi.oauth_hmac_key, data, hashlib.sha1).hexdigest()\n+\n+    def check_authorization(self, action, data):\n+        errors = []\n+        data = self.request.form\n+        if not data.get(\"form.time\", None) or not data.get(\"form.nonce\", None):\n+            errors.append(InvalidRequest)\n+            return errors\n+        max_time = datetime.fromtimestamp(float(data[\"form.time\"])) + \\\n+            timedelta(seconds=capi.oauth_authorization_token_expiry_time)\n+        if (datetime.now() > max_time):\n+            errors.append(InvalidGrant)\n+        if data[\"form.nonce\"] != self.generate_nonce(data[\"form.time\"]):\n+            errors.append(InvalidGrant)\n+        return errors\n+\n+    def handle_failure(self, action, data, errors):\n+        return ErrorPage(self.context, self.request, errors[0])()\n+\n+    @form.action(_(u\"Authorize application\"), name=\"authorize\",\n+        validator=check_authorization, failure=handle_failure)\n     def handle_authorize_app(self, action, data):\n         session = Session()\n         oauth_authorization = domain.OAuthAuthorization()\n         oauth_authorization.user_id = get_db_user().user_id\n         app = session.query(domain.OAuthApplication\n-            ).filter(domain.OAuthApplication.application_identifier ==\n+            ).filter(domain.OAuthApplication.identifier ==\n                 data[\"client_id\"]\n             ).one()\n         oauth_authorization.application_id = app.application_id\n         oauth_authorization.authorization_code = get_key()\n         oauth_authorization.expiry = datetime.now() + timedelta(\n-            seconds=capi.oauth_auth_expiry_time)\n+            seconds=capi.oauth_authorization_token_expiry_time)\n+        oauth_authorization.active = True\n         session.add(oauth_authorization)\n         redirect_uri = \"{0}?code={1}\".format(\n             app.redirection_endpoint, oauth_authorization.authorization_code)\n@@ -213,10 +247,10 @@ def handle_cancel(self, action, data):\n                      == data[\"client_id\"]\n             ).one()\n         error = UnauthorizedClient(app.redirection_endpoint, data[\"state\"])\n-        redirect_error(self.request, error)\n+        redirect_error(self.context, self.request, error)\n \n \n-def redirect_error(request, error):\n+def redirect_error(context, request, error):\n     if error.redirect_uri:\n         next_url = \"{0}?error={1}&error_description={2}\".format(\n             error.redirect_uri, error.error, error.error_description)\n@@ -224,10 +258,10 @@ def redirect_error(request, error):\n             next_url = \"{0}&state={1}\".format(next_url, error.state)\n         return request.response.redirect(next_url, trusted=True)\n     else:\n-        bad_request(request, error)\n+        return ErrorPage(context, request, error)()\n \n \n-def bad_request(request, error):\n+def bad_request(context, request, error):\n     request.response.setStatus(400)\n     data = {\"error\": error.error, \"error_description\": error.error_description}\n     return simplejson.dumps(data)\n@@ -277,7 +311,7 @@ def __call__(self):\n         except UnauthorizedClient as e:\n             return ErrorPage(self.context, self.request, e)()\n         except OAuthException as e:\n-            return redirect_error(self.request, e)\n+            return redirect_error(self.context, self.request, e)\n \n         if not IUnauthenticatedPrincipal.providedBy(self.request.principal):\n             # authorize form\n@@ -345,7 +379,7 @@ def __call__(self):\n         try:\n             parameters = self.parameters()\n         except OAuthException as e:\n-            return bad_request(self.request, e)\n+            return bad_request(self.context, self.request, e)\n         assert (self.authorization is not None,\n             \"Authorization object not initalized\")\n         self.authorization.expiry = datetime.now()\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\nindex 18c6363b5..1372b42bf 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/descriptor\/descriptor.py\n@@ -1718,13 +1718,13 @@ class ItemScheduleVoteDescriptor(ModelDescriptor):\n class OAuthApplicationDescriptor(ModelDescriptor):\n     localisable = False\n     fields = [\n-        F(name=\"application_identifier\",\n+        F(name=\"identifier\",\n           label=\"Unique Application Identifier\",\n           required=True,\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_name\",\n+        F(name=\"name\",\n           label=\"Application Name\",\n           required=True,\n           value_type=\"text\",\n@@ -1736,8 +1736,8 @@ class OAuthApplicationDescriptor(ModelDescriptor):\n           value_type=\"text\",\n           render_type=\"text_line\"\n         ),\n-        F(name=\"application_key\",\n-          label=\"Application Key\",\n+        F(name=\"secret\",\n+          label=\"Application Secret\",\n           localizable=[show(\"view\"), hide(\"add\")],\n           required=True,\n           value_type=\"text\",\ndiff --git a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\nindex 57deb7ee2..66b0dbd7b 100644\n--- a\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n+++ b\/bungeni.main\/branches\/oauth\/bungeni\/ui\/menu.zcml\n@@ -1265,5 +1265,14 @@\n      viewName=\"\"\n      weight=\"30\"\n      \/-->\n+   <!--OAuth-->\n+   <browser:menuItem menu=\"plone_contentmenu\"\n+        for=\"bungeni.models.interfaces.IOAuthApplicationContainer\"\n+        title=\"Add OAuth Application\"\n+        action=\"add\"\n+        permission=\"bungeni.o_auth_application.Add\"\n+        layer=\".interfaces.IAdminSectionLayer\"\n+        order=\"62\"\n+    \/>\n <\/configure>\n \n","files":{"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py":{"changes":[{"diff":"\n     (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n     (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n         # non-workflowed\n-    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n+    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),\n     (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n     (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n     (\"title_type\", TI(None, interfaces.ITitleType)),","add":1,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/alchemist\/type_info.py","badparts":["    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),"],"goodparts":["    (\"o_auth_application\", TI(None, interfaces.IOAuthApplication)),"]}],"source":"\n \"\"\"Aggregation of information about loaded domain types. No public methods here --all available methods from this are those exposed via bungeni.capi. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\") from zope.interface.interfaces import IInterface from zope.security.proxy import removeSecurityProxy from zope.dottedname.resolve import resolve from bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface from bungeni.alchemist.model import( new_custom_domain_interface, new_custom_domain_model, ) from bungeni.alchemist.catalyst import( INTERFACE_MODULE, MODEL_MODULE ) from bungeni.models import interfaces from bungeni.models import domain from bungeni.core.workflow.interfaces import IWorkflow from bungeni.utils import naming __all__=[] def _iter(): \"\"\"Return iterator on all(key, TypeInfo) entries in TYPE_REGISTRY. Usage: capi.iter_type_info() \"\"\" for type_key, ti in TYPE_REGISTRY: yield type_key, ti def _get(discriminator): \"\"\"Get the TypeInfo instance for discriminator, that may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: provides IBungeniContent domain model instance: type provides IBungeniContent descriptor: provides IModelDescriptor Raise KeyError if no entry matched. Usage: capi.get_type_info(discriminator) \"\"\" if discriminator is None: m=\"type_info._get discriminator is None\" log.error(m) raise ValueError(m) discri=removeSecurityProxy(discriminator) getter=None if IIModelInterface.providedBy(discri): discri=naming.type_key(\"table_schema_interface_name\", discri.__name__) elif IInterface.providedBy(discri): discri=naming.type_key(\"model_interface_name\", discri.__name__) elif type(discri) is type and issubclass(discri, domain.Entity): discri=naming.polymorphic_identity(discri) elif isinstance(discri, domain.Entity): discri=naming.polymorphic_identity(type(discri)) if isinstance(discri, basestring): getter=_get_by_type_key elif IWorkflow.providedBy(discri): getter=_get_by_workflow elif IModelDescriptor.implementedBy(discri): getter=_get_by_descriptor_model if getter is not None: ti=getter(discri) if ti is not None: return ti else: m=\"No type registered for discriminator: %r\" %(discriminator) else: m=\"Invalid type info lookup discriminator: %r\" %(discriminator) from bungeni.ui.utils import debug log.debug(debug.interfaces(discriminator)) log.debug(m) raise KeyError(m) def _get_by_type_key(key): for type_key, ti in _iter(): if type_key==key: return ti ''' !+IALCHEMISTCONTENT fails on different interfaces with same name! (Pdb) ti.interface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) ti.interface.__bases__ (<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>) (Pdb) iface <InterfaceClass bungeni.models.interfaces.ISession> (Pdb) iface.__bases__ (<InterfaceClass zope.interface.Interface>,) ''' def _get_by_model(model): for type_key, ti in _iter(): if model is ti.domain_model: return ti def _get_by_instance(instance): return _get_by_model(type(instance)) def _get_by_workflow(wf): for type_key, ti in _iter(): if wf is ti.workflow: return ti def _get_by_descriptor_model(descriptor_model): for type_key, ti in _iter(): if descriptor_model is ti.descriptor_model: return ti class TI(object): \"\"\"TypeInfo, associates together the following attributes for a given type: workflow_key the workflow file name defaults to the type_key for workflowed types that DO NOT specify is None for non-workflowed types workflow same workflow insatnce may be used by multiple types is None for non-workflowed types interface the manually applied application-dedicated model interface (if any) for the type derived_table_schema auto-generated db schema interface, provides IIModelInterface domain_model the domain class descriptor_model the descriptor model for UI views for the type container_class container class for domain_model container_interface interface for the container class for domain_model \"\"\" def __init__(self, workflow_key, iface, domain_model=None): self.workflow_key=workflow_key self.interface=iface self.derived_table_schema=None self.workflow=None self.domain_model=domain_model self.descriptor_model=None self.container_class=None self.container_interface=None self.custom=False def __str__(self): return str(self.__dict__) @property def scope(self): if self.custom: return \"custom\" if self.descriptor_model is not None: return self.descriptor_model.scope @property def permission_type_key(self): if self.custom: return self.workflow.name return(self.workflow_key or naming.type_key(\"model_name\", self.domain_model.__name__) ) ''' !+TYPE_REGISTRY externalize further to bungeni_custom, currently: -association of type key and dedicated interface are hard-wired here -ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when loading workflows and descriptors -type_key IS the underscore-separated lowercase of the domain cls name i.e. utils.naming.polymorphic_identity(domain_model) -!+ti.workflow_key SHOULD always be equal to type_key -!+corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated -!+dedicated interfaces for archetype incantations should be auto-generated, from specific workflow name\/attr... e.g. via: zope.interface.interface.InterfaceClass(iname, bases, __module__) -!+should ti.interface be automatically generated also for system types? Usage: from bungeni.capi import capi capi.get_type_info(discriminator) -> TypeInfo capi.iter_type_info() -> iterator of all registered(key, TypeInfo) ''' TYPE_REGISTRY=[ (\"user_address\", TI(\"address\", interfaces.IUserAddress)), (\"group_address\", TI(\"address\", interfaces.IGroupAddress)), (\"attachment\", TI(\"attachment\", interfaces.IAttachment)), (\"event\", TI(\"event\", interfaces.IEvent)), (\"sitting\", TI(\"sitting\", interfaces.ISitting)), (\"heading\", TI(\"heading\", interfaces.IHeading)), (\"user\", TI(\"user\", interfaces.IBungeniUser)), (\"signatory\", TI(\"signatory\", interfaces.ISignatory)), (\"group\", TI(\"group\", interfaces.IBungeniGroup)), (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)), (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)), (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)), (\"oauth_application\", TI(None, interfaces.IOAuthApplication)), (\"debate_media\", TI(None, interfaces.IDebateMedia)), (\"user_delegation\", TI(None, interfaces.IUserDelegation)), (\"title_type\", TI(None, interfaces.ITitleType)), (\"member_title\", TI(None, interfaces.IMemberTitle)), (\"change\", TI(None, interfaces.IChange)), (\"doc\", TI(None, interfaces.IDoc)), (\"doc_version\", TI(None, None)), (\"attachment_version\", TI(None, None)), (\"venue\", TI(None, interfaces.IVenue)), (\"session\", TI(None, interfaces.ISession)), (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)), (\"country\", TI(None, interfaces.ICountry)), (\"item_schedule\", TI(None, interfaces.IItemSchedule)), (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)), (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)), (\"editorial_note\", TI(None, interfaces.IEditorialNote)), (\"sitting_report\", TI(None, interfaces.ISittingReport)), (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)), ] def register_new_custom_type(type_key, workflow_key, archetype_key): \"\"\"Retrieve(create if needed) a domain interface and model for type_key, and register as new entry on TYPE_REGISTER. \"\"\" domain_iface_name=naming.model_interface_name(type_key) try: domain_iface=resolve(\"%s.%s\" %(INTERFACE_MODULE.__name__, domain_iface_name)) log.warn(\"Custom interface ALREADY EXISTS: %s\" %(domain_iface)) except ImportError: domain_iface=new_custom_domain_interface(type_key, domain_iface_name) domain_model_name=naming.model_name(type_key) try: domain_model=resolve(\"%s.%s\" %(MODEL_MODULE.__name__, domain_model_name)) log.warn(\"Custom domain model ALREADY EXISTS: %s\" %(domain_model)) except ImportError: domain_model=new_custom_domain_model(type_key, domain_iface, archetype_key) ti=TI(workflow_key, domain_iface, domain_model) ti.custom=True TYPE_REGISTRY.append((type_key, ti)) log.info(\"Registered custom type[%s]: %s\" %(archetype_key, type_key)) return type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Aggregation of information about loaded domain types.\n\nNo public methods here -- all available methods from this are those exposed \nvia bungeni.capi.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.alchemist.type_info\")\n\nfrom zope.interface.interfaces import IInterface\nfrom zope.security.proxy import removeSecurityProxy\nfrom zope.dottedname.resolve import resolve\n\nfrom bungeni.alchemist.interfaces import IModelDescriptor, IIModelInterface\nfrom bungeni.alchemist.model import (\n    new_custom_domain_interface,\n    new_custom_domain_model,\n)\nfrom bungeni.alchemist.catalyst import (\n    INTERFACE_MODULE, \n    MODEL_MODULE\n)\nfrom bungeni.models import interfaces\nfrom bungeni.models import domain\nfrom bungeni.core.workflow.interfaces import IWorkflow\nfrom bungeni.utils import naming\n\n__all__ = []\n\n\n# acessors exposed via capi\n\ndef _iter():\n    \"\"\"Return iterator on all (key, TypeInfo) entries in TYPE_REGISTRY.\n    \n    Usage: capi.iter_type_info()\n    \"\"\"\n    for type_key, ti in TYPE_REGISTRY:\n        yield type_key, ti\n\ndef _get(discriminator):\n    \"\"\"Get the TypeInfo instance for discriminator, that may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: provides IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor: provides IModelDescriptor\n    \n    Raise KeyError if no entry matched.\n    \n    Usage: capi.get_type_info(discriminator)\n    \"\"\"\n    if discriminator is None:\n        m = \"type_info._get discriminator is None\"\n        log.error(m)\n        raise ValueError(m)\n    discri = removeSecurityProxy(discriminator)\n    getter = None\n    \n    # !+IALCHEMISTCONTENT normalize trickier discriminator cases to type_key\n    if IIModelInterface.providedBy(discri):\n        discri = naming.type_key(\"table_schema_interface_name\", discri.__name__)\n    elif IInterface.providedBy(discri):\n        discri = naming.type_key(\"model_interface_name\", discri.__name__)\n    elif type(discri) is type and issubclass(discri, domain.Entity):\n        discri = naming.polymorphic_identity(discri)\n    elif isinstance(discri, domain.Entity):\n        discri = naming.polymorphic_identity(type(discri))\n    \n    if isinstance(discri, basestring):\n        getter = _get_by_type_key\n    #elif IInterface.providedBy(discri):\n    #    getter = _get_by_interface\n    #!+elif interfaces.IBungeniContent.implementedBy(discri):\n    #elif issubclass(discri, domain.Entity):\n    #    getter = _get_by_model\n    #!+elif interfaces.IBungeniContent.providedBy(discri):\n    #elif isinstance(discri, domain.Entity):\n    #    getter = _get_by_instance\n    elif IWorkflow.providedBy(discri):\n        getter = _get_by_workflow\n    elif IModelDescriptor.implementedBy(discri):\n        getter = _get_by_descriptor_model\n    \n    if getter is not None:\n        ti = getter(discri)\n        if ti is not None:\n            return ti\n        else:\n            m = \"No type registered for discriminator: %r\" % (discriminator)\n    else: \n        m = \"Invalid type info lookup discriminator: %r\" % (discriminator)\n    from bungeni.ui.utils import debug\n    log.debug(debug.interfaces(discriminator))\n    log.debug(m)\n    raise KeyError(m)\n\n\n# following getters return \"first matching\" TypeInfo instance in registry\n    \ndef _get_by_type_key(key):\n    for type_key, ti in _iter():\n        if type_key == key:\n            return ti\n#def _get_by_interface(iface):\n''' !+IALCHEMISTCONTENT fails on different interfaces with same name!\n(Pdb) ti.interface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) ti.interface.__bases__\n(<InterfaceClass ore.alchemist.interfaces.ITableSchema>, <InterfaceClass ore.alchemist.interfaces.IAlchemistContent>)\n(Pdb) iface\n<InterfaceClass bungeni.models.interfaces.ISession>\n(Pdb) iface.__bases__\n(<InterfaceClass zope.interface.Interface>,)\n'''\n#    for type_key, ti in _iter():\n#        if iface is ti.interface: #!+issubclass(iface, ti.interface)?\n#            return ti\ndef _get_by_model(model):\n    for type_key, ti in _iter():\n        if model is ti.domain_model: #!+issubclass(model, ti.domain_model)?\n            return ti\ndef _get_by_instance(instance):\n    return _get_by_model(type(instance))\ndef _get_by_workflow(wf):\n    for type_key, ti in _iter():\n        if wf is ti.workflow:\n            return ti\ndef _get_by_descriptor_model(descriptor_model):\n    for type_key, ti in _iter():\n        if descriptor_model is ti.descriptor_model:\n            return ti\n\n# \n\nclass TI(object):\n    \"\"\"TypeInfo, associates together the following attributes for a given type:\n            workflow_key \n                the workflow file name\n                defaults to the type_key for workflowed types that DO NOT specify\n                is None for non-workflowed types\n            workflow \n                same workflow insatnce may be used by multiple types\n                is None for non-workflowed types\n            interface\n                the manually applied application-dedicated model interface \n                (if any) for the type\n            derived_table_schema\n                auto-generated db schema interface, provides IIModelInterface\n            domain_model\n                the domain class\n            descriptor_model\n                the descriptor model for UI views for the type\n            container_class\n                container class for domain_model\n            container_interface\n                interface for the container class for domain_model\n    \"\"\"\n    def __init__(self, workflow_key, iface, domain_model=None):\n        self.workflow_key = workflow_key\n        self.interface = iface\n        self.derived_table_schema = None # provides IIModelInterface\n        self.workflow = None\n        self.domain_model = domain_model\n        self.descriptor_model = None\n        self.container_class = None\n        self.container_interface = None\n        self.custom = False # type loaded from custom configuration \n        # NOTE: only needed temporarily (until descriptor_model is set), \n        # then ti.custom not be inconsistent descriptor_model.scope i.e.\n        #if self.custom: assert self.descriptor_model.scope == \"custom\"\n        # !+ archetype_key?\n    def __str__(self):\n        return str(self.__dict__)\n    \n    @property\n    def scope(self):\n        # !+CUSTOM_TYPE_DESCRIPTOR the self.custom check below MUST precede the\n        # check on self.descriptor_model.scope as otherwise the \"in-transit\" \n        # custom types will not be picked up as custom types -- as during\n        # loading the descriptors for all custom types may not yet have been \n        # autogenerated (and would therefore correctly have \n        # descriptor_model.scope=\"custom\" set).\n        if self.custom:\n            return \"custom\"\n        if self.descriptor_model is not None:\n            return self.descriptor_model.scope\n    \n    @property\n    def permission_type_key(self):\n        if self.custom:\n            # custom types ALWAYS have a type_key-bound workflow instance - that\n            # may therefore have a different name than workflow_key e.g. Office\n            # uses the \"group\" workflow, that is type-relative reloaded as the\n            # \"office\" workflow instance.\n            return self.workflow.name\n        # system types ALWAYS use workflow_key - even if multiple types use the \n        # same workflow e.g. UserAddress & GroupAddress. \n        # if no workflow, compute type_key from domain_model\n        # #!+REDUNDANT(mb, 2012) This type key is already known during type\n        # setup i.e. TYPE_REGISTRY\n        return (self.workflow_key or \n            naming.type_key(\"model_name\", self.domain_model.__name__)\n        )\n\n'''\n!+TYPE_REGISTRY externalize further to bungeni_custom, currently:\n- association of type key and dedicated interface are hard-wired here\n- ti.workflow\/ti.domain_model\/ti.descriptor are added dynamically when \n  loading workflows and descriptors\n- type_key IS the underscore-separated lowercase of the domain cls name \n  i.e. utils.naming.polymorphic_identity(domain_model)\n- !+ ti.workflow_key SHOULD always be equal to type_key\n- !+ corresponding Container\/Version\/X interfaces should ALWAYS be auto-generated\n- !+ dedicated interfaces for archetype incantations should be auto-generated, \n    from specific workflow name\/attr... e.g. via:\n    zope.interface.interface.InterfaceClass(iname, bases, __module__)\n- !+ should ti.interface be automatically generated also for system types?\n\nUsage:\n    from bungeni.capi import capi\n    capi.get_type_info(discriminator) -> TypeInfo\n    capi.iter_type_info() -> iterator of all registered (key, TypeInfo)\n'''\nTYPE_REGISTRY = [\n    # (key, ti)\n    # - the type key, unique for each type, is the underscore-separated \n    #   lowercase name of the domain_model (the domain class)\n    # - order is relevant (dictates workflow loading order)\n    \n    # feature \"support\" types, system types, required\n    \n    # workflowed\n    (\"user_address\", TI(\"address\", interfaces.IUserAddress)),\n    (\"group_address\", TI(\"address\", interfaces.IGroupAddress)),\n    # !+Attachment (mr, jul-2011)\n    # a) must be loaded before any other type that *may* support attachments!\n    # b) MUST support versions\n    (\"attachment\", TI(\"attachment\", interfaces.IAttachment)),\n    (\"event\", TI(\"event\", interfaces.IEvent)),\n    (\"sitting\", TI(\"sitting\", interfaces.ISitting)),\n    (\"heading\", TI(\"heading\", interfaces.IHeading)),\n    (\"user\", TI(\"user\", interfaces.IBungeniUser)),\n    (\"signatory\", TI(\"signatory\", interfaces.ISignatory)),\n    \n    # !+NAMING: member-related -> Group name + \"Member\" (no + \"ship\")\n    (\"group\", TI(\"group\", interfaces.IBungeniGroup)),\n    (\"group_membership\", TI(\"group_membership\", interfaces.IBungeniGroupMembership)),\n    (\"group_document_assignment\", TI(\"group_assignment\", interfaces.IGroupDocumentAssignment)),\n    (\"debate_record\", TI(\"debate_record\", interfaces.IDebateRecord)),\n        # non-workflowed\n    (\"oauth_application\", TI(None, interfaces.IOAuthApplication)),\n    (\"debate_media\", TI(None, interfaces.IDebateMedia)),\n    (\"user_delegation\", TI(None, interfaces.IUserDelegation)),\n    (\"title_type\", TI(None, interfaces.ITitleType)),\n    (\"member_title\", TI(None, interfaces.IMemberTitle)),\n    (\"change\", TI(None, interfaces.IChange)),\n    (\"doc\", TI(None, interfaces.IDoc)),\n    (\"doc_version\", TI(None, None)), #interfaces.IDocVersion)), #!+IVERSION\n    (\"attachment_version\", TI(None, None)), #interfaces.IAttachmentVersion)), #!+IVERSION\n    (\"venue\", TI(None, interfaces.IVenue)),\n    (\"session\", TI(None, interfaces.ISession)),\n    (\"sitting_attendance\", TI(None, interfaces.ISittingAttendance)),\n    (\"country\", TI(None, interfaces.ICountry)),\n    (\"item_schedule\", TI(None, interfaces.IItemSchedule)),\n    (\"item_schedule_discussion\", TI(None, interfaces.IItemScheduleDiscussion)),\n    (\"item_schedule_vote\", TI(None, interfaces.IItemScheduleVote)),\n    (\"editorial_note\", TI(None, interfaces.IEditorialNote)),\n    (\"sitting_report\", TI(None, interfaces.ISittingReport)),\n    (\"group_membership_role\", TI(None, interfaces.IGroupMembershipRole)),\n    \n    # additional custom types are loaded dynamically from bungeni_custom\/types.xml\n]\n\n\n\n\n# register custom types\n\ndef register_new_custom_type(type_key, workflow_key, archetype_key):\n    \"\"\"Retrieve (create if needed) a domain interface and model for type_key,\n    and register as new entry on TYPE_REGISTER.\n    \"\"\"\n    \n    # generate custom domain interface\n    domain_iface_name = naming.model_interface_name(type_key)\n    try:\n        domain_iface = resolve(\"%s.%s\" % (INTERFACE_MODULE.__name__, domain_iface_name))\n        log.warn(\"Custom interface ALREADY EXISTS: %s\" % (domain_iface))\n    except ImportError:\n        domain_iface = new_custom_domain_interface(type_key, domain_iface_name)\n    \n    # generate custom domain_model\n    domain_model_name = naming.model_name(type_key)\n    try:\n        domain_model = resolve(\"%s.%s\" % (MODEL_MODULE.__name__, domain_model_name))\n        log.warn(\"Custom domain model ALREADY EXISTS: %s\" % (domain_model))\n    except ImportError:\n        domain_model = new_custom_domain_model(type_key, domain_iface, archetype_key)\n    \n    # type_info entry\n    ti = TI(workflow_key, domain_iface, domain_model)\n    ti.custom = True\n    TYPE_REGISTRY.append((type_key, ti))\n    \n    log.info(\"Registered custom type [%s]: %s\" % (archetype_key, type_key))\n    return type_key, ti\n\n\n\n\n\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py":{"changes":[{"diff":"\n         \"\"\"time in seconds before an oauth authorization code expires\n         max recommended time is 10min\n         \"\"\"\n-        return int(bc.oauth_auth_expiry_time)\n+        return int(bc.oauth_authorization_token_expiry_time)\n+\n+    @cached_property.cachedIn(\"__oauth_hmac_key__\")\n+    @bungeni_custom_errors\n+    def oauth_hmac_key(self):\n+        \"\"\"String used to to generate nonces. KEEP SECRET.\n+        \"\"\"\n+        return bc.oauth_hmac_key\n     # utility methods\n     \n     def get_root_path(self)","add":8,"remove":1,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/capi\/_capi.py","badparts":["        return int(bc.oauth_auth_expiry_time)"],"goodparts":["        return int(bc.oauth_authorization_token_expiry_time)","    @cached_property.cachedIn(\"__oauth_hmac_key__\")","    @bungeni_custom_errors","    def oauth_hmac_key(self):","        \"\"\"String used to to generate nonces. KEEP SECRET.","        \"\"\"","        return bc.oauth_hmac_key"]}],"source":"\n \"\"\"Defines the accessor class for Bungeni Custom parameters. See bungeni.capi __init__.py for usage. $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.capi\") import sys import time import os from zope.dottedname.resolve import resolve from zope.cachedescriptors import property as cached_property from bungeni.utils import error from bungeni.alchemist import type_info import bungeni_custom as bc class BungeniCustomError(Exception): \"\"\"A configuration error during loading of configuration. \"\"\" class BungeniCustomRuntimeError(BungeniCustomError): \"\"\"Internal error while executing a callable determined from configuration. \"\"\" def bungeni_custom_errors(f): \"\"\"Decorator to intercept any error raised by function f and re-raise it as a BungeniCustomError. To be used to decorate any function involved in reading\/validating\/processing any bungeni_custom parameters. \"\"\" return error.exceptions_as(BungeniCustomError)(f) def wrapped_callable(unwrapped): assert callable(unwrapped), unwrapped def wrapped(*args): log.debug(\"Calling %s with args: %s\" %(unwrapped, args)) try: return unwrapped(*args) except: exc=sys.exc_info()[1] log.debug(\"BungeniCustomRuntimeError[%r] in wrapped_callable: %s %s\", exc, wrapped, args) raise wrapped._unwrapped=unwrapped wrapped.__name__=unwrapped.__name__ return wrapped class CAPI(object): \"\"\"Accessor class for Bungeni Custom parameters. \"\"\" def __init__(self): self.validate_properties() def validate_properties(self): \"\"\"Validate this capi instance. Ensure valid setup of properties at instantiation of CAPI instance \"\"\" self.default_language self.country_code self.right_to_left_languages @property @bungeni_custom_errors def zope_i18n_allowed_languages(self): return tuple(bc.zope_i18n_allowed_languages.split()) @property @bungeni_custom_errors def zope_i18n_compile_mo_files(self): return bool( bc.zope_i18n_compile_mo_files is True or bc.zope_i18n_compile_mo_files==\"1\") @property @bungeni_custom_errors def country_code(self): \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this bungeni instance. \"\"\" return bc.country_code @property @bungeni_custom_errors def default_language(self): assert bc.default_language in self.zope_i18n_allowed_languages, \\ \"Default language[%s] not in allowed languages[%s]\" %( bc.default_language, self.zope_i18n_allowed_languages,) return bc.default_language @property @bungeni_custom_errors def right_to_left_languages(self): rtl_langs=tuple(bc.right_to_left_languages.split()) assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\ \"Right to left languages[%s] not in allowed languages[%s]\" %( bc.right_to_left_languages, self.zope_i18n_allowed_languages) return rtl_langs @property @bungeni_custom_errors def check_auto_reload_localization(self): \"\"\"() -> int minimum number of seconds to wait between checks for whether a localization file needs reloading; 0 means never check(deployment) \"\"\" int(bc.check_auto_reload_localization) return bc.check_auto_reload_localization @bungeni_custom_errors def get_workflow_condition(self, condition): condition_module=resolve(\"._conditions\", \"bungeni_custom.workflows\") condition=getattr(condition_module, condition) return wrapped_callable(condition) @bungeni_custom_errors def get_workflow_action(self, action): action_module=resolve(\"._actions\", \"bungeni_custom.workflows\") action=getattr(action_module, action) return wrapped_callable(action) @bungeni_custom_errors def get_form_constraint(self, constraint): constraint_module=resolve(\"._constraints\", \"bungeni_custom.forms\") constraint=getattr(constraint_module, constraint) return wrapped_callable(constraint) @bungeni_custom_errors def get_form_validator(self, validation): validator_module=resolve(\"._validations\", \"bungeni_custom.forms\") validator=getattr(validator_module, validation) return wrapped_callable(validator) @bungeni_custom_errors def get_form_derived(self, derived): derived_module=resolve(\"._derived\", \"bungeni_custom.forms\") derived_def=getattr(derived_module, derived) return wrapped_callable(derived_def) @property @bungeni_custom_errors def default_number_of_listing_items(self): \"\"\"This is the max number of items that are displayed in a listing by default. Returns an integer \"\"\" return int(bc.default_number_of_listing_items) @property @bungeni_custom_errors def long_text_column_listings_truncate_at(self): \"\"\"When listing text columns, only display first so many characters.\"\"\" return int(bc.long_text_column_listings_truncate_at) def xml_workspace_tabs_file(self): \"\"\"helper function used by workspace tab info APIs\"\"\" TABS_FILE=\"tabs.xml\" from lxml import etree ws_path=self.get_path_for(\"workspace\") file_path=os.path.join(ws_path, TABS_FILE) tabs=etree.fromstring(open(file_path).read()) return tabs @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\") @bungeni_custom_errors def workspace_tab_count_cache_refresh_time(self): \"\"\"The duration in seconds between tab count refresh operations\"\"\" tabs=self.xml_workspace_tabs_file() tabs_count_refresh=tabs.attrib[\"tab_count_cache_refresh_time\"] return int(tabs_count_refresh) @cached_property.cachedIn(\"__workspace_tabs__\") @bungeni_custom_errors def workspace_tabs(self): \"\"\"The tabs in the workspace\"\"\" ws_tabs=[] tabs=self.xml_workspace_tabs_file() for tab in tabs.iterchildren(tag=\"tab\"): ws_tabs.append(tab.attrib[\"id\"]) return ws_tabs @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\") @bungeni_custom_errors def oauth_access_token_expiry_time(self): \"\"\"time in seconds before an access token expires\"\"\" return(bc.oauth_access_token_expiry_time) @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\") @bungeni_custom_errors def oauth_authorization_token_expiry_time(self): \"\"\"time in seconds before an oauth authorization code expires max recommended time is 10min \"\"\" return int(bc.oauth_auth_expiry_time) def get_root_path(self): \"\"\"Get absolute physical path location for currently active bungeni_custom package folder. \"\"\" return os.path.dirname(os.path.abspath(bc.__file__)) def get_path_for(self, *path_components): \"\"\"Get absolute path, under bungeni_custom, for path_components. \"\"\" return os.path.join(*(self.get_root_path(),)+path_components) def put_env(self, key): \"\"\"Set capi value for{key} as the environment variable{key} i.e. use to set os.environ[key]. Wrapper on os.put_env(key, string_value) --to take care of the value string-casting required by os.put_env while still allowing the liberty of data-typing values of capi attributes as needed. \"\"\" value=getattr(self, key) try: os.environ[key]=value except TypeError: try: os.environ[key]=\" \".join(value) except TypeError: os.environ[key]=repr(value) assert eval(os.environ[key])==value _is_modified_since_last_times={} def is_modified_since(self, abspath, modified_on_first_check=True): \"\"\"(abspath:str, modified_on_first_check:bool) -> bool Checks file path st_mtime to see if file has been modified since last check. Updates entry per path, with last(check, modified) times. \"\"\" check_auto_reload_localization=self.check_auto_reload_localization now=time.time() last_checked, old_last_modified=\\ self._is_modified_since_last_times.get(abspath) or(0, 0) if not check_auto_reload_localization: if last_checked or not modified_on_first_check: return False if not now-last_checked > check_auto_reload_localization: return False last_modified=os.stat(abspath).st_mtime self._is_modified_since_last_times[abspath]=(now, last_modified) if not last_checked: return modified_on_first_check return(old_last_modified < last_modified) def get_type_info(self, discriminator): \"\"\"Get the TypeInfo instance for discriminator(see core.type_info). The discriminator may be any of: type_key: str(the lowercase underscore-separated of domain cls name) workflow: an instance of Workflow, provides IWorkflow interface: provides IInterface domain model: implements IBungeniContent domain model instance: type provides IBungeniContent descriptor_model: implements IModelDescriptor Raise KeyError if no entry matched. \"\"\" return type_info._get(discriminator) def iter_type_info(self, scope=None): \"\"\"Return iterator on all registered(key, TypeInfo) entries. scope:either(None, \"system\", \"archetype\", \"custom\") \"\"\" for type_key, ti in type_info._iter(): if(scope is None or ti.scope==scope): yield type_key, ti ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"Defines the accessor class for Bungeni Custom parameters.\n\nSee bungeni.capi __init__.py for usage.\n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.capi\")\n\nimport sys\nimport time\nimport os\nfrom zope.dottedname.resolve import resolve\nfrom zope.cachedescriptors import property as cached_property\nfrom bungeni.utils import error\nfrom bungeni.alchemist import type_info\nimport bungeni_custom as bc\n\n\n# utils \n\nclass BungeniCustomError(Exception):\n    \"\"\"A configuration error during loading of configuration.\n    \"\"\"\nclass BungeniCustomRuntimeError(BungeniCustomError): \n    \"\"\"Internal error while executing a callable determined from configuration.\n    \"\"\" \n\ndef bungeni_custom_errors(f):\n    \"\"\"Decorator to intercept any error raised by function f and re-raise it\n    as a BungeniCustomError. To be used to decorate any function involved \n    in reading\/validating\/processing any bungeni_custom parameters. \n    \"\"\"\n    return error.exceptions_as(BungeniCustomError)(f)\n\n\ndef wrapped_callable(unwrapped):\n    assert callable(unwrapped), unwrapped\n    def wrapped(*args):\n        log.debug(\"Calling %s with args: %s\" % (unwrapped, args))\n        try:\n            return unwrapped(*args)\n        except:\n            # intercept exc, to re-raise it *unchanged*, only for debugging\n            # e.g. constraints raise numerous (expected?) NoInputData errors\n            exc = sys.exc_info()[1]\n            log.debug(\"BungeniCustomRuntimeError [%r] in wrapped_callable: %s %s\",\n                    exc, wrapped, args)\n            raise\n    # remember original unwrapped callable\n    wrapped._unwrapped = unwrapped\n    wrapped.__name__ = unwrapped.__name__\n    return wrapped\n\n\n# capi (singleton)\n\nclass CAPI(object):\n    \"\"\"Accessor class for Bungeni Custom parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.validate_properties()\n    \n    def validate_properties(self):\n        \"\"\"Validate this capi instance.\n        Ensure valid setup of properties at instantiation of CAPI instance\n        \"\"\"\n        self.default_language\n        self.country_code\n        self.right_to_left_languages\n        \n    # bungeni_custom parameter properties\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_allowed_languages(self):\n        # NOTE: zope.i18n.config.ALLOWED_LANGUAGES expects the value of the \n        # env variable for this to be a COMMA or SPACE separated STRING\n        return tuple(bc.zope_i18n_allowed_languages.split())\n    \n    @property\n    @bungeni_custom_errors\n    def zope_i18n_compile_mo_files(self):\n        return bool(\n            bc.zope_i18n_compile_mo_files is True or \n            bc.zope_i18n_compile_mo_files == \"1\")\n   \n    @property\n    @bungeni_custom_errors\n    def country_code(self):\n        \"\"\"The official ISO 3166-1 alpha-2 country code for locale of this \n        bungeni instance.\n        \"\"\"\n        return bc.country_code\n\n    @property\n    @bungeni_custom_errors\n    def default_language(self):\n        assert bc.default_language in self.zope_i18n_allowed_languages, \\\n            \"Default language [%s] not in allowed languages [%s]\" % (\n                bc.default_language, self.zope_i18n_allowed_languages,)\n        return bc.default_language\n        \n    @property\n    @bungeni_custom_errors\n    def right_to_left_languages(self):\n        rtl_langs = tuple(bc.right_to_left_languages.split())\n        assert set(rtl_langs).issubset(set(self.zope_i18n_allowed_languages)),\\\n            \"Right to left languages [%s] not in allowed languages [%s]\" % (\n                bc.right_to_left_languages, self.zope_i18n_allowed_languages)\n        return rtl_langs\n    \n    @property\n    @bungeni_custom_errors\n    def check_auto_reload_localization(self):\n        \"\"\" () -> int\n        minimum number of seconds to wait between checks for whether a \n        localization file needs reloading; 0 means never check (deployment)\n        \"\"\"\n        int(bc.check_auto_reload_localization) # TypeError if not an int\n        return bc.check_auto_reload_localization\n    \n    \n    @bungeni_custom_errors\n    def get_workflow_condition(self, condition):\n        condition_module = resolve(\"._conditions\", \"bungeni_custom.workflows\")\n        condition = getattr(condition_module, condition) # raises AttributeError\n        return wrapped_callable(condition)\n    \n    @bungeni_custom_errors\n    def get_workflow_action(self, action):\n        action_module = resolve(\"._actions\", \"bungeni_custom.workflows\")\n        action = getattr(action_module, action) # raises AttributeError\n        return wrapped_callable(action)\n    \n    @bungeni_custom_errors\n    def get_form_constraint(self, constraint):\n        constraint_module = resolve(\"._constraints\", \"bungeni_custom.forms\")\n        constraint = getattr(constraint_module, constraint) # raises AttributeError\n        return wrapped_callable(constraint)\n    \n    @bungeni_custom_errors\n    def get_form_validator(self, validation):\n        validator_module = resolve(\"._validations\", \"bungeni_custom.forms\")\n        validator = getattr(validator_module, validation) # raises AttributeError\n        return wrapped_callable(validator)\n    \n    @bungeni_custom_errors\n    def get_form_derived(self, derived):\n        derived_module = resolve(\"._derived\", \"bungeni_custom.forms\")\n        derived_def = getattr(derived_module, derived) # raises AttributeError\n        return wrapped_callable(derived_def)\n    \n    \n    @property\n    @bungeni_custom_errors\n    def default_number_of_listing_items(self):\n        \"\"\"This is the max number of items that are displayed in a listing by\n        default. Returns an integer\n        \"\"\"\n        return int(bc.default_number_of_listing_items)\n    \n    @property\n    @bungeni_custom_errors\n    def long_text_column_listings_truncate_at(self):\n        \"\"\"When listing text columns, only display first so many characters.\"\"\"\n        return int(bc.long_text_column_listings_truncate_at)\n    \n    def xml_workspace_tabs_file(self):\n        \"\"\"helper function used by workspace tab info APIs\"\"\"\n        TABS_FILE = \"tabs.xml\"    \n        from lxml import etree\n        ws_path = self.get_path_for(\"workspace\")\n        file_path = os.path.join(ws_path, TABS_FILE)\n        tabs = etree.fromstring(open(file_path).read()) \n        return tabs                \n    \n    @cached_property.cachedIn(\"__workspace_tabs_count_refresh__\")\n    @bungeni_custom_errors\n    def workspace_tab_count_cache_refresh_time(self):\n        \"\"\"The duration in seconds between tab count refresh operations\"\"\"\n        tabs = self.xml_workspace_tabs_file()\n        tabs_count_refresh = tabs.attrib[\"tab_count_cache_refresh_time\"]\n        return int(tabs_count_refresh)\n    \n    @cached_property.cachedIn(\"__workspace_tabs__\")\n    @bungeni_custom_errors\n    def workspace_tabs(self):\n        \"\"\"The tabs in the workspace\"\"\"\n        ws_tabs = []\n        tabs = self.xml_workspace_tabs_file()\n        for tab in tabs.iterchildren(tag=\"tab\"):\n            ws_tabs.append(tab.attrib[\"id\"])\n        return ws_tabs    \n\n    @cached_property.cachedIn(\"__oauth_access_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_access_token_expiry_time(self):\n        \"\"\"time in seconds before an access token expires\"\"\"\n        return (bc.oauth_access_token_expiry_time)\n\n    @cached_property.cachedIn(\"__oauth_authorization_token_expiry_time__\")\n    @bungeni_custom_errors\n    def oauth_authorization_token_expiry_time(self):\n        \"\"\"time in seconds before an oauth authorization code expires\n        max recommended time is 10min\n        \"\"\"\n        return int(bc.oauth_auth_expiry_time)\n    # utility methods\n    \n    def get_root_path(self):\n        \"\"\"Get absolute physical path location for currently active \n        bungeni_custom package folder.\n        \"\"\"\n        return os.path.dirname(os.path.abspath(bc.__file__)) \n    \n    def get_path_for(self, *path_components):\n        \"\"\"Get absolute path, under bungeni_custom, for path_components.\n        \"\"\"\n        return os.path.join(*(self.get_root_path(),)+path_components)\n    \n    def put_env(self, key):\n        \"\"\"Set capi value for {key} as the environment variable {key}\n        i.e. use to set os.environ[key].\n        \n        Wrapper on os.put_env(key, string_value) -- to take care of\n        the value string-casting required by os.put_env while still \n        allowing the liberty of data-typing values of capi attributes \n        as needed.\n        \"\"\"\n        value = getattr(self, key)\n        try:\n            os.environ[key] = value\n            # OK, value is a string... done.\n        except TypeError:\n            # putenv() argument 2 must be string, not <...>\n            # i.e. value is NOT a string... try string-casting:\n            try:\n                # some zope code expects sequences to be specified as a \n                # COMMA or SPACE separated STRING, so we first try the value \n                # as a sequence, and serialize it to an environment variable \n                # value as expected by zope\n                os.environ[key] = \" \".join(value)\n            except TypeError:\n                # not a sequence, just fallback on repr(value)\n                os.environ[key] = repr(value)\n                # ensure that the original object value defines a __repr__ \n                # that can correctly re-instantiate the original object\n                assert eval(os.environ[key]) == value\n    \n    _is_modified_since_last_times = {} # {path: (last_checked, last_modified)}\n    def is_modified_since(self, abspath, modified_on_first_check=True):\n        \"\"\" (abspath:str, modified_on_first_check:bool) -> bool\n        Checks file path st_mtime to see if file has been modified since last \n        check. Updates entry per path, with last (check, modified) times.\n        \"\"\"\n        check_auto_reload_localization = self.check_auto_reload_localization\n        now = time.time()\n        last_checked, old_last_modified = \\\n            self._is_modified_since_last_times.get(abspath) or (0, 0)\n        if not check_auto_reload_localization:\n            # 0 =>> never check (unless this is the first check...)\n            if last_checked or not modified_on_first_check:\n                return False\n        if not now-last_checked > check_auto_reload_localization:\n            # last check too recent, avoid doing os.stat\n            return False\n        last_modified = os.stat(abspath).st_mtime\n        self._is_modified_since_last_times[abspath] = (now, last_modified)\n        if not last_checked:\n            # last_checked==0, this is the first check\n            return modified_on_first_check\n        return (old_last_modified < last_modified)\n    \n    # type registry\n    \n    def get_type_info(self, discriminator):\n        \"\"\"Get the TypeInfo instance for discriminator (see core.type_info). \n        \n        The discriminator may be any of:\n            type_key: str (the lowercase underscore-separated of domain cls name)\n            workflow: an instance of Workflow, provides IWorkflow\n            interface: provides IInterface\n            domain model: implements IBungeniContent\n            domain model instance: type provides IBungeniContent\n            descriptor_model: implements IModelDescriptor\n        \n        Raise KeyError if no entry matched.\n        \"\"\"\n        return type_info._get(discriminator)\n    \n    def iter_type_info(self, scope=None):\n        \"\"\"Return iterator on all registered (key, TypeInfo) entries.\n        scope:either(None, \"system\", \"archetype\", \"custom\")\n        \"\"\"\n        for type_key, ti in type_info._iter():\n            if (scope is None or ti.scope == scope):\n                yield type_key, ti\n\n\n"},"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py":{"changes":[{"diff":"\n             description=_(u\"Bungeni OAuth API\"),\n             default_name=\"index.html\",\n         )\n-        api[u\"applications\"] = domain.OAuthApplicationContainer()\n-        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n+        admin[u\"applications\"] = domain.OAuthApplicationContainer()\n+        to_locatable_container(domain.OAuthApplication, admin[u\"applications\"","add":2,"remove":2,"filename":"\/bungeni.main\/branches\/oauth\/bungeni\/core\/app.py","badparts":["        api[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])"],"goodparts":["        admin[u\"applications\"] = domain.OAuthApplicationContainer()","        to_locatable_container(domain.OAuthApplication, admin[u\"applications\""]}],"source":"\n \"\"\"The Bungeni Application $Id$ \"\"\" log=__import__(\"logging\").getLogger(\"bungeni.core.app\") from zope.interface import implements from zope.interface import implementedBy from zope import component from zope.interface.declarations import alsoProvides from zope.app.appsetup.appsetup import getConfigContext from zope.app.component import site from zope.location.interfaces import ILocation from ore.wsgiapp.app import Application from ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent from bungeni.models import domain from bungeni.models import interfaces as model_interfaces from bungeni.models.utils import get_current_parliament from bungeni.models.utils import container_getter from bungeni.core import interfaces from bungeni.core import location from bungeni.core.content import(Section, AdminSection, AkomaNtosoSection, WorkspaceSection, APISection, OAuthSection) from bungeni.core.content import QueryContent from bungeni.core.i18n import _ from bungeni.core.workspace import(WorkspaceContainer, WorkspaceUnderConsiderationContainer, WorkspaceTrackedDocumentsContainer, WorkspaceGroupsContainer, WorkspaceSchedulableContainer, load_workspaces) from bungeni.core.notifications import load_notifications from bungeni.core.emailnotifications import load_email from bungeni.core.serialize import serialization_notifications from bungeni.ui.utils import url, common from bungeni.capi import capi from bungeni.utils import register @register.handler( (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent)) def on_wsgi_application_created_event(application, event): \"\"\"Additional setup on IWSGIApplicationCreatedEvent. \"\"\" log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) for type_key, ti in capi.iter_type_info(): if ti.workflow: ti.workflow.validate_permissions_roles() import bungeni.core.workflows.events load_workspaces() load_notifications() load_email() serialization_notifications() import bungeni.core.events app_setup=model_interfaces.IBungeniSetup(application) app_setup.setUp() try: import bungeni.utils.xmlconfexport as confexp confexp.write_all() except: log.debug((\"on_wsgi_application_created:\" \"error while exporting config parameters to xml\")) log.debug(\"on_wsgi_application_created_event: _features: %s\" %( getConfigContext()._features)) def to_locatable_container(domain_class, *domain_containers): component.provideAdapter(location.ContainerLocation(*domain_containers), (implementedBy(domain_class), ILocation)) class BungeniApp(Application): implements(model_interfaces.IBungeniApplication) class AppSetup(object): implements(model_interfaces.IBungeniSetup) def __init__(self, application): self.context=application def setUp(self): from zope.configuration import xmlconfig xmlconfig.string(\"\"\" <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\" xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\"> <include package=\"zope.i18n\" file=\"meta.zcml\" \/> <i18n:registerTranslations directory=\"%s\" \/> <\/configure> \"\"\" %(capi.get_path_for(\"translations\", \"bungeni\"))) import index index.setupFieldDefinitions(index.indexer) sm=site.LocalSiteManager(self.context) self.context.setSiteManager(sm) from bungeni.core import language from bungeni.ui import z3evoque z3evoque.set_get_gettext() z3evoque.setup_evoque() z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\")) z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL) z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name) z3evoque.domain.set_on_globals(\"get_base_direction\", language.get_base_direction) z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl) self.context[\"bungeni\"]=AkomaNtosoSection( title=_(u\"Bungeni\"), description=_(u\"Current parliamentary activity\"), default_name=\"bung\", ) workspace=self.context[\"workspace\"]=WorkspaceSection( title=_(\"section_workspace\", default=u\"Workspace\"), description=_(u\"Current parliamentary activity\"), default_name=\"my-documents\", ) alsoProvides(workspace, interfaces.ISearchableSection) workspace[\"my-documents\"]=WorkspaceSection( title=_(\"section_workspace_documents\", default=u\"my documents\"), description=_(u\"my documents workspace section\"), default_name=\"inbox\", marker=interfaces.IWorkspaceDocuments, ) for tab in capi.workspace_tabs: workspace[\"my-documents\"][tab]=WorkspaceContainer( tab_type=tab, title=_(\"section_workspace_%s\" % tab, default=tab), marker=interfaces.IWorkspaceTab ) ws_uc=workspace[\"under-consideration\"]=WorkspaceSection( title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), default_name=\"documents\", marker=interfaces.IWorkspaceUnderConsideration) ws_uc[\"documents\"]=WorkspaceUnderConsiderationContainer( name=\"documents\", title=_(u\"under consideration\"), description=_(u\"documents under consideration\"), marker=interfaces.IWorkspaceTrackedDocuments) ws_uc[\"tracked-documents\"]=WorkspaceTrackedDocumentsContainer( name=\"tracked documents\", title=_(u\"tracked documents\"), description=_(u\"tracked documents\")) ws_sched=workspace[\"scheduling\"]=Section( title=_(\"section_scheduling\", default=u\"Scheduling\"), description=_(u\"Workspace Scheduling\"), default_name=\"index\", marker=interfaces.IWorkspaceScheduling) ws_sched[\"committees\"]=QueryContent( container_getter(get_current_parliament, \"committees\"), title=_(\"section_scheduling_committees\", default=u\"Committees\"), description=_(u\"Committee schedules\")) ws_sched[\"documents\"]=WorkspaceSchedulableContainer( name=_(u\"schedulable items\"), title=_(u\"schedulable items\"), description=_(u\"documents available for scheduling\")) ws_sched[\"sittings\"]=QueryContent( container_getter(get_current_parliament, \"sittings\"), title=_(\"section_scheduling_sittings\", default=u\"Sittings\"), description=_(u\"Plenary Sittings\")) ws_sched[\"agendaitems\"]=QueryContent( container_getter(get_current_parliament, \"agendaitems\"), title=_(\"section_scheduling_agenda_items\", default=u\"Agenda items\"), description=_(u\"Manage agenda items\")) workspace[\"groups\"]=WorkspaceSection( title=_(\"section_groups\", default=u\"Groups\"), description=_(u\"Bungeni Groups\"), default_name=\"my-groups\", marker=interfaces.IWorkspaceGroups) workspace[\"groups\"][\"my-groups\"]=WorkspaceGroupsContainer( name=\"my-groups\", title=_(u\"My Groups\"), description=_(u\"Groups that the user is a member of\")) for key, info in capi.iter_type_info(): if model_interfaces.IScheduleContent.implementedBy(info.domain_model): container_name=\"%ss\" % key container=\"%sContainer\" % info.domain_model.__name__ ws_sched[container_name]=getattr(domain, container)() to_locatable_container(info.domain_model, ws_sched[container_name]) admin=self.context[\"admin\"]=AdminSection( title=_(u\"Administration\"), description=_(u\"Manage bungeni settings\"), default_name=\"admin-index\", marker=model_interfaces.IBungeniAdmin) alsoProvides(admin, interfaces.ISearchableSection) content=admin[\"content\"]=Section( title=_(u\"Content\"), description=_(u\"browse bungeni content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"browse-admin\") admin[\"email-settings\"]=Section( title=_(u\"email settings\"), description=_(u\"manage email settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"email-settings\") admin[\"xapian-settings\"]=Section( title=_(u\"search index settings\"), description=_(u\"manage search index settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"xapian-settings\") admin[\"registry-settings\"]=Section( title=_(u\"registry settings\"), description=_(u\"manage registry settings\"), marker=model_interfaces.IBungeniAdmin, default_name=\"registry-settings\") admin[\"serialization-manager\"]=Section( title=_(u\"serialization manager\"), description=_(u\"batch serialization of content\"), marker=model_interfaces.IBungeniAdmin, default_name=\"serialization-manager\") content[u\"parliaments\"]=domain.ParliamentContainer() to_locatable_container(domain.Parliament, content[u\"parliaments\"]) content[u\"users\"]=domain.UserContainer() to_locatable_container(domain.User, content[u\"users\"]) api=self.context[\"api\"]=APISection( title=_(u\"Bungeni API\"), description=_(u\"Bungeni REST API\"), default_name=\"index.html\", ) api[\"oauth\"]=OAuthSection( title=_(u\"Bungeni OAuth API\"), description=_(u\"Bungeni OAuth API\"), default_name=\"index.html\", ) api[u\"applications\"]=domain.OAuthApplicationContainer() to_locatable_container(domain.OAuthApplication, api[u\"applications\"]) ","sourceWithComments":"# Bungeni Parliamentary Information System - http:\/\/www.bungeni.org\/\n# Copyright (C) 2010 - Africa i-Parliaments - http:\/\/www.parliaments.info\/\n# Licensed under GNU GPL v2 - http:\/\/www.gnu.org\/licenses\/gpl-2.0.txt\n\n\"\"\"The Bungeni Application \n\n$Id$\n\"\"\"\nlog = __import__(\"logging\").getLogger(\"bungeni.core.app\")\n\nfrom zope.interface import implements\nfrom zope.interface import implementedBy\nfrom zope import component\nfrom zope.interface.declarations import alsoProvides\n\nfrom zope.app.appsetup.appsetup import getConfigContext\nfrom zope.app.component import site\nfrom zope.location.interfaces import ILocation\n\nfrom ore.wsgiapp.app import Application\nfrom ore.wsgiapp.interfaces import IWSGIApplicationCreatedEvent\n\nfrom bungeni.models import domain\nfrom bungeni.models import interfaces as model_interfaces\nfrom bungeni.models.utils import get_current_parliament\nfrom bungeni.models.utils import container_getter\n\nfrom bungeni.core import interfaces\nfrom bungeni.core import location\nfrom bungeni.core.content import (Section, AdminSection, AkomaNtosoSection,\n    WorkspaceSection, APISection, OAuthSection)\nfrom bungeni.core.content import QueryContent\nfrom bungeni.core.i18n import _\nfrom bungeni.core.workspace import (WorkspaceContainer,\n    WorkspaceUnderConsiderationContainer,\n    WorkspaceTrackedDocumentsContainer,\n    WorkspaceGroupsContainer,\n    WorkspaceSchedulableContainer,\n    load_workspaces)\nfrom bungeni.core.notifications import load_notifications\nfrom bungeni.core.emailnotifications import load_email\nfrom bungeni.core.serialize import serialization_notifications\nfrom bungeni.ui.utils import url, common # !+ core dependency on ui\nfrom bungeni.capi import capi\nfrom bungeni.utils import register\n\n\n\n@register.handler(\n    (model_interfaces.IBungeniApplication, IWSGIApplicationCreatedEvent))\ndef on_wsgi_application_created_event(application, event):\n    \"\"\"Additional setup on IWSGIApplicationCreatedEvent.\n    \"\"\"\n    # !+ui.app.on_wsgi_application_created_event ALWAYS gets called prior to this\n    log.debug(\"CORE ON_WSGI_APPLICATION_CREATED_EVENT: %s, %s\", application, event) \n    \n    # additional workflow validation\n    for type_key, ti in capi.iter_type_info():\n        if ti.workflow:\n            ti.workflow.validate_permissions_roles()\n    \n    # import events module, registering handlers\n    import bungeni.core.workflows.events\n    \n    # load workspaces\n    load_workspaces()\n    \n    # load notifications\n    load_notifications()\n\n    # load email notifications\n    load_email()\n\n    # set up serialization notifications\n    serialization_notifications()\n    \n    # import events modules, registering handlers\n    import bungeni.core.events\n    \n    app_setup = model_interfaces.IBungeniSetup(application)\n    app_setup.setUp()\n    \n    # write configuration parameters to xml\n    try:\n        import bungeni.utils.xmlconfexport as confexp\n        confexp.write_all()\n    except:\n        log.debug((\"on_wsgi_application_created :\"\n            \"error while exporting config parameters to xml\"))\n    \n    log.debug(\"on_wsgi_application_created_event: _features: %s\" % (\n        getConfigContext()._features))\n\n\ndef to_locatable_container(domain_class, *domain_containers):\n    component.provideAdapter(location.ContainerLocation(*domain_containers),\n               (implementedBy(domain_class), ILocation))\n\n\nclass BungeniApp(Application):\n    implements(model_interfaces.IBungeniApplication)\n\nclass AppSetup(object):\n    \n    implements(model_interfaces.IBungeniSetup)\n    \n    def __init__(self, application):\n        self.context = application\n    \n    def setUp(self):\n        \n        # register translations\n        #import zope.i18n.zcml\n        #zope.i18n.zcml.registerTranslations(getConfigContext(),\n        #    capi.get_path_for(\"translations\", \"bungeni\"))\n        # !+ZCML_PYTHON(mr, apr-2011) above registerTranslations() in python \n        # does not work, as subsequent utility lookup fails. We workaround it \n        # by executing the following parametrized bit of ZCML:\n        from zope.configuration import xmlconfig\n        xmlconfig.string(\"\"\"\n            <configure xmlns=\"http:\/\/namespaces.zope.org\/zope\"\n                xmlns:i18n=\"http:\/\/namespaces.zope.org\/i18n\">\n                <include package=\"zope.i18n\" file=\"meta.zcml\" \/>\n                <i18n:registerTranslations directory=\"%s\" \/>\n            <\/configure>\n            \"\"\" % (capi.get_path_for(\"translations\", \"bungeni\")))\n        \n        # ensure indexing facilities are setup(lazy)\n        import index\n        index.setupFieldDefinitions(index.indexer)\n        \n        sm = site.LocalSiteManager(self.context)\n        self.context.setSiteManager(sm)\n        \n        from bungeni.core import language\n        from bungeni.ui import z3evoque\n        z3evoque.set_get_gettext()\n        z3evoque.setup_evoque()\n        z3evoque.domain.set_on_globals(\"devmode\", common.has_feature(\"devmode\"))\n        z3evoque.domain.set_on_globals(\"absoluteURL\", url.absoluteURL)\n        z3evoque.domain.set_on_globals(\"get_section_name\", url.get_section_name)\n        z3evoque.domain.set_on_globals(\"get_base_direction\", \n            language.get_base_direction)\n        z3evoque.domain.set_on_globals(\"is_rtl\", language.is_rtl)          \n        \n        # !+ where is the view name for the app root (slash) set?\n        \n        # CONVENTION: the action of each site top-section is made to point \n        # directly the primary sub-section (the INDEX) that it contains.\n        # EXCEPTION: the \"\/\", when logged in, is redirected to \"\/workspace\/pi\"\n        \n        self.context[\"bungeni\"] = AkomaNtosoSection(\n            title=_(u\"Bungeni\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"bung\", # !+NAMING(mr, jul-2011) bung?!?\n        )\n        \n        # top-level sections\n        workspace = self.context[\"workspace\"] = WorkspaceSection(\n            title=_(\"section_workspace\", default=u\"Workspace\"),\n            description=_(u\"Current parliamentary activity\"),\n            default_name=\"my-documents\",\n        )\n        alsoProvides(workspace, interfaces.ISearchableSection)\n        \n        workspace[\"my-documents\"] = WorkspaceSection(\n            title=_(\"section_workspace_documents\", default=u\"my documents\"),\n            description=_(u\"my documents workspace section\"),\n            default_name=\"inbox\",\n            marker=interfaces.IWorkspaceDocuments,\n        )\n        \n        for tab in capi.workspace_tabs:\n            workspace[\"my-documents\"][tab] = WorkspaceContainer(\n                tab_type=tab,\n                title=_(\"section_workspace_%s\" % tab, default=tab),\n                marker=interfaces.IWorkspaceTab\n            )\n\n        ws_uc = workspace[\"under-consideration\"] = WorkspaceSection(\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            default_name=\"documents\",\n            marker=interfaces.IWorkspaceUnderConsideration)\n        ws_uc[\"documents\"] = WorkspaceUnderConsiderationContainer(\n            name=\"documents\",\n            title=_(u\"under consideration\"),\n            description=_(u\"documents under consideration\"),\n            marker=interfaces.IWorkspaceTrackedDocuments)\n        ws_uc[\"tracked-documents\"] = WorkspaceTrackedDocumentsContainer(\n            name=\"tracked documents\",\n            title=_(u\"tracked documents\"),\n            description=_(u\"tracked documents\"))\n        \n        ws_sched = workspace[\"scheduling\"] = Section(\n            title=_(\"section_scheduling\", default=u\"Scheduling\"),\n            description=_(u\"Workspace Scheduling\"),\n            default_name=\"index\",\n            marker=interfaces.IWorkspaceScheduling)\n        ws_sched[\"committees\"] = QueryContent(\n            container_getter(get_current_parliament, \"committees\"),\n            title=_(\"section_scheduling_committees\", default=u\"Committees\"),\n            #!+marker=interfaces.ICommitteeAddContext,\n            description=_(u\"Committee schedules\"))\n        ws_sched[\"documents\"] = WorkspaceSchedulableContainer(\n            name=_(u\"schedulable items\"),\n            title=_(u\"schedulable items\"),\n            description=_(u\"documents available for scheduling\"))\n        ws_sched[\"sittings\"] = QueryContent(\n            container_getter(get_current_parliament, \"sittings\"),\n            title=_(\"section_scheduling_sittings\", default=u\"Sittings\"),\n            description=_(u\"Plenary Sittings\"))\n        ws_sched[\"agendaitems\"] = QueryContent(\n            container_getter(get_current_parliament, \"agendaitems\"),\n            title=_(\"section_scheduling_agenda_items\", \n                default=u\"Agenda items\"),\n            #marker=interfaces.IAgendaItemAddContext,\n            description=_(u\"Manage agenda items\"))\n        \n        workspace[\"groups\"] = WorkspaceSection(\n            title=_(\"section_groups\", default=u\"Groups\"),\n            description=_(u\"Bungeni Groups\"),\n            default_name=\"my-groups\",\n            marker=interfaces.IWorkspaceGroups)\n        workspace[\"groups\"][\"my-groups\"] = WorkspaceGroupsContainer(\n            name=\"my-groups\",\n            title=_(u\"My Groups\"),\n            description=_(u\"Groups that the user is a member of\"))\n        \n        #!+TIMING\n        #!+AUTO CONTAINERS SCHEDULING(mb, April-2012)\n        # type_info missing container name\n        for key, info in capi.iter_type_info():\n            if model_interfaces.IScheduleContent.implementedBy(info.domain_model):\n                container_name = \"%ss\" % key\n                container = \"%sContainer\" % info.domain_model.__name__\n                ws_sched[container_name] = getattr(domain, container)()\n                to_locatable_container(info.domain_model, ws_sched[container_name])\n        \n        \n        ##########\n        # Admin User Interface\n        # Administration section\n        \n        #!+SECURITY(miano. nov-2010) Admin section now uses AdminSection\n        # container that is identical to Section, only difference is that\n        # traversing though it requires zope.ManageSite permission as defined\n        # in core\/configure.zcml\n        \n        admin = self.context[\"admin\"] = AdminSection(\n            title=_(u\"Administration\"),\n            description=_(u\"Manage bungeni settings\"),\n            default_name=\"admin-index\",\n            marker=model_interfaces.IBungeniAdmin)\n        alsoProvides(admin, interfaces.ISearchableSection)\n        \n        content = admin[\"content\"] = Section(\n            title=_(u\"Content\"),\n            description=_(u\"browse bungeni content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"browse-admin\")\n        \n        admin[\"email-settings\"] = Section(\n            title=_(u\"email settings\"),\n            description=_(u\"manage email settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"email-settings\")\n        \n        admin[\"xapian-settings\"] = Section(\n            title=_(u\"search index settings\"),\n            description=_(u\"manage search index settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"xapian-settings\")\n        \n        admin[\"registry-settings\"] = Section(\n            title=_(u\"registry settings\"),\n            description=_(u\"manage registry settings\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"registry-settings\")\n        \n        admin[\"serialization-manager\"] = Section(\n            title=_(u\"serialization manager\"),\n            description=_(u\"batch serialization of content\"),\n            marker=model_interfaces.IBungeniAdmin,\n            default_name=\"serialization-manager\")\n        \n        content[u\"parliaments\"] = domain.ParliamentContainer()\n        to_locatable_container(domain.Parliament, content[u\"parliaments\"])\n        \n        content[u\"users\"] = domain.UserContainer()\n        to_locatable_container(domain.User, content[u\"users\"])\n\n        api = self.context[\"api\"] = APISection(\n            title=_(u\"Bungeni API\"),\n            description=_(u\"Bungeni REST API\"),\n            default_name=\"index.html\",\n        )\n        api[\"oauth\"] = OAuthSection(\n            title=_(u\"Bungeni OAuth API\"),\n            description=_(u\"Bungeni OAuth API\"),\n            default_name=\"index.html\",\n        )\n        api[u\"applications\"] = domain.OAuthApplicationContainer()\n        to_locatable_container(domain.OAuthApplication, api[u\"applications\"])\n"}},"msg":"Improved error checking and handling in OAuth API. Added nonce to authorization form to prevent replay attacks. Moved OAuth application containter to admin settings."}},"https:\/\/github.com\/nextleap-project\/countermitm":{"8fcedc69338844b9768b78dc7b7010901ca95dad":{"url":"https:\/\/api.github.com\/repos\/nextleap-project\/countermitm\/commits\/8fcedc69338844b9768b78dc7b7010901ca95dad","html_url":"https:\/\/github.com\/nextleap-project\/countermitm\/commit\/8fcedc69338844b9768b78dc7b7010901ca95dad","message":"Version 0.10.0 (Incorporating feedback and finalizing)\n\n- include feedback received after sharing countermitm\n  with the messaging@moderncrypto.org mailing list:\n\n  - build verified group and history verification\n    based on contact verification.\n\n  - prevent replay attacks\n\n- improve readability and clarity in the entire document.\n  (Wouter Lueks)\n\n- refine and document the interaction of encryption\n  with verified and opportunistic Autocrypt keys.\n\n- address device loss in a verified group scenario.\n\n- add presentation slides for OpenPGP Summit 2018 in Brussels.","sha":"8fcedc69338844b9768b78dc7b7010901ca95dad","keyword":"replay attack improve","diff":"diff --git a\/source\/conf.py b\/source\/conf.py\nindex ba929c1..1b58ae5 100644\n--- a\/source\/conf.py\n+++ b\/source\/conf.py\n@@ -58,9 +58,9 @@\n # built documents.\n #\n # The short X.Y version.\n-version = u'0.9'\n+version = u'0.10'\n # The full version, including alpha\/beta\/rc tags.\n-release = u'0.9.1'\n+release = u'0.10.0'\n \n # The language for content autogenerated by Sphinx. Refer to documentation\n # for a list of supported languages.\n","files":{"\/source\/conf.py":{"changes":[{"diff":"\n # built documents.\n #\n # The short X.Y version.\n-version = u'0.9'\n+version = u'0.10'\n # The full version, including alpha\/beta\/rc tags.\n-release = u'0.9.1'\n+release = u'0.10.0'\n \n # The language for content autogenerated by Sphinx. Refer to documentation\n # for a list of supported languages.\n","add":2,"remove":2,"filename":"\/source\/conf.py","badparts":["version = u'0.9'","release = u'0.9.1'"],"goodparts":["version = u'0.10'","release = u'0.10.0'"]}],"source":"\n import sys import os extensions=[ 'sphinx.ext.intersphinx', 'sphinx.ext.todo', 'sphinx.ext.mathjax', ] templates_path=['_templates'] source_suffix='.rst' master_doc='index' project=u'Counter Mitm' copyright=u'2018' author=u'NEXTLEAP researchers' version=u'0.9' release=u'0.9.1' language=None exclude_patterns=['drafts'] pygments_style='sphinx' todo_include_todos=False html_theme='alabaster' html_logo=\"img\/nextleap_logo_transp_1004x538.png\" html_static_path=['_static'] html_sidebars={ 'index':[ 'sidebarintro.html', 'globaltoc.html', 'searchbox.html' ], '**':[ 'sidebarintro.html', 'globaltoc.html', 'relations.html', 'searchbox.html' ] } htmlhelp_basename='CounterMitmdoc' latex_elements={ 'pointsize': '12pt', 'preamble': '''\\\\setcounter{secnumdepth}{3}''', 'preamble': ''' \\\\newcommand{\\\\countermitmrelease}{%s} \\\\setcounter{secnumdepth}{3} '''%(release,), } latex_documents=[ (master_doc, 'CounterMitm.tex', u'Detecting and preventing active attacks against Autocrypt', u'NEXTLEAP researchers', 'howto'), ] latex_use_parts=False latex_show_pagerefs=True latex_show_urls='footnote' latex_domain_indices=False man_pages=[ (master_doc, 'countermitm', u'Detecting and preventing active attacks against Autocrypt', [author], 1) ] texinfo_documents=[ (master_doc, 'CounterMitm', u'Counter Mitm Documentation', author, 'CounterMitm', 'One line description of project.', 'Miscellaneous'), ] if __name__==\"__main__\": print(release) ","sourceWithComments":"# -*- coding: utf-8 -*-\n#\n# Counter Mitm documentation build configuration file, created by\n# sphinx-quickstart on Fri Jan 12 14:21:14 2018.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#sys.path.insert(0, os.path.abspath('.'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    'sphinx.ext.intersphinx',\n    'sphinx.ext.todo',\n    'sphinx.ext.mathjax',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = '.rst'\n\n# The encoding of source files.\n#source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# General information about the project.\nproject = u'Counter Mitm'\ncopyright = u'2018'\nauthor = u'NEXTLEAP researchers'\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u'0.9'\n# The full version, including alpha\/beta\/rc tags.\nrelease = u'0.9.1'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = ['drafts']\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n#default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'sphinx'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n# If true, keep warnings as \"system message\" paragraphs in the built documents.\n#keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = 'alabaster'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\nhtml_logo = \"img\/nextleap_logo_transp_1004x538.png\"\n\n# The name of an image file (relative to this directory) to use as a favicon of\n# the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n#html_extra_path = []\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\nhtml_sidebars = {\n    'index': [\n        'sidebarintro.html',\n        'globaltoc.html',\n        'searchbox.html'\n    ],\n    '**': [\n        'sidebarintro.html',\n        'globaltoc.html',\n        'relations.html',\n        'searchbox.html'\n    ]\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'\n#   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'\n#html_search_language = 'en'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only 'ja' uses this config value\n#html_search_options = {'type': 'default'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n#html_search_scorer = 'scorer.js'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'CounterMitmdoc'\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n# The paper size ('letterpaper' or 'a4paper').\n#'papersize': 'letterpaper',\n\n# The font size ('10pt', '11pt' or '12pt').\n'pointsize': '12pt',\n     'preamble': '''\\\\setcounter{secnumdepth}{3}''',\n\n# Additional stuff for the LaTeX preamble.\n#'preamble': '',\n\n     'preamble': '''\n\\\\newcommand{\\\\countermitmrelease}{%s}\n\\\\setcounter{secnumdepth}{3}\n'''%(release,),\n\n# Latex figure (float) alignment\n#'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, 'CounterMitm.tex',\n    u'Detecting and preventing active attacks against Autocrypt',\n     u'NEXTLEAP researchers', 'howto'),\n]\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#\nlatex_use_parts = False\n\n# If true, show page references after internal links.\n#\nlatex_show_pagerefs = True\n\n# If true, show URL addresses after external links.\n#\nlatex_show_urls = 'footnote'\n# latex_show_urls = True\n\n# Documents to append as an appendix to all manuals.\n#\n# latex_appendices = []\n\n# It false, will not define \\strong, \\code, \titleref, \\crossref ... but only\n# \\sphinxstrong, ..., \\sphinxtitleref, ... To help avoid clash with user added\n# packages.\n#\n# latex_keep_old_macro_names = True\n\n# If false, no module index is generated.\n#\nlatex_domain_indices = False\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, 'countermitm', u'Detecting and preventing active attacks against Autocrypt',\n     [author], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, 'CounterMitm', u'Counter Mitm Documentation',\n     author, 'CounterMitm', 'One line description of project.',\n     'Miscellaneous'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n#texinfo_show_urls = 'footnote'\n\n# If true, do not generate a @detailmenu in the \"Top\" node's menu.\n#texinfo_no_detailmenu = False\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\n# intersphinx_mapping = {'https:\/\/docs.python.org\/': None}\n#\nif __name__ == \"__main__\":\n    print(release)\n"}},"msg":"Version 0.10.0 (Incorporating feedback and finalizing)\n\n- include feedback received after sharing countermitm\n  with the messaging@moderncrypto.org mailing list:\n\n  - build verified group and history verification\n    based on contact verification.\n\n  - prevent replay attacks\n\n- improve readability and clarity in the entire document.\n  (Wouter Lueks)\n\n- refine and document the interaction of encryption\n  with verified and opportunistic Autocrypt keys.\n\n- address device loss in a verified group scenario.\n\n- add presentation slides for OpenPGP Summit 2018 in Brussels."}},"https:\/\/github.com\/Von-Vaughny\/robots_vs_dinosaurs":{"78bff207f041cdd91a7fe50407d6620846a8effe":{"url":"https:\/\/api.github.com\/repos\/Von-Vaughny\/robots_vs_dinosaurs\/commits\/78bff207f041cdd91a7fe50407d6620846a8effe","html_url":"https:\/\/github.com\/Von-Vaughny\/robots_vs_dinosaurs\/commit\/78bff207f041cdd91a7fe50407d6620846a8effe","message":"Simplified class battlefields's select_robot_weapon(), coin_toss(), battle_phase(), robots_turn(), display_robot_attack(), dinosaur_turn(), display_dinosaur_attack(); added message to classes herd's and fleet's display_(player)_selection() and remove_(player)(); changed classes robot() and dinosaur() attack() to d20; added replay class to replay game; and added end game result status to main.","sha":"78bff207f041cdd91a7fe50407d6620846a8effe","keyword":"replay attack change","diff":"diff --git a\/battlefield.py b\/battlefield.py\nindex 4b9d63f..ba8d23b 100644\n--- a\/battlefield.py\n+++ b\/battlefield.py\n@@ -11,210 +11,163 @@\n class Battlefield:\n     def __init__(self):\n         self.herd = Herd()\n-        self.fleet = Fleet()\n+        self.fleet = Fleet() \n         self.herd.add_dinosaur(Dinosaur('T-Rex', random.randint(10, 25)))\n         self.herd.add_dinosaur(Dinosaur('Pterodactyl', random.randint(10, 25)))\n         self.herd.add_dinosaur(Dinosaur('Helicoprion', random.randint(10, 25)))    \n-        # Can probably minimize this. Just need to randomly choose name and atack power.   \n-        self.weapon_1 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n-        self.weapon_2 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n-        self.weapon_3 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n-        self.weapons = [self.weapon_1, self.weapon_2, self.weapon_3]\n-        self.player_turn = 1\n+        self.weapons = [Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)),\n+                        Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)),\n+                        Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))]\n+        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]   \n+        self.turn = random.choice([True, False])\n+        self.user_input, self.robo_no, self.dino_no = \"\", \"\", \"\"\n+        self.player_turn, self.robo_wins, self.dino_wins  = 1, 0, 0 \n            \n     def run_game(self):\n         self.display_welcome()\n         self.display_players_stats()\n         self.coin_toss()\n         self.battle_phase()\n-        self.display_winner()\n+        self.winner = self.display_winner()\n+        return self.winner\n \n     def display_welcome(self):\n-        print(\"Robot vs Dinosaur\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")\n+        print(\"Robots vs Dinosaurs\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")\n \n     def display_players_stats(self):\n-        print(\"The Raging Dinosaurs Roster\\n\")\n-        for i in range(len(self.herd.herd_list)):\n-            print(f\"{i + 1}. {self.herd.herd_list[i].name}, HP: {self.herd.herd_list[i].health}, ATT: {self.herd.herd_list[i].attack_power}\")\n+        self.herd.display_dinosaurs_stats()\n         self.select_robot_weapon()\n-        print(\"\\nThe Destructive Robots Roster\\n\")\n-        for i in range(len(self.fleet.fleet_list)):\n-            print(f\"{i + 1}. {self.fleet.fleet_list[i].name}, HP: {self.fleet.fleet_list[i].health}, Weapon: \"\\\n-                f\"{self.fleet.fleet_list[i].active_weapon.name}, ATT: {self.fleet.fleet_list[i].active_weapon.attack_power}\")\n-        print()\n+        self.fleet.display_robots_stats()\n \n     def select_robot_weapon(self):\n-        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]\n         for i in range(len(self.robot_names)):\n-            print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")\n-            for n in range(len(self.weapons)):\n-                print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")\n-            self.m = input(\"\\nWeapon \")\n-            self.n = re.sub(r\"[^0-9]\", \"\", self.m)\n-            while len(self.n) == 0 or int(self.n) not in range(len(self.weapons)):\n-                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}\\n\")\n+            while len(self.user_input) == 0 or int(self.user_input) not in range(len(self.weapons)):\n+                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")\n                 for n in range(len(self.weapons)):\n                     print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")\n-                self.m = input(\"\\nWeapon \")\n-                self.n = re.sub(r\"[^0-9]\", \"\", self.m)\n-            if int(self.n) in range(len(self.weapons)):\n-                print(f\"You've selected {self.weapons[int(self.n)].name} (ATT: {self.weapons[int(self.n)].attack_power})\")\n-                self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.n)].name, self.weapons[int(self.n)].attack_power))\n-                self.weapons.remove(self.weapons[int(self.n)])\n+                self.raw_user_input = input(\"\\nPlayer equips weapon \")\n+                self.user_input = re.sub(r\"[^0-2]\", \"\", self.raw_user_input)\n+            print(f\"You've selected {self.weapons[int(self.user_input)].name} (ATT: {self.weapons[int(self.user_input)].attack_power})\")\n+            self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.user_input)].name, self.weapons[int(self.user_input)].attack_power))\n+            self.weapons.remove(self.weapons[int(self.user_input)])\n+            self.user_input = \"\"\n \n     def coin_toss(self):\n-        # Can probably simplify this.\n-        self.coin = random.choice(['heads', 'tails'])\n-        self.turn = True\n-        if self.coin == 'tails':\n-            self.turn = not(self.turn)\n-        print(\"Coin Toss Results\")\n-        if self.turn == True:\n-            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Destructive Robots will be starting this battle!\")\n-        elif self.turn == False:\n-            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Raging Dinosaurs will be starting this battle!\")\n+        print(\"\\nCoin Toss Results\")\n+        if self.turn:\n+            print(f\"The coin toss result is in and its... HEADS! The Destructive Robots will be starting this battle!\")\n+        elif not(self.turn):\n+            print(f\"The coin toss result is in and its... TAILS! The Raging Dinosaurs will be starting this battle!\")\n \n-    # Consider reducing lines of code: initializing variables in the init(), creating a battle_phase_battle_status() for status, fix the \n-    # \"has been ELIMINATED\" as a reflect could knock out a player on the player's own turn - probably need to use different variables in\n-    # the (current_player)_turn().  \n     def battle_phase(self):\n         while len(self.fleet.fleet_list) > 0 and len(self.herd.herd_list) > 0:\n-            self.current_turn = math.ceil(self.player_turn\/2)\n-            i, j = 0, 0\n-            if self.turn == True:\n-                i, j = self.robots_turn()\n-                n = int(self.fleet.fleet_list[i].attack(self.herd.herd_list[j]))\n-                print(f\"\\nTurn {self.current_turn}: Robots\")\n-                print(f\"{self.display_robot_attack(n, i, j)[0]} Robot {self.fleet.fleet_list[i].name} attacks {self.herd.herd_list[j].name} with \"\\\n-                    f\"{self.fleet.fleet_list[i].active_weapon.name} for\", self.display_robot_attack(n, i, j)[1])\n-                print(f\"Dinosaur {self.herd.herd_list[j].name} has {self.herd.herd_list[j].health if self.herd.herd_list[j].health > 0 else 0} \"\\\n-                    f\"health remaining! \")\n-                if self.herd.herd_list[j].health <= 0:\n-                    print(f\"Dinosaur {self.herd.herd_list[j].name} has been ELIMINATED!\")\n-                    self.herd.remove_dinosaur()\n-                self.turn = False\n-            elif self.turn == False:\n-                i, j = self.dinosaurs_turn()\n-                n = int(self.herd.herd_list[i].attack(self.fleet.fleet_list[j]))\n-                print(f\"\\nTurn {self.current_turn}: Dinosaurs\")\n-                print(f\"{self.display_dinosaur_attack(n, i, j)[0]} Dinosaur {self.herd.herd_list[i].name} attacks {self.fleet.fleet_list[j].name} for\",\\\n-                    self.display_dinosaur_attack(n, i, j)[1])\n-                print(f\"Robot {self.fleet.fleet_list[j].name} has {self.fleet.fleet_list[j].health if self.fleet.fleet_list[j].health > 0 else 0} \"\\\n-                    f\"health remaining!\")\n-                if self.fleet.fleet_list[j].health <= 0:\n-                    print(f\"Robot {self.fleet.fleet_list[j].name} has been ELIMINATED!\")\n-                    self.fleet.remove_robot()\n-                self.turn = True            \n+            self.current_round = math.ceil(self.player_turn\/2)\n+            if self.turn:\n+                self.robots_turn()\n+            else:\n+                self.dinosaurs_turn()\n+            self.fleet.remove_robot()\n+            self.herd.remove_dinosaur()\n+            self.turn = not(self.turn)        \n             self.player_turn += 1\n             \n-    # Consider reducing lines of code\n     def robots_turn(self):\n-        print(\"\\nSelect your attacking robot:\")\n-        self.fleet.display_robot_selection()\n-        self.h = input(\"Robot \")\n-        self.i = re.sub(r\"[^0-9]\", \"\", self.h)\n-        while len(self.i) == 0 or int(self.i) not in range(len(self.fleet.fleet_list)):\n-            print(\"\\nSelect your attacking robot:\")\n+        self.robo_no, self.dino_no = \"\", \"\"\n+        while len(self.robo_no) == 0 or int(self.robo_no) not in range(len(self.fleet.fleet_list)):\n             self.fleet.display_robot_selection()\n-            self.h = input(\"Robot \")\n-            self.i = re.sub(r\"[^0-9]\", \"\", self.h)\n-        if int(self.i) in range(len(self.fleet.fleet_list)):\n-            print(f\"You've selected {self.fleet.fleet_list[int(self.i)].name}!\")\n-            print(\"\\nSelect a dinosaur to attack:\")\n+            self.robo_no = re.sub(r\"[^0-2]\", \"\", input(\"\\nRobot \"))\n+        print(f\"You've selected {self.fleet.fleet_list[int(self.robo_no)].name}!\")\n+        while len(self.dino_no) == 0 or int(self.dino_no) not in range(len(self.herd.herd_list)):\n             self.herd.display_dinosaur_selection()\n-            self.k = input(\"Dinosaur \")\n-            self.j = re.sub(r\"[^0-9]\", \"\", self.k)\n-            while len(self.j) == 0 or int(self.j) not in range(len(self.herd.herd_list)):\n-                print(\"\\nSelect a dinosaur to attack:\")\n-                self.herd.display_dinosaur_selection()\n-                self.k = input(\"Dinosuar \")\n-                self.j = re.sub(r\"[^0-9]\", \"\", self.k)\n-            print(f\"You've selected to attack {self.herd.herd_list[int(self.j)].name}\")\n-        self.turn = False\n-        return int(self.i), int(self.j)\n-    \n-    # Consider reducing lines of code, intializing variables in init(), Reconfigure the conditions. Maybe include another if\/else \n-    # clause after \"if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):\" to check if it\n-    # the value is bigger than self.dinosaur_attack_max, self.robot_attack_max to select max.\n-    def dinosaurs_turn(self):\n-        self.dinosaur_attack_max, self.robot_attack_max = 0, 0\n-        i, j = 0, 0\n-        for n in range(1, len(self.herd.herd_list)-1):\n-            if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):\n-                self.dinosaur_attack_max = int(self.herd.herd_list[n-1].attack_power)\n-            else:\n-                self.dinosaur_attack_max = int(self.herd.herd_list[n].attack_power)\n-        for n in range(len(self.herd.herd_list)):\n-            if self.herd.herd_list[n].attack_power == self.dinosaur_attack_max:\n-                i = n\n-        for n in range(1, len(self.fleet.fleet_list)-1):\n-            if int(self.fleet.fleet_list[n-1].active_weapon.attack_power) >= int(self.fleet.fleet_list[n].active_weapon.attack_power):\n-                self.robot_attack_max = int(self.fleet.fleet_list[n-1].active_weapon.attack_power)\n-            else:\n-                self.robot_attack_max = int(self.fleet.fleet_list[n].active_weapon.attack_power)\n-        for n in range(len(self.fleet.fleet_list)):\n-            if self.fleet.fleet_list[n].active_weapon.attack_power == self.robot_attack_max:\n-                j = n\n-        return i, j\n-    \n-    # Consider moving hit to its own function and\/or combining display_(player)_attack by the self.turn booleaan to determine statements.\n-    def display_robot_attack(self, n, i, j):\n+            self.dino_no = re.sub(r\"[^0-2]\", \"\", input(\"\\nDinosuar \"))\n+        print(f\"You've selected to attack {self.herd.herd_list[int(self.dino_no)].name}\")\n+        self.d20 = int(self.fleet.fleet_list[int(self.robo_no)].attack(self.herd.herd_list[int(self.dino_no)]))\n+        print(f\"\\nTurn {self.current_round}: Robots\")\n+        print(f\"{self.display_robot_attack(self.d20, self.robo_no, self.dino_no)[0]} Robot {self.fleet.fleet_list[int(self.robo_no)].name} attacks \" \n+              f\"{self.herd.herd_list[int(self.dino_no)].name} with {self.fleet.fleet_list[int(self.robo_no)].active_weapon.name} for\", \n+              f\"{self.display_robot_attack(self.d20, self.robo_no, self.dino_no)[1]}\")\n+        print(f\"Dinosaur {self.herd.herd_list[int(self.dino_no)].name} has \"\n+              f\"{self.herd.herd_list[int(self.dino_no)].health if self.herd.herd_list[int(self.dino_no)].health > 0 else 0} health remaining!\")\n+\n+    def display_robot_attack(self, d20, robo_no, dino_no):\n         hit = \"HIT!\"\n-        statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage!\"\n-        if n == 1: \n+        status = f\"{self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} damage!\"\n+        if int(d20) in range(19, 20):\n             hit = \"3x CRITCAL HIT!\"\n-            statement = f\"triple damage ({3 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"\n-        elif n in range(2, 10):\n+            status = f\"triple damage ({3 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} dmg)!\"\n+        elif int(d20) in range(15, 18):\n             hit = \"2x CRITICAL HIT!\"\n-            statement = f\"double damage ({2 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"\n-        elif n == 100:\n+            status = f\"double damage ({2 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} dmg)!\"\n+        elif int(d20) in range(7, 10):\n+            hit = \"WEAK HIT!\"\n+            status= f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power)} dmg) as \"\\\n+                f\"{self.herd.herd_list[int(dino_no)].name} blocked the attack!\"\n+        elif int(d20) in range(5, 7):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attacked and healed quite a bit!\"\n-        elif n in range(96, 99):\n+            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attack!\"\n+        elif int(d20) in range(3, 5):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack and healed a little bit!\"\n-        elif n in range(86, 95):\n+            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attack and healed a little bit!\"\n+        elif int(d20) == 2:\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack!\"\n-        elif n in range(53, 85):\n-            hit = \"WEAK HIT!\"\n-            statement = f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(i)].active_weapon.attack_power)} dmg) as \"\\\n-                f\"{self.herd.herd_list[int(j)].name} blocked the attack!\"\n-        elif n == 50:\n+            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attacked and healed quite a bit!\"\n+        elif int(d20) == 1:\n             hit = \"HIT REFLECTED!\"\n-            statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\\n-                        f\"{self.fleet.fleet_list[int(i)].name}!\"\n-        return hit, statement\n+            status = f\"{self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\\n+                        f\"{self.fleet.fleet_list[int(robo_no)].name}!\\nRobot {self.fleet.fleet_list[int(robo_no)]} has \"\\\n+                        f\"{self.fleet.fleet_list[int(robo_no)]} health remaining!\"\n+        return hit, status\n \n-    def display_dinosaur_attack(self, n, i, j):\n+    def dinosaurs_turn(self):\n+        self.dinosaur_attack_max, self.robot_attack_max = 0, 0\n+        for n in range(len(self.herd.herd_list)):\n+            if self.herd.herd_list[n].attack_power > self.dinosaur_attack_max:\n+                self.dinosaur_attack_max = self.herd.herd_list[n].attack_power\n+                self.dino_no = str(n)\n+        for n in range(len(self.fleet.fleet_list)):       \n+            if self.fleet.fleet_list[n].active_weapon.attack_power > self.robot_attack_max:\n+                self.robot_attack_max = self.fleet.fleet_list[n].active_weapon.attack_power\n+                self.robo_no = str(n)\n+        self.d20 = int(self.herd.herd_list[int(self.dino_no)].attack(self.fleet.fleet_list[int(self.robo_no)]))\n+        print(f\"\\nTurn {self.current_round}: Dinosaurs\")\n+        print(f\"{self.display_dinosaur_attack(self.d20, self.dino_no, self.robo_no)[0]} Dinosaur {self.herd.herd_list[int(self.dino_no)].name} \"\n+            f\"attacks {self.fleet.fleet_list[int(self.robo_no)].name} for\", self.display_dinosaur_attack(self.d20, self.dino_no, self.robo_no)[1])\n+        print(f\"Robot {self.fleet.fleet_list[int(self.robo_no)].name} has \"\n+            f\"{self.fleet.fleet_list[int(self.robo_no)].health if self.fleet.fleet_list[int(self.robo_no)].health > 0 else 0} health remaining!\")       \n+\n+    def display_dinosaur_attack(self, d20, dino_no, robo_no):\n         hit = \"HIT!\"\n-        statement = f\"{self.herd.herd_list[int(i)].attack_power} damage!\"\n-        if n == 1:\n+        status = f\"{self.herd.herd_list[int(dino_no)].attack_power} damage!\"\n+        if int(d20) in range(19, 20):\n             hit = \"3x CRITICAL HIT!\"\n-            statement = f\"triple damage ({3 * self.herd.herd_list[int(i)].attack_power} dmg)!\"\n-        elif n in range(2, 10):\n+            status = f\"triple damage ({3 * self.herd.herd_list[int(dino_no)].attack_power} dmg)!\"\n+        elif int(d20) in range(15, 18):\n             hit = \"2x CRITICAL HIT!\"\n-            statement = f\"double damage ({2 * self.herd.herd_list[int(i)].attack_power} dmg)!\"\n-        elif n == 100:\n+            status = f\"double damage ({2 * self.herd.herd_list[int(dino_no)].attack_power} dmg)!\"\n+        elif int(d20) in range(7, 10):\n+            hit = \"WEAK HIT!\"\n+            status = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(dino_no)].attack_power)} dmg) as \"\\\n+                f\"{self.fleet.fleet_list[int(robo_no)].name} blocked the attack!\"   \n+        elif int(d20) in range(5, 7):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed quite a bit!\"\n-        elif n in range(96, 99):\n+            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack!\"\n+        elif int(d20) in range(3, 5):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed a little bit!\"\n-        elif n in range(86, 95):\n+            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack and healed a little bit!\"    \n+        elif int(d20) == 2:\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack!\"     \n-        elif n in range(53, 85):\n-            hit = \"WEAK HIT!\"\n-            statement = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(i)].attack_power)} dmg) as {self.fleet.fleet_list[int(j)].name} \"\\\n-                f\"blocked the attack!\"    \n-        elif n == 50:\n+            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack and healed quite a bit!\"  \n+        elif int(d20) == 1:\n             hit = \"HIT REFLECTED!\"    \n-            statement = f\"{self.herd.herd_list[int(i)].attack_power} damage but it was deflected back at dinosaur {self.herd.herd_list[int(i)].name}!\"   \n-        return hit, statement\n+            status = f\"{self.herd.herd_list[int(dino_no)].attack_power} damage but it was deflected back at dinosaur \"\\\n+                f\"{self.herd.herd_list[int(dino_no)].name}!\\nDinosaur {self.herd.herd_list[int(dino_no)].name} has \"\\\n+                f\"{self.herd.herd_list[int(dino_no)].health} remaining!\"   \n+        return hit, status\n \n     def display_winner(self): \n         if len(self.fleet.fleet_list) == 0:\n             print(\"\\nTHE RAGING DINOSAURS WIN!\")\n+            return \"dinosaurs\"\n         elif len(self.herd.herd_list) == 0: \n             print(\"\\nTHE DESTRUCTIVE ROBOTS WIN!\")\n+            return \"robots\"\ndiff --git a\/dinosaur.py b\/dinosaur.py\nindex 3e6e5e8..34f7ce4 100644\n--- a\/dinosaur.py\n+++ b\/dinosaur.py\n@@ -4,26 +4,25 @@\n class Dinosaur:\n     def __init__(self, name, attack_power):\n         self.name = name\n-        self.health = random.randint(50, 100)\n         self.attack_power = attack_power\n+        self.health = random.randint(50, 100)\n \n-    # Add block - 50% damage, and dodge capability.\n     def attack(self, robot):\n-        n = random.randint(1, 100)\n-        if n == 1:\n+        d20 = random.randint(1, 20)\n+        if d20 in range(19, 20):       \n             robot.health -= (3 * self.attack_power)\n-        elif n in range(1, 10):\n+        elif d20 in range(15, 18):\n             robot.health -= (2 * self.attack_power)\n-        elif n == 100:\n-            robot.health += random.randint(10, 25)\n-        elif n in range(96, 99):\n-            robot.health += random.randint(1, 10)  \n-        elif n in range (86, 95):\n+        elif d20 in range(7, 10):        \n+            robot.health -= math.ceil(0.5 * self.attack_power)        \n+        elif d20 in range(5, 7):\n             pass\n-        elif n in range(53, 85):         \n-            robot.health -= math.ceil(0.5 * self.attack_power)\n-        elif n == 50:\n+        elif d20 in range(3, 5):\n+            robot.health += random.randint(1, 10)\n+        elif d20 == 2:\n+            robot.health += random.randint(10, 25)  \n+        elif d20 == 1:\n             self.health -= self.attack_power\n         else:\n             robot.health -= self.attack_power\n-        return n\n\\ No newline at end of file\n+        return d20\n\\ No newline at end of file\ndiff --git a\/fleet.py b\/fleet.py\nindex 592b1a1..45ae9e3 100644\n--- a\/fleet.py\n+++ b\/fleet.py\n@@ -1,19 +1,24 @@\n-from robot import Robot\n-\n class Fleet:\n     def __init__(self):\n-        self.fleet_list = []\n+        self.fleet_list = [] \n \n     def add_robot(self, robot):\n-        self.fleet_list.append(robot)\n+        self.fleet_list.append(robot)     \n+\n+    def display_robots_stats(self):\n+        print(\"\\nThe Destructive Robots Roster\\n\")\n+        for i in range(len(self.fleet_list)):\n+            print(f\"{i + 1}. {self.fleet_list[i].name}, HP: {self.fleet_list[i].health}, Weapon: {self.fleet_list[i].active_weapon.name}, \"\\\n+                f\"ATT: {self.fleet_list[i].active_weapon.attack_power}\")\n \n     def display_robot_selection(self):\n+        print(\"\\nSelect your attacking robot:\")\n         for i in range(len(self.fleet_list)):\n-            print(f\"Input {i} to select robot {self.fleet_list[i].name} (ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\\n+            print(f\"Input {i} to select robot {self.fleet_list[i].name} (W_ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\\n                 f\"{self.fleet_list[i].health})\")\n-        print()\n \n     def remove_robot(self):\n-        for i, j in enumerate(self.fleet_list):\n+        for i, robot in enumerate(self.fleet_list):\n             if self.fleet_list[i].health <= 0:\n-                self.fleet_list.remove(j)\n\\ No newline at end of file\n+                print(f\"Robot {self.fleet_list[i].name} has been ELIMINATED!\")\n+                self.fleet_list.remove(robot)\n\\ No newline at end of file\ndiff --git a\/herd.py b\/herd.py\nindex f9b68fb..57fe35e 100644\n--- a\/herd.py\n+++ b\/herd.py\n@@ -1,5 +1,3 @@\n-from dinosaur import Dinosaur\n-\n class Herd:\n     def __init__(self):\n         self.herd_list = []\n@@ -7,12 +5,18 @@ def __init__(self):\n     def add_dinosaur(self, dinosaur):\n         self.herd_list.append(dinosaur)\n \n+    def display_dinosaurs_stats(self):\n+        print(\"The Raging Dinosaurs Roster\\n\")\n+        for i in range(len(self.herd_list)):\n+            print(f\"{i + 1}. {self.herd_list[i].name}, HP: {self.herd_list[i].health}, ATT: {self.herd_list[i].attack_power}\")\n+\n     def display_dinosaur_selection(self):\n+        print(\"\\nSelect a dinosaur to attack:\")\n         for i in range(len(self.herd_list)):\n             print(f\"Input {i} to select dinosaur {self.herd_list[i].name} (ATT: {self.herd_list[i].attack_power}, HP: {self.herd_list[i].health})\")\n-        print()\n \n     def remove_dinosaur(self):\n-        for i, j in enumerate(self.herd_list):\n+        for i, dinosaur in enumerate(self.herd_list):\n             if self.herd_list[i].health <= 0:\n-                self.herd_list.remove(j)\n\\ No newline at end of file\n+                print(f\"Dinosaur {self.herd_list[i].name} has been ELIMINATED!\")\n+                self.herd_list.remove(dinosaur)\n\\ No newline at end of file\ndiff --git a\/main.py b\/main.py\nindex fb7d55b..1bac7ef 100644\n--- a\/main.py\n+++ b\/main.py\n@@ -1,6 +1,24 @@\n from battlefield import Battlefield\n+from replay import Replay\n+\n+\n+user_input = True\n+times_played = 0\n+wins = [0, 0]\n+\n+while user_input:\n+    battlefield_one = Battlefield()\n+    winner = battlefield_one.run_game()\n+    replay = Replay()\n+    user_input = replay.replay()\n+    times_played += 1\n+    if winner == \"robots\":\n+        wins[0] = int(wins[0]) + 1\n+    elif winner == \"dinosaurs\":\n+        wins[1] = int(wins[1]) + 1\n+\n+print(f\"\\nYou have played a total of {times_played} games!\")\n+print(f\"The Destructive Robots wins: {wins[0]}\")\n+print(f\"The Raging Dinosaurs wins: {wins[1]}\\n\")\n \n \n-# Consider adding a replay()\n-battlefield_one = Battlefield()\n-battlefield_one.run_game()\n\\ No newline at end of file\ndiff --git a\/replay.py b\/replay.py\nnew file mode 100644\nindex 0000000..5955281\n--- \/dev\/null\n+++ b\/replay.py\n@@ -0,0 +1,16 @@\n+import re\n+\n+\n+class Replay:\n+    def __init__(self):\n+        self.raw_user_input = \"\"\n+        self.cor_user_input = \"\"\n+\n+    def replay(self):\n+        while len(self.cor_user_input) == 0 or int(self.cor_user_input) not in range(2):\n+            self.raw_user_input = input(\"\\nPlay again? (Input 0 for yes, 1 for no) \")\n+            self.cor_user_input = re.sub(r\"[^0-1]\", \"\", self.raw_user_input)\n+        if int(self.cor_user_input) == 0:\n+            return True\n+        else:\n+            return False\n\\ No newline at end of file\ndiff --git a\/robot.py b\/robot.py\nindex d016c9c..e576552 100644\n--- a\/robot.py\n+++ b\/robot.py\n@@ -10,21 +10,21 @@ def __init__(self, name, weapon, attack_power):\n         self.active_weapon = Weapon(weapon, attack_power)\n \n     def attack(self, dinosaur):\n-        n = random.randint(1, 100)\n-        if n == 1:\n+        d20 = random.randint(1, 20)\n+        if d20 in range(19, 20):\n             dinosaur.health -= (3 * self.active_weapon.attack_power)\n-        elif n in range(2, 10):\n+        elif d20 in range(15, 18):\n             dinosaur.health -= (2 * self.active_weapon.attack_power)\n-        elif n == 100:\n-            dinosaur.health += random.randint(10, 25)\n-        elif n in range(96, 99):\n-            dinosaur.health += random.randint(1, 10)      \n-        elif n in range (86, 95):\n-            pass        \n-        elif n in range(53, 85):\n+        elif d20 in range(7, 10):\n             dinosaur.health -= math.ceil(0.5 * self.active_weapon.attack_power)\n-        elif n == 50:\n-            self.health -= self.active_weapon.attack_power\n+        elif d20 in range(5, 7):\n+            pass\n+        elif d20 in range(3, 5):\n+            dinosaur.health += random.randint(1, 10) \n+        elif d20 == 2:\n+            dinosaur.health += random.randint(10, 25)        \n+        elif d20 == 1:\n+            self.health -= self.active_weapon.attack_power           \n         else: \n             dinosaur.health -= self.active_weapon.attack_power\n-        return n\n\\ No newline at end of file\n+        return d20\n\\ No newline at end of file\ndiff --git a\/weapon.py b\/weapon.py\nindex 353c0dd..9d2c997 100644\n--- a\/weapon.py\n+++ b\/weapon.py\n@@ -1,6 +1,4 @@\n class Weapon:\n-    # May add self.ability: stun - chance to lose a turn, freeze - chance frozen player takes damage when attacking, burn - chance burnt player takes\n-    # more damage when attacked.\n     def __init__(self, name, attack_power):\n         self.name = name\n         self.attack_power = attack_power\n\\ No newline at end of file\n","files":{"\/battlefield.py":{"changes":[{"diff":"\n class Battlefield:\n     def __init__(self):\n         self.herd = Herd()\n-        self.fleet = Fleet()\n+        self.fleet = Fleet() \n         self.herd.add_dinosaur(Dinosaur('T-Rex', random.randint(10, 25)))\n         self.herd.add_dinosaur(Dinosaur('Pterodactyl', random.randint(10, 25)))\n         self.herd.add_dinosaur(Dinosaur('Helicoprion', random.randint(10, 25)))    \n-        # Can probably minimize this. Just need to randomly choose name and atack power.   \n-        self.weapon_1 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n-        self.weapon_2 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n-        self.weapon_3 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n-        self.weapons = [self.weapon_1, self.weapon_2, self.weapon_3]\n-        self.player_turn = 1\n+        self.weapons = [Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)),\n+                        Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)),\n+                        Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))]\n+        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]   \n+        self.turn = random.choice([True, False])\n+        self.user_input, self.robo_no, self.dino_no = \"\", \"\", \"\"\n+        self.player_turn, self.robo_wins, self.dino_wins  = 1, 0, 0 \n            \n     def run_game(self):\n         self.display_welcome()\n         self.display_players_stats()\n         self.coin_toss()\n         self.battle_phase()\n-        self.display_winner()\n+        self.winner = self.display_winner()\n+        return self.winner\n \n     def display_welcome(self):\n-        print(\"Robot vs Dinosaur\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")\n+        print(\"Robots vs Dinosaurs\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")\n \n     def display_players_stats(self):\n-        print(\"The Raging Dinosaurs Roster\\n\")\n-        for i in range(len(self.herd.herd_list)):\n-            print(f\"{i + 1}. {self.herd.herd_list[i].name}, HP: {self.herd.herd_list[i].health}, ATT: {self.herd.herd_list[i].attack_power}\")\n+        self.herd.display_dinosaurs_stats()\n         self.select_robot_weapon()\n-        print(\"\\nThe Destructive Robots Roster\\n\")\n-        for i in range(len(self.fleet.fleet_list)):\n-            print(f\"{i + 1}. {self.fleet.fleet_list[i].name}, HP: {self.fleet.fleet_list[i].health}, Weapon: \"\\\n-                f\"{self.fleet.fleet_list[i].active_weapon.name}, ATT: {self.fleet.fleet_list[i].active_weapon.attack_power}\")\n-        print()\n+        self.fleet.display_robots_stats()\n \n     def select_robot_weapon(self):\n-        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]\n         for i in range(len(self.robot_names)):\n-            print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")\n-            for n in range(len(self.weapons)):\n-                print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")\n-            self.m = input(\"\\nWeapon \")\n-            self.n = re.sub(r\"[^0-9]\", \"\", self.m)\n-            while len(self.n) == 0 or int(self.n) not in range(len(self.weapons)):\n-                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}\\n\")\n+            while len(self.user_input) == 0 or int(self.user_input) not in range(len(self.weapons)):\n+                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")\n                 for n in range(len(self.weapons)):\n                     print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")\n-                self.m = input(\"\\nWeapon \")\n-                self.n = re.sub(r\"[^0-9]\", \"\", self.m)\n-            if int(self.n) in range(len(self.weapons)):\n-                print(f\"You've selected {self.weapons[int(self.n)].name} (ATT: {self.weapons[int(self.n)].attack_power})\")\n-                self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.n)].name, self.weapons[int(self.n)].attack_power))\n-                self.weapons.remove(self.weapons[int(self.n)])\n+                self.raw_user_input = input(\"\\nPlayer equips weapon \")\n+                self.user_input = re.sub(r\"[^0-2]\", \"\", self.raw_user_input)\n+            print(f\"You've selected {self.weapons[int(self.user_input)].name} (ATT: {self.weapons[int(self.user_input)].attack_power})\")\n+            self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.user_input)].name, self.weapons[int(self.user_input)].attack_power))\n+            self.weapons.remove(self.weapons[int(self.user_input)])\n+            self.user_input = \"\"\n \n     def coin_toss(self):\n-        # Can probably simplify this.\n-        self.coin = random.choice(['heads', 'tails'])\n-        self.turn = True\n-        if self.coin == 'tails':\n-            self.turn = not(self.turn)\n-        print(\"Coin Toss Results\")\n-        if self.turn == True:\n-            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Destructive Robots will be starting this battle!\")\n-        elif self.turn == False:\n-            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Raging Dinosaurs will be starting this battle!\")\n+        print(\"\\nCoin Toss Results\")\n+        if self.turn:\n+            print(f\"The coin toss result is in and its... HEADS! The Destructive Robots will be starting this battle!\")\n+        elif not(self.turn):\n+            print(f\"The coin toss result is in and its... TAILS! The Raging Dinosaurs will be starting this battle!\")\n \n-    # Consider reducing lines of code: initializing variables in the init(), creating a battle_phase_battle_status() for status, fix the \n-    # \"has been ELIMINATED\" as a reflect could knock out a player on the player's own turn - probably need to use different variables in\n-    # the (current_player)_turn().  \n     def battle_phase(self):\n         while len(self.fleet.fleet_list) > 0 and len(self.herd.herd_list) > 0:\n-            self.current_turn = math.ceil(self.player_turn\/2)\n-            i, j = 0, 0\n-            if self.turn == True:\n-                i, j = self.robots_turn()\n-                n = int(self.fleet.fleet_list[i].attack(self.herd.herd_list[j]))\n-                print(f\"\\nTurn {self.current_turn}: Robots\")\n-                print(f\"{self.display_robot_attack(n, i, j)[0]} Robot {self.fleet.fleet_list[i].name} attacks {self.herd.herd_list[j].name} with \"\\\n-                    f\"{self.fleet.fleet_list[i].active_weapon.name} for\", self.display_robot_attack(n, i, j)[1])\n-                print(f\"Dinosaur {self.herd.herd_list[j].name} has {self.herd.herd_list[j].health if self.herd.herd_list[j].health > 0 else 0} \"\\\n-                    f\"health remaining! \")\n-                if self.herd.herd_list[j].health <= 0:\n-                    print(f\"Dinosaur {self.herd.herd_list[j].name} has been ELIMINATED!\")\n-                    self.herd.remove_dinosaur()\n-                self.turn = False\n-            elif self.turn == False:\n-                i, j = self.dinosaurs_turn()\n-                n = int(self.herd.herd_list[i].attack(self.fleet.fleet_list[j]))\n-                print(f\"\\nTurn {self.current_turn}: Dinosaurs\")\n-                print(f\"{self.display_dinosaur_attack(n, i, j)[0]} Dinosaur {self.herd.herd_list[i].name} attacks {self.fleet.fleet_list[j].name} for\",\\\n-                    self.display_dinosaur_attack(n, i, j)[1])\n-                print(f\"Robot {self.fleet.fleet_list[j].name} has {self.fleet.fleet_list[j].health if self.fleet.fleet_list[j].health > 0 else 0} \"\\\n-                    f\"health remaining!\")\n-                if self.fleet.fleet_list[j].health <= 0:\n-                    print(f\"Robot {self.fleet.fleet_list[j].name} has been ELIMINATED!\")\n-                    self.fleet.remove_robot()\n-                self.turn = True            \n+            self.current_round = math.ceil(self.player_turn\/2)\n+            if self.turn:\n+                self.robots_turn()\n+            else:\n+                self.dinosaurs_turn()\n+            self.fleet.remove_robot()\n+            self.herd.remove_dinosaur()\n+            self.turn = not(self.turn)        \n             self.player_turn += 1\n             \n-    # Consider reducing lines of code\n     def robots_turn(self):\n-        print(\"\\nSelect your attacking robot:\")\n-        self.fleet.display_robot_selection()\n-        self.h = input(\"Robot \")\n-        self.i = re.sub(r\"[^0-9]\", \"\", self.h)\n-        while len(self.i) == 0 or int(self.i) not in range(len(self.fleet.fleet_list)):\n-            print(\"\\nSelect your attacking robot:\")\n+        self.robo_no, self.dino_no = \"\", \"\"\n+        while len(self.robo_no) == 0 or int(self.robo_no) not in range(len(self.fleet.fleet_list)):\n             self.fleet.display_robot_selection()\n-            self.h = input(\"Robot \")\n-            self.i = re.sub(r\"[^0-9]\", \"\", self.h)\n-        if int(self.i) in range(len(self.fleet.fleet_list)):\n-            print(f\"You've selected {self.fleet.fleet_list[int(self.i)].name}!\")\n-            print(\"\\nSelect a dinosaur to attack:\")\n+            self.robo_no = re.sub(r\"[^0-2]\", \"\", input(\"\\nRobot \"))\n+        print(f\"You've selected {self.fleet.fleet_list[int(self.robo_no)].name}!\")\n+        while len(self.dino_no) == 0 or int(self.dino_no) not in range(len(self.herd.herd_list)):\n             self.herd.display_dinosaur_selection()\n-            self.k = input(\"Dinosaur \")\n-            self.j = re.sub(r\"[^0-9]\", \"\", self.k)\n-            while len(self.j) == 0 or int(self.j) not in range(len(self.herd.herd_list)):\n-                print(\"\\nSelect a dinosaur to attack:\")\n-                self.herd.display_dinosaur_selection()\n-                self.k = input(\"Dinosuar \")\n-                self.j = re.sub(r\"[^0-9]\", \"\", self.k)\n-            print(f\"You've selected to attack {self.herd.herd_list[int(self.j)].name}\")\n-        self.turn = False\n-        return int(self.i), int(self.j)\n-    \n-    # Consider reducing lines of code, intializing variables in init(), Reconfigure the conditions. Maybe include another if\/else \n-    # clause after \"if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):\" to check if it\n-    # the value is bigger than self.dinosaur_attack_max, self.robot_attack_max to select max.\n-    def dinosaurs_turn(self):\n-        self.dinosaur_attack_max, self.robot_attack_max = 0, 0\n-        i, j = 0, 0\n-        for n in range(1, len(self.herd.herd_list)-1):\n-            if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):\n-                self.dinosaur_attack_max = int(self.herd.herd_list[n-1].attack_power)\n-            else:\n-                self.dinosaur_attack_max = int(self.herd.herd_list[n].attack_power)\n-        for n in range(len(self.herd.herd_list)):\n-            if self.herd.herd_list[n].attack_power == self.dinosaur_attack_max:\n-                i = n\n-        for n in range(1, len(self.fleet.fleet_list)-1):\n-            if int(self.fleet.fleet_list[n-1].active_weapon.attack_power) >= int(self.fleet.fleet_list[n].active_weapon.attack_power):\n-                self.robot_attack_max = int(self.fleet.fleet_list[n-1].active_weapon.attack_power)\n-            else:\n-                self.robot_attack_max = int(self.fleet.fleet_list[n].active_weapon.attack_power)\n-        for n in range(len(self.fleet.fleet_list)):\n-            if self.fleet.fleet_list[n].active_weapon.attack_power == self.robot_attack_max:\n-                j = n\n-        return i, j\n-    \n-    # Consider moving hit to its own function and\/or combining display_(player)_attack by the self.turn booleaan to determine statements.\n-    def display_robot_attack(self, n, i, j):\n+            self.dino_no = re.sub(r\"[^0-2]\", \"\", input(\"\\nDinosuar \"))\n+        print(f\"You've selected to attack {self.herd.herd_list[int(self.dino_no)].name}\")\n+        self.d20 = int(self.fleet.fleet_list[int(self.robo_no)].attack(self.herd.herd_list[int(self.dino_no)]))\n+        print(f\"\\nTurn {self.current_round}: Robots\")\n+        print(f\"{self.display_robot_attack(self.d20, self.robo_no, self.dino_no)[0]} Robot {self.fleet.fleet_list[int(self.robo_no)].name} attacks \" \n+              f\"{self.herd.herd_list[int(self.dino_no)].name} with {self.fleet.fleet_list[int(self.robo_no)].active_weapon.name} for\", \n+              f\"{self.display_robot_attack(self.d20, self.robo_no, self.dino_no)[1]}\")\n+        print(f\"Dinosaur {self.herd.herd_list[int(self.dino_no)].name} has \"\n+              f\"{self.herd.herd_list[int(self.dino_no)].health if self.herd.herd_list[int(self.dino_no)].health > 0 else 0} health remaining!\")\n+\n+    def display_robot_attack(self, d20, robo_no, dino_no):\n         hit = \"HIT!\"\n-        statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage!\"\n-        if n == 1: \n+        status = f\"{self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} damage!\"\n+        if int(d20) in range(19, 20):\n             hit = \"3x CRITCAL HIT!\"\n-            statement = f\"triple damage ({3 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"\n-        elif n in range(2, 10):\n+            status = f\"triple damage ({3 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} dmg)!\"\n+        elif int(d20) in range(15, 18):\n             hit = \"2x CRITICAL HIT!\"\n-            statement = f\"double damage ({2 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"\n-        elif n == 100:\n+            status = f\"double damage ({2 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} dmg)!\"\n+        elif int(d20) in range(7, 10):\n+            hit = \"WEAK HIT!\"\n+            status= f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power)} dmg) as \"\\\n+                f\"{self.herd.herd_list[int(dino_no)].name} blocked the attack!\"\n+        elif int(d20) in range(5, 7):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attacked and healed quite a bit!\"\n-        elif n in range(96, 99):\n+            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attack!\"\n+        elif int(d20) in range(3, 5):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack and healed a little bit!\"\n-        elif n in range(86, 95):\n+            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attack and healed a little bit!\"\n+        elif int(d20) == 2:\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack!\"\n-        elif n in range(53, 85):\n-            hit = \"WEAK HIT!\"\n-            statement = f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(i)].active_weapon.attack_power)} dmg) as \"\\\n-                f\"{self.herd.herd_list[int(j)].name} blocked the attack!\"\n-        elif n == 50:\n+            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attacked and healed quite a bit!\"\n+        elif int(d20) == 1:\n             hit = \"HIT REFLECTED!\"\n-            statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\\n-                        f\"{self.fleet.fleet_list[int(i)].name}!\"\n-        return hit, statement\n+            status = f\"{self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\\n+                        f\"{self.fleet.fleet_list[int(robo_no)].name}!\\nRobot {self.fleet.fleet_list[int(robo_no)]} has \"\\\n+                        f\"{self.fleet.fleet_list[int(robo_no)]} health remaining!\"\n+        return hit, status\n \n-    def display_dinosaur_attack(self, n, i, j):\n+    def dinosaurs_turn(self):\n+        self.dinosaur_attack_max, self.robot_attack_max = 0, 0\n+        for n in range(len(self.herd.herd_list)):\n+            if self.herd.herd_list[n].attack_power > self.dinosaur_attack_max:\n+                self.dinosaur_attack_max = self.herd.herd_list[n].attack_power\n+                self.dino_no = str(n)\n+        for n in range(len(self.fleet.fleet_list)):       \n+            if self.fleet.fleet_list[n].active_weapon.attack_power > self.robot_attack_max:\n+                self.robot_attack_max = self.fleet.fleet_list[n].active_weapon.attack_power\n+                self.robo_no = str(n)\n+        self.d20 = int(self.herd.herd_list[int(self.dino_no)].attack(self.fleet.fleet_list[int(self.robo_no)]))\n+        print(f\"\\nTurn {self.current_round}: Dinosaurs\")\n+        print(f\"{self.display_dinosaur_attack(self.d20, self.dino_no, self.robo_no)[0]} Dinosaur {self.herd.herd_list[int(self.dino_no)].name} \"\n+            f\"attacks {self.fleet.fleet_list[int(self.robo_no)].name} for\", self.display_dinosaur_attack(self.d20, self.dino_no, self.robo_no)[1])\n+        print(f\"Robot {self.fleet.fleet_list[int(self.robo_no)].name} has \"\n+            f\"{self.fleet.fleet_list[int(self.robo_no)].health if self.fleet.fleet_list[int(self.robo_no)].health > 0 else 0} health remaining!\")       \n+\n+    def display_dinosaur_attack(self, d20, dino_no, robo_no):\n         hit = \"HIT!\"\n-        statement = f\"{self.herd.herd_list[int(i)].attack_power} damage!\"\n-        if n == 1:\n+        status = f\"{self.herd.herd_list[int(dino_no)].attack_power} damage!\"\n+        if int(d20) in range(19, 20):\n             hit = \"3x CRITICAL HIT!\"\n-            statement = f\"triple damage ({3 * self.herd.herd_list[int(i)].attack_power} dmg)!\"\n-        elif n in range(2, 10):\n+            status = f\"triple damage ({3 * self.herd.herd_list[int(dino_no)].attack_power} dmg)!\"\n+        elif int(d20) in range(15, 18):\n             hit = \"2x CRITICAL HIT!\"\n-            statement = f\"double damage ({2 * self.herd.herd_list[int(i)].attack_power} dmg)!\"\n-        elif n == 100:\n+            status = f\"double damage ({2 * self.herd.herd_list[int(dino_no)].attack_power} dmg)!\"\n+        elif int(d20) in range(7, 10):\n+            hit = \"WEAK HIT!\"\n+            status = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(dino_no)].attack_power)} dmg) as \"\\\n+                f\"{self.fleet.fleet_list[int(robo_no)].name} blocked the attack!\"   \n+        elif int(d20) in range(5, 7):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed quite a bit!\"\n-        elif n in range(96, 99):\n+            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack!\"\n+        elif int(d20) in range(3, 5):\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed a little bit!\"\n-        elif n in range(86, 95):\n+            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack and healed a little bit!\"    \n+        elif int(d20) == 2:\n             hit = \"MISS!\"\n-            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack!\"     \n-        elif n in range(53, 85):\n-            hit = \"WEAK HIT!\"\n-            statement = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(i)].attack_power)} dmg) as {self.fleet.fleet_list[int(j)].name} \"\\\n-                f\"blocked the attack!\"    \n-        elif n == 50:\n+            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack and healed quite a bit!\"  \n+        elif int(d20) == 1:\n             hit = \"HIT REFLECTED!\"    \n-            statement = f\"{self.herd.herd_list[int(i)].attack_power} damage but it was deflected back at dinosaur {self.herd.herd_list[int(i)].name}!\"   \n-        return hit, statement\n+            status = f\"{self.herd.herd_list[int(dino_no)].attack_power} damage but it was deflected back at dinosaur \"\\\n+                f\"{self.herd.herd_list[int(dino_no)].name}!\\nDinosaur {self.herd.herd_list[int(dino_no)].name} has \"\\\n+                f\"{self.herd.herd_list[int(dino_no)].health} remaining!\"   \n+        return hit, status\n \n     def display_winner(self): \n         if len(self.fleet.fleet_list) == 0:\n             print(\"\\nTHE RAGING DINOSAURS WIN!\")\n+            return \"dinosaurs\"\n         elif len(self.herd.herd_list) == 0: \n             print(\"\\nTHE DESTRUCTIVE ROBOTS WIN!\")\n+            return \"robots\"","add":110,"remove":157,"filename":"\/battlefield.py","badparts":["        self.fleet = Fleet()","        self.weapon_1 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))","        self.weapon_2 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))","        self.weapon_3 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))","        self.weapons = [self.weapon_1, self.weapon_2, self.weapon_3]","        self.player_turn = 1","        self.display_winner()","        print(\"Robot vs Dinosaur\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")","        print(\"The Raging Dinosaurs Roster\\n\")","        for i in range(len(self.herd.herd_list)):","            print(f\"{i + 1}. {self.herd.herd_list[i].name}, HP: {self.herd.herd_list[i].health}, ATT: {self.herd.herd_list[i].attack_power}\")","        print(\"\\nThe Destructive Robots Roster\\n\")","        for i in range(len(self.fleet.fleet_list)):","            print(f\"{i + 1}. {self.fleet.fleet_list[i].name}, HP: {self.fleet.fleet_list[i].health}, Weapon: \"\\","                f\"{self.fleet.fleet_list[i].active_weapon.name}, ATT: {self.fleet.fleet_list[i].active_weapon.attack_power}\")","        print()","        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]","            print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")","            for n in range(len(self.weapons)):","                print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")","            self.m = input(\"\\nWeapon \")","            self.n = re.sub(r\"[^0-9]\", \"\", self.m)","            while len(self.n) == 0 or int(self.n) not in range(len(self.weapons)):","                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}\\n\")","                self.m = input(\"\\nWeapon \")","                self.n = re.sub(r\"[^0-9]\", \"\", self.m)","            if int(self.n) in range(len(self.weapons)):","                print(f\"You've selected {self.weapons[int(self.n)].name} (ATT: {self.weapons[int(self.n)].attack_power})\")","                self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.n)].name, self.weapons[int(self.n)].attack_power))","                self.weapons.remove(self.weapons[int(self.n)])","        self.coin = random.choice(['heads', 'tails'])","        self.turn = True","        if self.coin == 'tails':","            self.turn = not(self.turn)","        print(\"Coin Toss Results\")","        if self.turn == True:","            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Destructive Robots will be starting this battle!\")","        elif self.turn == False:","            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Raging Dinosaurs will be starting this battle!\")","            self.current_turn = math.ceil(self.player_turn\/2)","            i, j = 0, 0","            if self.turn == True:","                i, j = self.robots_turn()","                n = int(self.fleet.fleet_list[i].attack(self.herd.herd_list[j]))","                print(f\"\\nTurn {self.current_turn}: Robots\")","                print(f\"{self.display_robot_attack(n, i, j)[0]} Robot {self.fleet.fleet_list[i].name} attacks {self.herd.herd_list[j].name} with \"\\","                    f\"{self.fleet.fleet_list[i].active_weapon.name} for\", self.display_robot_attack(n, i, j)[1])","                print(f\"Dinosaur {self.herd.herd_list[j].name} has {self.herd.herd_list[j].health if self.herd.herd_list[j].health > 0 else 0} \"\\","                    f\"health remaining! \")","                if self.herd.herd_list[j].health <= 0:","                    print(f\"Dinosaur {self.herd.herd_list[j].name} has been ELIMINATED!\")","                    self.herd.remove_dinosaur()","                self.turn = False","            elif self.turn == False:","                i, j = self.dinosaurs_turn()","                n = int(self.herd.herd_list[i].attack(self.fleet.fleet_list[j]))","                print(f\"\\nTurn {self.current_turn}: Dinosaurs\")","                print(f\"{self.display_dinosaur_attack(n, i, j)[0]} Dinosaur {self.herd.herd_list[i].name} attacks {self.fleet.fleet_list[j].name} for\",\\","                    self.display_dinosaur_attack(n, i, j)[1])","                print(f\"Robot {self.fleet.fleet_list[j].name} has {self.fleet.fleet_list[j].health if self.fleet.fleet_list[j].health > 0 else 0} \"\\","                    f\"health remaining!\")","                if self.fleet.fleet_list[j].health <= 0:","                    print(f\"Robot {self.fleet.fleet_list[j].name} has been ELIMINATED!\")","                    self.fleet.remove_robot()","                self.turn = True            ","        print(\"\\nSelect your attacking robot:\")","        self.fleet.display_robot_selection()","        self.h = input(\"Robot \")","        self.i = re.sub(r\"[^0-9]\", \"\", self.h)","        while len(self.i) == 0 or int(self.i) not in range(len(self.fleet.fleet_list)):","            print(\"\\nSelect your attacking robot:\")","            self.h = input(\"Robot \")","            self.i = re.sub(r\"[^0-9]\", \"\", self.h)","        if int(self.i) in range(len(self.fleet.fleet_list)):","            print(f\"You've selected {self.fleet.fleet_list[int(self.i)].name}!\")","            print(\"\\nSelect a dinosaur to attack:\")","            self.k = input(\"Dinosaur \")","            self.j = re.sub(r\"[^0-9]\", \"\", self.k)","            while len(self.j) == 0 or int(self.j) not in range(len(self.herd.herd_list)):","                print(\"\\nSelect a dinosaur to attack:\")","                self.herd.display_dinosaur_selection()","                self.k = input(\"Dinosuar \")","                self.j = re.sub(r\"[^0-9]\", \"\", self.k)","            print(f\"You've selected to attack {self.herd.herd_list[int(self.j)].name}\")","        self.turn = False","        return int(self.i), int(self.j)","    def dinosaurs_turn(self):","        self.dinosaur_attack_max, self.robot_attack_max = 0, 0","        i, j = 0, 0","        for n in range(1, len(self.herd.herd_list)-1):","            if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):","                self.dinosaur_attack_max = int(self.herd.herd_list[n-1].attack_power)","            else:","                self.dinosaur_attack_max = int(self.herd.herd_list[n].attack_power)","        for n in range(len(self.herd.herd_list)):","            if self.herd.herd_list[n].attack_power == self.dinosaur_attack_max:","                i = n","        for n in range(1, len(self.fleet.fleet_list)-1):","            if int(self.fleet.fleet_list[n-1].active_weapon.attack_power) >= int(self.fleet.fleet_list[n].active_weapon.attack_power):","                self.robot_attack_max = int(self.fleet.fleet_list[n-1].active_weapon.attack_power)","            else:","                self.robot_attack_max = int(self.fleet.fleet_list[n].active_weapon.attack_power)","        for n in range(len(self.fleet.fleet_list)):","            if self.fleet.fleet_list[n].active_weapon.attack_power == self.robot_attack_max:","                j = n","        return i, j","    def display_robot_attack(self, n, i, j):","        statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage!\"","        if n == 1: ","            statement = f\"triple damage ({3 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"","        elif n in range(2, 10):","            statement = f\"double damage ({2 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"","        elif n == 100:","            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attacked and healed quite a bit!\"","        elif n in range(96, 99):","            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack and healed a little bit!\"","        elif n in range(86, 95):","            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack!\"","        elif n in range(53, 85):","            hit = \"WEAK HIT!\"","            statement = f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(i)].active_weapon.attack_power)} dmg) as \"\\","                f\"{self.herd.herd_list[int(j)].name} blocked the attack!\"","        elif n == 50:","            statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\","                        f\"{self.fleet.fleet_list[int(i)].name}!\"","        return hit, statement","    def display_dinosaur_attack(self, n, i, j):","        statement = f\"{self.herd.herd_list[int(i)].attack_power} damage!\"","        if n == 1:","            statement = f\"triple damage ({3 * self.herd.herd_list[int(i)].attack_power} dmg)!\"","        elif n in range(2, 10):","            statement = f\"double damage ({2 * self.herd.herd_list[int(i)].attack_power} dmg)!\"","        elif n == 100:","            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed quite a bit!\"","        elif n in range(96, 99):","            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed a little bit!\"","        elif n in range(86, 95):","            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack!\"     ","        elif n in range(53, 85):","            hit = \"WEAK HIT!\"","            statement = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(i)].attack_power)} dmg) as {self.fleet.fleet_list[int(j)].name} \"\\","                f\"blocked the attack!\"    ","        elif n == 50:","            statement = f\"{self.herd.herd_list[int(i)].attack_power} damage but it was deflected back at dinosaur {self.herd.herd_list[int(i)].name}!\"   ","        return hit, statement"],"goodparts":["        self.fleet = Fleet() ","        self.weapons = [Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)),","                        Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)),","                        Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))]","        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]   ","        self.turn = random.choice([True, False])","        self.user_input, self.robo_no, self.dino_no = \"\", \"\", \"\"","        self.player_turn, self.robo_wins, self.dino_wins  = 1, 0, 0 ","        self.winner = self.display_winner()","        return self.winner","        print(\"Robots vs Dinosaurs\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")","        self.herd.display_dinosaurs_stats()","        self.fleet.display_robots_stats()","            while len(self.user_input) == 0 or int(self.user_input) not in range(len(self.weapons)):","                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")","                self.raw_user_input = input(\"\\nPlayer equips weapon \")","                self.user_input = re.sub(r\"[^0-2]\", \"\", self.raw_user_input)","            print(f\"You've selected {self.weapons[int(self.user_input)].name} (ATT: {self.weapons[int(self.user_input)].attack_power})\")","            self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.user_input)].name, self.weapons[int(self.user_input)].attack_power))","            self.weapons.remove(self.weapons[int(self.user_input)])","            self.user_input = \"\"","        print(\"\\nCoin Toss Results\")","        if self.turn:","            print(f\"The coin toss result is in and its... HEADS! The Destructive Robots will be starting this battle!\")","        elif not(self.turn):","            print(f\"The coin toss result is in and its... TAILS! The Raging Dinosaurs will be starting this battle!\")","            self.current_round = math.ceil(self.player_turn\/2)","            if self.turn:","                self.robots_turn()","            else:","                self.dinosaurs_turn()","            self.fleet.remove_robot()","            self.herd.remove_dinosaur()","            self.turn = not(self.turn)        ","        self.robo_no, self.dino_no = \"\", \"\"","        while len(self.robo_no) == 0 or int(self.robo_no) not in range(len(self.fleet.fleet_list)):","            self.robo_no = re.sub(r\"[^0-2]\", \"\", input(\"\\nRobot \"))","        print(f\"You've selected {self.fleet.fleet_list[int(self.robo_no)].name}!\")","        while len(self.dino_no) == 0 or int(self.dino_no) not in range(len(self.herd.herd_list)):","            self.dino_no = re.sub(r\"[^0-2]\", \"\", input(\"\\nDinosuar \"))","        print(f\"You've selected to attack {self.herd.herd_list[int(self.dino_no)].name}\")","        self.d20 = int(self.fleet.fleet_list[int(self.robo_no)].attack(self.herd.herd_list[int(self.dino_no)]))","        print(f\"\\nTurn {self.current_round}: Robots\")","        print(f\"{self.display_robot_attack(self.d20, self.robo_no, self.dino_no)[0]} Robot {self.fleet.fleet_list[int(self.robo_no)].name} attacks \" ","              f\"{self.herd.herd_list[int(self.dino_no)].name} with {self.fleet.fleet_list[int(self.robo_no)].active_weapon.name} for\", ","              f\"{self.display_robot_attack(self.d20, self.robo_no, self.dino_no)[1]}\")","        print(f\"Dinosaur {self.herd.herd_list[int(self.dino_no)].name} has \"","              f\"{self.herd.herd_list[int(self.dino_no)].health if self.herd.herd_list[int(self.dino_no)].health > 0 else 0} health remaining!\")","    def display_robot_attack(self, d20, robo_no, dino_no):","        status = f\"{self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} damage!\"","        if int(d20) in range(19, 20):","            status = f\"triple damage ({3 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} dmg)!\"","        elif int(d20) in range(15, 18):","            status = f\"double damage ({2 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} dmg)!\"","        elif int(d20) in range(7, 10):","            hit = \"WEAK HIT!\"","            status= f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power)} dmg) as \"\\","                f\"{self.herd.herd_list[int(dino_no)].name} blocked the attack!\"","        elif int(d20) in range(5, 7):","            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attack!\"","        elif int(d20) in range(3, 5):","            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attack and healed a little bit!\"","        elif int(d20) == 2:","            status = f\"0 damage as {self.herd.herd_list[int(dino_no)].name} dodged the attacked and healed quite a bit!\"","        elif int(d20) == 1:","            status = f\"{self.fleet.fleet_list[int(robo_no)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\","                        f\"{self.fleet.fleet_list[int(robo_no)].name}!\\nRobot {self.fleet.fleet_list[int(robo_no)]} has \"\\","                        f\"{self.fleet.fleet_list[int(robo_no)]} health remaining!\"","        return hit, status","    def dinosaurs_turn(self):","        self.dinosaur_attack_max, self.robot_attack_max = 0, 0","        for n in range(len(self.herd.herd_list)):","            if self.herd.herd_list[n].attack_power > self.dinosaur_attack_max:","                self.dinosaur_attack_max = self.herd.herd_list[n].attack_power","                self.dino_no = str(n)","        for n in range(len(self.fleet.fleet_list)):       ","            if self.fleet.fleet_list[n].active_weapon.attack_power > self.robot_attack_max:","                self.robot_attack_max = self.fleet.fleet_list[n].active_weapon.attack_power","                self.robo_no = str(n)","        self.d20 = int(self.herd.herd_list[int(self.dino_no)].attack(self.fleet.fleet_list[int(self.robo_no)]))","        print(f\"\\nTurn {self.current_round}: Dinosaurs\")","        print(f\"{self.display_dinosaur_attack(self.d20, self.dino_no, self.robo_no)[0]} Dinosaur {self.herd.herd_list[int(self.dino_no)].name} \"","            f\"attacks {self.fleet.fleet_list[int(self.robo_no)].name} for\", self.display_dinosaur_attack(self.d20, self.dino_no, self.robo_no)[1])","        print(f\"Robot {self.fleet.fleet_list[int(self.robo_no)].name} has \"","            f\"{self.fleet.fleet_list[int(self.robo_no)].health if self.fleet.fleet_list[int(self.robo_no)].health > 0 else 0} health remaining!\")       ","    def display_dinosaur_attack(self, d20, dino_no, robo_no):","        status = f\"{self.herd.herd_list[int(dino_no)].attack_power} damage!\"","        if int(d20) in range(19, 20):","            status = f\"triple damage ({3 * self.herd.herd_list[int(dino_no)].attack_power} dmg)!\"","        elif int(d20) in range(15, 18):","            status = f\"double damage ({2 * self.herd.herd_list[int(dino_no)].attack_power} dmg)!\"","        elif int(d20) in range(7, 10):","            hit = \"WEAK HIT!\"","            status = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(dino_no)].attack_power)} dmg) as \"\\","                f\"{self.fleet.fleet_list[int(robo_no)].name} blocked the attack!\"   ","        elif int(d20) in range(5, 7):","            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack!\"","        elif int(d20) in range(3, 5):","            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack and healed a little bit!\"    ","        elif int(d20) == 2:","            status = f\"0 damage as {self.fleet.fleet_list[int(robo_no)].name} dodged the attack and healed quite a bit!\"  ","        elif int(d20) == 1:","            status = f\"{self.herd.herd_list[int(dino_no)].attack_power} damage but it was deflected back at dinosaur \"\\","                f\"{self.herd.herd_list[int(dino_no)].name}!\\nDinosaur {self.herd.herd_list[int(dino_no)].name} has \"\\","                f\"{self.herd.herd_list[int(dino_no)].health} remaining!\"   ","        return hit, status","            return \"dinosaurs\"","            return \"robots\""]}],"source":"\nfrom fleet import Fleet from herd import Herd from robot import Robot from dinosaur import Dinosaur from weapon import Weapon import random import math import re class Battlefield: def __init__(self): self.herd=Herd() self.fleet=Fleet() self.herd.add_dinosaur(Dinosaur('T-Rex', random.randint(10, 25))) self.herd.add_dinosaur(Dinosaur('Pterodactyl', random.randint(10, 25))) self.herd.add_dinosaur(Dinosaur('Helicoprion', random.randint(10, 25))) self.weapon_1=Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)) self.weapon_2=Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)) self.weapon_3=Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25)) self.weapons=[self.weapon_1, self.weapon_2, self.weapon_3] self.player_turn=1 def run_game(self): self.display_welcome() self.display_players_stats() self.coin_toss() self.battle_phase() self.display_winner() def display_welcome(self): print(\"Robot vs Dinosaur\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\") def display_players_stats(self): print(\"The Raging Dinosaurs Roster\\n\") for i in range(len(self.herd.herd_list)): print(f\"{i +1}.{self.herd.herd_list[i].name}, HP:{self.herd.herd_list[i].health}, ATT:{self.herd.herd_list[i].attack_power}\") self.select_robot_weapon() print(\"\\nThe Destructive Robots Roster\\n\") for i in range(len(self.fleet.fleet_list)): print(f\"{i +1}.{self.fleet.fleet_list[i].name}, HP:{self.fleet.fleet_list[i].health}, Weapon: \"\\ f\"{self.fleet.fleet_list[i].active_weapon.name}, ATT:{self.fleet.fleet_list[i].active_weapon.attack_power}\") print() def select_robot_weapon(self): self.robot_names=['Terminator', 'Destroyer', \"Annihilator\"] for i in range(len(self.robot_names)): print(f\"\\nSelect a weapon for robot{self.robot_names[i]}:\") for n in range(len(self.weapons)): print(f\"Input{n} to select:{self.weapons[n].name}, ATT:{self.weapons[n].attack_power}\") self.m=input(\"\\nWeapon \") self.n=re.sub(r\"[^0-9]\", \"\", self.m) while len(self.n)==0 or int(self.n) not in range(len(self.weapons)): print(f\"\\nSelect a weapon for robot{self.robot_names[i]}\\n\") for n in range(len(self.weapons)): print(f\"Input{n} to select:{self.weapons[n].name}, ATT:{self.weapons[n].attack_power}\") self.m=input(\"\\nWeapon \") self.n=re.sub(r\"[^0-9]\", \"\", self.m) if int(self.n) in range(len(self.weapons)): print(f\"You've selected{self.weapons[int(self.n)].name}(ATT:{self.weapons[int(self.n)].attack_power})\") self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.n)].name, self.weapons[int(self.n)].attack_power)) self.weapons.remove(self.weapons[int(self.n)]) def coin_toss(self): self.coin=random.choice(['heads', 'tails']) self.turn=True if self.coin=='tails': self.turn=not(self.turn) print(\"Coin Toss Results\") if self.turn==True: print(f\"The coin toss result is in and its...{self.coin.upper()}! The Destructive Robots will be starting this battle!\") elif self.turn==False: print(f\"The coin toss result is in and its...{self.coin.upper()}! The Raging Dinosaurs will be starting this battle!\") def battle_phase(self): while len(self.fleet.fleet_list) > 0 and len(self.herd.herd_list) > 0: self.current_turn=math.ceil(self.player_turn\/2) i, j=0, 0 if self.turn==True: i, j=self.robots_turn() n=int(self.fleet.fleet_list[i].attack(self.herd.herd_list[j])) print(f\"\\nTurn{self.current_turn}: Robots\") print(f\"{self.display_robot_attack(n, i, j)[0]} Robot{self.fleet.fleet_list[i].name} attacks{self.herd.herd_list[j].name} with \"\\ f\"{self.fleet.fleet_list[i].active_weapon.name} for\", self.display_robot_attack(n, i, j)[1]) print(f\"Dinosaur{self.herd.herd_list[j].name} has{self.herd.herd_list[j].health if self.herd.herd_list[j].health > 0 else 0} \"\\ f\"health remaining! \") if self.herd.herd_list[j].health <=0: print(f\"Dinosaur{self.herd.herd_list[j].name} has been ELIMINATED!\") self.herd.remove_dinosaur() self.turn=False elif self.turn==False: i, j=self.dinosaurs_turn() n=int(self.herd.herd_list[i].attack(self.fleet.fleet_list[j])) print(f\"\\nTurn{self.current_turn}: Dinosaurs\") print(f\"{self.display_dinosaur_attack(n, i, j)[0]} Dinosaur{self.herd.herd_list[i].name} attacks{self.fleet.fleet_list[j].name} for\",\\ self.display_dinosaur_attack(n, i, j)[1]) print(f\"Robot{self.fleet.fleet_list[j].name} has{self.fleet.fleet_list[j].health if self.fleet.fleet_list[j].health > 0 else 0} \"\\ f\"health remaining!\") if self.fleet.fleet_list[j].health <=0: print(f\"Robot{self.fleet.fleet_list[j].name} has been ELIMINATED!\") self.fleet.remove_robot() self.turn=True self.player_turn +=1 def robots_turn(self): print(\"\\nSelect your attacking robot:\") self.fleet.display_robot_selection() self.h=input(\"Robot \") self.i=re.sub(r\"[^0-9]\", \"\", self.h) while len(self.i)==0 or int(self.i) not in range(len(self.fleet.fleet_list)): print(\"\\nSelect your attacking robot:\") self.fleet.display_robot_selection() self.h=input(\"Robot \") self.i=re.sub(r\"[^0-9]\", \"\", self.h) if int(self.i) in range(len(self.fleet.fleet_list)): print(f\"You've selected{self.fleet.fleet_list[int(self.i)].name}!\") print(\"\\nSelect a dinosaur to attack:\") self.herd.display_dinosaur_selection() self.k=input(\"Dinosaur \") self.j=re.sub(r\"[^0-9]\", \"\", self.k) while len(self.j)==0 or int(self.j) not in range(len(self.herd.herd_list)): print(\"\\nSelect a dinosaur to attack:\") self.herd.display_dinosaur_selection() self.k=input(\"Dinosuar \") self.j=re.sub(r\"[^0-9]\", \"\", self.k) print(f\"You've selected to attack{self.herd.herd_list[int(self.j)].name}\") self.turn=False return int(self.i), int(self.j) def dinosaurs_turn(self): self.dinosaur_attack_max, self.robot_attack_max=0, 0 i, j=0, 0 for n in range(1, len(self.herd.herd_list)-1): if int(self.herd.herd_list[n-1].attack_power) >=int(self.herd.herd_list[n].attack_power): self.dinosaur_attack_max=int(self.herd.herd_list[n-1].attack_power) else: self.dinosaur_attack_max=int(self.herd.herd_list[n].attack_power) for n in range(len(self.herd.herd_list)): if self.herd.herd_list[n].attack_power==self.dinosaur_attack_max: i=n for n in range(1, len(self.fleet.fleet_list)-1): if int(self.fleet.fleet_list[n-1].active_weapon.attack_power) >=int(self.fleet.fleet_list[n].active_weapon.attack_power): self.robot_attack_max=int(self.fleet.fleet_list[n-1].active_weapon.attack_power) else: self.robot_attack_max=int(self.fleet.fleet_list[n].active_weapon.attack_power) for n in range(len(self.fleet.fleet_list)): if self.fleet.fleet_list[n].active_weapon.attack_power==self.robot_attack_max: j=n return i, j def display_robot_attack(self, n, i, j): hit=\"HIT!\" statement=f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage!\" if n==1: hit=\"3x CRITCAL HIT!\" statement=f\"triple damage({3 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\" elif n in range(2, 10): hit=\"2x CRITICAL HIT!\" statement=f\"double damage({2 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\" elif n==100: hit=\"MISS!\" statement=f\"0 damage as{self.herd.herd_list[int(j)].name} dodged the attacked and healed quite a bit!\" elif n in range(96, 99): hit=\"MISS!\" statement=f\"0 damage as{self.herd.herd_list[int(j)].name} dodged the attack and healed a little bit!\" elif n in range(86, 95): hit=\"MISS!\" statement=f\"0 damage as{self.herd.herd_list[int(j)].name} dodged the attack!\" elif n in range(53, 85): hit=\"WEAK HIT!\" statement=f\"half the damage({math.ceil(0.5 * self.fleet.fleet_list[int(i)].active_weapon.attack_power)} dmg) as \"\\ f\"{self.herd.herd_list[int(j)].name} blocked the attack!\" elif n==50: hit=\"HIT REFLECTED!\" statement=f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\ f\"{self.fleet.fleet_list[int(i)].name}!\" return hit, statement def display_dinosaur_attack(self, n, i, j): hit=\"HIT!\" statement=f\"{self.herd.herd_list[int(i)].attack_power} damage!\" if n==1: hit=\"3x CRITICAL HIT!\" statement=f\"triple damage({3 * self.herd.herd_list[int(i)].attack_power} dmg)!\" elif n in range(2, 10): hit=\"2x CRITICAL HIT!\" statement=f\"double damage({2 * self.herd.herd_list[int(i)].attack_power} dmg)!\" elif n==100: hit=\"MISS!\" statement=f\"0 damage as{self.fleet.fleet_list[int(j)].name} dodged the attack and healed quite a bit!\" elif n in range(96, 99): hit=\"MISS!\" statement=f\"0 damage as{self.fleet.fleet_list[int(j)].name} dodged the attack and healed a little bit!\" elif n in range(86, 95): hit=\"MISS!\" statement=f\"0 damage as{self.fleet.fleet_list[int(j)].name} dodged the attack!\" elif n in range(53, 85): hit=\"WEAK HIT!\" statement=f\"half the damage({math.ceil(0.5 * self.herd.herd_list[int(i)].attack_power)} dmg) as{self.fleet.fleet_list[int(j)].name} \"\\ f\"blocked the attack!\" elif n==50: hit=\"HIT REFLECTED!\" statement=f\"{self.herd.herd_list[int(i)].attack_power} damage but it was deflected back at dinosaur{self.herd.herd_list[int(i)].name}!\" return hit, statement def display_winner(self): if len(self.fleet.fleet_list)==0: print(\"\\nTHE RAGING DINOSAURS WIN!\") elif len(self.herd.herd_list)==0: print(\"\\nTHE DESTRUCTIVE ROBOTS WIN!\") ","sourceWithComments":"from fleet import Fleet\nfrom herd import Herd\nfrom robot import Robot\nfrom dinosaur import Dinosaur\nfrom weapon import Weapon\nimport random\nimport math\nimport re\n\n\nclass Battlefield:\n    def __init__(self):\n        self.herd = Herd()\n        self.fleet = Fleet()\n        self.herd.add_dinosaur(Dinosaur('T-Rex', random.randint(10, 25)))\n        self.herd.add_dinosaur(Dinosaur('Pterodactyl', random.randint(10, 25)))\n        self.herd.add_dinosaur(Dinosaur('Helicoprion', random.randint(10, 25)))    \n        # Can probably minimize this. Just need to randomly choose name and atack power.   \n        self.weapon_1 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n        self.weapon_2 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n        self.weapon_3 = Weapon(random.choice(['Canon Launcher', 'Laser Blaster', 'Star Crusher']), random.randint(10, 25))\n        self.weapons = [self.weapon_1, self.weapon_2, self.weapon_3]\n        self.player_turn = 1\n           \n    def run_game(self):\n        self.display_welcome()\n        self.display_players_stats()\n        self.coin_toss()\n        self.battle_phase()\n        self.display_winner()\n\n    def display_welcome(self):\n        print(\"Robot vs Dinosaur\\n\\nWelcome to the battle of the ages! There can only be one! Which side will win?\\n\")\n\n    def display_players_stats(self):\n        print(\"The Raging Dinosaurs Roster\\n\")\n        for i in range(len(self.herd.herd_list)):\n            print(f\"{i + 1}. {self.herd.herd_list[i].name}, HP: {self.herd.herd_list[i].health}, ATT: {self.herd.herd_list[i].attack_power}\")\n        self.select_robot_weapon()\n        print(\"\\nThe Destructive Robots Roster\\n\")\n        for i in range(len(self.fleet.fleet_list)):\n            print(f\"{i + 1}. {self.fleet.fleet_list[i].name}, HP: {self.fleet.fleet_list[i].health}, Weapon: \"\\\n                f\"{self.fleet.fleet_list[i].active_weapon.name}, ATT: {self.fleet.fleet_list[i].active_weapon.attack_power}\")\n        print()\n\n    def select_robot_weapon(self):\n        self.robot_names = ['Terminator', 'Destroyer', \"Annihilator\"]\n        for i in range(len(self.robot_names)):\n            print(f\"\\nSelect a weapon for robot {self.robot_names[i]}:\")\n            for n in range(len(self.weapons)):\n                print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")\n            self.m = input(\"\\nWeapon \")\n            self.n = re.sub(r\"[^0-9]\", \"\", self.m)\n            while len(self.n) == 0 or int(self.n) not in range(len(self.weapons)):\n                print(f\"\\nSelect a weapon for robot {self.robot_names[i]}\\n\")\n                for n in range(len(self.weapons)):\n                    print(f\"Input {n} to select: {self.weapons[n].name}, ATT: {self.weapons[n].attack_power}\")\n                self.m = input(\"\\nWeapon \")\n                self.n = re.sub(r\"[^0-9]\", \"\", self.m)\n            if int(self.n) in range(len(self.weapons)):\n                print(f\"You've selected {self.weapons[int(self.n)].name} (ATT: {self.weapons[int(self.n)].attack_power})\")\n                self.fleet.add_robot(Robot(self.robot_names[i], self.weapons[int(self.n)].name, self.weapons[int(self.n)].attack_power))\n                self.weapons.remove(self.weapons[int(self.n)])\n\n    def coin_toss(self):\n        # Can probably simplify this.\n        self.coin = random.choice(['heads', 'tails'])\n        self.turn = True\n        if self.coin == 'tails':\n            self.turn = not(self.turn)\n        print(\"Coin Toss Results\")\n        if self.turn == True:\n            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Destructive Robots will be starting this battle!\")\n        elif self.turn == False:\n            print(f\"The coin toss result is in and its... {self.coin.upper()}! The Raging Dinosaurs will be starting this battle!\")\n\n    # Consider reducing lines of code: initializing variables in the init(), creating a battle_phase_battle_status() for status, fix the \n    # \"has been ELIMINATED\" as a reflect could knock out a player on the player's own turn - probably need to use different variables in\n    # the (current_player)_turn().  \n    def battle_phase(self):\n        while len(self.fleet.fleet_list) > 0 and len(self.herd.herd_list) > 0:\n            self.current_turn = math.ceil(self.player_turn\/2)\n            i, j = 0, 0\n            if self.turn == True:\n                i, j = self.robots_turn()\n                n = int(self.fleet.fleet_list[i].attack(self.herd.herd_list[j]))\n                print(f\"\\nTurn {self.current_turn}: Robots\")\n                print(f\"{self.display_robot_attack(n, i, j)[0]} Robot {self.fleet.fleet_list[i].name} attacks {self.herd.herd_list[j].name} with \"\\\n                    f\"{self.fleet.fleet_list[i].active_weapon.name} for\", self.display_robot_attack(n, i, j)[1])\n                print(f\"Dinosaur {self.herd.herd_list[j].name} has {self.herd.herd_list[j].health if self.herd.herd_list[j].health > 0 else 0} \"\\\n                    f\"health remaining! \")\n                if self.herd.herd_list[j].health <= 0:\n                    print(f\"Dinosaur {self.herd.herd_list[j].name} has been ELIMINATED!\")\n                    self.herd.remove_dinosaur()\n                self.turn = False\n            elif self.turn == False:\n                i, j = self.dinosaurs_turn()\n                n = int(self.herd.herd_list[i].attack(self.fleet.fleet_list[j]))\n                print(f\"\\nTurn {self.current_turn}: Dinosaurs\")\n                print(f\"{self.display_dinosaur_attack(n, i, j)[0]} Dinosaur {self.herd.herd_list[i].name} attacks {self.fleet.fleet_list[j].name} for\",\\\n                    self.display_dinosaur_attack(n, i, j)[1])\n                print(f\"Robot {self.fleet.fleet_list[j].name} has {self.fleet.fleet_list[j].health if self.fleet.fleet_list[j].health > 0 else 0} \"\\\n                    f\"health remaining!\")\n                if self.fleet.fleet_list[j].health <= 0:\n                    print(f\"Robot {self.fleet.fleet_list[j].name} has been ELIMINATED!\")\n                    self.fleet.remove_robot()\n                self.turn = True            \n            self.player_turn += 1\n            \n    # Consider reducing lines of code\n    def robots_turn(self):\n        print(\"\\nSelect your attacking robot:\")\n        self.fleet.display_robot_selection()\n        self.h = input(\"Robot \")\n        self.i = re.sub(r\"[^0-9]\", \"\", self.h)\n        while len(self.i) == 0 or int(self.i) not in range(len(self.fleet.fleet_list)):\n            print(\"\\nSelect your attacking robot:\")\n            self.fleet.display_robot_selection()\n            self.h = input(\"Robot \")\n            self.i = re.sub(r\"[^0-9]\", \"\", self.h)\n        if int(self.i) in range(len(self.fleet.fleet_list)):\n            print(f\"You've selected {self.fleet.fleet_list[int(self.i)].name}!\")\n            print(\"\\nSelect a dinosaur to attack:\")\n            self.herd.display_dinosaur_selection()\n            self.k = input(\"Dinosaur \")\n            self.j = re.sub(r\"[^0-9]\", \"\", self.k)\n            while len(self.j) == 0 or int(self.j) not in range(len(self.herd.herd_list)):\n                print(\"\\nSelect a dinosaur to attack:\")\n                self.herd.display_dinosaur_selection()\n                self.k = input(\"Dinosuar \")\n                self.j = re.sub(r\"[^0-9]\", \"\", self.k)\n            print(f\"You've selected to attack {self.herd.herd_list[int(self.j)].name}\")\n        self.turn = False\n        return int(self.i), int(self.j)\n    \n    # Consider reducing lines of code, intializing variables in init(), Reconfigure the conditions. Maybe include another if\/else \n    # clause after \"if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):\" to check if it\n    # the value is bigger than self.dinosaur_attack_max, self.robot_attack_max to select max.\n    def dinosaurs_turn(self):\n        self.dinosaur_attack_max, self.robot_attack_max = 0, 0\n        i, j = 0, 0\n        for n in range(1, len(self.herd.herd_list)-1):\n            if int(self.herd.herd_list[n-1].attack_power) >= int(self.herd.herd_list[n].attack_power):\n                self.dinosaur_attack_max = int(self.herd.herd_list[n-1].attack_power)\n            else:\n                self.dinosaur_attack_max = int(self.herd.herd_list[n].attack_power)\n        for n in range(len(self.herd.herd_list)):\n            if self.herd.herd_list[n].attack_power == self.dinosaur_attack_max:\n                i = n\n        for n in range(1, len(self.fleet.fleet_list)-1):\n            if int(self.fleet.fleet_list[n-1].active_weapon.attack_power) >= int(self.fleet.fleet_list[n].active_weapon.attack_power):\n                self.robot_attack_max = int(self.fleet.fleet_list[n-1].active_weapon.attack_power)\n            else:\n                self.robot_attack_max = int(self.fleet.fleet_list[n].active_weapon.attack_power)\n        for n in range(len(self.fleet.fleet_list)):\n            if self.fleet.fleet_list[n].active_weapon.attack_power == self.robot_attack_max:\n                j = n\n        return i, j\n    \n    # Consider moving hit to its own function and\/or combining display_(player)_attack by the self.turn booleaan to determine statements.\n    def display_robot_attack(self, n, i, j):\n        hit = \"HIT!\"\n        statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage!\"\n        if n == 1: \n            hit = \"3x CRITCAL HIT!\"\n            statement = f\"triple damage ({3 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"\n        elif n in range(2, 10):\n            hit = \"2x CRITICAL HIT!\"\n            statement = f\"double damage ({2 * self.fleet.fleet_list[int(i)].active_weapon.attack_power} dmg)!\"\n        elif n == 100:\n            hit = \"MISS!\"\n            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attacked and healed quite a bit!\"\n        elif n in range(96, 99):\n            hit = \"MISS!\"\n            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack and healed a little bit!\"\n        elif n in range(86, 95):\n            hit = \"MISS!\"\n            statement = f\"0 damage as {self.herd.herd_list[int(j)].name} dodged the attack!\"\n        elif n in range(53, 85):\n            hit = \"WEAK HIT!\"\n            statement = f\"half the damage ({math.ceil(0.5 * self.fleet.fleet_list[int(i)].active_weapon.attack_power)} dmg) as \"\\\n                f\"{self.herd.herd_list[int(j)].name} blocked the attack!\"\n        elif n == 50:\n            hit = \"HIT REFLECTED!\"\n            statement = f\"{self.fleet.fleet_list[int(i)].active_weapon.attack_power} damage but it was deflected back at Robot \"\\\n                        f\"{self.fleet.fleet_list[int(i)].name}!\"\n        return hit, statement\n\n    def display_dinosaur_attack(self, n, i, j):\n        hit = \"HIT!\"\n        statement = f\"{self.herd.herd_list[int(i)].attack_power} damage!\"\n        if n == 1:\n            hit = \"3x CRITICAL HIT!\"\n            statement = f\"triple damage ({3 * self.herd.herd_list[int(i)].attack_power} dmg)!\"\n        elif n in range(2, 10):\n            hit = \"2x CRITICAL HIT!\"\n            statement = f\"double damage ({2 * self.herd.herd_list[int(i)].attack_power} dmg)!\"\n        elif n == 100:\n            hit = \"MISS!\"\n            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed quite a bit!\"\n        elif n in range(96, 99):\n            hit = \"MISS!\"\n            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack and healed a little bit!\"\n        elif n in range(86, 95):\n            hit = \"MISS!\"\n            statement = f\"0 damage as {self.fleet.fleet_list[int(j)].name} dodged the attack!\"     \n        elif n in range(53, 85):\n            hit = \"WEAK HIT!\"\n            statement = f\"half the damage ({math.ceil(0.5 * self.herd.herd_list[int(i)].attack_power)} dmg) as {self.fleet.fleet_list[int(j)].name} \"\\\n                f\"blocked the attack!\"    \n        elif n == 50:\n            hit = \"HIT REFLECTED!\"    \n            statement = f\"{self.herd.herd_list[int(i)].attack_power} damage but it was deflected back at dinosaur {self.herd.herd_list[int(i)].name}!\"   \n        return hit, statement\n\n    def display_winner(self): \n        if len(self.fleet.fleet_list) == 0:\n            print(\"\\nTHE RAGING DINOSAURS WIN!\")\n        elif len(self.herd.herd_list) == 0: \n            print(\"\\nTHE DESTRUCTIVE ROBOTS WIN!\")\n"},"\/dinosaur.py":{"changes":[{"diff":"\n class Dinosaur:\n     def __init__(self, name, attack_power):\n         self.name = name\n-        self.health = random.randint(50, 100)\n         self.attack_power = attack_power\n+        self.health = random.randint(50, 100)\n \n-    # Add block - 50% damage, and dodge capability.\n     def attack(self, robot):\n-        n = random.randint(1, 100)\n-        if n == 1:\n+        d20 = random.randint(1, 20)\n+        if d20 in range(19, 20):       \n             robot.health -= (3 * self.attack_power)\n-        elif n in range(1, 10):\n+        elif d20 in range(15, 18):\n             robot.health -= (2 * self.attack_power)\n-        elif n == 100:\n-            robot.health += random.randint(10, 25)\n-        elif n in range(96, 99):\n-            robot.health += random.randint(1, 10)  \n-        elif n in range (86, 95):\n+        elif d20 in range(7, 10):        \n+            robot.health -= math.ceil(0.5 * self.attack_power)        \n+        elif d20 in range(5, 7):\n             pass\n-        elif n in range(53, 85):         \n-            robot.health -= math.ceil(0.5 * self.attack_power)\n-        elif n == 50:\n+        elif d20 in range(3, 5):\n+            robot.health += random.randint(1, 10)\n+        elif d20 == 2:\n+            robot.health += random.randint(10, 25)  \n+        elif d20 == 1:\n             self.health -= self.attack_power\n         else:\n             robot.health -= self.attack_power\n-        return n\n\\ No newline at end of file\n+        return d20\n\\ No newline at end of fil","add":13,"remove":14,"filename":"\/dinosaur.py","badparts":["        self.health = random.randint(50, 100)","        n = random.randint(1, 100)","        if n == 1:","        elif n in range(1, 10):","        elif n == 100:","            robot.health += random.randint(10, 25)","        elif n in range(96, 99):","            robot.health += random.randint(1, 10)  ","        elif n in range (86, 95):","        elif n in range(53, 85):         ","            robot.health -= math.ceil(0.5 * self.attack_power)","        elif n == 50:","        return n"],"goodparts":["        self.health = random.randint(50, 100)","        d20 = random.randint(1, 20)","        if d20 in range(19, 20):       ","        elif d20 in range(15, 18):","        elif d20 in range(7, 10):        ","            robot.health -= math.ceil(0.5 * self.attack_power)        ","        elif d20 in range(5, 7):","        elif d20 in range(3, 5):","            robot.health += random.randint(1, 10)","        elif d20 == 2:","            robot.health += random.randint(10, 25)  ","        elif d20 == 1:","        return d20"]}],"source":"\nimport random import math class Dinosaur: def __init__(self, name, attack_power): self.name=name self.health=random.randint(50, 100) self.attack_power=attack_power def attack(self, robot): n=random.randint(1, 100) if n==1: robot.health -=(3 * self.attack_power) elif n in range(1, 10): robot.health -=(2 * self.attack_power) elif n==100: robot.health +=random.randint(10, 25) elif n in range(96, 99): robot.health +=random.randint(1, 10) elif n in range(86, 95): pass elif n in range(53, 85): robot.health -=math.ceil(0.5 * self.attack_power) elif n==50: self.health -=self.attack_power else: robot.health -=self.attack_power return n ","sourceWithComments":"import random\nimport math\n\nclass Dinosaur:\n    def __init__(self, name, attack_power):\n        self.name = name\n        self.health = random.randint(50, 100)\n        self.attack_power = attack_power\n\n    # Add block - 50% damage, and dodge capability.\n    def attack(self, robot):\n        n = random.randint(1, 100)\n        if n == 1:\n            robot.health -= (3 * self.attack_power)\n        elif n in range(1, 10):\n            robot.health -= (2 * self.attack_power)\n        elif n == 100:\n            robot.health += random.randint(10, 25)\n        elif n in range(96, 99):\n            robot.health += random.randint(1, 10)  \n        elif n in range (86, 95):\n            pass\n        elif n in range(53, 85):         \n            robot.health -= math.ceil(0.5 * self.attack_power)\n        elif n == 50:\n            self.health -= self.attack_power\n        else:\n            robot.health -= self.attack_power\n        return n"},"\/fleet.py":{"changes":[{"diff":"\n-from robot import Robot\n-\n class Fleet:\n     def __init__(self):\n-        self.fleet_list = []\n+        self.fleet_list = [] \n \n     def add_robot(self, robot):\n-        self.fleet_list.append(robot)\n+        self.fleet_list.append(robot)     \n+\n+    def display_robots_stats(self):\n+        print(\"\\nThe Destructive Robots Roster\\n\")\n+        for i in range(len(self.fleet_list)):\n+            print(f\"{i + 1}. {self.fleet_list[i].name}, HP: {self.fleet_list[i].health}, Weapon: {self.fleet_list[i].active_weapon.name}, \"\\\n+                f\"ATT: {self.fleet_list[i].active_weapon.attack_power}\")\n \n     def display_robot_selection(self):\n+        print(\"\\nSelect your attacking robot:\")\n         for i in range(len(self.fleet_list)):\n-            print(f\"Input {i} to select robot {self.fleet_list[i].name} (ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\\n+            print(f\"Input {i} to select robot {self.fleet_list[i].name} (W_ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\\n                 f\"{self.fleet_list[i].health})\")\n-        print()\n \n     def remove_robot(self):\n-        for i, j in enumerate(self.fleet_list):\n+        for i, robot in enumerate(self.fleet_list):\n             if self.fleet_list[i].health <= 0:\n-                self.fleet_list.remove(j)\n\\ No newline at end of file\n+                print(f\"Robot {self.fleet_list[i].name} has been ELIMINATED!\")\n+                self.fleet_list.remove(robot)\n\\ No newline at end of fi","add":13,"remove":8,"filename":"\/fleet.py","badparts":["from robot import Robot","        self.fleet_list = []","        self.fleet_list.append(robot)","            print(f\"Input {i} to select robot {self.fleet_list[i].name} (ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\","        print()","        for i, j in enumerate(self.fleet_list):","                self.fleet_list.remove(j)"],"goodparts":["        self.fleet_list = [] ","        self.fleet_list.append(robot)     ","    def display_robots_stats(self):","        print(\"\\nThe Destructive Robots Roster\\n\")","        for i in range(len(self.fleet_list)):","            print(f\"{i + 1}. {self.fleet_list[i].name}, HP: {self.fleet_list[i].health}, Weapon: {self.fleet_list[i].active_weapon.name}, \"\\","                f\"ATT: {self.fleet_list[i].active_weapon.attack_power}\")","        print(\"\\nSelect your attacking robot:\")","            print(f\"Input {i} to select robot {self.fleet_list[i].name} (W_ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\","        for i, robot in enumerate(self.fleet_list):","                print(f\"Robot {self.fleet_list[i].name} has been ELIMINATED!\")","                self.fleet_list.remove(robot)"]}],"source":"\nfrom robot import Robot class Fleet: def __init__(self): self.fleet_list=[] def add_robot(self, robot): self.fleet_list.append(robot) def display_robot_selection(self): for i in range(len(self.fleet_list)): print(f\"Input{i} to select robot{self.fleet_list[i].name}(ATT:{self.fleet_list[i].active_weapon.attack_power}, HP:\",\\ f\"{self.fleet_list[i].health})\") print() def remove_robot(self): for i, j in enumerate(self.fleet_list): if self.fleet_list[i].health <=0: self.fleet_list.remove(j) ","sourceWithComments":"from robot import Robot\n\nclass Fleet:\n    def __init__(self):\n        self.fleet_list = []\n\n    def add_robot(self, robot):\n        self.fleet_list.append(robot)\n\n    def display_robot_selection(self):\n        for i in range(len(self.fleet_list)):\n            print(f\"Input {i} to select robot {self.fleet_list[i].name} (ATT: {self.fleet_list[i].active_weapon.attack_power}, HP:\",\\\n                f\"{self.fleet_list[i].health})\")\n        print()\n\n    def remove_robot(self):\n        for i, j in enumerate(self.fleet_list):\n            if self.fleet_list[i].health <= 0:\n                self.fleet_list.remove(j)"},"\/herd.py":{"changes":[{"diff":"\n-from dinosaur import Dinosaur\n-\n class Herd:\n     def __init__(self):\n         self.herd_list = []\n","add":0,"remove":2,"filename":"\/herd.py","badparts":["from dinosaur import Dinosaur"],"goodparts":[]},{"diff":"\n     def add_dinosaur(self, dinosaur):\n         self.herd_list.append(dinosaur)\n \n+    def display_dinosaurs_stats(self):\n+        print(\"The Raging Dinosaurs Roster\\n\")\n+        for i in range(len(self.herd_list)):\n+            print(f\"{i + 1}. {self.herd_list[i].name}, HP: {self.herd_list[i].health}, ATT: {self.herd_list[i].attack_power}\")\n+\n     def display_dinosaur_selection(self):\n+        print(\"\\nSelect a dinosaur to attack:\")\n         for i in range(len(self.herd_list)):\n             print(f\"Input {i} to select dinosaur {self.herd_list[i].name} (ATT: {self.herd_list[i].attack_power}, HP: {self.herd_list[i].health})\")\n-        print()\n \n     def remove_dinosaur(self):\n-        for i, j in enumerate(self.herd_list):\n+        for i, dinosaur in enumerate(self.herd_list):\n             if self.herd_list[i].health <= 0:\n-                self.herd_list.remove(j)\n\\ No newline at end of file\n+                print(f\"Dinosaur {self.herd_list[i].name} has been ELIMINATED!\")\n+                self.herd_list.remove(dinosaur)\n\\ No newline at end of f","add":9,"remove":3,"filename":"\/herd.py","badparts":["        print()","        for i, j in enumerate(self.herd_list):","                self.herd_list.remove(j)"],"goodparts":["    def display_dinosaurs_stats(self):","        print(\"The Raging Dinosaurs Roster\\n\")","        for i in range(len(self.herd_list)):","            print(f\"{i + 1}. {self.herd_list[i].name}, HP: {self.herd_list[i].health}, ATT: {self.herd_list[i].attack_power}\")","        print(\"\\nSelect a dinosaur to attack:\")","        for i, dinosaur in enumerate(self.herd_list):","                print(f\"Dinosaur {self.herd_list[i].name} has been ELIMINATED!\")","                self.herd_list.remove(dinosaur)"]}],"source":"\nfrom dinosaur import Dinosaur class Herd: def __init__(self): self.herd_list=[] def add_dinosaur(self, dinosaur): self.herd_list.append(dinosaur) def display_dinosaur_selection(self): for i in range(len(self.herd_list)): print(f\"Input{i} to select dinosaur{self.herd_list[i].name}(ATT:{self.herd_list[i].attack_power}, HP:{self.herd_list[i].health})\") print() def remove_dinosaur(self): for i, j in enumerate(self.herd_list): if self.herd_list[i].health <=0: self.herd_list.remove(j) ","sourceWithComments":"from dinosaur import Dinosaur\n\nclass Herd:\n    def __init__(self):\n        self.herd_list = []\n\n    def add_dinosaur(self, dinosaur):\n        self.herd_list.append(dinosaur)\n\n    def display_dinosaur_selection(self):\n        for i in range(len(self.herd_list)):\n            print(f\"Input {i} to select dinosaur {self.herd_list[i].name} (ATT: {self.herd_list[i].attack_power}, HP: {self.herd_list[i].health})\")\n        print()\n\n    def remove_dinosaur(self):\n        for i, j in enumerate(self.herd_list):\n            if self.herd_list[i].health <= 0:\n                self.herd_list.remove(j)"},"\/main.py":{"changes":[{"diff":"\n from battlefield import Battlefield\n+from replay import Replay\n+\n+\n+user_input = True\n+times_played = 0\n+wins = [0, 0]\n+\n+while user_input:\n+    battlefield_one = Battlefield()\n+    winner = battlefield_one.run_game()\n+    replay = Replay()\n+    user_input = replay.replay()\n+    times_played += 1\n+    if winner == \"robots\":\n+        wins[0] = int(wins[0]) + 1\n+    elif winner == \"dinosaurs\":\n+        wins[1] = int(wins[1]) + 1\n+\n+print(f\"\\nYou have played a total of {times_played} games!\")\n+print(f\"The Destructive Robots wins: {wins[0]}\")\n+print(f\"The Raging Dinosaurs wins: {wins[1]}\\n\")\n \n \n-# Consider adding a replay()\n-battlefield_one = Battlefield()\n-battlefield_one.run_game()\n\\ No newline at end of ","add":21,"remove":3,"filename":"\/main.py","badparts":["battlefield_one = Battlefield()","battlefield_one.run_game()"],"goodparts":["from replay import Replay","user_input = True","times_played = 0","wins = [0, 0]","while user_input:","    battlefield_one = Battlefield()","    winner = battlefield_one.run_game()","    replay = Replay()","    user_input = replay.replay()","    times_played += 1","    if winner == \"robots\":","        wins[0] = int(wins[0]) + 1","    elif winner == \"dinosaurs\":","        wins[1] = int(wins[1]) + 1","print(f\"\\nYou have played a total of {times_played} games!\")","print(f\"The Destructive Robots wins: {wins[0]}\")","print(f\"The Raging Dinosaurs wins: {wins[1]}\\n\")"]}],"source":"\nfrom battlefield import Battlefield battlefield_one=Battlefield() battlefield_one.run_game() ","sourceWithComments":"from battlefield import Battlefield\n\n\n# Consider adding a replay()\nbattlefield_one = Battlefield()\nbattlefield_one.run_game()"},"\/robot.py":{"changes":[{"diff":"\n         self.active_weapon = Weapon(weapon, attack_power)\n \n     def attack(self, dinosaur):\n-        n = random.randint(1, 100)\n-        if n == 1:\n+        d20 = random.randint(1, 20)\n+        if d20 in range(19, 20):\n             dinosaur.health -= (3 * self.active_weapon.attack_power)\n-        elif n in range(2, 10):\n+        elif d20 in range(15, 18):\n             dinosaur.health -= (2 * self.active_weapon.attack_power)\n-        elif n == 100:\n-            dinosaur.health += random.randint(10, 25)\n-        elif n in range(96, 99):\n-            dinosaur.health += random.randint(1, 10)      \n-        elif n in range (86, 95):\n-            pass        \n-        elif n in range(53, 85):\n+        elif d20 in range(7, 10):\n             dinosaur.health -= math.ceil(0.5 * self.active_weapon.attack_power)\n-        elif n == 50:\n-            self.health -= self.active_weapon.attack_power\n+        elif d20 in range(5, 7):\n+            pass\n+        elif d20 in range(3, 5):\n+            dinosaur.health += random.randint(1, 10) \n+        elif d20 == 2:\n+            dinosaur.health += random.randint(10, 25)        \n+        elif d20 == 1:\n+            self.health -= self.active_weapon.attack_power           \n         else: \n             dinosaur.health -= self.active_weapon.attack_power\n-        return n\n\\ No newline at end of file\n+        return d20\n\\ No newline at end o","add":13,"remove":13,"filename":"\/robot.py","badparts":["        n = random.randint(1, 100)","        if n == 1:","        elif n in range(2, 10):","        elif n == 100:","            dinosaur.health += random.randint(10, 25)","        elif n in range(96, 99):","            dinosaur.health += random.randint(1, 10)      ","        elif n in range (86, 95):","            pass        ","        elif n in range(53, 85):","        elif n == 50:","            self.health -= self.active_weapon.attack_power","        return n"],"goodparts":["        d20 = random.randint(1, 20)","        if d20 in range(19, 20):","        elif d20 in range(15, 18):","        elif d20 in range(7, 10):","        elif d20 in range(5, 7):","            pass","        elif d20 in range(3, 5):","            dinosaur.health += random.randint(1, 10) ","        elif d20 == 2:","            dinosaur.health += random.randint(10, 25)        ","        elif d20 == 1:","            self.health -= self.active_weapon.attack_power           ","        return d20"]}],"source":"\nfrom weapon import Weapon import random import math class Robot: def __init__(self, name, weapon, attack_power): self.name=name self.health=random.randint(50, 100) self.active_weapon=Weapon(weapon, attack_power) def attack(self, dinosaur): n=random.randint(1, 100) if n==1: dinosaur.health -=(3 * self.active_weapon.attack_power) elif n in range(2, 10): dinosaur.health -=(2 * self.active_weapon.attack_power) elif n==100: dinosaur.health +=random.randint(10, 25) elif n in range(96, 99): dinosaur.health +=random.randint(1, 10) elif n in range(86, 95): pass elif n in range(53, 85): dinosaur.health -=math.ceil(0.5 * self.active_weapon.attack_power) elif n==50: self.health -=self.active_weapon.attack_power else: dinosaur.health -=self.active_weapon.attack_power return n ","sourceWithComments":"from weapon import Weapon\nimport random\nimport math\n\n\nclass Robot:\n    def __init__(self, name, weapon, attack_power):\n        self.name = name\n        self.health = random.randint(50, 100)\n        self.active_weapon = Weapon(weapon, attack_power)\n\n    def attack(self, dinosaur):\n        n = random.randint(1, 100)\n        if n == 1:\n            dinosaur.health -= (3 * self.active_weapon.attack_power)\n        elif n in range(2, 10):\n            dinosaur.health -= (2 * self.active_weapon.attack_power)\n        elif n == 100:\n            dinosaur.health += random.randint(10, 25)\n        elif n in range(96, 99):\n            dinosaur.health += random.randint(1, 10)      \n        elif n in range (86, 95):\n            pass        \n        elif n in range(53, 85):\n            dinosaur.health -= math.ceil(0.5 * self.active_weapon.attack_power)\n        elif n == 50:\n            self.health -= self.active_weapon.attack_power\n        else: \n            dinosaur.health -= self.active_weapon.attack_power\n        return n"}},"msg":"Simplified class battlefields's select_robot_weapon(), coin_toss(), battle_phase(), robots_turn(), display_robot_attack(), dinosaur_turn(), display_dinosaur_attack(); added message to classes herd's and fleet's display_(player)_selection() and remove_(player)(); changed classes robot() and dinosaur() attack() to d20; added replay class to replay game; and added end game result status to main."}},"https:\/\/github.com\/rogerils\/antispoofing.motion":{"eb8eea4c449bac81e4940778c4a7579c3b29a898":{"url":"https:\/\/api.github.com\/repos\/rogerils\/antispoofing.motion\/commits\/eb8eea4c449bac81e4940778c4a7579c3b29a898","html_url":"https:\/\/github.com\/rogerils\/antispoofing.motion\/commit\/eb8eea4c449bac81e4940778c4a7579c3b29a898","message":"Reflect replay attack DB changes","sha":"eb8eea4c449bac81e4940778c4a7579c3b29a898","keyword":"replay attack change","diff":"diff --git a\/antispoofing\/motion\/script\/diffcluster.py b\/antispoofing\/motion\/script\/diffcluster.py\nindex c6a2e96..1d13569 100644\n--- a\/antispoofing\/motion\/script\/diffcluster.py\n+++ b\/antispoofing\/motion\/script\/diffcluster.py\n@@ -30,7 +30,7 @@ def main():\n   import numpy\n   from xbob.db.replay import Database\n \n-  protocols = Database().protocols()\n+  protocols = [k.name() for k in Database().protocols()]\n \n   basedir = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\n   INPUTDIR = os.path.join(basedir, 'framediff')\n@@ -76,8 +76,7 @@ def main():\n \n   db = Database()\n \n-  process = db.files(directory=args.inputdir, extension='.hdf5', \n-      protocol=args.protocol, support=args.support)\n+  process = db.objects(protocol=args.protocol, support=args.support)\n   \n   if args.grid_count:\n     print len(process)\n@@ -97,11 +96,11 @@ def main():\n   sys.stdout.flush()\n \n   counter = 0\n-  for key, filename in process.items():\n+  for obj in process.items():\n     counter += 1\n      \n-    filename = os.path.expanduser(filename)\n-    \n+    filename = obj.make_path(args.inputdir, '.hdf5')\n+ \n     sys.stdout.write(\"Processing file %s [%d\/%d] \" % (filename, counter, len(process)))\n \n     input = bob.io.load(filename)\n@@ -109,7 +108,7 @@ def main():\n     d_face = cluster_5quantities(input[:,0], args.window_size, args.overlap)\n     d_bg   = cluster_5quantities(input[:,1], args.window_size, args.overlap)\n     arr = numpy.hstack((d_face, d_bg))\n-    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')\n+    obj.save(arr, directory=args.outputdir, extension='.hdf5')\n     sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir)\n     sys.stdout.flush()\n \n","files":{"\/antispoofing\/motion\/script\/diffcluster.py":{"changes":[{"diff":"\n   import numpy\n   from xbob.db.replay import Database\n \n-  protocols = Database().protocols()\n+  protocols = [k.name() for k in Database().protocols()]\n \n   basedir = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\n   INPUTDIR = os.path.join(basedir, 'framediff')\n","add":1,"remove":1,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["  protocols = Database().protocols()"],"goodparts":["  protocols = [k.name() for k in Database().protocols()]"]},{"diff":"\n \n   db = Database()\n \n-  process = db.files(directory=args.inputdir, extension='.hdf5', \n-      protocol=args.protocol, support=args.support)\n+  process = db.objects(protocol=args.protocol, support=args.support)\n   \n   if args.grid_count:\n     print len(process)\n","add":1,"remove":2,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["  process = db.files(directory=args.inputdir, extension='.hdf5', ","      protocol=args.protocol, support=args.support)"],"goodparts":["  process = db.objects(protocol=args.protocol, support=args.support)"]},{"diff":"\n   sys.stdout.flush()\n \n   counter = 0\n-  for key, filename in process.items():\n+  for obj in process.items():\n     counter += 1\n      \n-    filename = os.path.expanduser(filename)\n-    \n+    filename = obj.make_path(args.inputdir, '.hdf5')\n+ \n     sys.stdout.write(\"Processing file %s [%d\/%d] \" % (filename, counter, len(process)))\n \n     input = bob.io.load(filename)\n","add":3,"remove":3,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["  for key, filename in process.items():","    filename = os.path.expanduser(filename)"],"goodparts":["  for obj in process.items():","    filename = obj.make_path(args.inputdir, '.hdf5')"]},{"diff":"\n     d_face = cluster_5quantities(input[:,0], args.window_size, args.overlap)\n     d_bg   = cluster_5quantities(input[:,1], args.window_size, args.overlap)\n     arr = numpy.hstack((d_face, d_bg))\n-    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')\n+    obj.save(arr, directory=args.outputdir, extension='.hdf5')\n     sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir)\n     sys.stdout.flush()\n \n","add":1,"remove":1,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')"],"goodparts":["    obj.save(arr, directory=args.outputdir, extension='.hdf5')"]}],"source":"\n \"\"\"Calculates the clustered values as described at the paper: Counter-Measures to Photo Attacks in Face Recognition: a public database and a baseline, Anjos & Marcel, IJCB'11. This script will output a number of clustered observations containing the 5 described quantities for windows of a configurable size(N): 1. The minimum value observed on the cluster 2. The maximum value observed on the cluster 3. The mean value observed 4. The standard deviation on the cluster 5. The DC ratio(D) as defined by: .. math:: D(N)=\\frac{\\sum_{i=1}^N{|FFT_i|}}{|FFT_0|} \"\"\" import os, sys import argparse def main(): import bob import numpy from xbob.db.replay import Database protocols=Database().protocols() basedir=os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0]))) INPUTDIR=os.path.join(basedir, 'framediff') OUTPUTDIR=os.path.join(basedir, 'clustered') parser=argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter) parser.add_argument('inputdir', metavar='DIR', type=str, default=INPUTDIR, nargs='?', help='Base directory containing the frame differences to be treated by this procedure(defaults to \"%(default)s\")') parser.add_argument('outputdir', metavar='DIR', type=str, default=OUTPUTDIR, nargs='?', help='Base output directory for every file created by this procedure(defaults to \"%(default)s\")') parser.add_argument('-p', '--protocol', metavar='PROTOCOL', type=str, default='grandtest', choices=protocols, dest=\"protocol\", help=\"The protocol type may be specified to subselect a smaller number of files to operate on(one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(protocols))) supports=('fixed', 'hand', 'hand+fixed') parser.add_argument('-s', '--support', metavar='SUPPORT', type=str, default='hand+fixed', dest='support', choices=supports, help=\"If you would like to select a specific support to be used, use this option(one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(supports))) parser.add_argument('-n', '--window-size', dest=\"window_size\", default=20, type=int, help=\"determines the window size to be used when clustering frame-difference observations(defaults to %(default)s)\"), parser.add_argument('-o', '--overlap', dest=\"overlap\", default=0, type=int, help=\"determines the window overlapping; this number has to be between 0(no overlapping) and 'window-size'-1(defaults to %(default)s)\"), parser.add_argument('--grid-count', dest='grid_count', action='store_true', default=False, help=argparse.SUPPRESS) args=parser.parse_args() if args.window_size <=0: parser.error(\"window-size has to be greater than 0\") if args.overlap >=args.window_size or args.overlap < 0: parser.error(\"overlap has to be smaller than window-size and greater or equal zero\") if args.support=='hand+fixed': args.support=('hand', 'fixed') from.. import cluster_5quantities db=Database() process=db.files(directory=args.inputdir, extension='.hdf5', protocol=args.protocol, support=args.support) if args.grid_count: print len(process) sys.exit(0) if os.environ.has_key('SGE_TASK_ID'): pos=int(os.environ['SGE_TASK_ID']) -1 ordered_keys=sorted(process.keys()) if pos >=len(ordered_keys): raise RuntimeError, \"Grid request for job %d on a setup with %d jobs\" % \\ (pos, len(ordered_keys)) key=ordered_keys[pos] process={key: process[key]} sys.stdout.write('Processing %d file(s)\\n' % len(process)) sys.stdout.flush() counter=0 for key, filename in process.items(): counter +=1 filename=os.path.expanduser(filename) sys.stdout.write(\"Processing file %s[%d\/%d] \" %(filename, counter, len(process))) input=bob.io.load(filename) d_face=cluster_5quantities(input[:,0], args.window_size, args.overlap) d_bg =cluster_5quantities(input[:,1], args.window_size, args.overlap) arr=numpy.hstack((d_face, d_bg)) db.save_one(key, arr, directory=args.outputdir, extension='.hdf5') sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir) sys.stdout.flush() sys.stdout.write('\\n') sys.stdout.flush() return 0 if __name__==\"__main__\": main() ","sourceWithComments":"#!\/usr\/bin\/env python\n# vim: set fileencoding=utf-8 :\n# Andre Anjos <andre.anjos@idiap.ch>\n# Mon 02 Aug 2010 11:31:31 CEST \n\n\"\"\"Calculates the clustered values as described at the paper:\nCounter-Measures to Photo Attacks in Face Recognition: a public database and a\nbaseline, Anjos & Marcel, IJCB'11.\n\nThis script will output a number of clustered observations containing the 5\ndescribed quantities for windows of a configurable size (N):\n\n1. The minimum value observed on the cluster\n2. The maximum value observed on the cluster\n3. The mean value observed\n4. The standard deviation on the cluster\n5. The DC ratio (D) as defined by:\n\n.. math::\n\n  D(N) = \\frac{\\sum_{i=1}^N{|FFT_i|}}{|FFT_0|}\n\"\"\"\n\nimport os, sys\nimport argparse\n\ndef main():\n\n  import bob\n  import numpy\n  from xbob.db.replay import Database\n\n  protocols = Database().protocols()\n\n  basedir = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\n  INPUTDIR = os.path.join(basedir, 'framediff')\n  OUTPUTDIR = os.path.join(basedir, 'clustered')\n\n  parser = argparse.ArgumentParser(description=__doc__,\n      formatter_class=argparse.RawDescriptionHelpFormatter)\n  parser.add_argument('inputdir', metavar='DIR', type=str, default=INPUTDIR,\n      nargs='?', help='Base directory containing the frame differences to be treated by this procedure (defaults to \"%(default)s\")')\n  parser.add_argument('outputdir', metavar='DIR', type=str, default=OUTPUTDIR,\n      nargs='?', help='Base output directory for every file created by this procedure (defaults to \"%(default)s\")')\n  parser.add_argument('-p', '--protocol', metavar='PROTOCOL', type=str,\n      default='grandtest', choices=protocols, dest=\"protocol\",\n      help=\"The protocol type may be specified to subselect a smaller number of files to operate on (one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(protocols)))\n\n  supports = ('fixed', 'hand', 'hand+fixed')\n\n  parser.add_argument('-s', '--support', metavar='SUPPORT', type=str,\n      default='hand+fixed', dest='support', choices=supports, help=\"If you would like to select a specific support to be used, use this option (one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(supports)))\n\n  parser.add_argument('-n', '--window-size', dest=\"window_size\", default=20,\n      type=int, help=\"determines the window size to be used when clustering frame-difference observations (defaults to %(default)s)\"),\n  parser.add_argument('-o', '--overlap', dest=\"overlap\", default=0, type=int,\n      help=\"determines the window overlapping; this number has to be between 0 (no overlapping) and 'window-size'-1 (defaults to %(default)s)\"),\n\n  # The next option just returns the total number of cases we will be running\n  # It can be used to set jman --array option. To avoid user confusion, this\n  # option is suppressed # from the --help menu\n  parser.add_argument('--grid-count', dest='grid_count', action='store_true',\n      default=False, help=argparse.SUPPRESS)\n\n  args = parser.parse_args()\n\n  # checks window size and overlap\n  if args.window_size <= 0:\n    parser.error(\"window-size has to be greater than 0\")\n  if args.overlap >= args.window_size or args.overlap < 0:\n    parser.error(\"overlap has to be smaller than window-size and greater or equal zero\")\n\n  if args.support == 'hand+fixed': args.support = ('hand', 'fixed')\n\n  from .. import cluster_5quantities\n\n  db = Database()\n\n  process = db.files(directory=args.inputdir, extension='.hdf5', \n      protocol=args.protocol, support=args.support)\n  \n  if args.grid_count:\n    print len(process)\n    sys.exit(0)\n \n  # if we are on a grid environment, just find what I have to process.\n  if os.environ.has_key('SGE_TASK_ID'):\n    pos = int(os.environ['SGE_TASK_ID']) - 1\n    ordered_keys = sorted(process.keys())\n    if pos >= len(ordered_keys):\n      raise RuntimeError, \"Grid request for job %d on a setup with %d jobs\" % \\\n          (pos, len(ordered_keys))\n    key = ordered_keys[pos] # gets the right key\n    process = {key: process[key]}\n\n  sys.stdout.write('Processing %d file(s)\\n' % len(process))\n  sys.stdout.flush()\n\n  counter = 0\n  for key, filename in process.items():\n    counter += 1\n     \n    filename = os.path.expanduser(filename)\n    \n    sys.stdout.write(\"Processing file %s [%d\/%d] \" % (filename, counter, len(process)))\n\n    input = bob.io.load(filename)\n    \n    d_face = cluster_5quantities(input[:,0], args.window_size, args.overlap)\n    d_bg   = cluster_5quantities(input[:,1], args.window_size, args.overlap)\n    arr = numpy.hstack((d_face, d_bg))\n    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')\n    sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir)\n    sys.stdout.flush()\n\n  sys.stdout.write('\\n')\n  sys.stdout.flush()\n\n  return 0\n\nif __name__ == \"__main__\":\n  main()\n"}},"msg":"Reflect replay attack DB changes"}},"https:\/\/github.com\/tiagofrepereira2012\/antispoofing.motion":{"eb8eea4c449bac81e4940778c4a7579c3b29a898":{"url":"https:\/\/api.github.com\/repos\/tiagofrepereira2012\/antispoofing.motion\/commits\/eb8eea4c449bac81e4940778c4a7579c3b29a898","html_url":"https:\/\/github.com\/tiagofrepereira2012\/antispoofing.motion\/commit\/eb8eea4c449bac81e4940778c4a7579c3b29a898","message":"Reflect replay attack DB changes","sha":"eb8eea4c449bac81e4940778c4a7579c3b29a898","keyword":"replay attack change","diff":"diff --git a\/antispoofing\/motion\/script\/diffcluster.py b\/antispoofing\/motion\/script\/diffcluster.py\nindex c6a2e96..1d13569 100644\n--- a\/antispoofing\/motion\/script\/diffcluster.py\n+++ b\/antispoofing\/motion\/script\/diffcluster.py\n@@ -30,7 +30,7 @@ def main():\n   import numpy\n   from xbob.db.replay import Database\n \n-  protocols = Database().protocols()\n+  protocols = [k.name() for k in Database().protocols()]\n \n   basedir = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\n   INPUTDIR = os.path.join(basedir, 'framediff')\n@@ -76,8 +76,7 @@ def main():\n \n   db = Database()\n \n-  process = db.files(directory=args.inputdir, extension='.hdf5', \n-      protocol=args.protocol, support=args.support)\n+  process = db.objects(protocol=args.protocol, support=args.support)\n   \n   if args.grid_count:\n     print len(process)\n@@ -97,11 +96,11 @@ def main():\n   sys.stdout.flush()\n \n   counter = 0\n-  for key, filename in process.items():\n+  for obj in process.items():\n     counter += 1\n      \n-    filename = os.path.expanduser(filename)\n-    \n+    filename = obj.make_path(args.inputdir, '.hdf5')\n+ \n     sys.stdout.write(\"Processing file %s [%d\/%d] \" % (filename, counter, len(process)))\n \n     input = bob.io.load(filename)\n@@ -109,7 +108,7 @@ def main():\n     d_face = cluster_5quantities(input[:,0], args.window_size, args.overlap)\n     d_bg   = cluster_5quantities(input[:,1], args.window_size, args.overlap)\n     arr = numpy.hstack((d_face, d_bg))\n-    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')\n+    obj.save(arr, directory=args.outputdir, extension='.hdf5')\n     sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir)\n     sys.stdout.flush()\n \n","files":{"\/antispoofing\/motion\/script\/diffcluster.py":{"changes":[{"diff":"\n   import numpy\n   from xbob.db.replay import Database\n \n-  protocols = Database().protocols()\n+  protocols = [k.name() for k in Database().protocols()]\n \n   basedir = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\n   INPUTDIR = os.path.join(basedir, 'framediff')\n","add":1,"remove":1,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["  protocols = Database().protocols()"],"goodparts":["  protocols = [k.name() for k in Database().protocols()]"]},{"diff":"\n \n   db = Database()\n \n-  process = db.files(directory=args.inputdir, extension='.hdf5', \n-      protocol=args.protocol, support=args.support)\n+  process = db.objects(protocol=args.protocol, support=args.support)\n   \n   if args.grid_count:\n     print len(process)\n","add":1,"remove":2,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["  process = db.files(directory=args.inputdir, extension='.hdf5', ","      protocol=args.protocol, support=args.support)"],"goodparts":["  process = db.objects(protocol=args.protocol, support=args.support)"]},{"diff":"\n   sys.stdout.flush()\n \n   counter = 0\n-  for key, filename in process.items():\n+  for obj in process.items():\n     counter += 1\n      \n-    filename = os.path.expanduser(filename)\n-    \n+    filename = obj.make_path(args.inputdir, '.hdf5')\n+ \n     sys.stdout.write(\"Processing file %s [%d\/%d] \" % (filename, counter, len(process)))\n \n     input = bob.io.load(filename)\n","add":3,"remove":3,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["  for key, filename in process.items():","    filename = os.path.expanduser(filename)"],"goodparts":["  for obj in process.items():","    filename = obj.make_path(args.inputdir, '.hdf5')"]},{"diff":"\n     d_face = cluster_5quantities(input[:,0], args.window_size, args.overlap)\n     d_bg   = cluster_5quantities(input[:,1], args.window_size, args.overlap)\n     arr = numpy.hstack((d_face, d_bg))\n-    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')\n+    obj.save(arr, directory=args.outputdir, extension='.hdf5')\n     sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir)\n     sys.stdout.flush()\n \n","add":1,"remove":1,"filename":"\/antispoofing\/motion\/script\/diffcluster.py","badparts":["    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')"],"goodparts":["    obj.save(arr, directory=args.outputdir, extension='.hdf5')"]}],"source":"\n \"\"\"Calculates the clustered values as described at the paper: Counter-Measures to Photo Attacks in Face Recognition: a public database and a baseline, Anjos & Marcel, IJCB'11. This script will output a number of clustered observations containing the 5 described quantities for windows of a configurable size(N): 1. The minimum value observed on the cluster 2. The maximum value observed on the cluster 3. The mean value observed 4. The standard deviation on the cluster 5. The DC ratio(D) as defined by: .. math:: D(N)=\\frac{\\sum_{i=1}^N{|FFT_i|}}{|FFT_0|} \"\"\" import os, sys import argparse def main(): import bob import numpy from xbob.db.replay import Database protocols=Database().protocols() basedir=os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0]))) INPUTDIR=os.path.join(basedir, 'framediff') OUTPUTDIR=os.path.join(basedir, 'clustered') parser=argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter) parser.add_argument('inputdir', metavar='DIR', type=str, default=INPUTDIR, nargs='?', help='Base directory containing the frame differences to be treated by this procedure(defaults to \"%(default)s\")') parser.add_argument('outputdir', metavar='DIR', type=str, default=OUTPUTDIR, nargs='?', help='Base output directory for every file created by this procedure(defaults to \"%(default)s\")') parser.add_argument('-p', '--protocol', metavar='PROTOCOL', type=str, default='grandtest', choices=protocols, dest=\"protocol\", help=\"The protocol type may be specified to subselect a smaller number of files to operate on(one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(protocols))) supports=('fixed', 'hand', 'hand+fixed') parser.add_argument('-s', '--support', metavar='SUPPORT', type=str, default='hand+fixed', dest='support', choices=supports, help=\"If you would like to select a specific support to be used, use this option(one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(supports))) parser.add_argument('-n', '--window-size', dest=\"window_size\", default=20, type=int, help=\"determines the window size to be used when clustering frame-difference observations(defaults to %(default)s)\"), parser.add_argument('-o', '--overlap', dest=\"overlap\", default=0, type=int, help=\"determines the window overlapping; this number has to be between 0(no overlapping) and 'window-size'-1(defaults to %(default)s)\"), parser.add_argument('--grid-count', dest='grid_count', action='store_true', default=False, help=argparse.SUPPRESS) args=parser.parse_args() if args.window_size <=0: parser.error(\"window-size has to be greater than 0\") if args.overlap >=args.window_size or args.overlap < 0: parser.error(\"overlap has to be smaller than window-size and greater or equal zero\") if args.support=='hand+fixed': args.support=('hand', 'fixed') from.. import cluster_5quantities db=Database() process=db.files(directory=args.inputdir, extension='.hdf5', protocol=args.protocol, support=args.support) if args.grid_count: print len(process) sys.exit(0) if os.environ.has_key('SGE_TASK_ID'): pos=int(os.environ['SGE_TASK_ID']) -1 ordered_keys=sorted(process.keys()) if pos >=len(ordered_keys): raise RuntimeError, \"Grid request for job %d on a setup with %d jobs\" % \\ (pos, len(ordered_keys)) key=ordered_keys[pos] process={key: process[key]} sys.stdout.write('Processing %d file(s)\\n' % len(process)) sys.stdout.flush() counter=0 for key, filename in process.items(): counter +=1 filename=os.path.expanduser(filename) sys.stdout.write(\"Processing file %s[%d\/%d] \" %(filename, counter, len(process))) input=bob.io.load(filename) d_face=cluster_5quantities(input[:,0], args.window_size, args.overlap) d_bg =cluster_5quantities(input[:,1], args.window_size, args.overlap) arr=numpy.hstack((d_face, d_bg)) db.save_one(key, arr, directory=args.outputdir, extension='.hdf5') sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir) sys.stdout.flush() sys.stdout.write('\\n') sys.stdout.flush() return 0 if __name__==\"__main__\": main() ","sourceWithComments":"#!\/usr\/bin\/env python\n# vim: set fileencoding=utf-8 :\n# Andre Anjos <andre.anjos@idiap.ch>\n# Mon 02 Aug 2010 11:31:31 CEST \n\n\"\"\"Calculates the clustered values as described at the paper:\nCounter-Measures to Photo Attacks in Face Recognition: a public database and a\nbaseline, Anjos & Marcel, IJCB'11.\n\nThis script will output a number of clustered observations containing the 5\ndescribed quantities for windows of a configurable size (N):\n\n1. The minimum value observed on the cluster\n2. The maximum value observed on the cluster\n3. The mean value observed\n4. The standard deviation on the cluster\n5. The DC ratio (D) as defined by:\n\n.. math::\n\n  D(N) = \\frac{\\sum_{i=1}^N{|FFT_i|}}{|FFT_0|}\n\"\"\"\n\nimport os, sys\nimport argparse\n\ndef main():\n\n  import bob\n  import numpy\n  from xbob.db.replay import Database\n\n  protocols = Database().protocols()\n\n  basedir = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\n  INPUTDIR = os.path.join(basedir, 'framediff')\n  OUTPUTDIR = os.path.join(basedir, 'clustered')\n\n  parser = argparse.ArgumentParser(description=__doc__,\n      formatter_class=argparse.RawDescriptionHelpFormatter)\n  parser.add_argument('inputdir', metavar='DIR', type=str, default=INPUTDIR,\n      nargs='?', help='Base directory containing the frame differences to be treated by this procedure (defaults to \"%(default)s\")')\n  parser.add_argument('outputdir', metavar='DIR', type=str, default=OUTPUTDIR,\n      nargs='?', help='Base output directory for every file created by this procedure (defaults to \"%(default)s\")')\n  parser.add_argument('-p', '--protocol', metavar='PROTOCOL', type=str,\n      default='grandtest', choices=protocols, dest=\"protocol\",\n      help=\"The protocol type may be specified to subselect a smaller number of files to operate on (one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(protocols)))\n\n  supports = ('fixed', 'hand', 'hand+fixed')\n\n  parser.add_argument('-s', '--support', metavar='SUPPORT', type=str,\n      default='hand+fixed', dest='support', choices=supports, help=\"If you would like to select a specific support to be used, use this option (one of '%s'; defaults to '%%(default)s')\" % '|'.join(sorted(supports)))\n\n  parser.add_argument('-n', '--window-size', dest=\"window_size\", default=20,\n      type=int, help=\"determines the window size to be used when clustering frame-difference observations (defaults to %(default)s)\"),\n  parser.add_argument('-o', '--overlap', dest=\"overlap\", default=0, type=int,\n      help=\"determines the window overlapping; this number has to be between 0 (no overlapping) and 'window-size'-1 (defaults to %(default)s)\"),\n\n  # The next option just returns the total number of cases we will be running\n  # It can be used to set jman --array option. To avoid user confusion, this\n  # option is suppressed # from the --help menu\n  parser.add_argument('--grid-count', dest='grid_count', action='store_true',\n      default=False, help=argparse.SUPPRESS)\n\n  args = parser.parse_args()\n\n  # checks window size and overlap\n  if args.window_size <= 0:\n    parser.error(\"window-size has to be greater than 0\")\n  if args.overlap >= args.window_size or args.overlap < 0:\n    parser.error(\"overlap has to be smaller than window-size and greater or equal zero\")\n\n  if args.support == 'hand+fixed': args.support = ('hand', 'fixed')\n\n  from .. import cluster_5quantities\n\n  db = Database()\n\n  process = db.files(directory=args.inputdir, extension='.hdf5', \n      protocol=args.protocol, support=args.support)\n  \n  if args.grid_count:\n    print len(process)\n    sys.exit(0)\n \n  # if we are on a grid environment, just find what I have to process.\n  if os.environ.has_key('SGE_TASK_ID'):\n    pos = int(os.environ['SGE_TASK_ID']) - 1\n    ordered_keys = sorted(process.keys())\n    if pos >= len(ordered_keys):\n      raise RuntimeError, \"Grid request for job %d on a setup with %d jobs\" % \\\n          (pos, len(ordered_keys))\n    key = ordered_keys[pos] # gets the right key\n    process = {key: process[key]}\n\n  sys.stdout.write('Processing %d file(s)\\n' % len(process))\n  sys.stdout.flush()\n\n  counter = 0\n  for key, filename in process.items():\n    counter += 1\n     \n    filename = os.path.expanduser(filename)\n    \n    sys.stdout.write(\"Processing file %s [%d\/%d] \" % (filename, counter, len(process)))\n\n    input = bob.io.load(filename)\n    \n    d_face = cluster_5quantities(input[:,0], args.window_size, args.overlap)\n    d_bg   = cluster_5quantities(input[:,1], args.window_size, args.overlap)\n    arr = numpy.hstack((d_face, d_bg))\n    db.save_one(key, arr, directory=args.outputdir, extension='.hdf5')\n    sys.stdout.write('Saving results to \"%s\"...\\n' % args.outputdir)\n    sys.stdout.flush()\n\n  sys.stdout.write('\\n')\n  sys.stdout.flush()\n\n  return 0\n\nif __name__ == \"__main__\":\n  main()\n"}},"msg":"Reflect replay attack DB changes"}},"https:\/\/github.com\/Grantkey\/prototype":{"35300cf8c3a8cc6a8d9ca78c57ab42760e798eb7":{"url":"https:\/\/api.github.com\/repos\/Grantkey\/prototype\/commits\/35300cf8c3a8cc6a8d9ca78c57ab42760e798eb7","html_url":"https:\/\/github.com\/Grantkey\/prototype\/commit\/35300cf8c3a8cc6a8d9ca78c57ab42760e798eb7","message":"add timestamp checks to prevent replay attacks","sha":"35300cf8c3a8cc6a8d9ca78c57ab42760e798eb7","keyword":"replay attack check","diff":"diff --git a\/Block.py b\/Block.py\nindex 6f6aa54..8627bf0 100644\n--- a\/Block.py\n+++ b\/Block.py\n@@ -5,7 +5,7 @@\n import re\n \n class Block:\n-    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number):\n+    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number,latest_block_ts):\n         self.persona = Persona()\n         self.contract_json = contract_json\n         #contract_str_tmp = contract_json.replace('{\"Payload\":','')\n@@ -20,6 +20,7 @@ def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block\n         self.fee = int(self.payload[\"fee\"])\n         self.party_key_str = rebend(self.contract[\"key\"])\n         #self.counterparty_key_str = rebend(self.payload[\"Counterparty Key\"])\n+        self.latest_block_ts = latest_block_ts\n         self.prior_signature = prior_signature\n         self.party_balance = party_balance\n         self.party_nfts = party_nfts\n@@ -93,6 +94,12 @@ def validate_contract(self):\n         if self.payload[\"tokens\"] != str(self.tokens):\n             print(\"invalid token value\")\n             return False\n+        if self.payload[\"created\"] > get_ts():\n+            return False\n+        if self.payload[\"created\"] < lim_ts():\n+            return False\n+        if self.payload[\"created\"] <= self.latest_block_ts:\n+            return False\n         #print(\"validate1\")\n         if self.fee < 1 and self.payload[\"origin\"] != AUTHORITY_ADDRESS:\n             print(\"invalid fee value\")\n@@ -107,9 +114,16 @@ def validate_contract(self):\n             return False\n         #print(\"validate4\")\n         if self.payload[\"type\"] == \"Transfer NFT\":\n+            if self.payload[\"data\"] == \"\":\n+                print(\"Invalid NFT\")\n+                return False\n             if self.payload[\"data\"] not in self.party_nfts:\n                 print(\"NFT does not belong to party\")\n                 return False\n+        if self.payload[\"type\"] == \"Mint NFT\":\n+            if self.payload[\"data\"] == \"\":\n+                print(\"Invalid NFT data\")\n+                return False\n \n         #print(\"validate5\")\n         return self.persona.validate_signature(self.payload_str,self.contract_signature,self.party_key_str)\n@@ -140,6 +154,6 @@ def __str__(self):\n     print(b)\n     \"\"\"\n     d = Contract(contract_type=\"Transfer NFT\",data=\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n-    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1)\n+    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1,lim_ts())\n     print(x)\n \ndiff --git a\/Blockchain.py b\/Blockchain.py\nindex 95294be..4e14c85 100644\n--- a\/Blockchain.py\n+++ b\/Blockchain.py\n@@ -22,6 +22,7 @@ def __init__(self, party_balances_storage='storage\/party_balances.pickle',previo\n         self.address_keys_storage = address_keys_storage\n         self.blockchain_storage = blockchain_storage\n         self.nft_storage = nft_storage\n+        self.latest_block_ts = get_ts()\n         \n         if path.exists(party_balances_storage):\n             self.party_balances = pickle.load(open(party_balances_storage,'rb'))\n@@ -95,6 +96,8 @@ def store(self):\n         with open(self.address_keys_storage,'wb') as bf:\n             pickle.dump(self.address_keys,bf)\n \n+        self.latest_block_ts = get_ts()\n+\n     def get_address_key(self,address):\n         address = address.lower()\n         return self.address_keys[address]\n@@ -141,10 +144,10 @@ def add(self,contract_json):\n         print(AUTHORITY_ADDRESS)\n         \"\"\"\n         party_nfts = set() if origin not in self.nfts else self.nfts[origin]\n-        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number)\n+        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number,self.latest_block_ts)\n         #print(\"return block\")\n         is_valid = block.validation_result\n-        #print(is_valid)\n+\n         if is_valid:\n             self.previous_signature = block.authority_signature\n             self.blockchain.append(block)\ndiff --git a\/static.py b\/static.py\nindex d4c9fdb..747c81d 100644\n--- a\/static.py\n+++ b\/static.py\n@@ -1,9 +1,12 @@\n from Persona import Persona\n p = Persona()\n-from datetime import timezone,datetime\n+from datetime import timezone,datetime,timedelta\n+import json\n \n utc_ts = datetime.now().replace(tzinfo = timezone.utc).timestamp\n-get_ts = lambda: str(datetime.now(timezone.utc))\n+get_ts = lambda: datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n+#get_ts = lambda: json.dumps(datetime.now(timezone.utc).isoformat())\n+lim_ts = lambda: (datetime.now(timezone.utc) - timedelta(seconds=2)).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n \n MB = 10485760\n HOST = \"grantkey.com\"\n@@ -45,3 +48,4 @@ def get_contract_json_str(payload):\n \n def extract_signed_json(d):\n         return '{\"address\":\"' + d['address'] + '\",\"payload\":' + get_contract_json_str(d['payload']) + ',\"key\":\"' + unbend(d['key']) + '\",\"signature\":\"' + d['signature'] + '\"}'\n+\n","files":{"\/Block.py":{"changes":[{"diff":"\n import re\n \n class Block:\n-    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number):\n+    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number,latest_block_ts):\n         self.persona = Persona()\n         self.contract_json = contract_json\n         #contract_str_tmp = contract_json.replace('{\"Payload\":','')\n","add":1,"remove":1,"filename":"\/Block.py","badparts":["    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number):"],"goodparts":["    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number,latest_block_ts):"]},{"diff":"\n     print(b)\n     \"\"\"\n     d = Contract(contract_type=\"Transfer NFT\",data=\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n-    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1)\n+    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1,lim_ts())\n     print(x)\n ","add":1,"remove":1,"filename":"\/Block.py","badparts":["    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1)"],"goodparts":["    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1,lim_ts())"]}],"source":"\nfrom Persona import Persona from static import * import binascii as ba import json import re class Block: def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number): self.persona=Persona() self.contract_json=contract_json self.contract=json.loads(contract_json) self.payload=self.contract[\"payload\"] self.payload_str=get_contract_json_str(self.payload) self.contract_signature=ba.unhexlify(self.contract[\"signature\"]) self.tokens=int(self.payload[\"tokens\"]) self.fee=int(self.payload[\"fee\"]) self.party_key_str=rebend(self.contract[\"key\"]) self.prior_signature=prior_signature self.party_balance=party_balance self.party_nfts=party_nfts self.block_number=block_number self.validation_timestamp=get_ts() self.validation_result=self.validate_contract() self.evaluation_ready=self.evaluate_execution_time() self.evaluation_result=self.evaluate_contract() self.authority_signature=self.persona.get_msg_signature_str(str(prior_signature) +str(block_number) +self.contract_json) if self.validation_result else None self.block_fields=[ \"block\", \"contract\", \"timestamp\", \"evaluation\", \"signature\", ] self.block_data=[ self.block_number, self.contract_json, self.validation_timestamp, self.evaluation_result, self.authority_signature, ] def is_invalid_hash(self,address,tp=\"address\"): if tp==\"data\" and address==\"\": return False if len(address) !=64: return True if address !=address.lower(): print(\"case error\") return True if not bool(re.match(r\"^[a-f0-9]{64}$\",address)): return True return False def validate_contract(self): if self.is_invalid_hash(self.payload[\"origin\"]): return False if self.is_invalid_hash(self.payload[\"destination\"]): return False if self.is_invalid_hash(self.payload[\"data\"],\"data\"): return False if self.payload[\"tokens\"] !=str(self.tokens): print(\"invalid token value\") return False if self.fee < 1 and self.payload[\"origin\"] !=AUTHORITY_ADDRESS: print(\"invalid fee value\") return False if self.tokens < 0: print(\"invalid token value\") return False if(self.tokens +self.fee) > self.party_balance: print(\"not enough tokens for contract\") return False if self.payload[\"type\"]==\"Transfer NFT\": if self.payload[\"data\"] not in self.party_nfts: print(\"NFT does not belong to party\") return False return self.persona.validate_signature(self.payload_str,self.contract_signature,self.party_key_str) def evaluate_execution_time(self): return True def evaluate_contract(self): if not self.evaluation_ready: return False return True def __str__(self): if self.validation_result: return '{\"block\":\"' +str(self.block_number) +'\",\"contract\":'+self.contract_json +',\"timestamp\":\"' +str(self.validation_timestamp) +'\",\"evaluation\":\"' +str(self.evaluation_result) +'\",\"signature\":\"' +self.authority_signature +'\"}' return \" INVALID CONTRACT\" if __name__=='__main__': from Contract import Contract \"\"\" c=Contract() b=Block(c.get_signed_json(),'fake_sig',10,{'aaa','bbb'},1) print(b) \"\"\" d=Contract(contract_type=\"Transfer NFT\",data=\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\") x=Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1) print(x) ","sourceWithComments":"from Persona import Persona\nfrom static import *\nimport binascii as ba\nimport json\nimport re\n\nclass Block:\n    def __init__(self, contract_json, prior_signature,party_balance,party_nfts,block_number):\n        self.persona = Persona()\n        self.contract_json = contract_json\n        #contract_str_tmp = contract_json.replace('{\"Payload\":','')\n        #marker_start = ',\"Payload\":'\n        #self.contract_str = contract_json[contract_json.find(',\"Payload\":') + len(marker_start):contract_json.find(',\"Signature\":\"')]\n        self.contract = json.loads(contract_json)\n        self.payload = self.contract[\"payload\"]\n        self.payload_str = get_contract_json_str(self.payload) #TODO get this into static!\n        #print(self.contract_str)\n        self.contract_signature = ba.unhexlify(self.contract[\"signature\"])\n        self.tokens = int(self.payload[\"tokens\"])\n        self.fee = int(self.payload[\"fee\"])\n        self.party_key_str = rebend(self.contract[\"key\"])\n        #self.counterparty_key_str = rebend(self.payload[\"Counterparty Key\"])\n        self.prior_signature = prior_signature\n        self.party_balance = party_balance\n        self.party_nfts = party_nfts\n        self.block_number = block_number\n        self.validation_timestamp = get_ts()\n        self.validation_result = self.validate_contract()\n        self.evaluation_ready = self.evaluate_execution_time()\n        self.evaluation_result = self.evaluate_contract()\n        self.authority_signature = self.persona.get_msg_signature_str(str(prior_signature) + str(block_number) + self.contract_json) if self.validation_result else None\n        self.block_fields = [\n            \"block\",\n            \"contract\",\n            #\"Authority\",\n            #\"Contract Address\",\n            #\"Contract Type\",\n            #\"Origin\",\n            #\"Destination\",\n            #\"Terms\",\n            #\"Data\",\n            #\"Tokens\",\n            #\"Effective Timestamp\",\n            #\"Fee\",\n            #\"Contract Key\",\n            #\"Contract Signature\",\n            \"timestamp\",\n            \"evaluation\",\n            \"signature\",\n        ]\n\n        self.block_data = [\n            self.block_number,\n            self.contract_json,\n            #self.payload[\"authority\"],\n            #self.contract[\"address\"],\n            #self.payload[\"type\"],\n            #self.payload[\"origin\"],\n            #self.payload[\"destination\"],\n            #self.payload[\"terms\"],\n            #self.payload[\"data\"],\n            #self.tokens,\n            #self.payload[\"effective\"],\n            #self.fee,\n            #self.contract[\"key\"],\n            #self.contract[\"signature\"],\n            self.validation_timestamp,\n            self.evaluation_result,\n            self.authority_signature,\n        ]\n\n    def is_invalid_hash(self,address,tp=\"address\"):\n        if tp == \"data\" and address == \"\":\n            return False\n        if len(address) != 64:\n            return True\n        if address != address.lower():\n            print(\"case error\")\n            return True\n        if not bool(re.match(r\"^[a-f0-9]{64}$\",address)):\n            return True\n        return False\n\n    def validate_contract(self):\n        # Validation code here\n        #print(\"validate\")\n        if self.is_invalid_hash(self.payload[\"origin\"]):\n            return False\n        if self.is_invalid_hash(self.payload[\"destination\"]):\n            return False\n        if self.is_invalid_hash(self.payload[\"data\"],\"data\"):\n            return False\n        if self.payload[\"tokens\"] != str(self.tokens):\n            print(\"invalid token value\")\n            return False\n        #print(\"validate1\")\n        if self.fee < 1 and self.payload[\"origin\"] != AUTHORITY_ADDRESS:\n            print(\"invalid fee value\")\n            return False\n        #print(\"validate2\")\n        if self.tokens < 0:\n            print(\"invalid token value\")\n            return False\n        #print(\"validate3\")\n        if (self.tokens + self.fee) > self.party_balance:\n            print(\"not enough tokens for contract\")\n            return False\n        #print(\"validate4\")\n        if self.payload[\"type\"] == \"Transfer NFT\":\n            if self.payload[\"data\"] not in self.party_nfts:\n                print(\"NFT does not belong to party\")\n                return False\n\n        #print(\"validate5\")\n        return self.persona.validate_signature(self.payload_str,self.contract_signature,self.party_key_str)\n\n    def evaluate_execution_time(self):\n        # Evaluation code here\n        return True\n\n    def evaluate_contract(self):\n        # Evaluation code here\n        if not self.evaluation_ready:\n            return False\n        return True\n\n    def __str__(self):\n        if self.validation_result:\n            #return \"\\n\\n  \"  + '\\n\\n  '.join([self.block_fields[i] + \":  \" + str(e) for i,e in enumerate(self.block_data)]) + \"\\n\\n  --------------\\n\"\n            #return '{\"'  + '\",\"'.join([self.block_fields[i] + '\":\"' + unbend(e) for i,e in enumerate(self.block_data)]) + '\"}'\n            return '{\"block\":\"' + str(self.block_number) + '\",\"contract\":'+ self.contract_json + ',\"timestamp\":\"' + str(self.validation_timestamp) + '\",\"evaluation\":\"' + str(self.evaluation_result) + '\",\"signature\":\"' + self.authority_signature + '\"}'\n        return \"  INVALID CONTRACT\"\n\nif __name__ == '__main__':\n    from Contract import Contract\n    \"\"\"\n    c = Contract()\n    b = Block(c.get_signed_json(),'fake_sig',10,{'aaa','bbb'},1)\n    #print(c.get_signed_json())\n    print(b)\n    \"\"\"\n    d = Contract(contract_type=\"Transfer NFT\",data=\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\")\n    x = Block(d.get_signed_json(),'fake_sig',10,{'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','bbb'},1)\n    print(x)\n\n"},"\/Blockchain.py":{"changes":[{"diff":"\n         print(AUTHORITY_ADDRESS)\n         \"\"\"\n         party_nfts = set() if origin not in self.nfts else self.nfts[origin]\n-        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number)\n+        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number,self.latest_block_ts)\n         #print(\"return block\")\n         is_valid = block.validation_result\n-        #print(is_valid)\n+\n         if is_valid:\n             self.previous_signature = block.authority_signature\n             self.blockchain.append(block","add":2,"remove":2,"filename":"\/Blockchain.py","badparts":["        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number)"],"goodparts":["        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number,self.latest_block_ts)"]}],"source":"\nfrom Block import Block from Persona import Persona from Contract import Contract import pickle from os import chmod,path from static import * import json class Blockchain: def __init__(self, party_balances_storage='storage\/party_balances.pickle',previous_signature_storage='storage\/previous_signature.pickle',blockchain_storage='storage\/blockchain_record.pickle',address_keys_storage='storage\/address_keys.pickle',nft_storage='storage\/nfts.pickle'): self.persona=Persona() self.blockchain=[] self.block_number=0 self.previous_signature='Genesis Signature Seed' self.address_keys={AUTHORITY_ADDRESS:AUTHORITY_KEY_STR} self.nfts={} self.party_balances={AUTHORITY_ADDRESS:GENESIS_TOKENS} self.party_balances_storage=party_balances_storage self.previous_signature_storage=previous_signature_storage self.address_keys_storage=address_keys_storage self.blockchain_storage=blockchain_storage self.nft_storage=nft_storage if path.exists(party_balances_storage): self.party_balances=pickle.load(open(party_balances_storage,'rb')) if path.exists(previous_signature_storage): self.previous_signature=pickle.load(open(previous_signature_storage,'rb')) if path.exists(address_keys_storage): self.address_keys=pickle.load(open(address_keys_storage,'rb')) if path.exists(nft_storage): self.nfts=pickle.load(open(nft_storage,'rb')) if path.exists(blockchain_storage): self.blockchain=pickle.load(open(blockchain_storage,'rb')) self.block_number=len(self.blockchain) else: c=Contract(AUTHORITY_ADDRESS.lower(),GENESIS_TOKENS,\"Genesis Block\",fee=0) self.add(c.get_signed_json()) c2=Contract('0DD7F8D140EBD5D3B2C9BC7E836D8E65393C6D808155066A9CF78AA2A029D97E'.lower(),9999999,\"Transfer Tokens\",data=\"\",fee=0) self.add(c2.get_signed_json()) \"\"\" c2=Contract(AUTHORITY_ADDRESS,0,\"Mint NFT\",data=\"NFT is being minted as the hash of this contract\",fee=0) self.add(c2.get_signed_json()) c3=Contract('1fd7cdc50046c21ea50a87e7be589095ba28f31584d87f0a2f52d0b233945374',0,\"Transfer NFT\",data=c2.address,fee=0) self.add(c3.get_signed_json()) c4=Contract('1fd7cdc50046c21ea50a87e7be589095ba28f31584d87f0a2f52d0b233945374',10000,\"Transfer Tokens\",data=c2.address,fee=0) self.add(c4.get_signed_json()) \"\"\" def faucet(self,payload): if self.block_number > FAUCET_LIMIT: return False authority_address=payload['authority'] if AUTHORITY_ADDRESS !=authority_address: return False server=payload['server'] if HOST !=server: return False if payload['destination'] in self.party_balances: print(\"account exists\") return False c=Contract(payload['destination'],FAUCET_TOKENS,\"Faucet Transfer\",fee=0) return self.add(c.get_signed_json()) def store(self): with open(self.blockchain_storage,'wb') as bf: pickle.dump([str(o) for o in self.blockchain],bf) with open(self.previous_signature_storage,'wb') as bf: pickle.dump(self.previous_signature,bf) with open(self.party_balances_storage,'wb') as bf: pickle.dump(self.party_balances,bf) with open(self.nft_storage,'wb') as bf: pickle.dump(self.nfts,bf) with open(self.address_keys_storage,'wb') as bf: pickle.dump(self.address_keys,bf) def get_address_key(self,address): address=address.lower() return self.address_keys[address] def get_address_balance(self,address): address=address.lower() tokens=0 if address not in self.party_balances else self.party_balances[address] nft_count=0 if address not in self.nfts else len(self.nfts[address]) nft_list='[]' if nft_count==0 else str(list(self.nfts[address])).replace(\"'\",'\"') return '{\"tokens\":' +str(tokens) +',\"nft_count\":' +str(nft_count) +',\"nft_list\":' +nft_list +'}' def add(self,contract_json): contract=json.loads(contract_json) payload=contract['payload'] authority_address=payload['authority'].lower() server=payload['server'].lower() if AUTHORITY_ADDRESS !=authority_address: return False if HOST !=server: return False party_key_str=rebend(contract['key']) origin=payload['origin'].lower() if origin not in self.address_keys: party_address=self.persona.get_key_address(party_key_str) if party_address !=origin: print(\"origin does not match public key hash\") return False self.address_keys[origin]=party_key_str if self.address_keys[origin] !=party_key_str: print(\"origin does not match public key\") return False destination=payload['destination'].lower() self.block_number=len(self.blockchain) \"\"\" print(self.party_balances[origin]) print(origin) print(AUTHORITY_ADDRESS) \"\"\" party_nfts=set() if origin not in self.nfts else self.nfts[origin] block=Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number) is_valid=block.validation_result if is_valid: self.previous_signature=block.authority_signature self.blockchain.append(block) self.party_balances[origin] -=(block.tokens +block.fee) if destination not in self.party_balances: self.party_balances[destination]=0 self.party_balances[destination] +=block.tokens self.party_balances[AUTHORITY_ADDRESS] +=block.fee if contract['payload']['type']==\"Mint NFT\": if destination in self.nfts: self.nfts[destination].add(contract['address']) else: self.nfts[destination]=set([contract['address']]) if contract['payload']['type']==\"Transfer NFT\": self.nfts[origin].remove(payload['data']) if destination not in self.nfts: self.nfts[destination]=set() self.nfts[destination].add(payload['data']) self.store() return True return False def __str__(self): return '[' +','.join([str(b) for b in self.blockchain]) +']' if __name__=='__main__': k=Blockchain() print(k) ","sourceWithComments":"from Block import Block\nfrom Persona import Persona\nfrom Contract import Contract\nimport pickle\nfrom os import chmod,path\nfrom static import *\nimport json\n\nclass Blockchain:\n    def __init__(self, party_balances_storage='storage\/party_balances.pickle',previous_signature_storage='storage\/previous_signature.pickle',blockchain_storage='storage\/blockchain_record.pickle',address_keys_storage='storage\/address_keys.pickle',nft_storage='storage\/nfts.pickle'):\n        \n        self.persona = Persona()\n        self.blockchain = []\n        self.block_number = 0\n        self.previous_signature = 'Genesis Signature Seed'\n        self.address_keys = {AUTHORITY_ADDRESS:AUTHORITY_KEY_STR}\n        #self.key_addresses = {AUTHORITY_KEY_STR:AUTHORITY_ADDRESS}\n        self.nfts = {}\n        self.party_balances = {AUTHORITY_ADDRESS:GENESIS_TOKENS}\n        self.party_balances_storage = party_balances_storage\n        self.previous_signature_storage = previous_signature_storage\n        self.address_keys_storage = address_keys_storage\n        self.blockchain_storage = blockchain_storage\n        self.nft_storage = nft_storage\n        \n        if path.exists(party_balances_storage):\n            self.party_balances = pickle.load(open(party_balances_storage,'rb'))\n\n        if path.exists(previous_signature_storage):\n             self.previous_signature = pickle.load(open(previous_signature_storage,'rb'))\n\n        if path.exists(address_keys_storage):\n            self.address_keys = pickle.load(open(address_keys_storage,'rb'))\n\n        if path.exists(nft_storage):\n            self.nfts = pickle.load(open(nft_storage,'rb'))\n\n        if path.exists(blockchain_storage):\n            self.blockchain = pickle.load(open(blockchain_storage,'rb'))\n            self.block_number = len(self.blockchain)\n        else:\n            c = Contract(AUTHORITY_ADDRESS.lower(),GENESIS_TOKENS,\"Genesis Block\",fee=0)\n            self.add(c.get_signed_json())\n\n            c2 = Contract('0DD7F8D140EBD5D3B2C9BC7E836D8E65393C6D808155066A9CF78AA2A029D97E'.lower(),9999999,\"Transfer Tokens\",data=\"\",fee=0)\n            self.add(c2.get_signed_json())\n            \"\"\"\n            c2 = Contract(AUTHORITY_ADDRESS,0,\"Mint NFT\",data=\"NFT is being minted as the hash of this contract\",fee=0)\n            self.add(c2.get_signed_json())\n            c3 = Contract('1fd7cdc50046c21ea50a87e7be589095ba28f31584d87f0a2f52d0b233945374',0,\"Transfer NFT\",data=c2.address,fee=0)\n            self.add(c3.get_signed_json())\n            c4 = Contract('1fd7cdc50046c21ea50a87e7be589095ba28f31584d87f0a2f52d0b233945374',10000,\"Transfer Tokens\",data=c2.address,fee=0)\n            self.add(c4.get_signed_json())\n            \"\"\"\n\n    def faucet(self,payload):\n        #print(faucet_request_json)\n        if self.block_number > FAUCET_LIMIT:\n            return False\n        #payload = json.loads(faucet_request_json)\n        #print(payload)\n        authority_address = payload['authority']\n        #print(authority_address)\n        if AUTHORITY_ADDRESS != authority_address:\n            return False\n\n        server = payload['server']\n        if HOST != server:\n            return False\n        #party_key_str = rebend(payload['Public Key'])\n\n        #party_address =  self.persona.get_key_address(party_key_str)       \n        if payload['destination'] in self.party_balances:\n            print(\"account exists\")\n            return False\n\n        c = Contract(payload['destination'],FAUCET_TOKENS,\"Faucet Transfer\",fee=0)\n        return self.add(c.get_signed_json())\n\n            \n    def store(self):\n        with open(self.blockchain_storage,'wb') as bf:\n            #pickle.dump(self.blockchain,bf)\n            pickle.dump([str(o) for o in self.blockchain],bf)\n\n        with open(self.previous_signature_storage,'wb') as bf:\n            pickle.dump(self.previous_signature,bf)\n\n        with open(self.party_balances_storage,'wb') as bf:\n            pickle.dump(self.party_balances,bf)\n\n        with open(self.nft_storage,'wb') as bf:\n            pickle.dump(self.nfts,bf)\n\n        with open(self.address_keys_storage,'wb') as bf:\n            pickle.dump(self.address_keys,bf)\n\n    def get_address_key(self,address):\n        address = address.lower()\n        return self.address_keys[address]\n\n    def get_address_balance(self,address):\n        address = address.lower()\n        tokens = 0 if address not in self.party_balances else self.party_balances[address]\n        nft_count = 0 if address not in self.nfts else len(self.nfts[address])\n        nft_list = '[]' if nft_count == 0 else str(list(self.nfts[address])).replace(\"'\",'\"')\n        return '{\"tokens\":' + str(tokens) + ',\"nft_count\":' + str(nft_count) + ',\"nft_list\":' + nft_list + '}'\n\n    def add(self,contract_json):\n        contract = json.loads(contract_json)\n        payload = contract['payload']\n        authority_address = payload['authority'].lower()\n        server = payload['server'].lower()\n\n        if AUTHORITY_ADDRESS != authority_address:\n            return False\n        if HOST != server:\n            return False\n        party_key_str = rebend(contract['key'])\n        origin = payload['origin'].lower()\n\n        if origin not in self.address_keys:\n            party_address = self.persona.get_key_address(party_key_str)\n            if party_address != origin:\n                print(\"origin does not match public key hash\")\n                return False\n            self.address_keys[origin] = party_key_str\n\n        if self.address_keys[origin] != party_key_str:\n            print(\"origin does not match public key\")\n            return False\n\n        destination = payload['destination'].lower()\n\n        #print(\"get block number\")\n        self.block_number = len(self.blockchain)\n\n        \"\"\"\n        print(self.party_balances[origin])\n        print(origin)\n        print(AUTHORITY_ADDRESS)\n        \"\"\"\n        party_nfts = set() if origin not in self.nfts else self.nfts[origin]\n        block = Block(contract_json,self.previous_signature,self.party_balances[origin],party_nfts,self.block_number)\n        #print(\"return block\")\n        is_valid = block.validation_result\n        #print(is_valid)\n        if is_valid:\n            self.previous_signature = block.authority_signature\n            self.blockchain.append(block)\n            self.party_balances[origin] -= (block.tokens + block.fee)\n            if destination not in self.party_balances:\n                self.party_balances[destination] = 0\n            self.party_balances[destination] += block.tokens\n            self.party_balances[AUTHORITY_ADDRESS] += block.fee\n            if contract['payload']['type'] == \"Mint NFT\":\n                if destination in self.nfts:\n                    self.nfts[destination].add(contract['address'])\n                else:    \n                    self.nfts[destination] = set([contract['address']])\n            if contract['payload']['type'] == \"Transfer NFT\":\n                self.nfts[origin].remove(payload['data'])\n                if destination not in self.nfts:\n                    self.nfts[destination] = set()\n                self.nfts[destination].add(payload['data'])\n                \n            self.store()\n            return True\n        return False\n\n    def __str__(self):\n        #return '\\n\\n'.join([\"\\nBlock Number: \" + str(i) + '\\n' + str(b) for i,b in enumerate(self.blockchain)])\n        return '[' + ','.join([str(b) for b in self.blockchain]) + ']'\n\nif __name__ == '__main__':\n    k = Blockchain()\n    print(k)\n"},"\/static.py":{"changes":[{"diff":"\n from Persona import Persona\n p = Persona()\n-from datetime import timezone,datetime\n+from datetime import timezone,datetime,timedelta\n+import json\n \n utc_ts = datetime.now().replace(tzinfo = timezone.utc).timestamp\n-get_ts = lambda: str(datetime.now(timezone.utc))\n+get_ts = lambda: datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n+#get_ts = lambda: json.dumps(datetime.now(timezone.utc).isoformat())\n+lim_ts = lambda: (datetime.now(timezone.utc) - timedelta(seconds=2)).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n \n MB = 10485760\n HOST = \"grantkey.com\"\n","add":5,"remove":2,"filename":"\/static.py","badparts":["from datetime import timezone,datetime","get_ts = lambda: str(datetime.now(timezone.utc))"],"goodparts":["from datetime import timezone,datetime,timedelta","import json","get_ts = lambda: datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"","lim_ts = lambda: (datetime.now(timezone.utc) - timedelta(seconds=2)).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\""]}],"source":"\nfrom Persona import Persona p=Persona() from datetime import timezone,datetime utc_ts=datetime.now().replace(tzinfo=timezone.utc).timestamp get_ts=lambda: str(datetime.now(timezone.utc)) MB=10485760 HOST=\"grantkey.com\" PORT=59999 AUTHORITY_KEY=p.get_key_from_file(\"config\/authority.key\") AUTHORITY_KEY_STR=p.get_key_str(AUTHORITY_KEY) AUTHORITY_ADDRESS=p.get_key_address(AUTHORITY_KEY_STR) PARTY_KEY=p.public_key PARTY_KEY_STR=str(p) PARTY_ADDRESS=p.get_key_address(PARTY_KEY_STR) GENESIS_TOKENS=999999999 FAUCET_LIMIT=500 FAUCET_TOKENS=250 CONTRACT_FIELDS=[ 'authority', 'server', 'created', 'type', 'origin', 'destination', 'data', 'tokens', 'effective', 'fee', ] def unbend(s): return str(s).replace('\\n','\\\\n') def rebend(s): return str(s).replace('\\\\n','\\n') def get_contract_field_str_data(payload): return ''.join([unbend(payload[e]) for e in CONTRACT_FIELDS]) def get_contract_json_str(payload): return '{\"' +'\",\"'.join([e +'\":\"' +unbend(payload[e]) for e in CONTRACT_FIELDS]) +'\"}' def extract_signed_json(d): return '{\"address\":\"' +d['address'] +'\",\"payload\":' +get_contract_json_str(d['payload']) +',\"key\":\"' +unbend(d['key']) +'\",\"signature\":\"' +d['signature'] +'\"}' ","sourceWithComments":"from Persona import Persona\np = Persona()\nfrom datetime import timezone,datetime\n\nutc_ts = datetime.now().replace(tzinfo = timezone.utc).timestamp\nget_ts = lambda: str(datetime.now(timezone.utc))\n\nMB = 10485760\nHOST = \"grantkey.com\"\nPORT = 59999\nAUTHORITY_KEY = p.get_key_from_file(\"config\/authority.key\")\nAUTHORITY_KEY_STR = p.get_key_str(AUTHORITY_KEY)\nAUTHORITY_ADDRESS = p.get_key_address(AUTHORITY_KEY_STR)\nPARTY_KEY = p.public_key\nPARTY_KEY_STR = str(p)\nPARTY_ADDRESS = p.get_key_address(PARTY_KEY_STR)\nGENESIS_TOKENS = 999999999\nFAUCET_LIMIT = 500\nFAUCET_TOKENS = 250\n\nCONTRACT_FIELDS = [\n            'authority',\n            'server',\n            'created',\n            'type',\n            'origin',\n            'destination',\n            'data',\n            'tokens',\n            'effective',\n            'fee',\n        ]\n\ndef unbend(s):\n    return str(s).replace('\\n','\\\\n')\n\ndef rebend(s):\n    return str(s).replace('\\\\n','\\n')\n\ndef get_contract_field_str_data(payload):\n        return ''.join([unbend(payload[e]) for e in CONTRACT_FIELDS])\n\ndef get_contract_json_str(payload):\n        return '{\"' + '\",\"'.join([e + '\":\"' + unbend(payload[e]) for e in CONTRACT_FIELDS]) + '\"}'\n\ndef extract_signed_json(d):\n        return '{\"address\":\"' + d['address'] + '\",\"payload\":' + get_contract_json_str(d['payload']) + ',\"key\":\"' + unbend(d['key']) + '\",\"signature\":\"' + d['signature'] + '\"}'\n"}},"msg":"add timestamp checks to prevent replay attacks"}},"https:\/\/github.com\/jadbin\/elgoog":{"fc01a6cf49c67d4973ad6edcb04276f685a7a397":{"url":"https:\/\/api.github.com\/repos\/jadbin\/elgoog\/commits\/fc01a6cf49c67d4973ad6edcb04276f685a7a397","html_url":"https:\/\/github.com\/jadbin\/elgoog\/commit\/fc01a6cf49c67d4973ad6edcb04276f685a7a397","message":"disable checking replay attack","sha":"fc01a6cf49c67d4973ad6edcb04276f685a7a397","keyword":"replay attack check","diff":"diff --git a\/elgoog\/blueprints\/search.py b\/elgoog\/blueprints\/search.py\nindex c8cca6d..c2c319d 100644\n--- a\/elgoog\/blueprints\/search.py\n+++ b\/elgoog\/blueprints\/search.py\n@@ -32,9 +32,6 @@ def search():\n     url = 'https:\/\/www.google.com.hk\/search?q={}&start={}'.format(quote(query), start)\n     resp = requests.get(url, verify=False, timeout=5, headers=headers)\n     resp_headers = remove_invalid_response_headers(dict(resp.headers))\n-\n-    defender.record(timestamp, nonce)\n-\n     return Response(response=resp.content, status=200, headers=resp_headers)\n \n \ndiff --git a\/elgoog\/defender.py b\/elgoog\/defender.py\nindex 1b14288..822f02c 100644\n--- a\/elgoog\/defender.py\n+++ b\/elgoog\/defender.py\n@@ -2,39 +2,20 @@\n \n import time\n import hashlib\n-from collections import deque\n \n from elgoog import config\n \n \n class Defender:\n-    def __init__(self, timestamp_interval=1800, defense_interval=3600):\n+    def __init__(self, timestamp_interval=600):\n         self.timestamp_interval = timestamp_interval\n-        self.defense_interval = defense_interval\n-        self.replay = set()\n-        self.queue = deque()\n \n     def verify(self, query, start, timestamp, nonce, signature):\n         t = int(time.time())\n-        while len(self.queue) > 0:\n-            if t - self.queue[0][0] < self.defense_interval:\n-                break\n-            o = self.queue.popleft()\n-            if o[1] in self.replay:\n-                self.replay.remove(o[1])\n         s = query + str(start) + str(timestamp) + str(nonce) + config.elgoog_token\n         h = hashlib.sha256(s.encode('utf-8')).hexdigest()\n         if h != signature:\n             return False, 'Bad signature'\n         if abs(t - timestamp) > self.timestamp_interval:\n             return False, 'Bad timestamp, timestamp={}, local timestamp={}'.format(timestamp, t)\n-        x = (timestamp, nonce)\n-        if x in self.replay:\n-            return False, 'Replay attack, timestamp={}, nonce={}'.format(timestamp, nonce)\n         return True, ''\n-\n-    def record(self, timestamp, nonce):\n-        t = int(time.time())\n-        x = (timestamp, nonce)\n-        self.queue.append((t, x))\n-        self.replay.add(x)\n","files":{"\/elgoog\/blueprints\/search.py":{"changes":[{"diff":"\n     url = 'https:\/\/www.google.com.hk\/search?q={}&start={}'.format(quote(query), start)\n     resp = requests.get(url, verify=False, timeout=5, headers=headers)\n     resp_headers = remove_invalid_response_headers(dict(resp.headers))\n-\n-    defender.record(timestamp, nonce)\n-\n     return Response(response=resp.content, status=200, headers=resp_headers)\n \n ","add":0,"remove":3,"filename":"\/elgoog\/blueprints\/search.py","badparts":["    defender.record(timestamp, nonce)"],"goodparts":[]}],"source":"\n import random from urllib.parse import quote import requests from flask import Blueprint, request, abort, Response from elgoog import config from elgoog.defender import Defender search_blueprint=Blueprint('search', __name__) defender=Defender() @search_blueprint.route('\/search', methods=['POST']) def search(): data=request.get_json() query=data.get('query') start=data.get('start') timestamp=data.get('timestamp') nonce=data.get('nonce') signature=data.get('signature') success, message=defender.verify(query, start, timestamp, nonce, signature) if not success: return abort(403, message) headers=config.default_headers headers['User-Agent']=random_user_agent() url='https:\/\/www.google.com.hk\/search?q={}&start={}'.format(quote(query), start) resp=requests.get(url, verify=False, timeout=5, headers=headers) resp_headers=remove_invalid_response_headers(dict(resp.headers)) defender.record(timestamp, nonce) return Response(response=resp.content, status=200, headers=resp_headers) def remove_invalid_response_headers(headers): for i in config.invalid_response_headers: if i in headers: del headers[i] return headers def random_user_agent(): chrome_version='{}.0.{}.{}'.format(random.randint(51, 70), random.randint(0, 9999), random.randint(0, 99)) webkit='{}.{}'.format(random.randint(531, 600), random.randint(0, 99)) os='Macintosh; Intel Mac OS X 10_10_4' return('Mozilla\/5.0({}) AppleWebKit\/{}(KHTML, like Gecko) ' 'Chrome\/{} Safari\/{}').format(os, webkit, chrome_version, webkit) ","sourceWithComments":"# coding=utf-8\n\nimport random\nfrom urllib.parse import quote\n\nimport requests\nfrom flask import Blueprint, request, abort, Response\n\nfrom elgoog import config\nfrom elgoog.defender import Defender\n\nsearch_blueprint = Blueprint('search', __name__)\n\ndefender = Defender()\n\n\n@search_blueprint.route('\/search', methods=['POST'])\ndef search():\n    data = request.get_json()\n    query = data.get('query')\n    start = data.get('start')\n    timestamp = data.get('timestamp')\n    nonce = data.get('nonce')\n    signature = data.get('signature')\n\n    success, message = defender.verify(query, start, timestamp, nonce, signature)\n    if not success:\n        return abort(403, message)\n\n    headers = config.default_headers\n    headers['User-Agent'] = random_user_agent()\n    url = 'https:\/\/www.google.com.hk\/search?q={}&start={}'.format(quote(query), start)\n    resp = requests.get(url, verify=False, timeout=5, headers=headers)\n    resp_headers = remove_invalid_response_headers(dict(resp.headers))\n\n    defender.record(timestamp, nonce)\n\n    return Response(response=resp.content, status=200, headers=resp_headers)\n\n\ndef remove_invalid_response_headers(headers):\n    for i in config.invalid_response_headers:\n        if i in headers:\n            del headers[i]\n    return headers\n\n\ndef random_user_agent():\n    chrome_version = '{}.0.{}.{}'.format(random.randint(51, 70),\n                                         random.randint(0, 9999), random.randint(0, 99))\n    webkit = '{}.{}'.format(random.randint(531, 600), random.randint(0, 99))\n    os = 'Macintosh; Intel Mac OS X 10_10_4'\n    return ('Mozilla\/5.0 ({}) AppleWebKit\/{} (KHTML, like Gecko) '\n            'Chrome\/{} Safari\/{}').format(os, webkit, chrome_version, webkit)\n"},"\/elgoog\/defender.py":{"changes":[{"diff":"\n \n import time\n import hashlib\n-from collections import deque\n \n from elgoog import config\n \n \n class Defender:\n-    def __init__(self, timestamp_interval=1800, defense_interval=3600):\n+    def __init__(self, timestamp_interval=600):\n         self.timestamp_interval = timestamp_interval\n-        self.defense_interval = defense_interval\n-        self.replay = set()\n-        self.queue = deque()\n \n     def verify(self, query, start, timestamp, nonce, signature):\n         t = int(time.time())\n-        while len(self.queue) > 0:\n-            if t - self.queue[0][0] < self.defense_interval:\n-                break\n-            o = self.queue.popleft()\n-            if o[1] in self.replay:\n-                self.replay.remove(o[1])\n         s = query + str(start) + str(timestamp) + str(nonce) + config.elgoog_token\n         h = hashlib.sha256(s.encode('utf-8')).hexdigest()\n         if h != signature:\n             return False, 'Bad signature'\n         if abs(t - timestamp) > self.timestamp_interval:\n             return False, 'Bad timestamp, timestamp={}, local timestamp={}'.format(timestamp, t)\n-        x = (timestamp, nonce)\n-        if x in self.replay:\n-            return False, 'Replay attack, timestamp={}, nonce={}'.format(timestamp, nonce)\n         return True, ''\n-\n-    def record(self, timestamp, nonce):\n-        t = int(time.time())\n-        x = (timestamp, nonce)\n-        self.queue.append((t, x))\n-        self.replay.add(x)\n","add":1,"remove":20,"filename":"\/elgoog\/defender.py","badparts":["from collections import deque","    def __init__(self, timestamp_interval=1800, defense_interval=3600):","        self.defense_interval = defense_interval","        self.replay = set()","        self.queue = deque()","        while len(self.queue) > 0:","            if t - self.queue[0][0] < self.defense_interval:","                break","            o = self.queue.popleft()","            if o[1] in self.replay:","                self.replay.remove(o[1])","        x = (timestamp, nonce)","        if x in self.replay:","            return False, 'Replay attack, timestamp={}, nonce={}'.format(timestamp, nonce)","    def record(self, timestamp, nonce):","        t = int(time.time())","        x = (timestamp, nonce)","        self.queue.append((t, x))","        self.replay.add(x)"],"goodparts":["    def __init__(self, timestamp_interval=600):"]}],"source":"\n import time import hashlib from collections import deque from elgoog import config class Defender: def __init__(self, timestamp_interval=1800, defense_interval=3600): self.timestamp_interval=timestamp_interval self.defense_interval=defense_interval self.replay=set() self.queue=deque() def verify(self, query, start, timestamp, nonce, signature): t=int(time.time()) while len(self.queue) > 0: if t -self.queue[0][0] < self.defense_interval: break o=self.queue.popleft() if o[1] in self.replay: self.replay.remove(o[1]) s=query +str(start) +str(timestamp) +str(nonce) +config.elgoog_token h=hashlib.sha256(s.encode('utf-8')).hexdigest() if h !=signature: return False, 'Bad signature' if abs(t -timestamp) > self.timestamp_interval: return False, 'Bad timestamp, timestamp={}, local timestamp={}'.format(timestamp, t) x=(timestamp, nonce) if x in self.replay: return False, 'Replay attack, timestamp={}, nonce={}'.format(timestamp, nonce) return True, '' def record(self, timestamp, nonce): t=int(time.time()) x=(timestamp, nonce) self.queue.append((t, x)) self.replay.add(x) ","sourceWithComments":"# coding=utf-8\n\nimport time\nimport hashlib\nfrom collections import deque\n\nfrom elgoog import config\n\n\nclass Defender:\n    def __init__(self, timestamp_interval=1800, defense_interval=3600):\n        self.timestamp_interval = timestamp_interval\n        self.defense_interval = defense_interval\n        self.replay = set()\n        self.queue = deque()\n\n    def verify(self, query, start, timestamp, nonce, signature):\n        t = int(time.time())\n        while len(self.queue) > 0:\n            if t - self.queue[0][0] < self.defense_interval:\n                break\n            o = self.queue.popleft()\n            if o[1] in self.replay:\n                self.replay.remove(o[1])\n        s = query + str(start) + str(timestamp) + str(nonce) + config.elgoog_token\n        h = hashlib.sha256(s.encode('utf-8')).hexdigest()\n        if h != signature:\n            return False, 'Bad signature'\n        if abs(t - timestamp) > self.timestamp_interval:\n            return False, 'Bad timestamp, timestamp={}, local timestamp={}'.format(timestamp, t)\n        x = (timestamp, nonce)\n        if x in self.replay:\n            return False, 'Replay attack, timestamp={}, nonce={}'.format(timestamp, nonce)\n        return True, ''\n\n    def record(self, timestamp, nonce):\n        t = int(time.time())\n        x = (timestamp, nonce)\n        self.queue.append((t, x))\n        self.replay.add(x)\n"}},"msg":"disable checking replay attack"}},"https:\/\/github.com\/ucam-cl-dtg\/nigori":{"4c7985a2ce8c6c20a87364a21635a4845caa9540":{"url":"https:\/\/api.github.com\/repos\/ucam-cl-dtg\/nigori\/commits\/4c7985a2ce8c6c20a87364a21635a4845caa9540","html_url":"https:\/\/github.com\/ucam-cl-dtg\/nigori\/commit\/4c7985a2ce8c6c20a87364a21635a4845caa9540","message":"Check for replay attacks.","sha":"4c7985a2ce8c6c20a87364a21635a4845caa9540","keyword":"replay attack check","diff":"diff --git a\/client\/nigori-client.py b\/client\/nigori-client.py\nindex 53e82e4..2722473 100755\n--- a\/client\/nigori-client.py\n+++ b\/client\/nigori-client.py\n@@ -72,11 +72,9 @@ def register(user, password):\n   print response.status, response.reason\n   print response.read()\n \n-def authenticate(user, password):\n+def do_auth(user, password, t):\n   keys = KeyDeriver(password)\n   schnorr = keys.schnorr()\n-  # FIXME: include server name, user name in t\n-  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n   (e,s) = schnorr.sign(t)\n   params = urllib.urlencode({\"user\": user,\n                              \"t\": t,\n@@ -88,6 +86,14 @@ def authenticate(user, password):\n   response = conn.getresponse()\n   print response.status, response.reason\n   print response.read()\n+\n+def authenticate(user, password):\n+  # FIXME: include server name, user name in t\n+  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n+  do_auth(user, password, t)\n+  # test replay attack\n+  print \"Replaying: this should fail\"\n+  do_auth(user, password, t)\n   \n def getList(password, name):\n   conn = connect()\ndiff --git a\/server\/nigori-server.py b\/server\/nigori-server.py\nindex a944d31..bc5c6b9 100644\n--- a\/server\/nigori-server.py\n+++ b\/server\/nigori-server.py\n@@ -150,6 +150,9 @@ def post(self):\n     user.publicKey = self.request.get('publicKey')\n     user.put()\n \n+class Token(db.Model):\n+  token = db.StringProperty()\n+\n class Authenticate(webapp.RequestHandler):\n   # AppEngine runs in Unicode, so we need to convert to ASCII\n   ascii = codecs.lookup('ascii')\n@@ -168,7 +171,15 @@ def post(self):\n     verifier = SchnorrVerifier(bin2int(b64dec(key)))\n     \n     t = self.request.get('t')\n-    # FIXME: check t for replay, check is recent\n+    # FIXME: check t is recent, expire old tokens\n+    tokens = db.GqlQuery(\"SELECT * FROM Token WHERE token = '\"\n+                         + t + \"'\")\n+    if tokens.count(1) > 0:\n+      self.response.set_status(401, \"This is a replay\")\n+      return\n+    token = Token()\n+    token.token = t\n+    token.put()\n     \n     s = self.getb64('s')\n     e = self.getb64('e')\n","files":{"\/client\/nigori-client.py":{"changes":[{"diff":"\n   print response.status, response.reason\n   print response.read()\n \n-def authenticate(user, password):\n+def do_auth(user, password, t):\n   keys = KeyDeriver(password)\n   schnorr = keys.schnorr()\n-  # FIXME: include server name, user name in t\n-  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n   (e,s) = schnorr.sign(t)\n   params = urllib.urlencode({\"user\": user,\n                              \"t\": t,\n","add":1,"remove":3,"filename":"\/client\/nigori-client.py","badparts":["def authenticate(user, password):","  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))"],"goodparts":["def do_auth(user, password, t):"]}],"source":"\n from base64 import urlsafe_b64encode as b64enc, urlsafe_b64decode as b64dec from Crypto.Cipher import AES from Crypto.Hash import HMAC from Crypto.Hash import SHA256 from Crypto.Util import randpool from nigori import SchnorrSigner import httplib import random import simplejson import sys import time import urllib class KeyDeriver: def __init__(self, password): self.crypt=SHA256.new(password).digest() self.mac=SHA256.new(self.crypt).digest() self.authenticate=SHA256.new(self.mac).digest() def encrypt(self, plain): pool=randpool.RandomPool() iv=pool.get_bytes(16) crypter=AES.new(self.crypt, AES.MODE_CBC, iv) pad=16 -len(plain) % 16 c='%c' % pad for i in range(pad): plain=plain +c crypted=crypter.encrypt(plain) hmac=HMAC.new(self.mac, crypted) crypted=b64enc(iv +crypted +hmac.digest()) return crypted def decrypt(self, crypted): crypted=b64dec(crypted) l=len(crypted) if l < 32: raise ValueError(\"value too short\") mac=crypted[l-16:] iv=crypted[:16] crypted=crypted[16:l-16] hmac=HMAC.new(self.mac, crypted) if mac !=hmac.digest(): raise ValueError(\"mac doesn't match\") crypter=AES.new(self.crypt, AES.MODE_CBC, iv) plain=crypter.decrypt(crypted) c=plain[-1] for i in range(-1, -ord(c), -1): if plain[i] !=c: raise ValueError(\"padding error\") plain=plain[:-ord(c)] return plain def schnorr(self): return SchnorrSigner(self.authenticate) def connect(): return httplib.HTTPConnection(\"localhost\", 8080) def register(user, password): keys=KeyDeriver(password) schnorr=keys.schnorr() public=schnorr.public() params=urllib.urlencode({\"user\": user, \"publicKey\": public}) headers={\"Content-Type\": \"application\/x-www-form-urlencoded\", \"Accept\": \"text\/plain\"} conn=connect() conn.request(\"POST\", \"\/register\", params, headers) response=conn.getresponse() print response.status, response.reason print response.read() def authenticate(user, password): keys=KeyDeriver(password) schnorr=keys.schnorr() t=\"%d:%d\" %(int(time.time()), random.SystemRandom().getrandbits(20)) (e,s)=schnorr.sign(t) params=urllib.urlencode({\"user\": user, \"t\": t, \"e\": b64enc(e), \"s\": b64enc(s)}) headers={\"Content-Type\": \"application\/x-www-form-urlencoded\"} conn=connect() conn.request(\"POST\", \"\/authenticate\", params, headers) response=conn.getresponse() print response.status, response.reason print response.read() def getList(password, name): conn=connect() conn.request(\"GET\", \"\/list-resource?name=\" +name) response=conn.getresponse() if response.status !=200: raise LookupError(\"HTTP error: %d %s\" %(response.status, response.reason)) json=response.read() records=simplejson.loads(json) keys=KeyDeriver(password) for record in records: value=keys.decrypt(record['value']) print \"%d at %f: %s\" %(record['version'], record['creationTime'], value) def add(password, name, value): keys=KeyDeriver(password) params=urllib.urlencode({\"name\": name, \"value\": keys.encrypt(value)}) headers={\"Content-Type\": \"application\/x-www-form-urlencoded\", \"Accept\": \"text\/plain\"} conn=connect() conn.request(\"POST\", \"\/add-resource\", params, headers) response=conn.getresponse() print response.status, response.reason print response.read() def main(): action=sys.argv[1] if action==\"get\": getList(sys.argv[2], sys.argv[3]) elif action==\"add\": add(sys.argv[2], sys.argv[3], sys.argv[4]) elif action==\"register\": register(sys.argv[2], sys.argv[3]) elif action==\"authenticate\": authenticate(sys.argv[2], sys.argv[3]) else: raise ValueError(\"Unrecognised action: \" +action) if __name__==\"__main__\": main() ","sourceWithComments":"#!\/usr\/local\/bin\/python\n\nfrom base64 import urlsafe_b64encode as b64enc, urlsafe_b64decode as b64dec\nfrom Crypto.Cipher import AES\nfrom Crypto.Hash import HMAC\nfrom Crypto.Hash import SHA256\nfrom Crypto.Util import randpool\nfrom nigori import SchnorrSigner\n\nimport httplib\nimport random\nimport simplejson\nimport sys\nimport time\nimport urllib\n\nclass KeyDeriver:\n  def __init__(self, password):\n    self.crypt = SHA256.new(password).digest()\n    self.mac = SHA256.new(self.crypt).digest()\n    self.authenticate = SHA256.new(self.mac).digest()\n\n  def encrypt(self, plain):\n    pool = randpool.RandomPool()\n    iv = pool.get_bytes(16)\n    crypter = AES.new(self.crypt, AES.MODE_CBC, iv)\n    pad = 16 - len(plain) % 16\n    c = '%c' % pad\n    for i in range(pad):\n      plain = plain + c\n    crypted = crypter.encrypt(plain)\n    hmac = HMAC.new(self.mac, crypted)\n    crypted = b64enc(iv + crypted + hmac.digest())\n    return crypted\n\n  def decrypt(self, crypted):\n    crypted = b64dec(crypted)\n    l = len(crypted)\n    if l < 32:\n      raise ValueError(\"value too short\")\n    mac = crypted[l-16:]\n    iv = crypted[:16]\n    crypted = crypted [16:l-16]\n    hmac = HMAC.new(self.mac, crypted)\n    if mac != hmac.digest():\n      raise ValueError(\"mac doesn't match\")\n    crypter = AES.new(self.crypt, AES.MODE_CBC, iv)\n    plain = crypter.decrypt(crypted)\n    c = plain[-1]\n    for i in range(-1, -ord(c), -1):\n      if plain[i] != c:\n        raise ValueError(\"padding error\")\n    plain = plain[:-ord(c)]\n    return plain\n\n  def schnorr(self):\n    return SchnorrSigner(self.authenticate)\n\ndef connect():\n  return httplib.HTTPConnection(\"localhost\", 8080)\n\ndef register(user, password):\n  keys = KeyDeriver(password)\n  schnorr = keys.schnorr()\n  public = schnorr.public()\n  params = urllib.urlencode({\"user\": user, \"publicKey\": public})\n  headers = {\"Content-Type\": \"application\/x-www-form-urlencoded\",\n             \"Accept\": \"text\/plain\" }\n  conn = connect()\n  conn.request(\"POST\", \"\/register\", params, headers)\n  response = conn.getresponse()\n  print response.status, response.reason\n  print response.read()\n\ndef authenticate(user, password):\n  keys = KeyDeriver(password)\n  schnorr = keys.schnorr()\n  # FIXME: include server name, user name in t\n  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n  (e,s) = schnorr.sign(t)\n  params = urllib.urlencode({\"user\": user,\n                             \"t\": t,\n                             \"e\": b64enc(e),\n                             \"s\": b64enc(s)})\n  headers = {\"Content-Type\": \"application\/x-www-form-urlencoded\"}\n  conn = connect()\n  conn.request(\"POST\", \"\/authenticate\", params, headers)\n  response = conn.getresponse()\n  print response.status, response.reason\n  print response.read()\n  \ndef getList(password, name):\n  conn = connect()\n  conn.request(\"GET\", \"\/list-resource?name=\" + name)\n  response = conn.getresponse()\n#  print response.status, response.reason\n  if response.status != 200:\n    # FIXME: define a ProtocolError, perhaps?\n    raise LookupError(\"HTTP error: %d %s\" % (response.status, response.reason))\n  json = response.read()\n#  print json\n  records = simplejson.loads(json)\n  keys = KeyDeriver(password)\n  for record in records:\n#    print record\n    value = keys.decrypt(record['value'])\n    print \"%d at %f: %s\" % (record['version'], record['creationTime'], value)\n\ndef add(password, name, value):\n  keys = KeyDeriver(password)\n  params = urllib.urlencode({\"name\": name, \"value\": keys.encrypt(value)})\n  headers = {\"Content-Type\": \"application\/x-www-form-urlencoded\",\n             \"Accept\": \"text\/plain\" }\n  conn = connect()\n  conn.request(\"POST\", \"\/add-resource\", params, headers)\n  response = conn.getresponse()\n  print response.status, response.reason\n  print response.read()\n\ndef main():\n  action = sys.argv[1]\n  if action == \"get\":\n    getList(sys.argv[2], sys.argv[3])\n  elif action == \"add\":\n    add(sys.argv[2], sys.argv[3], sys.argv[4])\n  elif action == \"register\":\n    register(sys.argv[2], sys.argv[3])\n  elif action == \"authenticate\":\n    authenticate(sys.argv[2], sys.argv[3])\n  else:\n    raise ValueError(\"Unrecognised action: \" + action)\n\nif __name__ == \"__main__\":\n  main()\n"}},"msg":"Check for replay attacks."}},"https:\/\/github.com\/asweigart123\/nigori":{"4c7985a2ce8c6c20a87364a21635a4845caa9540":{"url":"https:\/\/api.github.com\/repos\/asweigart123\/nigori\/commits\/4c7985a2ce8c6c20a87364a21635a4845caa9540","html_url":"https:\/\/github.com\/asweigart123\/nigori\/commit\/4c7985a2ce8c6c20a87364a21635a4845caa9540","message":"Check for replay attacks.","sha":"4c7985a2ce8c6c20a87364a21635a4845caa9540","keyword":"replay attack check","diff":"diff --git a\/client\/nigori-client.py b\/client\/nigori-client.py\nindex 53e82e4..2722473 100755\n--- a\/client\/nigori-client.py\n+++ b\/client\/nigori-client.py\n@@ -72,11 +72,9 @@ def register(user, password):\n   print response.status, response.reason\n   print response.read()\n \n-def authenticate(user, password):\n+def do_auth(user, password, t):\n   keys = KeyDeriver(password)\n   schnorr = keys.schnorr()\n-  # FIXME: include server name, user name in t\n-  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n   (e,s) = schnorr.sign(t)\n   params = urllib.urlencode({\"user\": user,\n                              \"t\": t,\n@@ -88,6 +86,14 @@ def authenticate(user, password):\n   response = conn.getresponse()\n   print response.status, response.reason\n   print response.read()\n+\n+def authenticate(user, password):\n+  # FIXME: include server name, user name in t\n+  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n+  do_auth(user, password, t)\n+  # test replay attack\n+  print \"Replaying: this should fail\"\n+  do_auth(user, password, t)\n   \n def getList(password, name):\n   conn = connect()\ndiff --git a\/server\/nigori-server.py b\/server\/nigori-server.py\nindex a944d31..bc5c6b9 100644\n--- a\/server\/nigori-server.py\n+++ b\/server\/nigori-server.py\n@@ -150,6 +150,9 @@ def post(self):\n     user.publicKey = self.request.get('publicKey')\n     user.put()\n \n+class Token(db.Model):\n+  token = db.StringProperty()\n+\n class Authenticate(webapp.RequestHandler):\n   # AppEngine runs in Unicode, so we need to convert to ASCII\n   ascii = codecs.lookup('ascii')\n@@ -168,7 +171,15 @@ def post(self):\n     verifier = SchnorrVerifier(bin2int(b64dec(key)))\n     \n     t = self.request.get('t')\n-    # FIXME: check t for replay, check is recent\n+    # FIXME: check t is recent, expire old tokens\n+    tokens = db.GqlQuery(\"SELECT * FROM Token WHERE token = '\"\n+                         + t + \"'\")\n+    if tokens.count(1) > 0:\n+      self.response.set_status(401, \"This is a replay\")\n+      return\n+    token = Token()\n+    token.token = t\n+    token.put()\n     \n     s = self.getb64('s')\n     e = self.getb64('e')\n","files":{"\/client\/nigori-client.py":{"changes":[{"diff":"\n   print response.status, response.reason\n   print response.read()\n \n-def authenticate(user, password):\n+def do_auth(user, password, t):\n   keys = KeyDeriver(password)\n   schnorr = keys.schnorr()\n-  # FIXME: include server name, user name in t\n-  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n   (e,s) = schnorr.sign(t)\n   params = urllib.urlencode({\"user\": user,\n                              \"t\": t,\n","add":1,"remove":3,"filename":"\/client\/nigori-client.py","badparts":["def authenticate(user, password):","  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))"],"goodparts":["def do_auth(user, password, t):"]}],"source":"\n from base64 import urlsafe_b64encode as b64enc, urlsafe_b64decode as b64dec from Crypto.Cipher import AES from Crypto.Hash import HMAC from Crypto.Hash import SHA256 from Crypto.Util import randpool from nigori import SchnorrSigner import httplib import random import simplejson import sys import time import urllib class KeyDeriver: def __init__(self, password): self.crypt=SHA256.new(password).digest() self.mac=SHA256.new(self.crypt).digest() self.authenticate=SHA256.new(self.mac).digest() def encrypt(self, plain): pool=randpool.RandomPool() iv=pool.get_bytes(16) crypter=AES.new(self.crypt, AES.MODE_CBC, iv) pad=16 -len(plain) % 16 c='%c' % pad for i in range(pad): plain=plain +c crypted=crypter.encrypt(plain) hmac=HMAC.new(self.mac, crypted) crypted=b64enc(iv +crypted +hmac.digest()) return crypted def decrypt(self, crypted): crypted=b64dec(crypted) l=len(crypted) if l < 32: raise ValueError(\"value too short\") mac=crypted[l-16:] iv=crypted[:16] crypted=crypted[16:l-16] hmac=HMAC.new(self.mac, crypted) if mac !=hmac.digest(): raise ValueError(\"mac doesn't match\") crypter=AES.new(self.crypt, AES.MODE_CBC, iv) plain=crypter.decrypt(crypted) c=plain[-1] for i in range(-1, -ord(c), -1): if plain[i] !=c: raise ValueError(\"padding error\") plain=plain[:-ord(c)] return plain def schnorr(self): return SchnorrSigner(self.authenticate) def connect(): return httplib.HTTPConnection(\"localhost\", 8080) def register(user, password): keys=KeyDeriver(password) schnorr=keys.schnorr() public=schnorr.public() params=urllib.urlencode({\"user\": user, \"publicKey\": public}) headers={\"Content-Type\": \"application\/x-www-form-urlencoded\", \"Accept\": \"text\/plain\"} conn=connect() conn.request(\"POST\", \"\/register\", params, headers) response=conn.getresponse() print response.status, response.reason print response.read() def authenticate(user, password): keys=KeyDeriver(password) schnorr=keys.schnorr() t=\"%d:%d\" %(int(time.time()), random.SystemRandom().getrandbits(20)) (e,s)=schnorr.sign(t) params=urllib.urlencode({\"user\": user, \"t\": t, \"e\": b64enc(e), \"s\": b64enc(s)}) headers={\"Content-Type\": \"application\/x-www-form-urlencoded\"} conn=connect() conn.request(\"POST\", \"\/authenticate\", params, headers) response=conn.getresponse() print response.status, response.reason print response.read() def getList(password, name): conn=connect() conn.request(\"GET\", \"\/list-resource?name=\" +name) response=conn.getresponse() if response.status !=200: raise LookupError(\"HTTP error: %d %s\" %(response.status, response.reason)) json=response.read() records=simplejson.loads(json) keys=KeyDeriver(password) for record in records: value=keys.decrypt(record['value']) print \"%d at %f: %s\" %(record['version'], record['creationTime'], value) def add(password, name, value): keys=KeyDeriver(password) params=urllib.urlencode({\"name\": name, \"value\": keys.encrypt(value)}) headers={\"Content-Type\": \"application\/x-www-form-urlencoded\", \"Accept\": \"text\/plain\"} conn=connect() conn.request(\"POST\", \"\/add-resource\", params, headers) response=conn.getresponse() print response.status, response.reason print response.read() def main(): action=sys.argv[1] if action==\"get\": getList(sys.argv[2], sys.argv[3]) elif action==\"add\": add(sys.argv[2], sys.argv[3], sys.argv[4]) elif action==\"register\": register(sys.argv[2], sys.argv[3]) elif action==\"authenticate\": authenticate(sys.argv[2], sys.argv[3]) else: raise ValueError(\"Unrecognised action: \" +action) if __name__==\"__main__\": main() ","sourceWithComments":"#!\/usr\/local\/bin\/python\n\nfrom base64 import urlsafe_b64encode as b64enc, urlsafe_b64decode as b64dec\nfrom Crypto.Cipher import AES\nfrom Crypto.Hash import HMAC\nfrom Crypto.Hash import SHA256\nfrom Crypto.Util import randpool\nfrom nigori import SchnorrSigner\n\nimport httplib\nimport random\nimport simplejson\nimport sys\nimport time\nimport urllib\n\nclass KeyDeriver:\n  def __init__(self, password):\n    self.crypt = SHA256.new(password).digest()\n    self.mac = SHA256.new(self.crypt).digest()\n    self.authenticate = SHA256.new(self.mac).digest()\n\n  def encrypt(self, plain):\n    pool = randpool.RandomPool()\n    iv = pool.get_bytes(16)\n    crypter = AES.new(self.crypt, AES.MODE_CBC, iv)\n    pad = 16 - len(plain) % 16\n    c = '%c' % pad\n    for i in range(pad):\n      plain = plain + c\n    crypted = crypter.encrypt(plain)\n    hmac = HMAC.new(self.mac, crypted)\n    crypted = b64enc(iv + crypted + hmac.digest())\n    return crypted\n\n  def decrypt(self, crypted):\n    crypted = b64dec(crypted)\n    l = len(crypted)\n    if l < 32:\n      raise ValueError(\"value too short\")\n    mac = crypted[l-16:]\n    iv = crypted[:16]\n    crypted = crypted [16:l-16]\n    hmac = HMAC.new(self.mac, crypted)\n    if mac != hmac.digest():\n      raise ValueError(\"mac doesn't match\")\n    crypter = AES.new(self.crypt, AES.MODE_CBC, iv)\n    plain = crypter.decrypt(crypted)\n    c = plain[-1]\n    for i in range(-1, -ord(c), -1):\n      if plain[i] != c:\n        raise ValueError(\"padding error\")\n    plain = plain[:-ord(c)]\n    return plain\n\n  def schnorr(self):\n    return SchnorrSigner(self.authenticate)\n\ndef connect():\n  return httplib.HTTPConnection(\"localhost\", 8080)\n\ndef register(user, password):\n  keys = KeyDeriver(password)\n  schnorr = keys.schnorr()\n  public = schnorr.public()\n  params = urllib.urlencode({\"user\": user, \"publicKey\": public})\n  headers = {\"Content-Type\": \"application\/x-www-form-urlencoded\",\n             \"Accept\": \"text\/plain\" }\n  conn = connect()\n  conn.request(\"POST\", \"\/register\", params, headers)\n  response = conn.getresponse()\n  print response.status, response.reason\n  print response.read()\n\ndef authenticate(user, password):\n  keys = KeyDeriver(password)\n  schnorr = keys.schnorr()\n  # FIXME: include server name, user name in t\n  t = \"%d:%d\" % (int(time.time()), random.SystemRandom().getrandbits(20))\n  (e,s) = schnorr.sign(t)\n  params = urllib.urlencode({\"user\": user,\n                             \"t\": t,\n                             \"e\": b64enc(e),\n                             \"s\": b64enc(s)})\n  headers = {\"Content-Type\": \"application\/x-www-form-urlencoded\"}\n  conn = connect()\n  conn.request(\"POST\", \"\/authenticate\", params, headers)\n  response = conn.getresponse()\n  print response.status, response.reason\n  print response.read()\n  \ndef getList(password, name):\n  conn = connect()\n  conn.request(\"GET\", \"\/list-resource?name=\" + name)\n  response = conn.getresponse()\n#  print response.status, response.reason\n  if response.status != 200:\n    # FIXME: define a ProtocolError, perhaps?\n    raise LookupError(\"HTTP error: %d %s\" % (response.status, response.reason))\n  json = response.read()\n#  print json\n  records = simplejson.loads(json)\n  keys = KeyDeriver(password)\n  for record in records:\n#    print record\n    value = keys.decrypt(record['value'])\n    print \"%d at %f: %s\" % (record['version'], record['creationTime'], value)\n\ndef add(password, name, value):\n  keys = KeyDeriver(password)\n  params = urllib.urlencode({\"name\": name, \"value\": keys.encrypt(value)})\n  headers = {\"Content-Type\": \"application\/x-www-form-urlencoded\",\n             \"Accept\": \"text\/plain\" }\n  conn = connect()\n  conn.request(\"POST\", \"\/add-resource\", params, headers)\n  response = conn.getresponse()\n  print response.status, response.reason\n  print response.read()\n\ndef main():\n  action = sys.argv[1]\n  if action == \"get\":\n    getList(sys.argv[2], sys.argv[3])\n  elif action == \"add\":\n    add(sys.argv[2], sys.argv[3], sys.argv[4])\n  elif action == \"register\":\n    register(sys.argv[2], sys.argv[3])\n  elif action == \"authenticate\":\n    authenticate(sys.argv[2], sys.argv[3])\n  else:\n    raise ValueError(\"Unrecognised action: \" + action)\n\nif __name__ == \"__main__\":\n  main()\n"}},"msg":"Check for replay attacks."}},"https:\/\/github.com\/gigamonkey\/vamonos":{"30a1ecf99d31c1aa1c9d2362ac5a3ed9b0a49513":{"url":"https:\/\/api.github.com\/repos\/gigamonkey\/vamonos\/commits\/30a1ecf99d31c1aa1c9d2362ac5a3ed9b0a49513","html_url":"https:\/\/github.com\/gigamonkey\/vamonos\/commit\/30a1ecf99d31c1aa1c9d2362ac5a3ed9b0a49513","message":"Add nonce checking to prevent replay attacks.","sha":"30a1ecf99d31c1aa1c9d2362ac5a3ed9b0a49513","keyword":"replay attack check","diff":"diff --git a\/app.py b\/app.py\nindex cd80705..74e0cbc 100644\n--- a\/app.py\n+++ b\/app.py\n@@ -1,11 +1,13 @@\n-from urllib.parse import quote, unquote\n-from base64 import b64decode, b64encode\n from auth import init, auth_url, postback\n-from db import LinkDB\n+from base64 import b64decode, b64encode\n+from db import LinkDB, NonceDB\n from flask import Flask, redirect, request, send_file, session\n from flask.json import jsonify\n from functools import wraps\n+from math import floor\n from os import urandom\n+from time import time\n+from urllib.parse import quote, unquote\n import json\n import re\n \n@@ -15,7 +17,7 @@\n # TODO:\n #\n # - Domain checking\n-# - Check nonce.\n+# - Make multi-arg requests default to 0-arg pattern + rest.\n \n discovery_url = 'https:\/\/accounts.google.com\/.well-known\/openid-configuration'\n oauth_config_file = 'oauth-config.json'\n@@ -24,6 +26,7 @@\n app.config['DEBUG'] = True\n app.secret_key = urandom(12)\n db = LinkDB(\"testdb\")\n+nonces = NonceDB(\"nonces\")\n \n disco, config = init(discovery_url, oauth_config_file)\n \n@@ -90,16 +93,19 @@ def auth():\n \n     resp = postback(token_endpoint, code, client_id, client_secret, uri)\n \n-    # TODO: Check nonce hasn't been seen before, etc. and then return\n-    # a redirect to wherever they were trying to go (recorded in\n-    # state) when we forced the authentication.\n-\n     if resp is not None:\n         jwt = resp['jwt']['payload']\n-        session['authenticated'] = True\n-        session['email'] = jwt['email']\n-        session['domain'] = jwt['hd'] if 'hd' in jwt else ''\n-        return redirect(decode_state(session['state']))\n+\n+        nonce = jwt['nonce']\n+\n+        if nonces.used(nonce_time(nonce), nonce):\n+            return jsonify(\"Reused nonce\"), 401\n+        else:\n+            session['authenticated'] = True\n+            session['email'] = jwt['email']\n+            session['domain'] = jwt['hd'] if 'hd' in jwt else ''\n+            return redirect(decode_state(session['state']))\n+\n     else:\n         return jsonify({'args': args, 'response': resp}), 401\n \n@@ -221,13 +227,19 @@ def authenticate():\n     uri = config['redirect_uris'][0]\n \n     state = encode_state(request.url)\n-    nonce = urandom(8).hex()\n+    nonce = urandom(8).hex() + str(floor(time()))\n \n     session['state'] = state\n     return redirect(auth_url(auth_endpoint, client_id, uri, state, nonce)), 302\n \n+\n def encode_state(url):\n     return quote(urandom(16).hex() + request.url)\n \n+\n def decode_state(state):\n     return unquote(state)[32:]\n+\n+\n+def nonce_time(nonce):\n+    return int(nonce[16:])\ndiff --git a\/db.py b\/db.py\nindex e1e395f..0468bc7 100644\n--- a\/db.py\n+++ b\/db.py\n@@ -1,7 +1,9 @@\n from collections import defaultdict\n from fcntl import LOCK_EX, LOCK_SH, LOCK_UN, flock\n from functools import wraps\n+from math import floor\n from os import fsync, SEEK_SET, SEEK_END\n+from time import time\n import json\n \n def accessor(f):\n@@ -38,12 +40,19 @@ def __init__(self, name):\n             self.cache = self.empty_cache()\n \n     def empty_cache(self):\n+        \"Return an empty cache for a new database.\"\n         pass\n \n     def fill_cache(self, data):\n+        \"Return a in-memory cache representing thet data loaded from disk.\"\n         pass\n \n+    def cache_to_json(self):\n+        \"Convert the cache to the form we want to serialize as JSON to disk.\"\n+        return self.cache\n+\n     def _replay(self, entry):\n+        \"Replay a log entry to reflect it in our in-memory cache.\"\n         pass\n \n     def _log(self, entry):\n@@ -82,7 +91,7 @@ def _save(self):\n         with open(self.file, 'w') as f:\n             flock(f, LOCK_EX)\n             json.dump({\n-                'cache': self.cache,\n+                'cache': self.cache_to_json(),\n                 'low_water_mark': self.low_water_mark\n             }, f, sort_keys=True, indent=2)\n             flock(f, LOCK_UN)\n@@ -152,6 +161,68 @@ def delete_pattern(self, name, n):\n     def set_pattern(self, name, n, pattern):\n         return ('SET', name, n, pattern)\n \n+class NonceDB (DB):\n+\n+    \"Database of nonces we've seen.\"\n+\n+    def empty_cache(self):\n+        return defaultdict(set)\n+\n+    def fill_cache(self, data):\n+        return defaultdict(set, { k:set(v) for k, v in data.items() })\n+\n+    def cache_to_json(self):\n+        return { k:list(v) for k, v in self.cache.items() }\n+\n+    def timekey(self, t):\n+        return str(300 + ((floor(t) \/\/ 300) * 300))\n+\n+\n+    # Accessors\n+\n+    @accessor\n+    def used(self, t, nonce):\n+        # Time recorded in nonce goes to a particular bucket. If the\n+        # bucket is the current bucket but it doesn't contain the\n+        # nonce, then we haven't seen it. If it's any other bucket\n+        # then we consider it to have been seen.\n+\n+        current = self.timekey(time())\n+        expired = self.timekey(t) != current\n+        seen = expired or nonce in self.cache[current]\n+\n+        if not seen: self.add_nonce(t, nonce)\n+\n+        # While we're here, expire old nonces.\n+        for k in self.cache.keys():\n+            if k != current:\n+                self.delete_chunk(k)\n+\n+        print('checking nonce: {}; t: {}; current: {}; timekey: {}; expired: {}; seen: {}'.format(\n+            nonce, t, current, self.timekey(t), expired, seen))\n+        return seen\n+\n+\n+    # Mutators\n+\n+    @mutator\n+    def add_nonce(self, t, nonce):\n+        return ['ADD_NONCE', t, nonce]\n+\n+    @mutator\n+    def delete_chunk(self, chunk):\n+        return ['DELETE_CHUNK', chunk]\n+\n+    def _replay(self, entry):\n+        verb, rest = entry.split('\\t', maxsplit=1)\n+        if verb == 'ADD_NONCE':\n+            time, nonce = rest.split('\\t')\n+            self.cache[self.timekey(int(time))].add(nonce)\n+        elif verb == 'DELETE_CHUNK':\n+            del self.cache[rest]\n+        else:\n+            raise Error('Bad log entry: {}'.format(entry))\n+\n \n class Log:\n \n","files":{"\/app.py":{"changes":[{"diff":"\n-from urllib.parse import quote, unquote\n-from base64 import b64decode, b64encode\n from auth import init, auth_url, postback\n-from db import LinkDB\n+from base64 import b64decode, b64encode\n+from db import LinkDB, NonceDB\n from flask import Flask, redirect, request, send_file, session\n from flask.json import jsonify\n from functools import wraps\n+from math import floor\n from os import urandom\n+from time import time\n+from urllib.parse import quote, unquote\n import json\n import re\n \n","add":5,"remove":3,"filename":"\/app.py","badparts":["from urllib.parse import quote, unquote","from base64 import b64decode, b64encode","from db import LinkDB"],"goodparts":["from base64 import b64decode, b64encode","from db import LinkDB, NonceDB","from math import floor","from time import time","from urllib.parse import quote, unquote"]},{"diff":"\n \n     resp = postback(token_endpoint, code, client_id, client_secret, uri)\n \n-    # TODO: Check nonce hasn't been seen before, etc. and then return\n-    # a redirect to wherever they were trying to go (recorded in\n-    # state) when we forced the authentication.\n-\n     if resp is not None:\n         jwt = resp['jwt']['payload']\n-        session['authenticated'] = True\n-        session['email'] = jwt['email']\n-        session['domain'] = jwt['hd'] if 'hd' in jwt else ''\n-        return redirect(decode_state(session['state']))\n+\n+        nonce = jwt['nonce']\n+\n+        if nonces.used(nonce_time(nonce), nonce):\n+            return jsonify(\"Reused nonce\"), 401\n+        else:\n+            session['authenticated'] = True\n+            session['email'] = jwt['email']\n+            session['domain'] = jwt['hd'] if 'hd' in jwt else ''\n+            return redirect(decode_state(session['state']))\n+\n     else:\n         return jsonify({'args': args, 'response': resp}), 401\n \n","add":11,"remove":8,"filename":"\/app.py","badparts":["        session['authenticated'] = True","        session['email'] = jwt['email']","        session['domain'] = jwt['hd'] if 'hd' in jwt else ''","        return redirect(decode_state(session['state']))"],"goodparts":["        nonce = jwt['nonce']","        if nonces.used(nonce_time(nonce), nonce):","            return jsonify(\"Reused nonce\"), 401","        else:","            session['authenticated'] = True","            session['email'] = jwt['email']","            session['domain'] = jwt['hd'] if 'hd' in jwt else ''","            return redirect(decode_state(session['state']))"]},{"diff":"\n     uri = config['redirect_uris'][0]\n \n     state = encode_state(request.url)\n-    nonce = urandom(8).hex()\n+    nonce = urandom(8).hex() + str(floor(time()))\n \n     session['state'] = state\n     return redirect(auth_url(auth_endpoint, client_id, uri, state, nonce)), 302\n \n+\n def encode_state(url):\n     return quote(urandom(16).hex() + request.url)\n \n+\n def decode_state(state):\n     return unquote(state)[32:]\n+\n+\n+def nonce_time(nonce):\n+    return int(nonce[16:])","add":7,"remove":1,"filename":"\/app.py","badparts":["    nonce = urandom(8).hex()"],"goodparts":["    nonce = urandom(8).hex() + str(floor(time()))","def nonce_time(nonce):","    return int(nonce[16:])"]}],"source":"\nfrom urllib.parse import quote, unquote from base64 import b64decode, b64encode from auth import init, auth_url, postback from db import LinkDB from flask import Flask, redirect, request, send_file, session from flask.json import jsonify from functools import wraps from os import urandom import json import re discovery_url='https:\/\/accounts.google.com\/.well-known\/openid-configuration' oauth_config_file='oauth-config.json' app=Flask(__name__) app.config['DEBUG']=True app.secret_key=urandom(12) db=LinkDB(\"testdb\") disco, config=init(discovery_url, oauth_config_file) def authenticated(f): @wraps(f) def wrapper(*args, **kwargs): if not session.get('authenticated'): return authenticate() return f(*args, **kwargs) return wrapper @app.after_request def add_header(r): if app.config['DEBUG']: r.headers['Cache-Control']='no-cache, no-store, must-revalidate, public, max-age=0' r.headers['Pragma']='no-cache' r.headers['Expires']='0' return r @app.route(\"\/\") @authenticated def index(): return send_file('static\/index.html') @app.route(\"\/!\/auth\", methods=['GET']) def auth(): \"The second step of the OAuth dance.\" args=request.args if 'state' not in session or args['state'] !=session['state']: return 'Bad state', 401 token_endpoint=disco['token_endpoint'] code =args['code'] client_id =config['client_id'] client_secret =config['client_secret'] uri =config['redirect_uris'][0] resp=postback(token_endpoint, code, client_id, client_secret, uri) if resp is not None: jwt=resp['jwt']['payload'] session['authenticated']=True session['email']=jwt['email'] session['domain']=jwt['hd'] if 'hd' in jwt else '' return redirect(decode_state(session['state'])) else: return jsonify({'args': args, 'response': resp}), 401 @app.route(\"\/!\/logout\", methods=['GET']) def logout(): session['authenticated']=False return \"Okay\", 200 @app.route(\"\/!\/user\", methods=['GET']) @authenticated def user(): data={'email': session['email'], 'domain': session['domain']} return jsonify(data), 200 @app.route(\"\/<name>\/\", defaults={'rest': None}) @app.route(\"\/<name>\/<path:rest>\") @authenticated def redirection(name, rest): name=''.join(filter(str.isalnum, name)) args=rest.split('\/') if rest else[] if db.has_pattern(name, len(args)): return redirect(db.get_pattern(name, len(args)).format(*args)), 307 else: return send_file('static\/index.html') @app.route(\"\/_\/\", methods=['GET']) @authenticated def get_all(): return jsonify(jsonify_db(db)) @app.route(\"\/_\/<name>\", methods=['GET']) @authenticated def get_name(name): if db.has_name(name): return jsonify(jsonify_item(db, name)) else: return jsonify({}), 404 @app.route(\"\/_\/<name>\", methods=['POST']) @authenticated def post_pattern(name): pattern=request.form['pattern'] n=count_args(pattern) if n is None: return jsonify({\"error\": \"Mixed arg types\"}), 400 else: db.set_pattern(name, n, pattern) r=jsonify(jsonify_item(db, name)) r.headers['Location']='\/_\/{}\/{}'.format(name, n) return r, 201 @app.route(\"\/_\/<name>\", methods=['DELETE']) @authenticated def delete_name(name): if db.has_name(name): db.delete_name(name) return jsonify({}) else: return jsonify({\"error\": \"No such name\"}), 404 @app.route(\"\/_\/<name>\/<int:n>\", methods=['DELETE']) @authenticated def delete_pattern(name, n): if db.get_pattern(name, n): db.delete_pattern(name, n) return jsonify(jsonify_item(db, name)) else: return jsonify({\"error\": \"No such pattern\"}), 404 def count_args(pattern): numbered_pats=re.findall('{\\d+}', pattern) auto_pats=re.findall('{}', pattern) if numbered_pats and auto_pats: return None elif numbered_pats: return 1 +max(int(x.strip('{}')) for x in numbered_pats) else: return len(auto_pats) def jsonify_db(db): \"Convert whole db into the JSON we send in API responses.\" return[jsonify_item(db, name) for name in db.names()] def jsonify_item(db, name): \"Convert one item into the JSON we send in API responses.\" patterns=[{'pattern': p, 'args': n} for n, p in db.get_patterns(name)] return{'name': name, 'patterns': patterns} def authenticate(): auth_endpoint=disco['authorization_endpoint'] client_id=config['client_id'] uri=config['redirect_uris'][0] state=encode_state(request.url) nonce=urandom(8).hex() session['state']=state return redirect(auth_url(auth_endpoint, client_id, uri, state, nonce)), 302 def encode_state(url): return quote(urandom(16).hex() +request.url) def decode_state(state): return unquote(state)[32:] ","sourceWithComments":"from urllib.parse import quote, unquote\nfrom base64 import b64decode, b64encode\nfrom auth import init, auth_url, postback\nfrom db import LinkDB\nfrom flask import Flask, redirect, request, send_file, session\nfrom flask.json import jsonify\nfrom functools import wraps\nfrom os import urandom\nimport json\nimport re\n\n# We use HTTP 307 mainly so the redirection can change. This also\n# allows us to log the use of links.\n\n# TODO:\n#\n# - Domain checking\n# - Check nonce.\n\ndiscovery_url = 'https:\/\/accounts.google.com\/.well-known\/openid-configuration'\noauth_config_file = 'oauth-config.json'\n\napp = Flask(__name__)\napp.config['DEBUG'] = True\napp.secret_key = urandom(12)\ndb = LinkDB(\"testdb\")\n\ndisco, config = init(discovery_url, oauth_config_file)\n\n\ndef authenticated(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        if not session.get('authenticated'):\n            return authenticate()\n\n        return f(*args, **kwargs)\n\n    return wrapper\n\n\n@app.after_request\ndef add_header(r):\n    if app.config['DEBUG']:\n        r.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, public, max-age=0'\n        r.headers['Pragma'] = 'no-cache'\n        r.headers['Expires'] = '0'\n    return r\n\n\n#\n# Web UI -- single page app that lets a user manage existing names,\n# create new names, see stats about what names are used, etc.\n#\n\n@app.route(\"\/\")\n@authenticated\ndef index():\n    return send_file('static\/index.html')\n\n\n#\n# Authentication endpoint\n#\n\n@app.route(\"\/!\/auth\", methods=['GET'])\ndef auth():\n    \"The second step of the OAuth dance.\"\n    args = request.args\n\n    # The browser is redirected to this endpoint by Google and will\n    # pass us the state we embedded in the URL we redirected them to\n    # in step one of the dance. We need to check that the state we are\n    # receiving now is one we handed out before, otherwise anyone\n    # could hit this endpoint, pretending to have been redirected\n    # here. They probably wouldn't be able to authenticate since they\n    # wouldn't have a valid code to give us (which we will then POST\n    # to google). It seems sufficient to put the state we are\n    # expecting into our session before we redirect them in step one\n    # since sessions are not forgeable.\n\n    if 'state' not in session or args['state'] != session['state']:\n        return 'Bad state', 401\n\n    token_endpoint = disco['token_endpoint']\n    code           = args['code']\n    client_id      = config['client_id']\n    client_secret  = config['client_secret']\n    uri            = config['redirect_uris'][0]\n\n    resp = postback(token_endpoint, code, client_id, client_secret, uri)\n\n    # TODO: Check nonce hasn't been seen before, etc. and then return\n    # a redirect to wherever they were trying to go (recorded in\n    # state) when we forced the authentication.\n\n    if resp is not None:\n        jwt = resp['jwt']['payload']\n        session['authenticated'] = True\n        session['email'] = jwt['email']\n        session['domain'] = jwt['hd'] if 'hd' in jwt else ''\n        return redirect(decode_state(session['state']))\n    else:\n        return jsonify({'args': args, 'response': resp}), 401\n\n\n@app.route(\"\/!\/logout\", methods=['GET'])\ndef logout():\n    session['authenticated'] = False\n    return \"Okay\", 200\n\n\n@app.route(\"\/!\/user\", methods=['GET'])\n@authenticated\ndef user():\n    data = {'email': session['email'], 'domain': session['domain']}\n    return jsonify(data), 200\n\n\n#\n# The actual redirector.\n#\n\n@app.route(\"\/<name>\/\", defaults={'rest': None})\n@app.route(\"\/<name>\/<path:rest>\")\n@authenticated\ndef redirection(name, rest):\n    name = ''.join(filter(str.isalnum, name))\n    args = rest.split('\/') if rest else []\n    if db.has_pattern(name, len(args)):\n        return redirect(db.get_pattern(name, len(args)).format(*args)), 307\n    else:\n        return send_file('static\/index.html')\n\n\n#\n# API - Restful API for CRUDing links.\n#\n\n@app.route(\"\/_\/\", methods=['GET'])\n@authenticated\ndef get_all():\n    return jsonify(jsonify_db(db))\n\n\n@app.route(\"\/_\/<name>\", methods=['GET'])\n@authenticated\ndef get_name(name):\n    if db.has_name(name):\n        return jsonify(jsonify_item(db, name))\n    else:\n        return jsonify({}), 404\n\n\n@app.route(\"\/_\/<name>\", methods=['POST'])\n@authenticated\ndef post_pattern(name):\n    pattern = request.form['pattern']\n    n = count_args(pattern)\n    if n is None:\n        # FIXME: there's more well-formedness checking we could do\n        # on the pattern.\n        return jsonify({\"error\": \"Mixed arg types\"}), 400\n    else:\n        db.set_pattern(name, n, pattern)\n        r = jsonify(jsonify_item(db, name))\n        r.headers['Location'] = '\/_\/{}\/{}'.format(name, n)\n        return r, 201\n\n\n@app.route(\"\/_\/<name>\", methods=['DELETE'])\n@authenticated\ndef delete_name(name):\n    if db.has_name(name):\n        db.delete_name(name)\n        return jsonify({})\n    else:\n        return jsonify({\"error\": \"No such name\"}), 404\n\n\n@app.route(\"\/_\/<name>\/<int:n>\", methods=['DELETE'])\n@authenticated\ndef delete_pattern(name, n):\n    if db.get_pattern(name, n):\n        db.delete_pattern(name, n)\n        return jsonify(jsonify_item(db, name))\n    else:\n        return jsonify({\"error\": \"No such pattern\"}), 404\n\n\n#\n# Utilities\n#\n\ndef count_args(pattern):\n    numbered_pats = re.findall('{\\d+}', pattern)\n    auto_pats = re.findall('{}', pattern)\n\n    if numbered_pats and auto_pats:\n        return None  # Poor man's Maybe\n    elif numbered_pats:\n        return 1 + max(int(x.strip('{}')) for x in numbered_pats)\n    else:\n        return len(auto_pats)\n\n\ndef jsonify_db(db):\n    \"Convert whole db into the JSON we send in API responses.\"\n    return [jsonify_item(db, name) for name in db.names()]\n\n\ndef jsonify_item(db, name):\n    \"Convert one item into the JSON we send in API responses.\"\n    patterns = [{'pattern': p, 'args': n} for n, p in db.get_patterns(name)]\n    return {'name': name, 'patterns': patterns}\n\n\ndef authenticate():\n    auth_endpoint = disco['authorization_endpoint']\n    client_id = config['client_id']\n    uri = config['redirect_uris'][0]\n\n    state = encode_state(request.url)\n    nonce = urandom(8).hex()\n\n    session['state'] = state\n    return redirect(auth_url(auth_endpoint, client_id, uri, state, nonce)), 302\n\ndef encode_state(url):\n    return quote(urandom(16).hex() + request.url)\n\ndef decode_state(state):\n    return unquote(state)[32:]\n"},"\/db.py":{"changes":[{"diff":"\n         with open(self.file, 'w') as f:\n             flock(f, LOCK_EX)\n             json.dump({\n-                'cache': self.cache,\n+                'cache': self.cache_to_json(),\n                 'low_water_mark': self.low_water_mark\n             }, f, sort_keys=True, indent=2)\n             flock(f, LOCK_UN)\n","add":1,"remove":1,"filename":"\/db.py","badparts":["                'cache': self.cache,"],"goodparts":["                'cache': self.cache_to_json(),"]}],"source":"\nfrom collections import defaultdict from fcntl import LOCK_EX, LOCK_SH, LOCK_UN, flock from functools import wraps from os import fsync, SEEK_SET, SEEK_END import json def accessor(f): @wraps(f) def wrapper(*args, **kwargs): args[0]._refresh() return f(*args, **kwargs) return wrapper def mutator(f): @wraps(f) def wrapper(*args, **kwargs): args[0]._log(f(*args, **kwargs)) return wrapper class DB: \"\"\"\\ A database implementation that sits on top of a write-ahead log and an in-memory cache. Mutations to the database are written to the log and all reads first replay any new log entries to make sure the cache is up to date with any changes made by this or other processes. We also write out the cache to disk to avoid having to replay the whole log at startup. \"\"\" def __init__(self, name): self.file=name +'.data' self.log=Log(name +'.log') try: self._load() except: self.low_water_mark=0 self.cache=self.empty_cache() def empty_cache(self): pass def fill_cache(self, data): pass def _replay(self, entry): pass def _log(self, entry): \"Log data to our transaction log.\" self.log.write('\\t'.join([str(x) for x in entry])) def _refresh(self): \"Replay any new log entries against our in-memory cache.\" new_lwm=self.low_water_mark for(entry, lsn) in self.log.read(self.low_water_mark): self._replay(entry) new_lwm=lsn if self.low_water_mark < new_lwm: self.low_water_mark=new_lwm self._save() def _load(self): \"Load cached data from disk so we don't have to replay the whole log.\" with open(self.file) as f: flock(f, LOCK_EX) data=json.load(f) self.cache=self.fill_cache(data['cache']) self.low_water_mark=data['low_water_mark'] flock(f, LOCK_UN) def _save(self): with open(self.file, 'w') as f: flock(f, LOCK_EX) json.dump({ 'cache': self.cache, 'low_water_mark': self.low_water_mark }, f, sort_keys=True, indent=2) flock(f, LOCK_UN) class LinkDB(DB): \"Database of link shortcuts.\" def empty_cache(self): return defaultdict(list) def fill_cache(self, data): return defaultdict(list, data) def _replay(self, entry): \"Replay a log entry to reflect it in our in-memory cache.\" verb, name, n, pattern=entry.split('\\t') if verb=='SET': n=int(n) expand(self.cache[name], n) self.cache[name][n]=pattern elif verb=='DELETE': n=int(n) expand(self.cache[name], n) self.cache[name][n]=None shrink(self.cache[name]) elif verb=='DELETE_NAME': del self.cache[name] else: raise Error('Bad log entry:{}'.format(entry)) @accessor def has_name(self, name): return name in self.cache @accessor def get_patterns(self, name): return[(n, p) for n, p in enumerate(self.cache[name]) if p is not None] @accessor def has_pattern(self, name, n): return n < len(self.cache[name]) and self.cache[name][n] is not None @accessor def get_pattern(self, name, n): return self.cache[name][n] @accessor def names(self): return self.cache.keys() @mutator def delete_name(self, name): return('DELETE_NAME', name, '*', '*') @mutator def delete_pattern(self, name, n): return('DELETE', name, n, self.cache[name][n]) @mutator def set_pattern(self, name, n, pattern): return('SET', name, n, pattern) class Log: \"Simple write-ahead log. Records each record as a line.\" def __init__(self, file): self.file=file def write(self, data): with open(self.file, mode='a') as f: flock(f, LOCK_EX) f.seek(0, SEEK_END) print(data, file=f) f.flush() fsync(f.fileno()) flock(f, LOCK_UN) return f.tell() def read(self, low_water_mark): with open(self.file, mode='r') as f: flock(f, LOCK_SH) f.seek(low_water_mark, SEEK_SET) while True: line=f.readline() pos=f.tell() if line=='': break yield line[:-1], pos flock(f, LOCK_UN) def expand(list, size): list +=[None] *(1 +(size -len(list))) def shrink(list): while list and list[-1] is None: list.pop() ","sourceWithComments":"from collections import defaultdict\nfrom fcntl import LOCK_EX, LOCK_SH, LOCK_UN, flock\nfrom functools import wraps\nfrom os import fsync, SEEK_SET, SEEK_END\nimport json\n\ndef accessor(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        args[0]._refresh()\n        return f(*args, **kwargs)\n    return wrapper\n\ndef mutator(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        args[0]._log(f(*args, **kwargs))\n    return wrapper\n\nclass DB:\n\n    \"\"\"\\\nA database implementation that sits on top of a write-ahead log and an\nin-memory cache. Mutations to the database are written to the log and\nall reads first replay any new log entries to make sure the cache is\nup to date with any changes made by this or other processes. We also\nwrite out the cache to disk to avoid having to replay the whole log at\nstartup.\n    \"\"\"\n\n    def __init__(self, name):\n        self.file = name + '.data'\n        self.log = Log(name + '.log')\n        try:\n            self._load()\n        except:\n            self.low_water_mark = 0\n            self.cache = self.empty_cache()\n\n    def empty_cache(self):\n        pass\n\n    def fill_cache(self, data):\n        pass\n\n    def _replay(self, entry):\n        pass\n\n    def _log(self, entry):\n        \"Log data to our transaction log.\"\n        self.log.write('\\t'.join([str(x) for x in entry]))\n\n    def _refresh(self):\n        \"Replay any new log entries against our in-memory cache.\"\n        new_lwm = self.low_water_mark\n        for (entry, lsn) in self.log.read(self.low_water_mark):\n            self._replay(entry)\n            new_lwm = lsn\n\n        if self.low_water_mark < new_lwm:\n            self.low_water_mark = new_lwm\n            self._save()\n\n    def _load(self):\n        \"Load cached data from disk so we don't have to replay the whole log.\"\n        with open(self.file) as f:\n            flock(f, LOCK_EX)\n            data = json.load(f)\n            self.cache = self.fill_cache(data['cache'])\n            self.low_water_mark = data['low_water_mark']\n            flock(f, LOCK_UN)\n\n    def _save(self):\n        # We could check that our low water mark is greater than the\n        # one already on disk before we write since it's possible that\n        # someone else has read farther in the log than us and gotten\n        # in and written out their cache to disk. But it doesn't\n        # really matter since we never actually read from the on-disk\n        # cache except at startup. Rolling the cache back in time will,\n        # at worst, make some processes have to replay a few more log\n        # records than they might have otherwise.\n        with open(self.file, 'w') as f:\n            flock(f, LOCK_EX)\n            json.dump({\n                'cache': self.cache,\n                'low_water_mark': self.low_water_mark\n            }, f, sort_keys=True, indent=2)\n            flock(f, LOCK_UN)\n\n\nclass LinkDB (DB):\n\n    \"Database of link shortcuts.\"\n\n    def empty_cache(self):\n        return defaultdict(list)\n\n    def fill_cache(self, data):\n        return defaultdict(list, data)\n\n    def _replay(self, entry):\n        \"Replay a log entry to reflect it in our in-memory cache.\"\n        verb, name, n, pattern = entry.split('\\t')\n        if verb == 'SET':\n            n = int(n)\n            expand(self.cache[name], n)\n            self.cache[name][n] = pattern\n        elif verb == 'DELETE':\n            n = int(n)\n            expand(self.cache[name], n)\n            self.cache[name][n] = None\n            shrink(self.cache[name])\n        elif verb == 'DELETE_NAME':\n            del self.cache[name]\n        else:\n            raise Error('Bad log entry: {}'.format(entry))\n\n\n    # Accessors -- must check for new entries in log.\n\n    @accessor\n    def has_name(self, name):\n        return name in self.cache\n\n    @accessor\n    def get_patterns(self, name):\n        return [(n, p) for n, p in enumerate(self.cache[name]) if p is not None]\n\n    @accessor\n    def has_pattern(self, name, n):\n        return n < len(self.cache[name]) and self.cache[name][n] is not None\n\n    @accessor\n    def get_pattern(self, name, n):\n        return self.cache[name][n]\n\n    @accessor\n    def names(self):\n        return self.cache.keys()\n\n    # Mutators -- write entries to log.\n\n    @mutator\n    def delete_name(self, name):\n        return ('DELETE_NAME', name, '*', '*')\n\n    @mutator\n    def delete_pattern(self, name, n):\n        return ('DELETE', name, n, self.cache[name][n])\n\n    @mutator\n    def set_pattern(self, name, n, pattern):\n        return ('SET', name, n, pattern)\n\n\nclass Log:\n\n    \"Simple write-ahead log. Records each record as a line.\"\n\n    def __init__(self, file):\n        self.file = file\n\n    def write(self, data):\n        with open(self.file, mode='a') as f:\n            flock(f, LOCK_EX)\n            f.seek(0, SEEK_END)\n            print(data, file=f)\n            f.flush()\n            fsync(f.fileno())\n            flock(f, LOCK_UN)\n            return f.tell()\n\n    def read(self, low_water_mark):\n        with open(self.file, mode='r') as f:\n            flock(f, LOCK_SH)\n            f.seek(low_water_mark, SEEK_SET)\n            while True:\n                line = f.readline()\n                pos = f.tell()\n                if line == '':\n                    break\n                yield line[:-1], pos\n            flock(f, LOCK_UN)\n\n\n#\n# Utilities\n#\n\ndef expand(list, size):\n    list += [None] * (1 + (size - len(list)))\n\n\ndef shrink(list):\n    while list and list[-1] is None: list.pop()\n"}},"msg":"Add nonce checking to prevent replay attacks."}},"https:\/\/github.com\/kratel\/secproject_basic_stream_app":{"e508bcea555b07a6ca6968da3dafc2713a6afa32":{"url":"https:\/\/api.github.com\/repos\/kratel\/secproject_basic_stream_app\/commits\/e508bcea555b07a6ca6968da3dafc2713a6afa32","html_url":"https:\/\/github.com\/kratel\/secproject_basic_stream_app\/commit\/e508bcea555b07a6ca6968da3dafc2713a6afa32","message":"Add hmac tagging for messages, and session and ccomponent IDs to prevent replay attacks and provide integrity. Added verification checks for client.","sha":"e508bcea555b07a6ca6968da3dafc2713a6afa32","keyword":"replay attack check","diff":"diff --git a\/streaming_client_asyncio.py b\/streaming_client_asyncio.py\nindex 135cbdd..7aaef28 100644\n--- a\/streaming_client_asyncio.py\n+++ b\/streaming_client_asyncio.py\n@@ -6,7 +6,7 @@\n import argparse\n import errno\n # For encryption\n-from cryptography.hazmat.primitives import hashes\n+from cryptography.hazmat.primitives import hashes, hmac\n from cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec\n from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n from cryptography.hazmat.backends import default_backend\n@@ -249,16 +249,23 @@ def verify(public_key, signature, message):\n         print(data)\n         if data == b\"DHFIN\":\n             print(\"DH Exchange complete\")\n+        # === DH KEY EXCHANGE END ===\n+\n         # Derive Key from shared key, length is in byte (32 byte = 256 bit)\n         derived_key = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'handshake data',).derive(shared_key)\n         print(\"Derived Key:\\n\", derived_key)\n \n-        # === DH KEY EXCHANGE END ===\n-\n         # A 16 byte IV will be derived so both client and server has the same IV.\n         derived_iv = HKDF(algorithm=hashes.SHA256(),length=16,salt=None,info=b'aes ofb iv',).derive(shared_key)\n         print(\"Derived IV:\\n\", derived_iv)\n \n+        # HMAC key\n+        derived_hmac_key = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'mac',).derive(shared_key)\n+\n+        # Session ID\n+        derived_session_id = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'session id',).derive(shared_key)\n+\n+        component_id_tracker = 0\n         # initialize data var\n         data = b\"\"\n         # Specify size as 8 bytes\n@@ -282,17 +289,53 @@ def verify(public_key, signature, message):\n                 if not packet: break\n                 data+=packet\n             # print(\"# Get packed size of received data, first 8 bytes of packet\")\n-            packed_msg_size = data[:payload_size]\n+            # TODO check if these are  len 0\n+            recv_hmac_sig = data[:32]\n+            if len(recv_hmac_sig) != 32:\n+                continue\n+            remote_session_id = data[32:32+32]\n+            if len(remote_session_id) != 32:\n+                continue\n+            remote_bytes_component_id = data[32+32:32+32+4]\n+            if len(remote_bytes_component_id) != 4:\n+                continue\n+            packed_msg_size = data[32+32+4:32+32+4+payload_size]\n+            if len(packed_msg_size) !=  payload_size:\n+                continue\n             # print(packed_msg_size)\n             # print(\"# Get the initial frame data, eveything after the first 8 bytes\")\n-            data = data[payload_size:]\n+            data = data[32+32+4+payload_size:]\n             # Unpack to get real size of expected message\n             msg_size = struct.unpack(\"Q\",packed_msg_size)[0]\n+            # if msg_size > 1536165:\n+\n             # Get the rest of the frame data\n-            while len(data) < msg_size:\n+            while (len(data) < msg_size) and (len(data) < 1536165):\n                 data += client_socket.recv(4*1024)\n             # Store the full frame data\n             frame_data = data[:msg_size]\n+\n+            ## Verification\n+            # Verify HMAC\n+            recv_message = remote_session_id + remote_bytes_component_id + packed_msg_size + frame_data\n+            h = hmac.HMAC(derived_hmac_key, hashes.SHA256())\n+            h.update(recv_message)\n+            try:\n+                h.verify(recv_hmac_sig)\n+            except InvalidSignature as e:\n+                continue\n+\n+            # Verify session id matches\n+            if derived_session_id != remote_session_id:\n+                continue\n+\n+            # Verify component id increased\n+            remote_int_component_id = int.from_bytes(remote_bytes_component_id, \"big\")\n+            if remote_int_component_id <= component_id_tracker:\n+                continue\n+            else:\n+                component_id_tracker = remote_int_component_id\n+\n             # Decrypt data\n             frame_data = decrypt(derived_key, frame_data, derived_iv)\n             # Keep the tail data in data variable\ndiff --git a\/streaming_multi_client_server_with_asyncio.py b\/streaming_multi_client_server_with_asyncio.py\nindex 21cf753..bf1de8e 100644\n--- a\/streaming_multi_client_server_with_asyncio.py\n+++ b\/streaming_multi_client_server_with_asyncio.py\n@@ -23,7 +23,7 @@\n # Needed to handle async calls\n import asyncio\n # For encryption\n-from cryptography.hazmat.primitives import hashes\n+from cryptography.hazmat.primitives import hashes, hmac\n from cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec\n from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n from cryptography.hazmat.backends import default_backend\n@@ -208,10 +208,14 @@ def verify(public_key, signature, message):\n async def new_client(reader, writer):\n     global lock, stream, outputFrame, serialized_RSA_server_public_key, RSA_server_private_key, disable_ecdh, loop\n     try:\n+        addr =  writer.get_extra_info('peername')\n+        print(addr)\n+        # addr =  reader.get_extra_info('peername')\n+        # print(addr)\n         # if client_socket:\n             # vid = cv2.VideoCapture(0)\n             # global outputFrame, lock\n-        ## --------- DH Key EXCHANGE -----------##\n+        ## --------- DH Key EXCHANGE START -----------##\n         if disable_ecdh:\n             host_private_key, host_public_key_enc = generate_dh_key_pairs()\n         else:\n@@ -259,12 +263,20 @@ async def new_client(reader, writer):\n                 shared_key = host_private_key.exchange(remote_public_key)\n             else:\n                 shared_key = host_private_key.exchange(ec.ECDH(), remote_public_key)\n+            # client_derived_keys_ivs[s] = (derived_key, derived_iv)\n+            ## --------- DH Key EXCHANGE END -----------##\n+\n             derived_key = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'handshake data',).derive(shared_key)\n             print(\"Derived Key:\\n\", derived_key)\n             derived_iv = HKDF(algorithm=hashes.SHA256(),length=16,salt=None,info=b'aes ofb iv',).derive(shared_key)\n             print(\"Derived IV:\\n\", derived_iv)\n-            # client_derived_keys_ivs[s] = (derived_key, derived_iv)\n-            ## --------- DH Key EXCHANGE -----------##\n+\n+            # HMAC key\n+            derived_hmac_key = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'mac',).derive(shared_key)\n+\n+            # Session ID\n+            derived_session_id = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'session id',).derive(shared_key)\n+            component_id = 1\n         else:\n             abort = True\n         while stream and not abort:\n@@ -277,16 +289,30 @@ async def new_client(reader, writer):\n                     serializedFrame = pickle.dumps(outputFrame)\n                     # print(\"serializedFrame\")\n                     # print(serializedFrame[:10])\n-                    encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)\n-                    # print(\"encr_serializedFrame\")\n-                    # print(encr_serializedFrame[:10])\n-                    message = struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame\n-                    # print(struct.pack(\"Q\",len(encr_serializedFrame)))\n-                    # message = len(serializedFrame).to_bytes(8, \"big\")+serializedFrame\n-                    # print(len(serializedFrame).to_bytes(8, \"big\"))\n+                encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)\n+                # print(\"encr_serializedFrame\")\n+                # print(encr_serializedFrame[:10])\n+                message = derived_session_id\n+                bytes_component_id = component_id.to_bytes(4,\"big\")\n+                message += bytes_component_id\n+                # when width was 800\n+                # 1200165 when aspect ratio was 16:10\n+                # 1080165 when aspect ratio was 16:9\n+                # print(\"len encr_serializedFrame\")\n+                # print(len(encr_serializedFrame))\n+                message += struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame\n+                # Make an hmac for message\n+                h = hmac.HMAC(derived_hmac_key, hashes.SHA256())\n+                h.update(message)\n+                message_hmac = h.finalize()\n+                message = message_hmac + message\n+                # print(struct.pack(\"Q\",len(encr_serializedFrame)))\n+                # message = len(serializedFrame).to_bytes(8, \"big\")+serializedFrame\n+                # print(len(serializedFrame).to_bytes(8, \"big\"))\n                 # print(\"sending FRAME\")\n                 writer.write(message)\n                 await writer.drain()\n+                component_id += 1\n             elif data == b'LEAVING':\n                 break    \n             if outputFrame is not None:\n@@ -305,6 +331,8 @@ async def new_client(reader, writer):\n         # raise e\n     except asyncio.TimeoutError:\n         print('Client Timed out')\n+    except ConnectionResetError as e:\n+        print('Client left unexpectdly')\n     finally:\n         writer.close()\n \n","files":{"\/streaming_client_asyncio.py":{"changes":[{"diff":"\n import argparse\n import errno\n # For encryption\n-from cryptography.hazmat.primitives import hashes\n+from cryptography.hazmat.primitives import hashes, hmac\n from cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec\n from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n from cryptography.hazmat.backends import default_backend\n","add":1,"remove":1,"filename":"\/streaming_client_asyncio.py","badparts":["from cryptography.hazmat.primitives import hashes"],"goodparts":["from cryptography.hazmat.primitives import hashes, hmac"]},{"diff":"\n                 if not packet: break\n                 data+=packet\n             # print(\"# Get packed size of received data, first 8 bytes of packet\")\n-            packed_msg_size = data[:payload_size]\n+            # TODO check if these are  len 0\n+            recv_hmac_sig = data[:32]\n+            if len(recv_hmac_sig) != 32:\n+                continue\n+            remote_session_id = data[32:32+32]\n+            if len(remote_session_id) != 32:\n+                continue\n+            remote_bytes_component_id = data[32+32:32+32+4]\n+            if len(remote_bytes_component_id) != 4:\n+                continue\n+            packed_msg_size = data[32+32+4:32+32+4+payload_size]\n+            if len(packed_msg_size) !=  payload_size:\n+                continue\n             # print(packed_msg_size)\n             # print(\"# Get the initial frame data, eveything after the first 8 bytes\")\n-            data = data[payload_size:]\n+            data = data[32+32+4+payload_size:]\n             # Unpack to get real size of expected message\n             msg_size = struct.unpack(\"Q\",packed_msg_size)[0]\n+            # if msg_size > 1536165:\n+\n             # Get the rest of the frame data\n-            while len(data) < msg_size:\n+            while (len(data) < msg_size) and (len(data) < 1536165):\n                 data += client_socket.recv(4*1024)\n             # Store the full frame data\n             frame_data = data[:msg_size]\n+\n+            ## Verification\n+            # Verify HMAC\n+            recv_message = remote_session_id + remote_bytes_component_id + packed_msg_size + frame_data\n+            h = hmac.HMAC(derived_hmac_key, hashes.SHA256())\n+            h.update(recv_message)\n+            try:\n+                h.verify(recv_hmac_sig)\n+            except InvalidSignature as e:\n+                continue\n+\n+            # Verify session id matches\n+            if derived_session_id != remote_session_id:\n+                continue\n+\n+            # Verify component id increased\n+            remote_int_component_id = int.from_bytes(remote_bytes_component_id, \"big\")\n+            if remote_int_component_id <= component_id_tracker:\n+                continue\n+            else:\n+                component_id_tracker = remote_int_component_id\n+\n             # Decrypt data\n             frame_data = decrypt(derived_key, frame_data, derived_iv)\n             # Keep the tail data in data variable","add":39,"remove":3,"filename":"\/streaming_client_asyncio.py","badparts":["            packed_msg_size = data[:payload_size]","            data = data[payload_size:]","            while len(data) < msg_size:"],"goodparts":["            recv_hmac_sig = data[:32]","            if len(recv_hmac_sig) != 32:","                continue","            remote_session_id = data[32:32+32]","            if len(remote_session_id) != 32:","                continue","            remote_bytes_component_id = data[32+32:32+32+4]","            if len(remote_bytes_component_id) != 4:","                continue","            packed_msg_size = data[32+32+4:32+32+4+payload_size]","            if len(packed_msg_size) !=  payload_size:","                continue","            data = data[32+32+4+payload_size:]","            while (len(data) < msg_size) and (len(data) < 1536165):","            recv_message = remote_session_id + remote_bytes_component_id + packed_msg_size + frame_data","            h = hmac.HMAC(derived_hmac_key, hashes.SHA256())","            h.update(recv_message)","            try:","                h.verify(recv_hmac_sig)","            except InvalidSignature as e:","                continue","            if derived_session_id != remote_session_id:","                continue","            remote_int_component_id = int.from_bytes(remote_bytes_component_id, \"big\")","            if remote_int_component_id <= component_id_tracker:","                continue","            else:","                component_id_tracker = remote_int_component_id"]}],"source":"\nimport socket import cv2 import pickle import struct import threading import argparse import errno from cryptography.hazmat.primitives import hashes from cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec from cryptography.hazmat.primitives.kdf.hkdf import HKDF from cryptography.hazmat.backends import default_backend from cryptography.hazmat.primitives.serialization import PublicFormat, Encoding, load_der_public_key, load_pem_public_key, load_pem_private_key from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes from cryptography.exceptions import InvalidSignature watching=True watch_char={ 0: \"\/\", 1: \"-\", 2: \"|\", 3: \"\\\\\", 4: \"|\", } disable_ecdh=False def key_capture_thread(): global watching input() watching=False print(\"starting exit process\") def encrypt(key, plaintext, iv): cipher=Cipher(algorithms.AES(key), modes.OFB(iv)) encryptor=cipher.encryptor() ciphertext=encryptor.update(plaintext) +encryptor.finalize() return ciphertext def decrypt(key, ciphertext, iv): cipher=Cipher(algorithms.AES(key), modes.OFB(iv)) decryptor=cipher.decryptor() deciphered_text=decryptor.update(ciphertext) +decryptor.finalize() return deciphered_text def generate_dh_key_pairs(): p=0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE45B3DC2007CB8A163BF0598DA48361C55D39A69163FA8FD24CF5F83655D23DCA3AD961C62F356208552BB9ED529077096966D670C354E4ABC9804F1746C08CA18217C32905E462E36CE3BE39E772C180E86039B2783A2EC07A28FB5C55DF06F4C52C9DE2BCBF6955817183995497CEA956AE515D2261898FA051015728E5A8AACAA68FFFFFFFFFFFFFFFF g=2 params_numbers=dh.DHParameterNumbers(p,g) parameters=params_numbers.parameters(default_backend()) host_private_key=parameters.generate_private_key() host_public_key_enc=host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo) return(host_private_key, host_public_key_enc) def generate_ecdh_key_pairs(): host_private_key=ec.generate_private_key( ec.SECP384R1() ) host_public_key_enc=host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo) return(host_private_key, host_public_key_enc) def client_dh_key_exchange(host_socket, host_private_key, host_public_key_enc, serialized_RSA_server_public_key, serialized_RSA_client_public_key, RSA_client_private_key): global disable_ecdh size=host_socket.recv(2) remote_public_key_enc=host_socket.recv(int.from_bytes(size, \"big\")) print(\"Size of remote's public key: \", int.from_bytes(size, \"big\")) print(\"Remote's public key:\\n\", remote_public_key_enc) remote_public_key=load_der_public_key(remote_public_key_enc, default_backend()) message_to_be_signed=serialized_RSA_server_public_key +serialized_RSA_client_public_key +remote_public_key_enc +host_public_key_enc message_signature=sign(RSA_client_private_key, message_to_be_signed) host_socket.send(b\"PUBK\" + len(host_public_key_enc).to_bytes(2, \"big\") + host_public_key_enc + len(message_signature).to_bytes(2, \"big\") + message_signature) print(\"Sent host's public key to\", host_ip, \":\", port) size=host_socket.recv(2) remote_signature=host_socket.recv(int.from_bytes(size, \"big\")) intended_message=serialized_RSA_server_public_key +host_public_key_enc verify(load_pem_public_key(serialized_RSA_server_public_key), remote_signature, intended_message) if disable_ecdh: shared_key=host_private_key.exchange(remote_public_key) else: shared_key=host_private_key.exchange(ec.ECDH(), remote_public_key) print(\"Shared Key:\\n\", shared_key) return shared_key def receive_and_decrypt_AES_OFB_message(host_socket, derived_key, derived_iv): size=host_socket.recv(2) ciphertext=host_socket.recv(int.from_bytes(size, \"big\")) deciphered_text=decrypt(derived_key, ciphertext, derived_iv) return deciphered_text def lookupIP(client_socket, public_key): client_socket.send(b'1') client_socket.send(len(public_key).to_bytes(2, \"big\") +public_key) output=client_socket.recv(1024) return output def registerPublicKey(client_socket, public_key, private_key): client_socket.send(b'0') signed_public_key=sign(private_key, public_key) client_socket.send(len(public_key).to_bytes(2, \"big\") +public_key) client_socket.send(len(signed_public_key).to_bytes(2, \"big\") +signed_public_key) output=client_socket.recv(1024) return output def sign(private_key, data): signature=private_key.sign( data, padding.PSS( mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH ), hashes.SHA256() ) return signature def verify(public_key, signature, message): print(\"IN VERIFY\") print(\"public_key:\\n\", public_key) print(\"signature:\\n\", signature) print(\"message:\\n\", message) public_key.verify( signature, message, padding.PSS( mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH ), hashes.SHA256() ) if __name__=='__main__': ap=argparse.ArgumentParser() ap.add_argument(\"-i\", \"--host-ip\", type=str, required=False, help=\"ip address of the server to connect to\", default='127.0.0.1') ap.add_argument(\"-p\", \"--port\", type=int, required=False, help=\"port number to connect to\", default=9898) ap.add_argument(\"--pki-host-ip\", type=str, required=False, help=\"ip address of the PKI server to connect to\", default='127.0.0.1') ap.add_argument(\"--pki-port\", type=int, required=False, help=\"PKI port number to connect to\", default=7777) ap.add_argument(\"--rsa-pub-key\", type=str, required=False, help=\"Path to RSA PEM public key\", default='env\/keys\/client\/client_01\/public-key.pem') ap.add_argument(\"--rsa-priv-key\", type=str, required=False, help=\"Path to RSA PEM private key\", default='env\/keys\/client\/client_01\/private-key.pem') ap.add_argument(\"--disable-ecdh\", type=bool, required=False, help=\"Disable Elliptic Curve key generation for Diffie-Hellman Key Exchange, needs to match server\", default=False) args=vars(ap.parse_args()) disable_ecdh=args[\"disable_ecdh\"] RSA_client_public_key=None RSA_client_private_key=None with open(args[\"rsa_pub_key\"], \"rb\") as key_file: RSA_client_public_key=load_pem_public_key( key_file.read() ) with open(args[\"rsa_priv_key\"], \"rb\") as key_file: RSA_client_private_key=load_pem_private_key( key_file.read(), password=None, ) serialized_RSA_client_public_key=RSA_client_public_key.public_bytes(Encoding.PEM, PublicFormat.SubjectPublicKeyInfo) client_socket=socket.socket(socket.AF_INET,socket.SOCK_STREAM) host_ip=args[\"host_ip\"] port=args[\"port\"] abort=False threading.Thread(target=key_capture_thread, args=(), name='key_capture_thread', daemon=True).start() try: if disable_ecdh: client_private_key, client_public_key_enc=generate_dh_key_pairs() else: client_private_key, client_public_key_enc=generate_ecdh_key_pairs() client_socket.connect((host_ip,port)) serialized_RSA_server_public_key=None initial_message=b\"HELO\" +len(serialized_RSA_client_public_key).to_bytes(2, \"big\") +serialized_RSA_client_public_key client_socket.sendall(initial_message) data=client_socket.recv(4) if data==b\"HELO\": size=client_socket.recv(2) serialized_RSA_server_public_key=client_socket.recv(int.from_bytes(size, \"big\")) else: abort=True client_socket.sendall(b\"DHINI\") shared_key=client_dh_key_exchange(client_socket, client_private_key, client_public_key_enc, serialized_RSA_server_public_key, serialized_RSA_client_public_key, RSA_client_private_key) print(\"ran DH func\") data=client_socket.recv(5) print(data) if data==b\"DHFIN\": print(\"DH Exchange complete\") derived_key=HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'handshake data',).derive(shared_key) print(\"Derived Key:\\n\", derived_key) derived_iv=HKDF(algorithm=hashes.SHA256(),length=16,salt=None,info=b'aes ofb iv',).derive(shared_key) print(\"Derived IV:\\n\", derived_iv) data=b\"\" payload_size=struct.calcsize(\"Q\") smud=0 stracker=0 while watching: client_socket.send(b\"READY\") while len(data) < payload_size: packet=client_socket.recv(4*1024) if smud < 200: if smud % 20==0: print(f\"{watch_char[stracker]} watching stream{watch_char[stracker]}\", end=\"\\r\") stracker +=1 if stracker > 4: stracker=0 smud +=1 else: smud=0 if not packet: break data+=packet packed_msg_size=data[:payload_size] data=data[payload_size:] msg_size=struct.unpack(\"Q\",packed_msg_size)[0] while len(data) < msg_size: data +=client_socket.recv(4*1024) frame_data=data[:msg_size] frame_data=decrypt(derived_key, frame_data, derived_iv) data=data[msg_size:] frame=pickle.loads(frame_data) cv2.imshow(\"WATCHING %s STREAM\" %(host_ip),frame) key=cv2.waitKey(1) & 0xFF if key ==ord('q') or not watching: print(\"\\nLeaving the Stream\") client_socket.sendall(b\"LEAVING\") break except struct.error as e: if len(packed_msg_size)==0: print(\"\\nStream has ended\") else: raise e except ConnectionResetError as e: if e.errno==errno.ECONNRESET: print(\"\\nStream has ended\") else: raise e finally: client_socket.close() ","sourceWithComments":"import socket\nimport cv2\nimport pickle\nimport struct\nimport threading\nimport argparse\nimport errno\n# For encryption\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec\nfrom cryptography.hazmat.primitives.kdf.hkdf import HKDF\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.serialization import PublicFormat, Encoding, load_der_public_key, load_pem_public_key, load_pem_private_key\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\nfrom cryptography.exceptions import InvalidSignature\n\nwatching = True\nwatch_char = {\n    0: \"\/\",\n    1: \"-\",\n    2: \"|\",\n    3: \"\\\\\",\n    4: \"|\",\n}\ndisable_ecdh = False\n\n# thread that listens for any input, used to terminate stream loop\ndef key_capture_thread():\n    global watching\n    input()\n    watching = False\n    print(\"starting exit process\")\n\ndef encrypt(key, plaintext, iv):\n    # Declare cipher type\n    cipher = Cipher(algorithms.AES(key), modes.OFB(iv))\n    encryptor = cipher.encryptor()\n\n    # Encrypt\n    ciphertext = encryptor.update(plaintext) + encryptor.finalize()\n\n    return ciphertext\n\ndef decrypt(key, ciphertext, iv):\n    # Declare cipher type\n    cipher = Cipher(algorithms.AES(key), modes.OFB(iv))\n    decryptor = cipher.decryptor()\n\n    # Decrypt\n    deciphered_text = decryptor.update(ciphertext) + decryptor.finalize()\n\n    return deciphered_text\n\ndef generate_dh_key_pairs():\n    # Hard-coded p and g for DH Key exchange (RFC 3526 - group id 14)\n    p = 0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE45B3DC2007CB8A163BF0598DA48361C55D39A69163FA8FD24CF5F83655D23DCA3AD961C62F356208552BB9ED529077096966D670C354E4ABC9804F1746C08CA18217C32905E462E36CE3BE39E772C180E86039B2783A2EC07A28FB5C55DF06F4C52C9DE2BCBF6955817183995497CEA956AE515D2261898FA051015728E5A8AACAA68FFFFFFFFFFFFFFFF\n    g = 2\n\n    # Use our p and g with cryptography library\n    params_numbers = dh.DHParameterNumbers(p,g)\n    parameters = params_numbers.parameters(default_backend())\n\n    # Generate private and public key\n    host_private_key = parameters.generate_private_key()\n    host_public_key_enc= host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo)\n    return (host_private_key, host_public_key_enc)\n\ndef generate_ecdh_key_pairs():\n    host_private_key = ec.generate_private_key(\n        ec.SECP384R1()\n    )\n    host_public_key_enc = host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo)\n    return (host_private_key, host_public_key_enc)\n\ndef client_dh_key_exchange(host_socket, host_private_key, host_public_key_enc, serialized_RSA_server_public_key, serialized_RSA_client_public_key, RSA_client_private_key):\n    global disable_ecdh\n    # Receiving size of remote's public key and remote's public key\n    size = host_socket.recv(2)\n    remote_public_key_enc = host_socket.recv(int.from_bytes(size, \"big\"))\n    print(\"Size of remote's public key: \", int.from_bytes(size, \"big\"))\n    print(\"Remote's public key:\\n\", remote_public_key_enc)\n\n    # Decode remote's public key\n    remote_public_key = load_der_public_key(remote_public_key_enc, default_backend())\n\n    # Send Message to let server know it's going to send the public key\n    # host_socket.send()\n    # Send size of public key and public key to remote\n    message_to_be_signed = serialized_RSA_server_public_key + serialized_RSA_client_public_key + remote_public_key_enc + host_public_key_enc\n    message_signature = sign(RSA_client_private_key, message_to_be_signed)\n    host_socket.send(b\"PUBK\" +\n                    len(host_public_key_enc).to_bytes(2, \"big\") +\n                    host_public_key_enc +\n                    len(message_signature).to_bytes(2, \"big\") +\n                    message_signature)\n    print(\"Sent host's public key to\", host_ip, \":\", port)\n    # Get server's signature\n    size = host_socket.recv(2)\n    remote_signature = host_socket.recv(int.from_bytes(size, \"big\"))\n    # Verify server's signature\n    intended_message = serialized_RSA_server_public_key + host_public_key_enc\n    verify(load_pem_public_key(serialized_RSA_server_public_key), remote_signature, intended_message)\n\n    # Generate shared key\n    if disable_ecdh:\n        shared_key = host_private_key.exchange(remote_public_key)\n    else:\n        shared_key = host_private_key.exchange(ec.ECDH(), remote_public_key)\n    print(\"Shared Key:\\n\", shared_key)\n\n    return shared_key\n\ndef receive_and_decrypt_AES_OFB_message(host_socket, derived_key, derived_iv):\n    size = host_socket.recv(2)\n    ciphertext = host_socket.recv(int.from_bytes(size, \"big\"))\n    deciphered_text = decrypt(derived_key, ciphertext, derived_iv)\n    return deciphered_text\n\ndef lookupIP(client_socket, public_key):\n    client_socket.send(b'1')\n    client_socket.send(len(public_key).to_bytes(2, \"big\") + public_key)\n    output = client_socket.recv(1024)\n\n    return output\n\ndef registerPublicKey(client_socket, public_key, private_key):\n    client_socket.send(b'0')\n    signed_public_key = sign(private_key, public_key)\n    client_socket.send(len(public_key).to_bytes(2, \"big\") + public_key)\n    client_socket.send(len(signed_public_key).to_bytes(2, \"big\") + signed_public_key)\n    output = client_socket.recv(1024)\n\n    return output\n\ndef sign(private_key, data):\n    signature = private_key.sign(\n        data,\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n\n    return signature\n\ndef verify(public_key, signature, message):\n    print(\"IN VERIFY\")\n    print(\"public_key:\\n\", public_key)\n    print(\"signature:\\n\", signature)\n    print(\"message:\\n\", message)\n    # Verify signature\n    public_key.verify(\n        signature,\n        message,\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n\n\n\n\nif __name__ == '__main__':\n    # Handle arguments\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-i\", \"--host-ip\", type=str, required=False,\n        help=\"ip address of the server to connect to\", default='127.0.0.1')\n    ap.add_argument(\"-p\", \"--port\", type=int, required=False,\n        help=\"port number to connect to\", default=9898)\n    ap.add_argument(\"--pki-host-ip\", type=str, required=False,\n        help=\"ip address of the PKI server to connect to\", default='127.0.0.1')\n    ap.add_argument(\"--pki-port\", type=int, required=False,\n        help=\"PKI port number to connect to\", default=7777)\n    ap.add_argument(\"--rsa-pub-key\", type=str, required=False,\n        help=\"Path to RSA PEM public key\", default='env\/keys\/client\/client_01\/public-key.pem')\n    ap.add_argument(\"--rsa-priv-key\", type=str, required=False,\n        help=\"Path to RSA PEM private key\", default='env\/keys\/client\/client_01\/private-key.pem')\n    ap.add_argument(\"--disable-ecdh\", type=bool, required=False,\n        help=\"Disable Elliptic Curve key generation for Diffie-Hellman Key Exchange, needs to match server\", default=False)\n    args = vars(ap.parse_args())\n\n    disable_ecdh = args[\"disable_ecdh\"]\n    RSA_client_public_key = None\n    RSA_client_private_key = None\n    with open(args[\"rsa_pub_key\"], \"rb\") as key_file:\n        RSA_client_public_key = load_pem_public_key(\n            key_file.read()\n        )\n    with open(args[\"rsa_priv_key\"], \"rb\") as key_file:\n        RSA_client_private_key = load_pem_private_key(\n            key_file.read(),\n            password=None,\n        )\n\n    # Serialize keys\n    serialized_RSA_client_public_key = RSA_client_public_key.public_bytes(Encoding.PEM, PublicFormat.SubjectPublicKeyInfo)\n\n    # ## --------- PKI Register Pub Keys START-----------##\n    # pki_client_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    # pki_host_ip = args[\"pki_host_ip\"]\n    # pki_port = args[\"pki_port\"]\n    # pki_client_socket.connect((pki_host_ip,pki_port))\n    # response = registerPublicKey(pki_client_socket, serialized_RSA_client_public_key, RSA_client_private_key)\n    # print(\"response:\", response)\n    # pki_client_socket.close()\n    # ## --------- PKI Register Pub Keys END  -----------##\n\n    # create socket\n    client_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    host_ip = args[\"host_ip\"]\n    port = args[\"port\"]\n    abort = False\n    threading.Thread(target=key_capture_thread, args=(), name='key_capture_thread', daemon=True).start()\n    try:\n\n        # Generate new dh key pairs before each connection\n        if disable_ecdh:\n            client_private_key, client_public_key_enc = generate_dh_key_pairs()\n        else:\n            client_private_key, client_public_key_enc = generate_ecdh_key_pairs()\n        # Initialize Connection\n        client_socket.connect((host_ip,port)) # a tuple\n        serialized_RSA_server_public_key = None\n        initial_message = b\"HELO\" + len(serialized_RSA_client_public_key).to_bytes(2, \"big\") + serialized_RSA_client_public_key\n        client_socket.sendall(initial_message)\n        # === GET RSA PUBLIC KEY START ===\n        data = client_socket.recv(4)\n        if data == b\"HELO\":\n            size = client_socket.recv(2)\n            serialized_RSA_server_public_key = client_socket.recv(int.from_bytes(size, \"big\"))\n        else:\n            abort = True\n        # === GET RSA PUBLIC KEY END ===\n\n\n        # === DH KEY EXCHANGE START ===\n        client_socket.sendall(b\"DHINI\")\n        shared_key = client_dh_key_exchange(client_socket,\n                                            client_private_key,\n                                            client_public_key_enc,\n                                            serialized_RSA_server_public_key,\n                                            serialized_RSA_client_public_key,\n                                            RSA_client_private_key)\n        print(\"ran DH func\")\n        data = client_socket.recv(5)\n        print(data)\n        if data == b\"DHFIN\":\n            print(\"DH Exchange complete\")\n        # Derive Key from shared key, length is in byte (32 byte = 256 bit)\n        derived_key = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'handshake data',).derive(shared_key)\n        print(\"Derived Key:\\n\", derived_key)\n\n        # === DH KEY EXCHANGE END ===\n\n        # A 16 byte IV will be derived so both client and server has the same IV.\n        derived_iv = HKDF(algorithm=hashes.SHA256(),length=16,salt=None,info=b'aes ofb iv',).derive(shared_key)\n        print(\"Derived IV:\\n\", derived_iv)\n\n        # initialize data var\n        data = b\"\"\n        # Specify size as 8 bytes\n        payload_size = struct.calcsize(\"Q\")\n        smud = 0\n        stracker = 0\n        while watching:\n            client_socket.send(b\"READY\")\n            # Grab packet\n            while len(data) < payload_size:\n                packet = client_socket.recv(4*1024)\n                if smud < 200:\n                    if smud % 20 == 0:\n                        print(f\"{watch_char[stracker]} watching stream {watch_char[stracker]}\", end=\"\\r\")\n                        stracker += 1\n                        if stracker > 4:\n                            stracker = 0\n                    smud += 1\n                else:\n                    smud = 0\n                if not packet: break\n                data+=packet\n            # print(\"# Get packed size of received data, first 8 bytes of packet\")\n            packed_msg_size = data[:payload_size]\n            # print(packed_msg_size)\n            # print(\"# Get the initial frame data, eveything after the first 8 bytes\")\n            data = data[payload_size:]\n            # Unpack to get real size of expected message\n            msg_size = struct.unpack(\"Q\",packed_msg_size)[0]\n            # Get the rest of the frame data\n            while len(data) < msg_size:\n                data += client_socket.recv(4*1024)\n            # Store the full frame data\n            frame_data = data[:msg_size]\n            # Decrypt data\n            frame_data = decrypt(derived_key, frame_data, derived_iv)\n            # Keep the tail data in data variable\n            data = data[msg_size:]\n            # Deserialize frame data\n            frame = pickle.loads(frame_data)\n            # Display the images\n            cv2.imshow(\"WATCHING %s STREAM\" % (host_ip),frame)\n            key = cv2.waitKey(1) & 0xFF\n            if key  == ord('q') or not watching:\n                print(\"\\nLeaving the Stream\")\n                client_socket.sendall(b\"LEAVING\")\n                break\n    except struct.error as e:\n        # Handle case when server stops sending data, i.e. stream ended\n        if len(packed_msg_size) == 0:\n            print(\"\\nStream has ended\")\n        else:\n            raise e\n    except ConnectionResetError as e:\n        if e.errno == errno.ECONNRESET:\n            print(\"\\nStream has ended\")\n        else:\n            raise e\n    finally:\n        client_socket.close()"},"\/streaming_multi_client_server_with_asyncio.py":{"changes":[{"diff":"\n # Needed to handle async calls\n import asyncio\n # For encryption\n-from cryptography.hazmat.primitives import hashes\n+from cryptography.hazmat.primitives import hashes, hmac\n from cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec\n from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n from cryptography.hazmat.backends import default_backend\n","add":1,"remove":1,"filename":"\/streaming_multi_client_server_with_asyncio.py","badparts":["from cryptography.hazmat.primitives import hashes"],"goodparts":["from cryptography.hazmat.primitives import hashes, hmac"]},{"diff":"\n                     serializedFrame = pickle.dumps(outputFrame)\n                     # print(\"serializedFrame\")\n                     # print(serializedFrame[:10])\n-                    encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)\n-                    # print(\"encr_serializedFrame\")\n-                    # print(encr_serializedFrame[:10])\n-                    message = struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame\n-                    # print(struct.pack(\"Q\",len(encr_serializedFrame)))\n-                    # message = len(serializedFrame).to_bytes(8, \"big\")+serializedFrame\n-                    # print(len(serializedFrame).to_bytes(8, \"big\"))\n+                encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)\n+                # print(\"encr_serializedFrame\")\n+                # print(encr_serializedFrame[:10])\n+                message = derived_session_id\n+                bytes_component_id = component_id.to_bytes(4,\"big\")\n+                message += bytes_component_id\n+                # when width was 800\n+                # 1200165 when aspect ratio was 16:10\n+                # 1080165 when aspect ratio was 16:9\n+                # print(\"len encr_serializedFrame\")\n+                # print(len(encr_serializedFrame))\n+                message += struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame\n+                # Make an hmac for message\n+                h = hmac.HMAC(derived_hmac_key, hashes.SHA256())\n+                h.update(message)\n+                message_hmac = h.finalize()\n+                message = message_hmac + message\n+                # print(struct.pack(\"Q\",len(encr_serializedFrame)))\n+                # message = len(serializedFrame).to_bytes(8, \"big\")+serializedFrame\n+                # print(len(serializedFrame).to_bytes(8, \"big\"))\n                 # print(\"sending FRAME\")\n                 writer.write(message)\n                 await writer.drain()\n+                component_id += 1\n             elif data == b'LEAVING':\n                 break    \n             if outputFrame is not None:\n","add":21,"remove":7,"filename":"\/streaming_multi_client_server_with_asyncio.py","badparts":["                    encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)","                    message = struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame"],"goodparts":["                encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)","                message = derived_session_id","                bytes_component_id = component_id.to_bytes(4,\"big\")","                message += bytes_component_id","                message += struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame","                h = hmac.HMAC(derived_hmac_key, hashes.SHA256())","                h.update(message)","                message_hmac = h.finalize()","                message = message_hmac + message","                component_id += 1"]}],"source":"\n\nimport threading import argparse import datetime import time import numpy as np import pyautogui import imutils import cv2 from PIL import UnidentifiedImageError, Image, ImageFile import os import socket import pickle import struct import select import queue import asyncio from cryptography.hazmat.primitives import hashes from cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec from cryptography.hazmat.primitives.kdf.hkdf import HKDF from cryptography.hazmat.backends import default_backend from cryptography.hazmat.primitives.serialization import PublicFormat, Encoding, load_der_public_key, load_pem_public_key, load_pem_private_key from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes ImageFile.LOAD_TRUNCATED_IMAGES=True outputFrame=None lock=threading.Lock() stream=True read_list=[] write_list=[] message_queues={} dh_keyexchanges={} client_derived_keys_ivs={} p=0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE45B3DC2007CB8A163BF0598DA48361C55D39A69163FA8FD24CF5F83655D23DCA3AD961C62F356208552BB9ED529077096966D670C354E4ABC9804F1746C08CA18217C32905E462E36CE3BE39E772C180E86039B2783A2EC07A28FB5C55DF06F4C52C9DE2BCBF6955817183995497CEA956AE515D2261898FA051015728E5A8AACAA68FFFFFFFFFFFFFFFF g=2 serialized_RSA_server_public_key=None RSA_server_private_key=None disable_ecdh=False loop=None def capture_frames(): global outputFrame, lock, stream, message_queues try: while stream: frame=pyautogui.screenshot() frame=cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR) frame=imutils.resize(frame, width=800) timestamp=datetime.datetime.now() cv2.putText(frame, timestamp.strftime( \"%A %d %B %Y %I:%M:%S%p\"),(10, frame.shape[0] -10), cv2.FONT_HERSHEY_SIMPLEX, 0.35,(0, 0, 255), 1) with lock: outputFrame=frame.copy() time.sleep(0.1) except UnidentifiedImageError as e: quoted_filename=e.args[0].split()[4] filename=quoted_filename.strip(\"'\") if os.path.exists(filename): os.remove(filename) print(\"Deleted leftover temp image file\") except OSError as e: if e.errno==2: pass else: raise e def encrypt(key, plaintext, iv): cipher=Cipher(algorithms.AES(key), modes.OFB(iv)) encryptor=cipher.encryptor() ciphertext=encryptor.update(plaintext) +encryptor.finalize() return ciphertext def decrypt(key, ciphertext, iv): cipher=Cipher(algorithms.AES(key), modes.OFB(iv)) decryptor=cipher.decryptor() deciphered_text=decryptor.update(ciphertext) +decryptor.finalize() return deciphered_text def generate_dh_key_pairs(): global p, g params_numbers=dh.DHParameterNumbers(p,g) parameters=params_numbers.parameters(default_backend()) host_private_key=parameters.generate_private_key() host_public_key_enc=host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo) return(host_private_key, host_public_key_enc) def generate_ecdh_key_pairs(): host_private_key=ec.generate_private_key( ec.SECP384R1() ) host_public_key_enc=host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo) return(host_private_key, host_public_key_enc) def encrypt_and_send_AES_OFB_message(client_socket, plaintext, key, iv): ciphertext=encrypt(key, plaintext, iv) client_socket.send(len(ciphertext).to_bytes(2, \"big\") +ciphertext) def lookupIP(client_socket, public_key): client_socket.send(b'1') client_socket.send(len(public_key).to_bytes(2, \"big\") +public_key) output=client_socket.recv(1024) return output def registerPublicKey(client_socket, public_key, private_key): client_socket.send(b'0') signed_public_key=sign(private_key, public_key) client_socket.send(len(public_key).to_bytes(2, \"big\") +public_key) client_socket.send(len(signed_public_key).to_bytes(2, \"big\") +signed_public_key) output=client_socket.recv(1024) return output def sign(private_key, data): signature=private_key.sign( data, padding.PSS( mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH ), hashes.SHA256() ) return signature def verify(public_key, signature, message): public_key.verify( signature, message, padding.PSS( mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH ), hashes.SHA256() ) async def new_client(reader, writer): global lock, stream, outputFrame, serialized_RSA_server_public_key, RSA_server_private_key, disable_ecdh, loop try: if disable_ecdh: host_private_key, host_public_key_enc=generate_dh_key_pairs() else: print(\"USING ECDH\") host_private_key, host_public_key_enc=generate_ecdh_key_pairs() data=await reader.read(4) size=None serialized_RSA_client_public_key=None abort=False if data==b\"HELO\": size=await reader.read(2) serialized_RSA_client_public_key=await reader.read(int.from_bytes(size, \"big\")) initial_message=b\"HELO\" +len(serialized_RSA_server_public_key).to_bytes(2, \"big\") +serialized_RSA_server_public_key writer.write(initial_message) await writer.drain() else: abort=True data=await reader.read(5) if data==b\"DHINI\" and not abort: writer.write(len(host_public_key_enc).to_bytes(2, \"big\") +host_public_key_enc) await writer.drain() else: abort=True data=await reader.read(4) if data==b\"PUBK\" and not abort: size=await reader.read(2) remote_public_key_enc=await reader.read(int.from_bytes(size, \"big\")) print(\"Size of remote's public key: \", int.from_bytes(size, \"big\")) print(\"Remote's public key:\\n\", remote_public_key_enc) size=await reader.read(2) remote_signature=await reader.read(int.from_bytes(size, \"big\")) intended_message=serialized_RSA_server_public_key +serialized_RSA_client_public_key +host_public_key_enc +remote_public_key_enc verify(load_pem_public_key(serialized_RSA_client_public_key), remote_signature, intended_message) print(\"Message Verified\") host_message=serialized_RSA_server_public_key +remote_public_key_enc with lock: host_signature=sign(RSA_server_private_key, host_message) writer.write(len(host_signature).to_bytes(2, \"big\") +host_signature +b\"DHFIN\") await writer.drain() remote_public_key=load_der_public_key(remote_public_key_enc, default_backend()) if disable_ecdh: shared_key=host_private_key.exchange(remote_public_key) else: shared_key=host_private_key.exchange(ec.ECDH(), remote_public_key) derived_key=HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'handshake data',).derive(shared_key) print(\"Derived Key:\\n\", derived_key) derived_iv=HKDF(algorithm=hashes.SHA256(),length=16,salt=None,info=b'aes ofb iv',).derive(shared_key) print(\"Derived IV:\\n\", derived_iv) else: abort=True while stream and not abort: data=await reader.read(1024) if data==b'READY': with lock: serializedFrame=pickle.dumps(outputFrame) encr_serializedFrame=encrypt(derived_key, serializedFrame, derived_iv) message=struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame writer.write(message) await writer.drain() elif data==b'LEAVING': break if outputFrame is not None: pass except KeyboardInterrupt as e: print(\"\\nClient Task was canceled\") stream=False loop.stop() except asyncio.TimeoutError: print('Client Timed out') finally: writer.close() async def boot_server(host_ip, port): server=await asyncio.start_server(new_client, port=port, host=host_ip) await server.serve_forever() if __name__=='__main__': ap=argparse.ArgumentParser() ap.add_argument(\"-i\", \"--host-ip\", type=str, required=False, help=\"ip address to serve on\", default='127.0.0.1') ap.add_argument(\"-p\", \"--port\", type=int, required=False, help=\"port number to listen to\", default=9898) ap.add_argument(\"--pki-host-ip\", type=str, required=False, help=\"ip address of the PKI server to connect to\", default='127.0.0.1') ap.add_argument(\"--pki-port\", type=int, required=False, help=\"PKI port number to connect to\", default=7777) ap.add_argument(\"--rsa-pub-key\", type=str, required=False, help=\"Path to RSA PEM public key\", default='env\/keys\/server\/public-key.pem') ap.add_argument(\"--rsa-priv-key\", type=str, required=False, help=\"Path to RSA PEM private key\", default='env\/keys\/server\/private-key.pem') ap.add_argument(\"--disable-ecdh\", type=bool, required=False, help=\"Disable Elliptic Curve key generation for Diffie-Hellman Key Exchange\", default=False) args=vars(ap.parse_args()) disable_ecdh=args[\"disable_ecdh\"] RSA_server_public_key=None RSA_server_private_key=None with open(args[\"rsa_pub_key\"], \"rb\") as key_file: RSA_server_public_key=load_pem_public_key( key_file.read() ) with open(args[\"rsa_priv_key\"], \"rb\") as key_file: RSA_server_private_key=load_pem_private_key( key_file.read(), password=None, ) serialized_RSA_server_public_key=RSA_server_public_key.public_bytes(Encoding.PEM, PublicFormat.SubjectPublicKeyInfo) print(\"Setting up server...\") host_ip=args[\"host_ip\"] port=args[\"port\"] socket_address=(host_ip,port) cap_frame_thread=threading.Thread(target=capture_frames, args=(), name='capture_frames', daemon=False) cap_frame_thread.start() threads=[] print(\"LISTENING AT:\",socket_address) loop=asyncio.get_event_loop() loop.create_task(boot_server(host_ip, port)) try: loop.run_forever() except KeyboardInterrupt: print(\"\\nServer is manually shutting down\") stream=False cap_frame_thread.join() finally: print(\"Shutting Down Server\") try: loop.stop() pending=asyncio.all_tasks() for task in pending: task.cancel() with suppress(asyncio.CancelledError): loop.run_until_complete(task) except RuntimeError as e: if e.args[0]=='no running event loop': pass else: raise e ","sourceWithComments":"# Need threading for multiple clients and a way to terminate gracefully\nimport threading\n# Process command line arguments\nimport argparse\n# Stamp the frames with a timestamp\nimport datetime\n# May need for sleep\nimport time\n# Necessary to process images with openCV\nimport numpy as np\nimport pyautogui\nimport imutils\nimport cv2\nfrom PIL import UnidentifiedImageError, Image, ImageFile\nimport os\n# Needed for network communication\nimport socket\nimport pickle\nimport struct\n# Needed to handle non-blocking server socket\nimport select\nimport queue\n# Needed to handle async calls\nimport asyncio\n# For encryption\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.asymmetric import dh, rsa, padding, ec\nfrom cryptography.hazmat.primitives.kdf.hkdf import HKDF\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives.serialization import PublicFormat, Encoding, load_der_public_key, load_pem_public_key, load_pem_private_key\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n# Globals for handling the frames\noutputFrame = None\nlock = threading.Lock()\nstream = True\nread_list = []\nwrite_list = []\nmessage_queues = {}\ndh_keyexchanges = {}\nclient_derived_keys_ivs = {}\np = 0xFFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A637ED6B0BFF5CB6F406B7EDEE386BFB5A899FA5AE9F24117C4B1FE649286651ECE45B3DC2007CB8A163BF0598DA48361C55D39A69163FA8FD24CF5F83655D23DCA3AD961C62F356208552BB9ED529077096966D670C354E4ABC9804F1746C08CA18217C32905E462E36CE3BE39E772C180E86039B2783A2EC07A28FB5C55DF06F4C52C9DE2BCBF6955817183995497CEA956AE515D2261898FA051015728E5A8AACAA68FFFFFFFFFFFFFFFF\ng = 2\nserialized_RSA_server_public_key = None\nRSA_server_private_key = None\ndisable_ecdh = False\nloop = None\n\n# thread that listens for any input, used to terminate stream loop\n# def key_capture_thread(server_socket):\n#     global stream\n#     input()\n#     stream = False\n#     print(\"starting exit process\")\n\ndef capture_frames():\n    global outputFrame, lock, stream, message_queues\n    # threading.Thread(target=key_capture_thread, args=(), name='key_capture_thread', daemon=True).start()\n    try:\n        # while not event.is_set():\n        while stream:\n            ##\n            # im = Image.open('.screenshot2021-0501_20-10-04-094593.png')\n            # im.load()\n            ##\n            # Grab a screenshot\n            frame = pyautogui.screenshot()\n            # Convert it cv2 color format and np array\n            frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n            # Resize so we send consistent amount of data\n            frame = imutils.resize(frame, width=800)\n\n            # Stamp Frame with current time.\n            timestamp = datetime.datetime.now()\n            cv2.putText(frame, timestamp.strftime(\n                \"%A %d %B %Y %I:%M:%S%p\"), (10, frame.shape[0] - 10),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n\n            with lock:\n                outputFrame = frame.copy()\n                # for sq in message_queues:\n                #     serializedFrame = pickle.dumps(outputFrame)\n                #     message = struct.pack(\"Q\",len(serializedFrame))+serializedFrame\n                #     message_queues[s].put(message)\n                # cv2.imshow(\"RECEIVING VIDEO\",outputFrame)\n                # cv2.waitKey()\n\n            time.sleep(0.1)\n            # print(\"captured a screenshot\")\n            # print(stream)\n    except UnidentifiedImageError as e:\n        quoted_filename = e.args[0].split()[4]\n        filename = quoted_filename.strip(\"'\")\n        if os.path.exists(filename):\n            os.remove(filename)\n            print(\"Deleted leftover temp image file\")\n    except OSError as e:\n        if e.errno == 2:\n            # Temp file was not written to disk\n            pass\n        else:\n            raise e\n\n\ndef encrypt(key, plaintext, iv):\n    # Declare cipher type\n    cipher = Cipher(algorithms.AES(key), modes.OFB(iv))\n    encryptor = cipher.encryptor()\n\n    # Encrypt\n    ciphertext = encryptor.update(plaintext) + encryptor.finalize()\n\n    return ciphertext\n\ndef decrypt(key, ciphertext, iv):\n    # Declare cipher type\n    cipher = Cipher(algorithms.AES(key), modes.OFB(iv))\n    decryptor = cipher.decryptor()\n\n    # Decrypt\n    deciphered_text = decryptor.update(ciphertext) + decryptor.finalize()\n\n    return deciphered_text\n\ndef generate_dh_key_pairs():\n    # Hard-coded p and g for DH Key exchange (RFC 3526 - group id 14)\n    global p, g\n\n    # Use our p and g with cryptography library\n    params_numbers = dh.DHParameterNumbers(p,g)\n    parameters = params_numbers.parameters(default_backend())\n\n    # Generate private and public key\n    host_private_key = parameters.generate_private_key()\n    host_public_key_enc= host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo)\n    return (host_private_key, host_public_key_enc)\n\ndef generate_ecdh_key_pairs():\n    host_private_key = ec.generate_private_key(\n        ec.SECP384R1()\n    )\n    host_public_key_enc = host_private_key.public_key().public_bytes(Encoding.DER, PublicFormat.SubjectPublicKeyInfo)\n    return (host_private_key, host_public_key_enc)\n\n# def server_dh_key_exchange(reader, writer, host_private_key, host_public_key_enc):\n#     # Send size of public key and public key to remote\n#     client_socket.send(len(host_public_key_enc).to_bytes(2, \"big\") + host_public_key_enc)\n#     print(\"Sent host's public key to \", caddr, \":\", cport)\n\n#     # Receiving size of remote's public key and remote's public key\n#     size = client_socket.recv(2)\n#     remote_public_key_enc = client_socket.recv(int.from_bytes(size, \"big\"))\n#     print(\"Size of remote's public key: \", int.from_bytes(size, \"big\"))\n#     print(\"Remote's public key:\\n\", remote_public_key_enc)\n\n#     # Decode remote's public key\n#     remote_public_key = load_der_public_key(remote_public_key_enc, default_backend())\n\n#     # Generate shared key\n#     shared_key = host_private_key.exchange(remote_public_key)\n#     return shared_key\n\ndef encrypt_and_send_AES_OFB_message(client_socket, plaintext, key, iv):\n    ciphertext = encrypt(key, plaintext, iv)\n    client_socket.send(len(ciphertext).to_bytes(2, \"big\") + ciphertext)\n\ndef lookupIP(client_socket, public_key):\n    client_socket.send(b'1')\n    client_socket.send(len(public_key).to_bytes(2, \"big\") + public_key)\n    output = client_socket.recv(1024)\n\n    return output\n\ndef registerPublicKey(client_socket, public_key, private_key):\n    client_socket.send(b'0')\n    signed_public_key = sign(private_key, public_key)\n    client_socket.send(len(public_key).to_bytes(2, \"big\") + public_key)\n    client_socket.send(len(signed_public_key).to_bytes(2, \"big\") + signed_public_key)\n    output = client_socket.recv(1024)\n\n    return output\n\ndef sign(private_key, data):\n    signature = private_key.sign(\n        data,\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n\n    return signature\n\ndef verify(public_key, signature, message):\n    # Verify signature\n    public_key.verify(\n        signature,\n        message,\n        padding.PSS(\n            mgf=padding.MGF1(hashes.SHA256()),\n            salt_length=padding.PSS.MAX_LENGTH\n        ),\n        hashes.SHA256()\n    )\n\nasync def new_client(reader, writer):\n    global lock, stream, outputFrame, serialized_RSA_server_public_key, RSA_server_private_key, disable_ecdh, loop\n    try:\n        # if client_socket:\n            # vid = cv2.VideoCapture(0)\n            # global outputFrame, lock\n        ## --------- DH Key EXCHANGE -----------##\n        if disable_ecdh:\n            host_private_key, host_public_key_enc = generate_dh_key_pairs()\n        else:\n            print(\"USING ECDH\")\n            host_private_key, host_public_key_enc = generate_ecdh_key_pairs()\n        data = await reader.read(4)\n        size = None\n        serialized_RSA_client_public_key = None\n        abort = False\n        if data == b\"HELO\":\n            size = await reader.read(2)\n            serialized_RSA_client_public_key = await reader.read(int.from_bytes(size, \"big\"))\n            initial_message = b\"HELO\" + len(serialized_RSA_server_public_key).to_bytes(2, \"big\") + serialized_RSA_server_public_key\n            writer.write(initial_message)\n            await writer.drain()\n        else:\n            abort = True\n        data = await reader.read(5)\n        if data == b\"DHINI\" and not abort:\n            writer.write(len(host_public_key_enc).to_bytes(2, \"big\") + host_public_key_enc)\n            await writer.drain()\n        else:\n            abort = True\n        data = await reader.read(4)\n        if data == b\"PUBK\" and not abort:\n            # The ECDH Key\n            size = await reader.read(2)\n            remote_public_key_enc = await reader.read(int.from_bytes(size, \"big\"))\n            print(\"Size of remote's public key: \", int.from_bytes(size, \"big\"))\n            print(\"Remote's public key:\\n\", remote_public_key_enc)\n            # The message signature\n            size = await reader.read(2)\n            remote_signature = await reader.read(int.from_bytes(size, \"big\"))\n            intended_message = serialized_RSA_server_public_key + serialized_RSA_client_public_key + host_public_key_enc + remote_public_key_enc\n            verify(load_pem_public_key(serialized_RSA_client_public_key), remote_signature, intended_message)\n            print(\"Message Verified\")\n            # The host_signature to prove the intended public key was received\n            host_message = serialized_RSA_server_public_key + remote_public_key_enc\n            with lock:\n                host_signature = sign(RSA_server_private_key, host_message)\n            writer.write(len(host_signature).to_bytes(2, \"big\") + host_signature + b\"DHFIN\")\n            await writer.drain()\n            remote_public_key = load_der_public_key(remote_public_key_enc, default_backend())\n            if disable_ecdh:\n                shared_key = host_private_key.exchange(remote_public_key)\n            else:\n                shared_key = host_private_key.exchange(ec.ECDH(), remote_public_key)\n            derived_key = HKDF(algorithm=hashes.SHA256(),length=32,salt=None,info=b'handshake data',).derive(shared_key)\n            print(\"Derived Key:\\n\", derived_key)\n            derived_iv = HKDF(algorithm=hashes.SHA256(),length=16,salt=None,info=b'aes ofb iv',).derive(shared_key)\n            print(\"Derived IV:\\n\", derived_iv)\n            # client_derived_keys_ivs[s] = (derived_key, derived_iv)\n            ## --------- DH Key EXCHANGE -----------##\n        else:\n            abort = True\n        while stream and not abort:\n            # img,frame = vid.read()\n            data = await reader.read(1024)\n            if data == b'READY':\n                # print(\"got a READY\")\n                with lock:\n                    # print(\"got LOCK\")\n                    serializedFrame = pickle.dumps(outputFrame)\n                    # print(\"serializedFrame\")\n                    # print(serializedFrame[:10])\n                    encr_serializedFrame = encrypt(derived_key, serializedFrame, derived_iv)\n                    # print(\"encr_serializedFrame\")\n                    # print(encr_serializedFrame[:10])\n                    message = struct.pack(\"Q\",len(encr_serializedFrame))+encr_serializedFrame\n                    # print(struct.pack(\"Q\",len(encr_serializedFrame)))\n                    # message = len(serializedFrame).to_bytes(8, \"big\")+serializedFrame\n                    # print(len(serializedFrame).to_bytes(8, \"big\"))\n                # print(\"sending FRAME\")\n                writer.write(message)\n                await writer.drain()\n            elif data == b'LEAVING':\n                break    \n            if outputFrame is not None:\n                pass\n                # # Show the image, debugging\n                # cv2.imshow('SERVER STREAMING VIDEO',outputFrame)\n                # # Way to close the feed, required for imshow to work properly\n                # key = cv2.waitKey(1) & 0xFF\n                # if key ==ord('q') or not stream:\n                #     # client_socket.close()\n                #     break\n    except KeyboardInterrupt as e:\n        print(\"\\nClient Task was canceled\")\n        stream = False\n        loop.stop()\n        # raise e\n    except asyncio.TimeoutError:\n        print('Client Timed out')\n    finally:\n        writer.close()\n\nasync def boot_server(host_ip, port):\n    server = await asyncio.start_server(new_client, port=port, host=host_ip)\n    # async with server:\n    await server.serve_forever()\n\nif __name__ == '__main__':\n    # Handle arguments\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"-i\", \"--host-ip\", type=str, required=False,\n        help=\"ip address to serve on\", default='127.0.0.1')\n    ap.add_argument(\"-p\", \"--port\", type=int, required=False,\n        help=\"port number to listen to\", default=9898)\n    ap.add_argument(\"--pki-host-ip\", type=str, required=False,\n        help=\"ip address of the PKI server to connect to\", default='127.0.0.1')\n    ap.add_argument(\"--pki-port\", type=int, required=False,\n        help=\"PKI port number to connect to\", default=7777)\n    ap.add_argument(\"--rsa-pub-key\", type=str, required=False,\n        help=\"Path to RSA PEM public key\", default='env\/keys\/server\/public-key.pem')\n    ap.add_argument(\"--rsa-priv-key\", type=str, required=False,\n        help=\"Path to RSA PEM private key\", default='env\/keys\/server\/private-key.pem')\n    ap.add_argument(\"--disable-ecdh\", type=bool, required=False,\n        help=\"Disable Elliptic Curve key generation for Diffie-Hellman Key Exchange\", default=False)\n    args = vars(ap.parse_args())\n\n    disable_ecdh = args[\"disable_ecdh\"]\n    RSA_server_public_key = None\n    RSA_server_private_key = None\n    with open(args[\"rsa_pub_key\"], \"rb\") as key_file:\n        RSA_server_public_key = load_pem_public_key(\n            key_file.read()\n        )\n    with open(args[\"rsa_priv_key\"], \"rb\") as key_file:\n        RSA_server_private_key = load_pem_private_key(\n            key_file.read(),\n            password=None,\n        )\n\n    # Serialize keys\n    serialized_RSA_server_public_key = RSA_server_public_key.public_bytes(Encoding.PEM, PublicFormat.SubjectPublicKeyInfo)\n    # ## --------- PKI Register Pub Keys START-----------##\n    # pki_client_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    # pki_host_ip = args[\"pki_host_ip\"]\n    # pki_port = args[\"pki_port\"]\n    # pki_client_socket.connect((pki_host_ip,pki_port))\n    # response = registerPublicKey(pki_client_socket, serialized_RSA_server_public_key, RSA_server_private_key)\n    # print(\"response:\", response)\n    # pki_client_socket.close()\n    # ## --------- PKI Register Pub Keys END  -----------##\n\n    print(\"Setting up server...\")\n    # Socket Create\n    # server_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n    # server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    host_ip = args[\"host_ip\"]\n    port = args[\"port\"]\n    socket_address = (host_ip,port)\n\n    # Socket Bind\n    # server_socket.bind(socket_address)\n\n    # Socket Listen\n    # server_socket.listen(5)\n    # server_socket.setblocking(False)\n\n    \n    # event = threading.Event()\n    # threading.Thread(target=key_capture_thread, args=(server_socket,), name='key_capture_thread', daemon=True).start()\n    cap_frame_thread = threading.Thread(target=capture_frames, args=(), name='capture_frames', daemon=False)\n    cap_frame_thread.start()\n    threads = []\n    \n    print(\"LISTENING AT:\",socket_address)\n    loop = asyncio.get_event_loop()\n    loop.create_task(boot_server(host_ip, port))\n    try:\n        loop.run_forever()\n        # event.wait()\n    except KeyboardInterrupt:\n        print(\"\\nServer is manually shutting down\")\n        stream = False\n        cap_frame_thread.join()\n        # event.set()\n    finally:\n        print(\"Shutting Down Server\")\n        # try:\n        #     loop.stop()\n        #     loop.run_until_complete(loop.shutdown_asyncgens())\n        # try:\n        #     # loop.stop()\n        #     pending = asyncio.all_tasks()\n        #     for task in penging:\n        #         task.cancel()\n        #         with suppress(asyncio.CancelledError):\n        #             loop.run_until_complete(task)\n        #     # loop.stop()\n        #     # loop.run_until_complete(loop.shutdown_asyncgens())\n        # try:\n        #     loop.stop()\n        #     pending = asyncio.all_tasks()\n        #     loop.run_until_complete(asyncio.gather(*pending))\n        try:\n            loop.stop()\n            pending = asyncio.all_tasks()\n            for task in pending:\n                task.cancel()\n                with suppress(asyncio.CancelledError):\n                    loop.run_until_complete(task)\n            # loop.run_until_complete(asyncio.gather(*pending))\n        except RuntimeError as e:\n            if e.args[0] == 'no running event loop':\n                pass\n            else:\n                raise e\n"}},"msg":"Add hmac tagging for messages, and session and ccomponent IDs to prevent replay attacks and provide integrity. Added verification checks for client."}},"https:\/\/github.com\/adieu\/python-openid":{"f05703e45f3ef162c4d927dc712b95cbac163bb4":{"url":"https:\/\/api.github.com\/repos\/adieu\/python-openid\/commits\/f05703e45f3ef162c4d927dc712b95cbac163bb4","html_url":"https:\/\/github.com\/adieu\/python-openid\/commit\/f05703e45f3ef162c4d927dc712b95cbac163bb4","message":"[project @ Added nonce to return_to to fix replay attack vulnerability]","sha":"f05703e45f3ef162c4d927dc712b95cbac163bb4","keyword":"replay attack vulnerable","diff":"diff --git a\/openid\/consumer\/consumer.py b\/openid\/consumer\/consumer.py\nindex b7a93bc..49f5663 100644\n--- a\/openid\/consumer\/consumer.py\n+++ b\/openid\/consumer\/consumer.py\n@@ -173,6 +173,7 @@\n import string\n import time\n import urllib\n+import cgi\n from urlparse import urlparse\n \n from urljr import fetchers\n@@ -279,13 +280,14 @@ class and its sublcasses.  For a filesystem-backed store,\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n@@ -295,9 +297,9 @@ def complete(self, query, token):\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n@@ -314,16 +316,39 @@ def complete(self, query, token):\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n@@ -466,9 +491,9 @@ def _getAssociation(self, server_url):\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n@@ -484,7 +509,7 @@ def _splitToken(self, token):\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n@@ -567,7 +592,7 @@ def _parseAssociation(self, results, dh, server_url):\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n@@ -579,6 +604,7 @@ def __init__(self, token, assoc, endpoint):\n         self.assoc = assoc\n         self.endpoint = endpoint\n         self.extra_args = {}\n+        self.return_to_args = {}\n         self.token = token\n \n     def addExtensionArg(self, namespace, key, value):\n@@ -591,6 +617,8 @@ def redirectURL(self, trust_root, return_to, immediate=False):\n         else:\n             mode = 'checkid_setup'\n \n+        return_to = oidutil.appendArgs(return_to, self.return_to_args)\n+\n         redir_args = {\n             'openid.mode': mode,\n             'openid.identity': self.endpoint.getServerID(),\n@@ -634,6 +662,9 @@ def extensionResponse(self, prefix):\n \n         return response\n \n+    def getReturnTo(self):\n+        return self.signed_args['openid.return_to']\n+\n class FailureResponse(OpenIDConsumerResponse):\n     status = 'failure'\n \ndiff --git a\/test\/consumer.py b\/test\/consumer.py\nindex 343c7a1..1b8fbe7 100644\n--- a\/test\/consumer.py\n+++ b\/test\/consumer.py\n@@ -119,19 +119,22 @@ def run():\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n@@ -140,7 +143,7 @@ def run():\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","files":{"\/openid\/consumer\/consumer.py":{"changes":[{"diff":"\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n","add":3,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            nonce,","        return OpenIDAuthRequest(token, assoc, service_endpoint)"],"goodparts":["        request = OpenIDAuthRequest(token, assoc, service_endpoint)","        request.return_to_args['nonce'] = nonce","        return request"]},{"diff":"\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            pieces = (None, None, None, None, None)","        (nonce, identity_url, delegate, server_url) = pieces"],"goodparts":["            pieces = (None, None, None)","        (identity_url, delegate, server_url) = pieces"]},{"diff":"\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n","add":27,"remove":4,"filename":"\/openid\/consumer\/consumer.py","badparts":["                if (response.status == 'success' and","                    not self.store.useNonce(nonce)):","                    return FailureResponse(identity_url, 'Nonce already used')"],"goodparts":["                if response.status == 'success':","                    return self._checkNonce(response, query.get('nonce'))","    def _checkNonce(self, response, nonce):","        parsed_url = urlparse(response.getReturnTo())","        query = parsed_url[4]","        for k, v in cgi.parse_qsl(query):","            if k == 'nonce':","                if v != nonce:","                    return FailureResponse(response.identity_url,","                                           'Nonce mismatch')","                else:","                    break","        else:","            return FailureResponse(response.identity_url,","                                   'Nonce missing from return_to: %r'","                                   % (response.getReturnTo()))","        if not self.store.useNonce(nonce):","            return FailureResponse(response.identity_url,","                                   'Nonce missing from store')","        return response"]},{"diff":"\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def _genToken(self, nonce, consumer_id, server_id, server_url):","        elements = [timestamp, nonce, consumer_id, server_id, server_url]"],"goodparts":["    def _genToken(self, consumer_id, server_id, server_url):","        elements = [timestamp, consumer_id, server_id, server_url]"]},{"diff":"\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["        if len(split) != 5:"],"goodparts":["        if len(split) != 4:"]},{"diff":"\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def __init__(self, token, assoc, endpoint):"],"goodparts":["    def __init__(self, token, assoc, endpoint  ):"]}],"source":"\n\"\"\" This module documents the main interface with the OpenID consumer libary. The only part of the library which has to be used and isn't documented in full here is the store required to create an C{L{OpenIDConsumer}} instance. More on the abstract store type and concrete implementations of it that are provided in the documentation for the C{L{__init__<OpenIDConsumer.__init__>}} method of the C{L{OpenIDConsumer}} class. OVERVIEW ======== The OpenID identity verification process most commonly uses the following steps, as visible to the user of this library: 1. The user enters their OpenID into a field on the consumer's site, and hits a login button. 2. The consumer site discovers the user's OpenID server using the YADIS protocol. 3. The consumer site sends the browser a redirect to the identity server. This is the authentication request as described in the OpenID specification. 4. The identity server's site sends the browser a redirect back to the consumer site. This redirect contains the server's response to the authentication request. The most important part of the flow to note is the consumer's site must handle two separate HTTP requests in order to perform the full identity check. LIBRARY DESIGN ============== This consumer library is designed with that flow in mind. The goal is to make it as easy as possible to perform the above steps securely. At a high level, there are two important parts in the consumer library. The first important part is this module, which contains the interface to actually use this library. The second is the C{L{openid.store.interface}} module, which describes the interface to use if you need to create a custom method for storing the state this library needs to maintain between requests. In general, the second part is less important for users of the library to know about, as several implementations are provided which cover a wide variety of situations in which consumers may use the library. This module contains a class, C{L{OpenIDConsumer}}, with methods corresponding to the actions necessary in each of steps 2, 3, and 4 described in the overview. Use of this library should be as easy as creating an C{L{OpenIDConsumer}} instance and calling the methods appropriate for the action the site wants to take. STORES AND DUMB MODE ==================== OpenID is a protocol that works best when the consumer site is able to store some state. This is the normal mode of operation for the protocol, and is sometimes referred to as smart mode. There is also a fallback mode, known as dumb mode, which is available when the consumer site is not able to store state. This mode should be avoided when possible, as it leaves the implementation more vulnerable to replay attacks. The mode the library works in for normal operation is determined by the store that it is given. The store is an abstraction that handles the data that the consumer needs to manage between http requests in order to operate efficiently and securely. Several store implementation are provided, and the interface is fully documented so that custom stores can be used as well. See the documentation for the C{L{OpenIDConsumer}} class for more information on the interface for stores. The implementations that are provided allow the consumer site to store the necessary data in several different ways, including several SQL databases and normal files on disk. There is an additional concrete store provided that puts the system in dumb mode. This is not recommended, as it removes the library's ability to stop replay attacks reliably. It still uses time-based checking to make replay attacks only possible within a small window, but they remain possible within that window. This store should only be used if the consumer site has no way to retain data between requests at all. IMMEDIATE MODE ============== In the flow described above, the user may need to confirm to the identity server that it's ok to authorize his or her identity. The server may draw pages asking for information from the user before it redirects the browser back to the consumer's site. This is generally transparent to the consumer site, so it is typically ignored as an implementation detail. There can be times, however, where the consumer site wants to get a response immediately. When this is the case, the consumer can put the library in immediate mode. In immediate mode, there is an extra response possible from the server, which is essentially the server reporting that it doesn't have enough information to answer the question yet. In addition to saying that, the identity server provides a URL to which the user can be sent to provide the needed information and let the server finish handling the original request. USING THIS LIBRARY ================== Integrating this library into an application is usually a relatively straightforward process. The process should basically follow this plan: Add an OpenID login field somewhere on your site. When an OpenID is entered in that field and the form is submitted, it should make a request to the your site which includes that OpenID URL. To start, the application should get an C{L{OpenIDConsumer}} instance, and call its C{L{begin<OpenIDConsumer.begin>}} method. This method takes the OpenID URL and, optionally, a session object. If the application has any sort of session framework that provides per-client state management, that should be used here. The library just expects the session object to support a C{dict}-like interface, if it provided. If no session object is provided, the application code needs to store the information that would have been put in the session in an alternate location. See the documentation for the C{L{begin<OpenIDConsumer.begin>}} call for more information. The C{L{begin<OpenIDConsumer.begin>}} method returns an C{L{OpenIDRequestBuilder}} object. Next, the application should call the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on the C{L{OpenIDRequestBuilder}} object. The return_to URL is the URL that the OpenID server will send the user back to after attempting to verify his or her identity. The trust_root is the URL(or URL pattern) that identifies your web site to the user when he or she is authorizing it. Send a redirect to the resulting URL to the user's browser. That's the first half of the authentication process. The second half of the process is done after the user's ID server sends the user's browser a redirect back to your site to complete their login. When that happens, the user will contact your site at the URL given as the C{return_to} URL to the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made above. The request will have several query parameters added to the URL by the identity server as the information necessary to finish the request. Get an C{L{OpenIDConsumer}} instance, and call its C{L{complete<OpenIDConsumer.complete>}} method, passing in all the received query arguments and either the user's session object or the token saved earlier. See the documentation for C{L{OpenIDRequestBuilder}} for more information about the token. There are multiple possible return types possible from that method. These indicate the whether or not the login was successful, and include any additional information appropriate for their type. \"\"\" import string import time import urllib from urlparse import urlparse from urljr import fetchers from openid.consumer.discover import discover as openIDDiscover from openid.consumer.discover import yadis_available from openid import cryptutil from openid import kvform from openid import oidutil from openid.association import Association from openid.dh import DiffieHellman __all__=['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse', 'SetupNeededResponse', 'CancelResponse', 'FailureResponse'] if yadis_available: from yadis.manager import Discovery class OpenIDConsumer(object): session_key_prefix=\"_openid_consumer_\" _token='last_token' def __init__(self, session, store): self.session=session self.consumer=GenericOpenIDConsumer(store) self._token_key=self.session_key_prefix +self._token def begin(self, user_url): openid_url=oidutil.normalizeUrl(user_url) if yadis_available: disco=Discovery(self.session, openid_url, 'XXX') endpoint=disco.getNextService(openIDDiscover) else: _, endpoints=openIDDiscover(openid_url) if not endpoints: endpoint=None else: endpoint=endpoints[0] if endpoint is None: return None else: return self.beginWithoutDiscovery(endpoint) def beginWithoutDiscovery(self, endpoint): auth_req=self.consumer.begin(endpoint) self.session[self._token_key]=auth_req.token return auth_req def complete(self, query): token=self.session.get(self._token_key) if token is None: response=FailureResponse(None, 'No session state found') else: response=self.consumer.complete(query, token) if response.status in['success', 'cancel' ]: if yadis_available and response.identity_url is not None: disco=Discovery(self.session, response.identity_url) disco.cleanup() return response class GenericOpenIDConsumer(object): \"\"\"This is the implementation of the common logic for OpenID consumers. It is unaware of the application in which it is running. \"\"\" TOKEN_LIFETIME=60 * 5 NONCE_LEN=8 NONCE_CHRS=string.letters +string.digits def __init__(self, store): \"\"\" This method initializes a new C{L{OpenIDConsumer}} instance to access the library. @param store: This must be an object that implements the interface in C{L{openid.store.interface.OpenIDStore}}. Several concrete implementations are provided, to cover most common use cases. For stores backed by MySQL or SQLite, see the C{L{openid.store.sqlstore.SQLStore}} class and its sublcasses. For a filesystem-backed store, see the C{L{openid.store.filestore}} module. As a last resort, if it isn't possible for the server to store state at all, an instance of C{L{openid.store.dumbstore.DumbStore}} can be used. This should be an absolute last resort, though, as it makes the consumer vulnerable to replay attacks over the lifespan of the tokens the library creates. @type store: C{L{openid.store.interface.OpenIDStore}} \"\"\" self.store=store def begin(self, service_endpoint): nonce=self._createNonce() token=self._genToken( nonce, service_endpoint.identity_url, service_endpoint.getServerID(), service_endpoint.server_url, ) assoc=self._getAssociation(service_endpoint.server_url) return OpenIDAuthRequest(token, assoc, service_endpoint) def complete(self, query, token): mode=query.get('openid.mode', '<no mode specified>') try: pieces=self._splitToken(token) except ValueError, why: oidutil.log(why[0]) pieces=(None, None, None, None, None) (nonce, identity_url, delegate, server_url)=pieces if mode=='cancel': return CancelResponse(identity_url) elif mode=='error': error=query.get('openid.error') return FailureResponse(identity_url, error) elif mode=='id_res': if identity_url is None: return FailureResponse(identity_url, 'No session state found') try: response=self._doIdRes( query, identity_url, delegate, server_url) except fetchers.HTTPFetchingError, why: message='HTTP request failed: %s' %(str(why),) return FailureResponse(identity_url, message) else: if(response.status=='success' and not self.store.useNonce(nonce)): return FailureResponse(identity_url, 'Nonce already used') else: return response else: return FailureResponse(identity_url, 'Invalid openid.mode: %r' %(mode,)) def _createNonce(self): nonce=cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS) self.store.storeNonce(nonce) return nonce def _makeKVPost(self, args, server_url): mode=args['openid.mode'] body=urllib.urlencode(args) resp=fetchers.fetch(server_url, body=body) if resp is None: fmt='openid.mode=%s: failed to fetch URL: %s' oidutil.log(fmt %(mode, server_url)) return None response=kvform.kvToDict(resp.body) if resp.status==400: server_error=response.get('error', '<no message from server>') fmt='openid.mode=%s: error returned from server %s: %s' oidutil.log(fmt %(mode, server_url, server_error)) return None elif resp.status !=200: fmt='openid.mode=%s: bad status code from server %s: %s' oidutil.log(fmt %(mode, server_url, resp.status)) return None return response def _doIdRes(self, query, consumer_id, server_id, server_url): user_setup_url=query.get('openid.user_setup_url') if user_setup_url is not None: return SetupNeededResponse(consumer_id, user_setup_url) return_to=query.get('openid.return_to') server_id2=query.get('openid.identity') assoc_handle=query.get('openid.assoc_handle') if return_to is None or server_id is None or assoc_handle is None: return FailureResponse(consumer_id, 'Missing required field') if server_id !=server_id2: return FailureResponse(consumer_id, 'Server ID(delegate) mismatch') signed=query.get('openid.signed') assoc=self.store.getAssociation(server_url, assoc_handle) if assoc is None: if self._checkAuth(query, server_url): return SuccessResponse.fromQuery(consumer_id, query, signed) else: return FailureResponse(consumer_id, 'Server denied check_authentication') if assoc.expiresIn <=0: msg='Association with %s expired' %(server_url,) return FailureResponse(consumer_id, msg) sig=query.get('openid.sig') if sig is None or signed is None: return FailureResponse(consumer_id, 'Missing argument signature') signed_list=signed.split(',') v_sig=assoc.signDict(signed_list, query) if v_sig !=sig: return FailureResponse(consumer_id, 'Bad signature') return SuccessResponse.fromQuery(consumer_id, query, signed) def _checkAuth(self, query, server_url): request=self._createCheckAuthRequest(query) if request is None: return False response=self._makeKVPost(request, server_url) if response is None: return False return self._processCheckAuthResponse(response) def _createCheckAuthRequest(self, query): signed=query.get('openid.signed') if signed is None: oidutil.log('No signature present; checkAuth aborted') return None whitelist=['assoc_handle', 'sig', 'signed', 'invalidate_handle'] signed=signed.split(',') +whitelist check_args=dict([(k, v) for k, v in query.iteritems() if k.startswith('openid.') and k[7:] in signed]) check_args['openid.mode']='check_authentication' return check_args def _processCheckAuthResponse(self, response): is_valid=response.get('is_valid', 'false') if is_valid=='true': invalidate_handle=response.get('invalidate_handle') if invalidate_handle is not None: self.store.removeAssociation(server_url, invalidate_handle) return True oidutil.log('Server responds that checkAuth call is not valid') return False def _getAssociation(self, server_url): if self.store.isDumb(): return None assoc=self.store.getAssociation(server_url) if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME: proto=urlparse(server_url)[0] if proto=='https': dh=None else: dh=DiffieHellman() args=self._createAssociateRequest(dh) try: response=self._makeKVPost(args, server_url) except fetchers.HTTPFetchingError, why: oidutil.log('openid.associate request failed: %s' % (str(why),)) assoc=None else: assoc=self._parseAssociation(response, dh, server_url) return assoc def _genToken(self, nonce, consumer_id, server_id, server_url): timestamp=str(int(time.time())) elements=[timestamp, nonce, consumer_id, server_id, server_url] joined='\\x00'.join(elements) sig=cryptutil.hmacSha1(self.store.getAuthKey(), joined) return oidutil.toBase64('%s%s' %(sig, joined)) def _splitToken(self, token): token=oidutil.fromBase64(token) if len(token) < 20: raise ValueError('Bad token length: %d' % len(token)) sig, joined=token[:20], token[20:] if cryptutil.hmacSha1(self.store.getAuthKey(), joined) !=sig: raise ValueError('Bad token signature') split=joined.split('\\x00') if len(split) !=5: raise ValueError('Bad token contents(not enough fields)') try: ts=int(split[0]) except ValueError: raise ValueError('Bad token contents(timestamp bad)') if ts +self.TOKEN_LIFETIME < time.time(): raise ValueError('Token expired') return tuple(split[1:]) def _createAssociateRequest(self, dh=None, args=None): if args is None: args={} args.update({ 'openid.mode': 'associate', 'openid.assoc_type':'HMAC-SHA1', }) if dh: cpub=cryptutil.longToBase64(dh.public) args.update({ 'openid.session_type':'DH-SHA1', 'openid.dh_consumer_public': cpub, }) if not dh.usingDefaultValues(): args.update({ 'openid.dh_modulus': cryptutil.longToBase64(dh.modulus), 'openid.dh_gen': cryptutil.longToBase64(dh.generator), }) return args def _parseAssociation(self, results, dh, server_url): try: assoc_type=results['assoc_type'] if assoc_type !='HMAC-SHA1': fmt='Unsupported assoc_type returned from server %s: %s' oidutil.log(fmt %(server_url, assoc_type)) return None assoc_handle=results['assoc_handle'] try: expires_in=int(results.get('expires_in', '0')) except ValueError, e: fmt='Getting Association: invalid expires_in field: %s' oidutil.log(fmt %(e[0],)) return None session_type=results.get('session_type') if session_type is None: secret=oidutil.fromBase64(results['mac_key']) else: if session_type !='DH-SHA1': fmt='Unsupported session_type from server %s: %s' oidutil.log(fmt %(server_url, session_type)) return None if dh is None: fmt='Not expecting a DH-SHA1 session from server %s' oidutil.log(fmt %(server_url)) return None spub=cryptutil.base64ToLong(results['dh_server_public']) enc_mac_key=oidutil.fromBase64(results['enc_mac_key']) secret=dh.xorSecret(spub, enc_mac_key) assoc=Association.fromExpiresIn( expires_in, assoc_handle, secret, assoc_type) self.store.storeAssociation(server_url, assoc) return assoc except KeyError, e: fmt='Getting association: missing key in response from %s: %s' oidutil.log(fmt %(server_url, e[0])) return None class OpenIDAuthRequest(object): def __init__(self, token, assoc, endpoint): \"\"\" Creates a new OpenIDAuthRequest object. This just stores each argument in an appropriately named field. Users of this library should not create instances of this class. Instances of this class are created by the library when needed. \"\"\" self.assoc=assoc self.endpoint=endpoint self.extra_args={} self.token=token def addExtensionArg(self, namespace, key, value): arg_name='.'.join('openid', namespace, key) self.extra_args[arg_name]=value def redirectURL(self, trust_root, return_to, immediate=False): if immediate: mode='checkid_immediate' else: mode='checkid_setup' redir_args={ 'openid.mode': mode, 'openid.identity': self.endpoint.getServerID(), 'openid.return_to': return_to, 'openid.trust_root': trust_root, } if self.assoc: redir_args['openid.assoc_handle']=self.assoc.handle redir_args.update(self.extra_args) return oidutil.appendArgs(self.endpoint.server_url, redir_args) class OpenIDConsumerResponse(object): status=None class SuccessResponse(OpenIDConsumerResponse): status='success' def __init__(self, identity_url, signed_args): self.identity_url=identity_url self.signed_args=signed_args def fromQuery(cls, identity_url, query, signed): signed_args={} for field_name in signed.split(','): field_name='openid.' +field_name signed_args[field_name]=query.get(field_name, '') return cls(identity_url, signed_args) fromQuery=classmethod(fromQuery) def extensionResponse(self, prefix): response={} prefix='openid.%s.' %(prefix,) prefix_len=len(prefix) for k, v in self.signed_args.iteritems(): if k.startswith(prefix): response_key=k[prefix_len:] response[response_key]=v return response class FailureResponse(OpenIDConsumerResponse): status='failure' def __init__(self, identity_url=None, message=None): self.identity_url=identity_url self.message=message class CancelResponse(OpenIDConsumerResponse): status='cancelled' def __init__(self, identity_url=None): self.identity_url=identity_url class SetupNeededResponse(OpenIDConsumerResponse): status='setup_needed' def __init__(self, identity_url=None, setup_url=None): self.identity_url=identity_url self.setup_url=setup_url ","sourceWithComments":"\"\"\"\nThis module documents the main interface with the OpenID consumer\nlibary.  The only part of the library which has to be used and isn't\ndocumented in full here is the store required to create an\nC{L{OpenIDConsumer}} instance.  More on the abstract store type and\nconcrete implementations of it that are provided in the documentation\nfor the C{L{__init__<OpenIDConsumer.__init__>}} method of the\nC{L{OpenIDConsumer}} class.\n\n\nOVERVIEW\n========\n\n    The OpenID identity verification process most commonly uses the\n    following steps, as visible to the user of this library:\n\n        1. The user enters their OpenID into a field on the consumer's\n           site, and hits a login button.\n\n        2. The consumer site discovers the user's OpenID server using\n           the YADIS protocol.\n\n        3. The consumer site sends the browser a redirect to the\n           identity server.  This is the authentication request as\n           described in the OpenID specification.\n\n        4. The identity server's site sends the browser a redirect\n           back to the consumer site.  This redirect contains the\n           server's response to the authentication request.\n\n    The most important part of the flow to note is the consumer's site\n    must handle two separate HTTP requests in order to perform the\n    full identity check.\n\n\nLIBRARY DESIGN\n==============\n\n    This consumer library is designed with that flow in mind.  The\n    goal is to make it as easy as possible to perform the above steps\n    securely.\n\n    At a high level, there are two important parts in the consumer\n    library.  The first important part is this module, which contains\n    the interface to actually use this library.  The second is the\n    C{L{openid.store.interface}} module, which describes the\n    interface to use if you need to create a custom method for storing\n    the state this library needs to maintain between requests.\n\n    In general, the second part is less important for users of the\n    library to know about, as several implementations are provided\n    which cover a wide variety of situations in which consumers may\n    use the library.\n\n    This module contains a class, C{L{OpenIDConsumer}}, with methods\n    corresponding to the actions necessary in each of steps 2, 3, and\n    4 described in the overview.  Use of this library should be as easy\n    as creating an C{L{OpenIDConsumer}} instance and calling the methods\n    appropriate for the action the site wants to take.\n\n\nSTORES AND DUMB MODE\n====================\n\n    OpenID is a protocol that works best when the consumer site is\n    able to store some state.  This is the normal mode of operation\n    for the protocol, and is sometimes referred to as smart mode.\n    There is also a fallback mode, known as dumb mode, which is\n    available when the consumer site is not able to store state.  This\n    mode should be avoided when possible, as it leaves the\n    implementation more vulnerable to replay attacks.\n\n    The mode the library works in for normal operation is determined\n    by the store that it is given.  The store is an abstraction that\n    handles the data that the consumer needs to manage between http\n    requests in order to operate efficiently and securely.\n\n    Several store implementation are provided, and the interface is\n    fully documented so that custom stores can be used as well.  See\n    the documentation for the C{L{OpenIDConsumer}} class for more\n    information on the interface for stores.  The implementations that\n    are provided allow the consumer site to store the necessary data\n    in several different ways, including several SQL databases and\n    normal files on disk.\n\n    There is an additional concrete store provided that puts the\n    system in dumb mode.  This is not recommended, as it removes the\n    library's ability to stop replay attacks reliably.  It still uses\n    time-based checking to make replay attacks only possible within a\n    small window, but they remain possible within that window.  This\n    store should only be used if the consumer site has no way to\n    retain data between requests at all.\n\n\nIMMEDIATE MODE\n==============\n\n    In the flow described above, the user may need to confirm to the\n    identity server that it's ok to authorize his or her identity.\n    The server may draw pages asking for information from the user\n    before it redirects the browser back to the consumer's site.  This\n    is generally transparent to the consumer site, so it is typically\n    ignored as an implementation detail.\n\n    There can be times, however, where the consumer site wants to get\n    a response immediately.  When this is the case, the consumer can\n    put the library in immediate mode.  In immediate mode, there is an\n    extra response possible from the server, which is essentially the\n    server reporting that it doesn't have enough information to answer\n    the question yet.  In addition to saying that, the identity server\n    provides a URL to which the user can be sent to provide the needed\n    information and let the server finish handling the original\n    request.\n\n\nUSING THIS LIBRARY\n==================\n\n    Integrating this library into an application is usually a\n    relatively straightforward process.  The process should basically\n    follow this plan:\n\n    Add an OpenID login field somewhere on your site.  When an OpenID\n    is entered in that field and the form is submitted, it should make\n    a request to the your site which includes that OpenID URL.\n\n    To start, the application should get an C{L{OpenIDConsumer}}\n    instance, and call its C{L{begin<OpenIDConsumer.begin>}} method.\n    This method takes the OpenID URL and, optionally, a session\n    object.  If the application has any sort of session framework that\n    provides per-client state management, that should be used here.\n    The library just expects the session object to support a\n    C{dict}-like interface, if it provided.  If no session object is\n    provided, the application code needs to store the information that\n    would have been put in the session in an alternate location.  See\n    the documentation for the C{L{begin<OpenIDConsumer.begin>}} call\n    for more information.  The C{L{begin<OpenIDConsumer.begin>}}\n    method returns an C{L{OpenIDRequestBuilder}} object.\n\n    Next, the application should call the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on\n    the C{L{OpenIDRequestBuilder}} object.  The return_to URL is the\n    URL that the OpenID server will send the user back to after\n    attempting to verify his or her identity.  The trust_root is the\n    URL (or URL pattern) that identifies your web site to the user\n    when he or she is authorizing it.  Send a redirect to the\n    resulting URL to the user's browser.\n\n    That's the first half of the authentication process.  The second\n    half of the process is done after the user's ID server sends the\n    user's browser a redirect back to your site to complete their\n    login.\n\n    When that happens, the user will contact your site at the URL\n    given as the C{return_to} URL to the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made\n    above.  The request will have several query parameters added to\n    the URL by the identity server as the information necessary to\n    finish the request.\n\n    Get an C{L{OpenIDConsumer}} instance, and call its\n    C{L{complete<OpenIDConsumer.complete>}} method, passing in all the\n    received query arguments and either the user's session object or\n    the token saved earlier.  See the documentation for\n    C{L{OpenIDRequestBuilder}} for more information about the token.\n\n    There are multiple possible return types possible from that\n    method.  These indicate the whether or not the login was\n    successful, and include any additional information appropriate for\n    their type.\n\"\"\"\n\nimport string\nimport time\nimport urllib\nfrom urlparse import urlparse\n\nfrom urljr import fetchers\n\nfrom openid.consumer.discover import discover as openIDDiscover\nfrom openid.consumer.discover import yadis_available\nfrom openid import cryptutil\nfrom openid import kvform\nfrom openid import oidutil\nfrom openid.association import Association\nfrom openid.dh import DiffieHellman\n\n__all__ = ['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse',\n           'SetupNeededResponse', 'CancelResponse', 'FailureResponse']\n\nif yadis_available:\n    from yadis.manager import Discovery\n\nclass OpenIDConsumer(object):\n    session_key_prefix = \"_openid_consumer_\"\n\n    _token = 'last_token'\n\n    def __init__(self, session, store):\n        self.session = session\n        self.consumer = GenericOpenIDConsumer(store)\n        self._token_key = self.session_key_prefix + self._token\n\n    def begin(self, user_url):\n        openid_url = oidutil.normalizeUrl(user_url)\n        if yadis_available:\n            disco = Discovery(self.session, openid_url, 'XXX')\n            endpoint = disco.getNextService(openIDDiscover)\n        else:\n            _, endpoints = openIDDiscover(openid_url)\n            if not endpoints:\n                endpoint = None\n            else:\n                endpoint = endpoints[0]\n\n        if endpoint is None:\n            return None\n        else:\n            return self.beginWithoutDiscovery(endpoint)\n\n    def beginWithoutDiscovery(self, endpoint):\n        auth_req = self.consumer.begin(endpoint)\n        self.session[self._token_key] = auth_req.token\n        return auth_req\n\n    def complete(self, query):\n        token = self.session.get(self._token_key)\n        if token is None:\n            response = FailureResponse(None, 'No session state found')\n        else:\n            response = self.consumer.complete(query, token)\n\n        if response.status in ['success',\n                               'cancel'#maybe\n                               ]:\n            if yadis_available and response.identity_url is not None:\n                disco = Discovery(self.session, response.identity_url)\n                # This is OK to do even if we did not do discovery in\n                # the first place.\n                disco.cleanup()\n\n        return response\n\nclass GenericOpenIDConsumer(object):\n    \"\"\"This is the implementation of the common logic for OpenID\n    consumers. It is unaware of the application in which it is\n    running.\n    \"\"\"\n\n    TOKEN_LIFETIME = 60 * 5 # five minutes\n    NONCE_LEN = 8\n    NONCE_CHRS = string.letters + string.digits\n\n    def __init__(self, store):\n        \"\"\"\n        This method initializes a new C{L{OpenIDConsumer}} instance to\n        access the library.\n\n        @param store: This must be an object that implements the\n            interface in C{L{openid.store.interface.OpenIDStore}}.\n            Several concrete implementations are provided, to cover\n            most common use cases.  For stores backed by MySQL or\n            SQLite, see the C{L{openid.store.sqlstore.SQLStore}}\n            class and its sublcasses.  For a filesystem-backed store,\n            see the C{L{openid.store.filestore}} module.\n\n            As a last resort, if it isn't possible for the server to\n            store state at all, an instance of\n            C{L{openid.store.dumbstore.DumbStore}} can be used.  This\n            should be an absolute last resort, though, as it makes the\n            consumer vulnerable to replay attacks over the lifespan of\n            the tokens the library creates.\n\n        @type store: C{L{openid.store.interface.OpenIDStore}}\n\n        \"\"\"\n        self.store = store\n\n    def begin(self, service_endpoint):\n        nonce = self._createNonce()\n        token = self._genToken(\n            nonce,\n            service_endpoint.identity_url,\n            service_endpoint.getServerID(),\n            service_endpoint.server_url,\n            )\n        assoc = self._getAssociation(service_endpoint.server_url)\n        return OpenIDAuthRequest(token, assoc, service_endpoint)\n\n    def complete(self, query, token):\n        mode = query.get('openid.mode', '<no mode specified>')\n\n        # Get the current request's state\n        try:\n            pieces = self._splitToken(token)\n        except ValueError, why:\n            oidutil.log(why[0])\n            pieces = (None, None, None, None, None)\n\n        (nonce, identity_url, delegate, server_url) = pieces\n\n        if mode == 'cancel':\n            return CancelResponse(identity_url)\n        elif mode == 'error':\n            error = query.get('openid.error')\n            return FailureResponse(identity_url, error)\n        elif mode == 'id_res':\n            if identity_url is None:\n                return FailureResponse(identity_url, 'No session state found')\n            try:\n                response = self._doIdRes(\n                    query, identity_url, delegate, server_url)\n            except fetchers.HTTPFetchingError, why:\n                message = 'HTTP request failed: %s' % (str(why),)\n                return FailureResponse(identity_url, message)\n            else:\n                if (response.status == 'success' and\n                    not self.store.useNonce(nonce)):\n\n                    return FailureResponse(identity_url, 'Nonce already used')\n                else:\n                    return response\n        else:\n            return FailureResponse(identity_url,\n                                   'Invalid openid.mode: %r' % (mode,))\n\n    def _createNonce(self):\n        nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n        self.store.storeNonce(nonce)\n        return nonce\n\n    def _makeKVPost(self, args, server_url):\n        mode = args['openid.mode']\n        body = urllib.urlencode(args)\n\n        resp = fetchers.fetch(server_url, body=body)\n        if resp is None:\n            fmt = 'openid.mode=%s: failed to fetch URL: %s'\n            oidutil.log(fmt % (mode, server_url))\n            return None\n\n        response = kvform.kvToDict(resp.body)\n        if resp.status == 400:\n            server_error = response.get('error', '<no message from server>')\n            fmt = 'openid.mode=%s: error returned from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, server_error))\n            return None\n        elif resp.status != 200:\n            fmt = 'openid.mode=%s: bad status code from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, resp.status))\n            return None\n\n        return response\n\n    def _doIdRes(self, query, consumer_id, server_id, server_url):\n        user_setup_url = query.get('openid.user_setup_url')\n        if user_setup_url is not None:\n            return SetupNeededResponse(consumer_id, user_setup_url)\n\n        return_to = query.get('openid.return_to')\n        server_id2 = query.get('openid.identity')\n        assoc_handle = query.get('openid.assoc_handle')\n\n        if return_to is None or server_id is None or assoc_handle is None:\n            return FailureResponse(consumer_id, 'Missing required field')\n\n        if server_id != server_id2:\n            return FailureResponse(consumer_id, 'Server ID (delegate) mismatch')\n\n        signed = query.get('openid.signed')\n\n        assoc = self.store.getAssociation(server_url, assoc_handle)\n\n        if assoc is None:\n            # It's not an association we know about.  Dumb mode is our\n            # only possible path for recovery.\n            if self._checkAuth(query, server_url):\n                return SuccessResponse.fromQuery(consumer_id, query, signed)\n            else:\n                return FailureResponse(consumer_id,\n                                       'Server denied check_authentication')\n\n        if assoc.expiresIn <= 0:\n            # XXX: It might be a good idea sometimes to re-start the\n            # authentication with a new association. Doing it\n            # automatically opens the possibility for\n            # denial-of-service by a server that just returns expired\n            # associations (or really short-lived associations)\n            msg = 'Association with %s expired' % (server_url,)\n            return FailureResponse(consumer_id, msg)\n\n        # Check the signature\n        sig = query.get('openid.sig')\n        if sig is None or signed is None:\n            return FailureResponse(consumer_id, 'Missing argument signature')\n\n        signed_list = signed.split(',')\n        v_sig = assoc.signDict(signed_list, query)\n\n        if v_sig != sig:\n            return FailureResponse(consumer_id, 'Bad signature')\n\n        return SuccessResponse.fromQuery(consumer_id, query, signed)\n\n    def _checkAuth(self, query, server_url):\n        request = self._createCheckAuthRequest(query)\n        if request is None:\n            return False\n        response = self._makeKVPost(request, server_url)\n        if response is None:\n            return False\n        return self._processCheckAuthResponse(response)\n\n    def _createCheckAuthRequest(self, query):\n        signed = query.get('openid.signed')\n        if signed is None:\n            oidutil.log('No signature present; checkAuth aborted')\n            return None\n\n        # Arguments that are always passed to the server and not\n        # included in the signature.\n        whitelist = ['assoc_handle', 'sig', 'signed', 'invalidate_handle']\n        signed = signed.split(',') + whitelist\n\n        check_args = dict([(k, v) for k, v in query.iteritems()\n                           if k.startswith('openid.') and k[7:] in signed])\n\n        check_args['openid.mode'] = 'check_authentication'\n        return check_args\n\n    def _processCheckAuthResponse(self, response):\n        is_valid = response.get('is_valid', 'false')\n\n        if is_valid == 'true':\n            invalidate_handle = response.get('invalidate_handle')\n            if invalidate_handle is not None:\n                self.store.removeAssociation(server_url, invalidate_handle)\n\n            return True\n\n        oidutil.log('Server responds that checkAuth call is not valid')\n        return False\n\n    def _getAssociation(self, server_url):\n        if self.store.isDumb():\n            return None\n\n        assoc = self.store.getAssociation(server_url)\n\n        if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME:\n            proto = urlparse(server_url)[0]\n            if proto == 'https':\n                dh = None\n            else:\n                dh = DiffieHellman()\n\n            args = self._createAssociateRequest(dh)\n            try:\n                response = self._makeKVPost(args, server_url)\n            except fetchers.HTTPFetchingError, why:\n                oidutil.log('openid.associate request failed: %s' %\n                            (str(why),))\n                assoc = None\n            else:\n                assoc = self._parseAssociation(response, dh, server_url)\n\n        return assoc\n\n    def _genToken(self, nonce, consumer_id, server_id, server_url):\n        timestamp = str(int(time.time()))\n        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n        joined = '\\x00'.join(elements)\n        sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n\n        return oidutil.toBase64('%s%s' % (sig, joined))\n\n    def _splitToken(self, token):\n        token = oidutil.fromBase64(token)\n        if len(token) < 20:\n            raise ValueError('Bad token length: %d' % len(token))\n\n        sig, joined = token[:20], token[20:]\n        if cryptutil.hmacSha1(self.store.getAuthKey(), joined) != sig:\n            raise ValueError('Bad token signature')\n\n        split = joined.split('\\x00')\n        if len(split) != 5:\n            raise ValueError('Bad token contents (not enough fields)')\n\n        try:\n            ts = int(split[0])\n        except ValueError:\n            raise ValueError('Bad token contents (timestamp bad)')\n\n        if ts + self.TOKEN_LIFETIME < time.time():\n            raise ValueError('Token expired')\n\n        return tuple(split[1:])\n\n    def _createAssociateRequest(self, dh=None, args=None):\n        if args is None:\n            args = {}\n\n        args.update({\n            'openid.mode': 'associate',\n            'openid.assoc_type':'HMAC-SHA1',\n            })\n\n        if dh:\n            cpub = cryptutil.longToBase64(dh.public)\n\n            args.update({\n                'openid.session_type':'DH-SHA1',\n                'openid.dh_consumer_public': cpub,\n                })\n\n            if not dh.usingDefaultValues():\n                args.update({\n                    'openid.dh_modulus': cryptutil.longToBase64(dh.modulus),\n                    'openid.dh_gen': cryptutil.longToBase64(dh.generator),\n                    })\n\n        return args\n\n    def _parseAssociation(self, results, dh, server_url):\n        try:\n            assoc_type = results['assoc_type']\n            if assoc_type != 'HMAC-SHA1':\n                fmt = 'Unsupported assoc_type returned from server %s: %s'\n                oidutil.log(fmt % (server_url, assoc_type))\n                return None\n\n            assoc_handle = results['assoc_handle']\n            try:\n                expires_in = int(results.get('expires_in', '0'))\n            except ValueError, e:\n                fmt = 'Getting Association: invalid expires_in field: %s'\n                oidutil.log(fmt % (e[0],))\n                return None\n\n            session_type = results.get('session_type')\n            if session_type is None:\n                secret = oidutil.fromBase64(results['mac_key'])\n            else:\n                if session_type != 'DH-SHA1':\n                    fmt = 'Unsupported session_type from server %s: %s'\n                    oidutil.log(fmt % (server_url, session_type))\n                    return None\n                if dh is None:\n                    fmt = 'Not expecting a DH-SHA1 session from server %s'\n                    oidutil.log(fmt % (server_url))\n                    return None\n\n                spub = cryptutil.base64ToLong(results['dh_server_public'])\n                enc_mac_key = oidutil.fromBase64(results['enc_mac_key'])\n                secret = dh.xorSecret(spub, enc_mac_key)\n\n            assoc = Association.fromExpiresIn(\n                expires_in, assoc_handle, secret, assoc_type)\n            self.store.storeAssociation(server_url, assoc)\n\n            return assoc\n\n        except KeyError, e:\n            fmt = 'Getting association: missing key in response from %s: %s'\n            oidutil.log(fmt % (server_url, e[0]))\n            return None\n\nclass OpenIDAuthRequest(object):\n    def __init__(self, token, assoc, endpoint):\n        \"\"\"\n        Creates a new OpenIDAuthRequest object.  This just stores each\n        argument in an appropriately named field.\n\n        Users of this library should not create instances of this\n        class.  Instances of this class are created by the library\n        when needed.\n        \"\"\"\n        self.assoc = assoc\n        self.endpoint = endpoint\n        self.extra_args = {}\n        self.token = token\n\n    def addExtensionArg(self, namespace, key, value):\n        arg_name = '.'.join('openid', namespace, key)\n        self.extra_args[arg_name] = value\n\n    def redirectURL(self, trust_root, return_to, immediate=False):\n        if immediate:\n            mode = 'checkid_immediate'\n        else:\n            mode = 'checkid_setup'\n\n        redir_args = {\n            'openid.mode': mode,\n            'openid.identity': self.endpoint.getServerID(),\n            'openid.return_to': return_to,\n            'openid.trust_root': trust_root,\n            }\n\n        if self.assoc:\n            redir_args['openid.assoc_handle'] = self.assoc.handle\n\n        redir_args.update(self.extra_args)\n        return oidutil.appendArgs(self.endpoint.server_url, redir_args)\n\nclass OpenIDConsumerResponse(object):\n    status = None\n\nclass SuccessResponse(OpenIDConsumerResponse):\n    status = 'success'\n\n    def __init__(self, identity_url, signed_args):\n        self.identity_url = identity_url\n        self.signed_args = signed_args\n\n    def fromQuery(cls, identity_url, query, signed):\n        signed_args = {}\n        for field_name in signed.split(','):\n            field_name = 'openid.' + field_name\n            signed_args[field_name] = query.get(field_name, '')\n        return cls(identity_url, signed_args)\n\n    fromQuery = classmethod(fromQuery)\n\n    def extensionResponse(self, prefix):\n        response = {}\n        prefix = 'openid.%s.' % (prefix,)\n        prefix_len = len(prefix)\n        for k, v in self.signed_args.iteritems():\n            if k.startswith(prefix):\n                response_key = k[prefix_len:]\n                response[response_key] = v\n\n        return response\n\nclass FailureResponse(OpenIDConsumerResponse):\n    status = 'failure'\n\n    def __init__(self, identity_url=None, message=None):\n        self.identity_url = identity_url\n        self.message = message\n\nclass CancelResponse(OpenIDConsumerResponse):\n    status = 'cancelled'\n\n    def __init__(self, identity_url=None):\n        self.identity_url = identity_url\n\nclass SetupNeededResponse(OpenIDConsumerResponse):\n    status = 'setup_needed'\n\n    def __init__(self, identity_url=None, setup_url=None):\n        self.identity_url = identity_url\n        self.setup_url = setup_url\n"},"\/test\/consumer.py":{"changes":[{"diff":"\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n","add":5,"remove":2,"filename":"\/test\/consumer.py","badparts":["            'openid.return_to':return_to,","            'openid.return_to':return_to,"],"goodparts":["        new_return_to = q['openid.return_to']","        del q['openid.return_to']","        assert new_return_to.startswith(return_to)","            'nonce':request.return_to_args['nonce'],","            'openid.return_to':new_return_to,"]},{"diff":"\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","add":1,"remove":1,"filename":"\/test\/consumer.py","badparts":["        assert info.status == 'success'"],"goodparts":["        assert info.status == 'success', info.message"]}],"source":"\nimport urlparse import cgi import time from openid import cryptutil, dh, oidutil, kvform from openid.consumer.discover import OpenIDServiceEndpoint from openid.consumer.consumer import GenericOpenIDConsumer from openid import association from openid.consumer import parse from urljr.fetchers import HTTPResponse from urljr import fetchers import _memstore assocs=[ ('another 20-byte key.', 'Snarky'), ('\\x00' * 20, 'Zeros'), ] def parseQuery(qs): q={} for(k, v) in cgi.parse_qsl(qs): assert not q.has_key(k) q[k]=v return q def associate(qs, assoc_secret, assoc_handle): \"\"\"Do the server's half of the associate call, using the given secret and handle.\"\"\" q=parseQuery(qs) assert q['openid.mode']=='associate' assert q['openid.assoc_type']=='HMAC-SHA1' if q.get('openid.session_type')=='DH-SHA1': assert len(q)==6 or len(q)==4 d=dh.DiffieHellman.fromBase64( q.get('openid.dh_modulus'), q.get('openid.dh_gen')) composite=cryptutil.base64ToLong(q['openid.dh_consumer_public']) enc_mac_key=oidutil.toBase64(d.xorSecret(composite, assoc_secret)) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'session_type':'DH-SHA1', 'dh_server_public':cryptutil.longToBase64(d.public), 'enc_mac_key':enc_mac_key, } else: assert len(q)==2 mac_key=oidutil.toBase64(assoc_secret) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'mac_key':mac_key, } return kvform.dictToKV(reply_dict) class TestFetcher(object): def __init__(self, user_url, user_page,(assoc_secret, assoc_handle)): self.get_responses={user_url:self.response(user_url, 200, user_page)} self.assoc_secret=assoc_secret self.assoc_handle=assoc_handle self.num_assocs=0 def response(self, url, status, body): return HTTPResponse( final_url=url, status=status, headers={}, body=body) def fetch(self, url, body=None, headers=None): if body is None: if url in self.get_responses: return self.get_responses[url] else: try: body.index('openid.mode=associate') except ValueError: pass else: if urlparse.urlparse(url)[0]=='https': assert body.find('DH-SHA1')==-1 else: assert body.find('DH-SHA1') !=-1 response=associate( body, self.assoc_secret, self.assoc_handle) self.num_assocs +=1 return self.response(url, 200, response) return self.response(url, 404, 'Not found') def _test_success(server_url, user_url, delegate_url, links, immediate=False): store=_memstore.MemoryStore() if immediate: mode='checkid_immediate' else: mode='checkid_setup' endpoint=OpenIDServiceEndpoint() endpoint.identity_url=user_url endpoint.server_url=server_url endpoint.delegate=delegate_url fetcher=TestFetcher(None, None, assocs[0]) fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False) def run(): trust_root=consumer_url consumer=GenericOpenIDConsumer(store) request=consumer.begin(endpoint) return_to=consumer_url redirect_url=request.redirectURL(trust_root, return_to, immediate) parsed=urlparse.urlparse(redirect_url) qs=parsed[4] q=parseQuery(qs) assert q=={ 'openid.mode':mode, 'openid.identity':delegate_url, 'openid.trust_root':trust_root, 'openid.assoc_handle':fetcher.assoc_handle, 'openid.return_to':return_to, },(q, user_url, delegate_url, mode) assert redirect_url.startswith(server_url) query={ 'openid.mode':'id_res', 'openid.return_to':return_to, 'openid.identity':delegate_url, 'openid.assoc_handle':fetcher.assoc_handle, } assoc=store.getAssociation(server_url, fetcher.assoc_handle) assoc.addSignature(['mode', 'return_to', 'identity'], query) info=consumer.complete(query, request.token) assert info.status=='success' assert info.identity_url==user_url assert fetcher.num_assocs==0 run() assert fetcher.num_assocs==1 run() assert fetcher.num_assocs==1 store.removeAssociation(server_url, fetcher.assoc_handle) run() assert fetcher.num_assocs==2 run() assert fetcher.num_assocs==2 import unittest http_server_url='http:\/\/server.example.com\/' consumer_url='http:\/\/consumer.example.com\/' https_server_url='https:\/\/server.example.com\/' class TestSuccess(unittest.TestCase): server_url=http_server_url user_url='http:\/\/www.example.com\/user.html' delegate_url='http:\/\/consumer.example.com\/user' def setUp(self): self.links='<link rel=\"openid.server\" href=\"%s\" \/>' %( self.server_url,) self.delegate_links=('<link rel=\"openid.server\" href=\"%s\" \/>' '<link rel=\"openid.delegate\" href=\"%s\" \/>') %( self.server_url, self.delegate_url) def test_nodelegate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links) def test_nodelegateImmediate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links, True) def test_delegate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links) def test_delegateImmediate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links, True) class TestSuccessHTTPS(TestSuccess): server_url=https_server_url class TestConstruct(unittest.TestCase): def setUp(self): self.store_sentinel=object() def test_construct(self): oidc=GenericOpenIDConsumer(self.store_sentinel) self.failUnless(oidc.store is self.store_sentinel) def test_nostore(self): self.failUnlessRaises(TypeError, GenericOpenIDConsumer) class TestIdRes(unittest.TestCase): consumer_class=GenericOpenIDConsumer def setUp(self): self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.return_to=\"nonny\" self.server_id=\"sirod\" self.server_url=\"serlie\" self.consumer_id=\"consu\" class TestSetupNeeded(TestIdRes): def test_setupNeeded(self): setup_url='http:\/\/unittest\/setup-here' query={ 'openid.mode': 'id_res', 'openid.user_setup_url': setup_url, } ret=self.consumer._doIdRes(query, self.consumer_id, self.server_id, self.server_url, ) self.failUnlessEqual(ret.status, 'setup_needed') self.failUnlessEqual(ret.setup_url, setup_url) class CheckAuthHappened(Exception): pass class CheckAuthDetectingConsumer(GenericOpenIDConsumer): def _checkAuth(self, *args): raise CheckAuthHappened(args) class CatchLogs(object): def setUp(self): self.old_logger=oidutil.log oidutil.log=self.gotLogMessage self.messages=[] def gotLogMessage(self, message): self.messages.append(message) def tearDown(self): oidutil.log=self.old_logger class TestCheckAuthTriggered(TestIdRes, CatchLogs): consumer_class=CheckAuthDetectingConsumer def setUp(self): TestIdRes.setUp(self) CatchLogs.setUp(self) def _doIdRes(self, query): return self.consumer._doIdRes( query, self.consumer_id, self.server_id, self.server_url) def test_checkAuthTriggered(self): query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r %s' % (result, self.messages)) def test_checkAuthTriggeredWithAssoc(self): issued=time.time() lifetime=1000 assoc=association.Association( 'handle', 'secret', issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r' %(result,)) def test_expiredAssoc(self): issued=time.time() -10 lifetime=0 handle='handle' assoc=association.Association( handle, 'secret', issued, lifetime, 'HMAC-SHA1') self.failUnless(assoc.expiresIn <=0) self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':handle, } info=self._doIdRes(query) self.failUnlessEqual('failure', info.status) self.failUnlessEqual(self.consumer_id, info.identity_url) info.message.index('expired') def test_newerAssoc(self): lifetime=1000 good_issued=time.time() -10 good_handle='handle' good_assoc=association.Association( good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, good_assoc) bad_issued=time.time() -5 bad_handle='handle2' bad_assoc=association.Association( bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, bad_assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':good_handle, } good_assoc.addSignature(['return_to', 'identity'], query) info=self._doIdRes(query) self.failUnlessEqual(info.status, 'success') self.failUnlessEqual(self.consumer_id, info.identity_url) class MockFetcher(object): def __init__(self, response=None): self.response=response or HTTPResponse() self.fetches=[] def fetch(self, url, body=None, headers=None): self.fetches.append((url, body, headers)) return self.response class ExceptionRaisingMockFetcher(object): def fetch(self, url, body=None, headers=None): raise Exception('mock fetcher exception') class BadArgCheckingConsumer(GenericOpenIDConsumer): def _makeKVPost(self, args, _): assert args=={ 'openid.mode':'check_authentication', 'openid.signed':'foo', }, args return None class TestCheckAuth(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') query={'openid.signed': 'stuff, things'} r=self.consumer._checkAuth(query, http_server_url) self.failIf(r) self.failUnless(self.messages) def test_bad_args(self): query={ 'openid.signed':'foo', 'closid.foo':'something', } consumer=BadArgCheckingConsumer(self.store) consumer._checkAuth(query, 'does:\/\/not.matter') class TestFetchAssoc(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.consumer=self.consumer_class(self.store) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') r=self.consumer._makeKVPost({'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnlessEqual(r, None) self.failUnless(self.messages) def test_error_exception(self): self.fetcher=ExceptionRaisingMockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._makeKVPost, {'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnless(self.consumer._getAssociation('some:\/\/url') is None) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._checkAuth, {'openid.signed':''}, 'some:\/\/url') if __name__=='__main__': unittest.main() ","sourceWithComments":"import urlparse\nimport cgi\nimport time\n\nfrom openid import cryptutil, dh, oidutil, kvform\nfrom openid.consumer.discover import OpenIDServiceEndpoint\nfrom openid.consumer.consumer import GenericOpenIDConsumer\nfrom openid import association\n\nfrom openid.consumer import parse\n\nfrom urljr.fetchers import HTTPResponse\nfrom urljr import fetchers\n\nimport _memstore\n\nassocs = [\n    ('another 20-byte key.', 'Snarky'),\n    ('\\x00' * 20, 'Zeros'),\n    ]\n\ndef parseQuery(qs):\n    q = {}\n    for (k, v) in cgi.parse_qsl(qs):\n        assert not q.has_key(k)\n        q[k] = v\n    return q\n\ndef associate(qs, assoc_secret, assoc_handle):\n    \"\"\"Do the server's half of the associate call, using the given\n    secret and handle.\"\"\"\n    q = parseQuery(qs)\n    assert q['openid.mode'] == 'associate'\n    assert q['openid.assoc_type'] == 'HMAC-SHA1'\n    if q.get('openid.session_type') == 'DH-SHA1':\n        assert len(q) == 6 or len(q) == 4\n        d = dh.DiffieHellman.fromBase64(\n            q.get('openid.dh_modulus'), q.get('openid.dh_gen'))\n\n        composite = cryptutil.base64ToLong(q['openid.dh_consumer_public'])\n        enc_mac_key = oidutil.toBase64(d.xorSecret(composite, assoc_secret))\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'session_type':'DH-SHA1',\n            'dh_server_public':cryptutil.longToBase64(d.public),\n            'enc_mac_key':enc_mac_key,\n            }\n    else:\n        assert len(q) == 2\n        mac_key = oidutil.toBase64(assoc_secret)\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'mac_key':mac_key,\n            }\n\n    return kvform.dictToKV(reply_dict)\n\nclass TestFetcher(object):\n    def __init__(self, user_url, user_page, (assoc_secret, assoc_handle)):\n        self.get_responses = {user_url:self.response(user_url, 200, user_page)}\n        self.assoc_secret = assoc_secret\n        self.assoc_handle = assoc_handle\n        self.num_assocs = 0\n\n    def response(self, url, status, body):\n        return HTTPResponse(\n            final_url=url, status=status, headers={}, body=body)\n\n    def fetch(self, url, body=None, headers=None):\n        if body is None:\n            if url in self.get_responses:\n                return self.get_responses[url]\n        else:\n            try:\n                body.index('openid.mode=associate')\n            except ValueError:\n                pass # fall through\n            else:\n                if urlparse.urlparse(url)[0] == 'https':\n                    # Should not be doing DH-SHA1 when using HTTPS.\n                    assert body.find('DH-SHA1') == -1\n                else:\n                    assert body.find('DH-SHA1') != -1\n                response = associate(\n                    body, self.assoc_secret, self.assoc_handle)\n                self.num_assocs += 1\n                return self.response(url, 200, response)\n\n        return self.response(url, 404, 'Not found')\n\ndef _test_success(server_url, user_url, delegate_url, links, immediate=False):\n    store = _memstore.MemoryStore()\n    if immediate:\n        mode = 'checkid_immediate'\n    else:\n        mode = 'checkid_setup'\n\n    endpoint = OpenIDServiceEndpoint()\n    endpoint.identity_url = user_url\n    endpoint.server_url = server_url\n    endpoint.delegate = delegate_url\n\n    fetcher = TestFetcher(None, None, assocs[0])\n    fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False)\n\n    def run():\n        trust_root = consumer_url\n\n        consumer = GenericOpenIDConsumer(store)\n        request = consumer.begin(endpoint)\n\n        return_to = consumer_url\n        redirect_url = request.redirectURL(trust_root, return_to, immediate)\n\n        parsed = urlparse.urlparse(redirect_url)\n        qs = parsed[4]\n        q = parseQuery(qs)\n        assert q == {\n            'openid.mode':mode,\n            'openid.identity':delegate_url,\n            'openid.trust_root':trust_root,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            'openid.return_to':return_to,\n            }, (q, user_url, delegate_url, mode)\n\n        assert redirect_url.startswith(server_url)\n\n        query = {\n            'openid.mode':'id_res',\n            'openid.return_to':return_to,\n            'openid.identity':delegate_url,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            }\n\n        assoc = store.getAssociation(server_url, fetcher.assoc_handle)\n        assoc.addSignature(['mode', 'return_to', 'identity'], query)\n\n        info = consumer.complete(query, request.token)\n        assert info.status == 'success'\n        assert info.identity_url == user_url\n\n    assert fetcher.num_assocs == 0\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Another association is created if we remove the existing one\n    store.removeAssociation(server_url, fetcher.assoc_handle)\n    run()\n    assert fetcher.num_assocs == 2\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 2\n\nimport unittest\n\nhttp_server_url = 'http:\/\/server.example.com\/'\nconsumer_url = 'http:\/\/consumer.example.com\/'\nhttps_server_url = 'https:\/\/server.example.com\/'\n\nclass TestSuccess(unittest.TestCase):\n    server_url = http_server_url\n    user_url = 'http:\/\/www.example.com\/user.html'\n    delegate_url = 'http:\/\/consumer.example.com\/user'\n\n    def setUp(self):\n        self.links = '<link rel=\"openid.server\" href=\"%s\" \/>' % (\n            self.server_url,)\n\n        self.delegate_links = ('<link rel=\"openid.server\" href=\"%s\" \/>'\n                               '<link rel=\"openid.delegate\" href=\"%s\" \/>') % (\n            self.server_url, self.delegate_url)\n\n    def test_nodelegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links)\n\n    def test_nodelegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links, True)\n\n    def test_delegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links)\n\n    def test_delegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links, True)\n\n\nclass TestSuccessHTTPS(TestSuccess):\n    server_url = https_server_url\n\n\nclass TestConstruct(unittest.TestCase):\n    def setUp(self):\n        self.store_sentinel = object()\n\n    def test_construct(self):\n        oidc = GenericOpenIDConsumer(self.store_sentinel)\n        self.failUnless(oidc.store is self.store_sentinel)\n\n    def test_nostore(self):\n        self.failUnlessRaises(TypeError, GenericOpenIDConsumer)\n\n\nclass TestIdRes(unittest.TestCase):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        self.store = _memstore.MemoryStore()\n        self.consumer = self.consumer_class(self.store)\n        self.return_to = \"nonny\"\n        self.server_id = \"sirod\"\n        self.server_url = \"serlie\"\n        self.consumer_id = \"consu\"\n\nclass TestSetupNeeded(TestIdRes):\n    def test_setupNeeded(self):\n        setup_url = 'http:\/\/unittest\/setup-here'\n        query = {\n            'openid.mode': 'id_res',\n            'openid.user_setup_url': setup_url,\n            }\n        ret = self.consumer._doIdRes(query,\n                                     self.consumer_id,\n                                     self.server_id,\n                                     self.server_url,\n                                     )\n        self.failUnlessEqual(ret.status, 'setup_needed')\n        self.failUnlessEqual(ret.setup_url, setup_url)\n\nclass CheckAuthHappened(Exception): pass\n\nclass CheckAuthDetectingConsumer(GenericOpenIDConsumer):\n    def _checkAuth(self, *args):\n        raise CheckAuthHappened(args)\n\nclass CatchLogs(object):\n    def setUp(self):\n        self.old_logger = oidutil.log\n        oidutil.log = self.gotLogMessage\n        self.messages = []\n\n    def gotLogMessage(self, message):\n        self.messages.append(message)\n\n    def tearDown(self):\n        oidutil.log = self.old_logger\n\nclass TestCheckAuthTriggered(TestIdRes, CatchLogs):\n    consumer_class = CheckAuthDetectingConsumer\n\n    def setUp(self):\n        TestIdRes.setUp(self)\n        CatchLogs.setUp(self)\n\n    def _doIdRes(self, query):\n        return self.consumer._doIdRes(\n            query,\n            self.consumer_id,\n            self.server_id,\n            self.server_url)\n\n    def test_checkAuthTriggered(self):\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r %s' %\n                      (result, self.messages))\n\n    def test_checkAuthTriggeredWithAssoc(self):\n        # Store an association for this server that does not match the\n        # handle that is in the query\n        issued = time.time()\n        lifetime = 1000\n        assoc = association.Association(\n            'handle', 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r' % (result,))\n\n    def test_expiredAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        issued = time.time() - 10\n        lifetime = 0\n        handle = 'handle'\n        assoc = association.Association(\n            handle, 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.failUnless(assoc.expiresIn <= 0)\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':handle,\n            }\n        info = self._doIdRes(query)\n        self.failUnlessEqual('failure', info.status)\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n        info.message.index('expired') # raises an exception if it's not there\n\n    def test_newerAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        lifetime = 1000\n\n        good_issued = time.time() - 10\n        good_handle = 'handle'\n        good_assoc = association.Association(\n            good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, good_assoc)\n\n        bad_issued = time.time() - 5\n        bad_handle = 'handle2'\n        bad_assoc = association.Association(\n            bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, bad_assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':good_handle,\n            }\n\n        good_assoc.addSignature(['return_to', 'identity'], query)\n        info = self._doIdRes(query)\n        self.failUnlessEqual(info.status, 'success')\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n\n\nclass MockFetcher(object):\n    def __init__(self, response=None):\n        self.response = response or HTTPResponse()\n        self.fetches = []\n\n    def fetch(self, url, body=None, headers=None):\n        self.fetches.append((url, body, headers))\n        return self.response\n\nclass ExceptionRaisingMockFetcher(object):\n    def fetch(self, url, body=None, headers=None):\n        raise Exception('mock fetcher exception')\n\nclass BadArgCheckingConsumer(GenericOpenIDConsumer):\n    def _makeKVPost(self, args, _):\n        assert args == {\n            'openid.mode':'check_authentication',\n            'openid.signed':'foo',\n            }, args\n        return None\n\nclass TestCheckAuth(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n\n        self.consumer = self.consumer_class(self.store)\n\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        query = {'openid.signed': 'stuff, things'}\n        r = self.consumer._checkAuth(query, http_server_url)\n        self.failIf(r)\n        self.failUnless(self.messages)\n\n    def test_bad_args(self):\n        query = {\n            'openid.signed':'foo',\n            'closid.foo':'something',\n            }\n        consumer = BadArgCheckingConsumer(self.store)\n        consumer._checkAuth(query, 'does:\/\/not.matter')\n\nclass TestFetchAssoc(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.consumer = self.consumer_class(self.store)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        r = self.consumer._makeKVPost({'openid.mode':'associate'},\n                                      \"http:\/\/server_url\")\n        self.failUnlessEqual(r, None)\n        self.failUnless(self.messages)\n\n    def test_error_exception(self):\n        self.fetcher = ExceptionRaisingMockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._makeKVPost,\n                              {'openid.mode':'associate'},\n                              \"http:\/\/server_url\")\n\n        # exception fetching returns no association\n        self.failUnless(self.consumer._getAssociation('some:\/\/url') is None)\n\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._checkAuth,\n                              {'openid.signed':''},\n                              'some:\/\/url')\n\nif __name__ == '__main__':\n    unittest.main()\n"}},"msg":"[project @ Added nonce to return_to to fix replay attack vulnerability]"}},"https:\/\/github.com\/eric-erki\/python-openid":{"f05703e45f3ef162c4d927dc712b95cbac163bb4":{"url":"https:\/\/api.github.com\/repos\/eric-erki\/python-openid\/commits\/f05703e45f3ef162c4d927dc712b95cbac163bb4","html_url":"https:\/\/github.com\/eric-erki\/python-openid\/commit\/f05703e45f3ef162c4d927dc712b95cbac163bb4","message":"[project @ Added nonce to return_to to fix replay attack vulnerability]","sha":"f05703e45f3ef162c4d927dc712b95cbac163bb4","keyword":"replay attack vulnerable","diff":"diff --git a\/openid\/consumer\/consumer.py b\/openid\/consumer\/consumer.py\nindex b7a93bc..49f5663 100644\n--- a\/openid\/consumer\/consumer.py\n+++ b\/openid\/consumer\/consumer.py\n@@ -173,6 +173,7 @@\n import string\n import time\n import urllib\n+import cgi\n from urlparse import urlparse\n \n from urljr import fetchers\n@@ -279,13 +280,14 @@ class and its sublcasses.  For a filesystem-backed store,\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n@@ -295,9 +297,9 @@ def complete(self, query, token):\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n@@ -314,16 +316,39 @@ def complete(self, query, token):\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n@@ -466,9 +491,9 @@ def _getAssociation(self, server_url):\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n@@ -484,7 +509,7 @@ def _splitToken(self, token):\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n@@ -567,7 +592,7 @@ def _parseAssociation(self, results, dh, server_url):\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n@@ -579,6 +604,7 @@ def __init__(self, token, assoc, endpoint):\n         self.assoc = assoc\n         self.endpoint = endpoint\n         self.extra_args = {}\n+        self.return_to_args = {}\n         self.token = token\n \n     def addExtensionArg(self, namespace, key, value):\n@@ -591,6 +617,8 @@ def redirectURL(self, trust_root, return_to, immediate=False):\n         else:\n             mode = 'checkid_setup'\n \n+        return_to = oidutil.appendArgs(return_to, self.return_to_args)\n+\n         redir_args = {\n             'openid.mode': mode,\n             'openid.identity': self.endpoint.getServerID(),\n@@ -634,6 +662,9 @@ def extensionResponse(self, prefix):\n \n         return response\n \n+    def getReturnTo(self):\n+        return self.signed_args['openid.return_to']\n+\n class FailureResponse(OpenIDConsumerResponse):\n     status = 'failure'\n \ndiff --git a\/test\/consumer.py b\/test\/consumer.py\nindex 343c7a1..1b8fbe7 100644\n--- a\/test\/consumer.py\n+++ b\/test\/consumer.py\n@@ -119,19 +119,22 @@ def run():\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n@@ -140,7 +143,7 @@ def run():\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","files":{"\/openid\/consumer\/consumer.py":{"changes":[{"diff":"\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n","add":3,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            nonce,","        return OpenIDAuthRequest(token, assoc, service_endpoint)"],"goodparts":["        request = OpenIDAuthRequest(token, assoc, service_endpoint)","        request.return_to_args['nonce'] = nonce","        return request"]},{"diff":"\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            pieces = (None, None, None, None, None)","        (nonce, identity_url, delegate, server_url) = pieces"],"goodparts":["            pieces = (None, None, None)","        (identity_url, delegate, server_url) = pieces"]},{"diff":"\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n","add":27,"remove":4,"filename":"\/openid\/consumer\/consumer.py","badparts":["                if (response.status == 'success' and","                    not self.store.useNonce(nonce)):","                    return FailureResponse(identity_url, 'Nonce already used')"],"goodparts":["                if response.status == 'success':","                    return self._checkNonce(response, query.get('nonce'))","    def _checkNonce(self, response, nonce):","        parsed_url = urlparse(response.getReturnTo())","        query = parsed_url[4]","        for k, v in cgi.parse_qsl(query):","            if k == 'nonce':","                if v != nonce:","                    return FailureResponse(response.identity_url,","                                           'Nonce mismatch')","                else:","                    break","        else:","            return FailureResponse(response.identity_url,","                                   'Nonce missing from return_to: %r'","                                   % (response.getReturnTo()))","        if not self.store.useNonce(nonce):","            return FailureResponse(response.identity_url,","                                   'Nonce missing from store')","        return response"]},{"diff":"\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def _genToken(self, nonce, consumer_id, server_id, server_url):","        elements = [timestamp, nonce, consumer_id, server_id, server_url]"],"goodparts":["    def _genToken(self, consumer_id, server_id, server_url):","        elements = [timestamp, consumer_id, server_id, server_url]"]},{"diff":"\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["        if len(split) != 5:"],"goodparts":["        if len(split) != 4:"]},{"diff":"\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def __init__(self, token, assoc, endpoint):"],"goodparts":["    def __init__(self, token, assoc, endpoint  ):"]}],"source":"\n\"\"\" This module documents the main interface with the OpenID consumer libary. The only part of the library which has to be used and isn't documented in full here is the store required to create an C{L{OpenIDConsumer}} instance. More on the abstract store type and concrete implementations of it that are provided in the documentation for the C{L{__init__<OpenIDConsumer.__init__>}} method of the C{L{OpenIDConsumer}} class. OVERVIEW ======== The OpenID identity verification process most commonly uses the following steps, as visible to the user of this library: 1. The user enters their OpenID into a field on the consumer's site, and hits a login button. 2. The consumer site discovers the user's OpenID server using the YADIS protocol. 3. The consumer site sends the browser a redirect to the identity server. This is the authentication request as described in the OpenID specification. 4. The identity server's site sends the browser a redirect back to the consumer site. This redirect contains the server's response to the authentication request. The most important part of the flow to note is the consumer's site must handle two separate HTTP requests in order to perform the full identity check. LIBRARY DESIGN ============== This consumer library is designed with that flow in mind. The goal is to make it as easy as possible to perform the above steps securely. At a high level, there are two important parts in the consumer library. The first important part is this module, which contains the interface to actually use this library. The second is the C{L{openid.store.interface}} module, which describes the interface to use if you need to create a custom method for storing the state this library needs to maintain between requests. In general, the second part is less important for users of the library to know about, as several implementations are provided which cover a wide variety of situations in which consumers may use the library. This module contains a class, C{L{OpenIDConsumer}}, with methods corresponding to the actions necessary in each of steps 2, 3, and 4 described in the overview. Use of this library should be as easy as creating an C{L{OpenIDConsumer}} instance and calling the methods appropriate for the action the site wants to take. STORES AND DUMB MODE ==================== OpenID is a protocol that works best when the consumer site is able to store some state. This is the normal mode of operation for the protocol, and is sometimes referred to as smart mode. There is also a fallback mode, known as dumb mode, which is available when the consumer site is not able to store state. This mode should be avoided when possible, as it leaves the implementation more vulnerable to replay attacks. The mode the library works in for normal operation is determined by the store that it is given. The store is an abstraction that handles the data that the consumer needs to manage between http requests in order to operate efficiently and securely. Several store implementation are provided, and the interface is fully documented so that custom stores can be used as well. See the documentation for the C{L{OpenIDConsumer}} class for more information on the interface for stores. The implementations that are provided allow the consumer site to store the necessary data in several different ways, including several SQL databases and normal files on disk. There is an additional concrete store provided that puts the system in dumb mode. This is not recommended, as it removes the library's ability to stop replay attacks reliably. It still uses time-based checking to make replay attacks only possible within a small window, but they remain possible within that window. This store should only be used if the consumer site has no way to retain data between requests at all. IMMEDIATE MODE ============== In the flow described above, the user may need to confirm to the identity server that it's ok to authorize his or her identity. The server may draw pages asking for information from the user before it redirects the browser back to the consumer's site. This is generally transparent to the consumer site, so it is typically ignored as an implementation detail. There can be times, however, where the consumer site wants to get a response immediately. When this is the case, the consumer can put the library in immediate mode. In immediate mode, there is an extra response possible from the server, which is essentially the server reporting that it doesn't have enough information to answer the question yet. In addition to saying that, the identity server provides a URL to which the user can be sent to provide the needed information and let the server finish handling the original request. USING THIS LIBRARY ================== Integrating this library into an application is usually a relatively straightforward process. The process should basically follow this plan: Add an OpenID login field somewhere on your site. When an OpenID is entered in that field and the form is submitted, it should make a request to the your site which includes that OpenID URL. To start, the application should get an C{L{OpenIDConsumer}} instance, and call its C{L{begin<OpenIDConsumer.begin>}} method. This method takes the OpenID URL and, optionally, a session object. If the application has any sort of session framework that provides per-client state management, that should be used here. The library just expects the session object to support a C{dict}-like interface, if it provided. If no session object is provided, the application code needs to store the information that would have been put in the session in an alternate location. See the documentation for the C{L{begin<OpenIDConsumer.begin>}} call for more information. The C{L{begin<OpenIDConsumer.begin>}} method returns an C{L{OpenIDRequestBuilder}} object. Next, the application should call the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on the C{L{OpenIDRequestBuilder}} object. The return_to URL is the URL that the OpenID server will send the user back to after attempting to verify his or her identity. The trust_root is the URL(or URL pattern) that identifies your web site to the user when he or she is authorizing it. Send a redirect to the resulting URL to the user's browser. That's the first half of the authentication process. The second half of the process is done after the user's ID server sends the user's browser a redirect back to your site to complete their login. When that happens, the user will contact your site at the URL given as the C{return_to} URL to the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made above. The request will have several query parameters added to the URL by the identity server as the information necessary to finish the request. Get an C{L{OpenIDConsumer}} instance, and call its C{L{complete<OpenIDConsumer.complete>}} method, passing in all the received query arguments and either the user's session object or the token saved earlier. See the documentation for C{L{OpenIDRequestBuilder}} for more information about the token. There are multiple possible return types possible from that method. These indicate the whether or not the login was successful, and include any additional information appropriate for their type. \"\"\" import string import time import urllib from urlparse import urlparse from urljr import fetchers from openid.consumer.discover import discover as openIDDiscover from openid.consumer.discover import yadis_available from openid import cryptutil from openid import kvform from openid import oidutil from openid.association import Association from openid.dh import DiffieHellman __all__=['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse', 'SetupNeededResponse', 'CancelResponse', 'FailureResponse'] if yadis_available: from yadis.manager import Discovery class OpenIDConsumer(object): session_key_prefix=\"_openid_consumer_\" _token='last_token' def __init__(self, session, store): self.session=session self.consumer=GenericOpenIDConsumer(store) self._token_key=self.session_key_prefix +self._token def begin(self, user_url): openid_url=oidutil.normalizeUrl(user_url) if yadis_available: disco=Discovery(self.session, openid_url, 'XXX') endpoint=disco.getNextService(openIDDiscover) else: _, endpoints=openIDDiscover(openid_url) if not endpoints: endpoint=None else: endpoint=endpoints[0] if endpoint is None: return None else: return self.beginWithoutDiscovery(endpoint) def beginWithoutDiscovery(self, endpoint): auth_req=self.consumer.begin(endpoint) self.session[self._token_key]=auth_req.token return auth_req def complete(self, query): token=self.session.get(self._token_key) if token is None: response=FailureResponse(None, 'No session state found') else: response=self.consumer.complete(query, token) if response.status in['success', 'cancel' ]: if yadis_available and response.identity_url is not None: disco=Discovery(self.session, response.identity_url) disco.cleanup() return response class GenericOpenIDConsumer(object): \"\"\"This is the implementation of the common logic for OpenID consumers. It is unaware of the application in which it is running. \"\"\" TOKEN_LIFETIME=60 * 5 NONCE_LEN=8 NONCE_CHRS=string.letters +string.digits def __init__(self, store): \"\"\" This method initializes a new C{L{OpenIDConsumer}} instance to access the library. @param store: This must be an object that implements the interface in C{L{openid.store.interface.OpenIDStore}}. Several concrete implementations are provided, to cover most common use cases. For stores backed by MySQL or SQLite, see the C{L{openid.store.sqlstore.SQLStore}} class and its sublcasses. For a filesystem-backed store, see the C{L{openid.store.filestore}} module. As a last resort, if it isn't possible for the server to store state at all, an instance of C{L{openid.store.dumbstore.DumbStore}} can be used. This should be an absolute last resort, though, as it makes the consumer vulnerable to replay attacks over the lifespan of the tokens the library creates. @type store: C{L{openid.store.interface.OpenIDStore}} \"\"\" self.store=store def begin(self, service_endpoint): nonce=self._createNonce() token=self._genToken( nonce, service_endpoint.identity_url, service_endpoint.getServerID(), service_endpoint.server_url, ) assoc=self._getAssociation(service_endpoint.server_url) return OpenIDAuthRequest(token, assoc, service_endpoint) def complete(self, query, token): mode=query.get('openid.mode', '<no mode specified>') try: pieces=self._splitToken(token) except ValueError, why: oidutil.log(why[0]) pieces=(None, None, None, None, None) (nonce, identity_url, delegate, server_url)=pieces if mode=='cancel': return CancelResponse(identity_url) elif mode=='error': error=query.get('openid.error') return FailureResponse(identity_url, error) elif mode=='id_res': if identity_url is None: return FailureResponse(identity_url, 'No session state found') try: response=self._doIdRes( query, identity_url, delegate, server_url) except fetchers.HTTPFetchingError, why: message='HTTP request failed: %s' %(str(why),) return FailureResponse(identity_url, message) else: if(response.status=='success' and not self.store.useNonce(nonce)): return FailureResponse(identity_url, 'Nonce already used') else: return response else: return FailureResponse(identity_url, 'Invalid openid.mode: %r' %(mode,)) def _createNonce(self): nonce=cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS) self.store.storeNonce(nonce) return nonce def _makeKVPost(self, args, server_url): mode=args['openid.mode'] body=urllib.urlencode(args) resp=fetchers.fetch(server_url, body=body) if resp is None: fmt='openid.mode=%s: failed to fetch URL: %s' oidutil.log(fmt %(mode, server_url)) return None response=kvform.kvToDict(resp.body) if resp.status==400: server_error=response.get('error', '<no message from server>') fmt='openid.mode=%s: error returned from server %s: %s' oidutil.log(fmt %(mode, server_url, server_error)) return None elif resp.status !=200: fmt='openid.mode=%s: bad status code from server %s: %s' oidutil.log(fmt %(mode, server_url, resp.status)) return None return response def _doIdRes(self, query, consumer_id, server_id, server_url): user_setup_url=query.get('openid.user_setup_url') if user_setup_url is not None: return SetupNeededResponse(consumer_id, user_setup_url) return_to=query.get('openid.return_to') server_id2=query.get('openid.identity') assoc_handle=query.get('openid.assoc_handle') if return_to is None or server_id is None or assoc_handle is None: return FailureResponse(consumer_id, 'Missing required field') if server_id !=server_id2: return FailureResponse(consumer_id, 'Server ID(delegate) mismatch') signed=query.get('openid.signed') assoc=self.store.getAssociation(server_url, assoc_handle) if assoc is None: if self._checkAuth(query, server_url): return SuccessResponse.fromQuery(consumer_id, query, signed) else: return FailureResponse(consumer_id, 'Server denied check_authentication') if assoc.expiresIn <=0: msg='Association with %s expired' %(server_url,) return FailureResponse(consumer_id, msg) sig=query.get('openid.sig') if sig is None or signed is None: return FailureResponse(consumer_id, 'Missing argument signature') signed_list=signed.split(',') v_sig=assoc.signDict(signed_list, query) if v_sig !=sig: return FailureResponse(consumer_id, 'Bad signature') return SuccessResponse.fromQuery(consumer_id, query, signed) def _checkAuth(self, query, server_url): request=self._createCheckAuthRequest(query) if request is None: return False response=self._makeKVPost(request, server_url) if response is None: return False return self._processCheckAuthResponse(response) def _createCheckAuthRequest(self, query): signed=query.get('openid.signed') if signed is None: oidutil.log('No signature present; checkAuth aborted') return None whitelist=['assoc_handle', 'sig', 'signed', 'invalidate_handle'] signed=signed.split(',') +whitelist check_args=dict([(k, v) for k, v in query.iteritems() if k.startswith('openid.') and k[7:] in signed]) check_args['openid.mode']='check_authentication' return check_args def _processCheckAuthResponse(self, response): is_valid=response.get('is_valid', 'false') if is_valid=='true': invalidate_handle=response.get('invalidate_handle') if invalidate_handle is not None: self.store.removeAssociation(server_url, invalidate_handle) return True oidutil.log('Server responds that checkAuth call is not valid') return False def _getAssociation(self, server_url): if self.store.isDumb(): return None assoc=self.store.getAssociation(server_url) if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME: proto=urlparse(server_url)[0] if proto=='https': dh=None else: dh=DiffieHellman() args=self._createAssociateRequest(dh) try: response=self._makeKVPost(args, server_url) except fetchers.HTTPFetchingError, why: oidutil.log('openid.associate request failed: %s' % (str(why),)) assoc=None else: assoc=self._parseAssociation(response, dh, server_url) return assoc def _genToken(self, nonce, consumer_id, server_id, server_url): timestamp=str(int(time.time())) elements=[timestamp, nonce, consumer_id, server_id, server_url] joined='\\x00'.join(elements) sig=cryptutil.hmacSha1(self.store.getAuthKey(), joined) return oidutil.toBase64('%s%s' %(sig, joined)) def _splitToken(self, token): token=oidutil.fromBase64(token) if len(token) < 20: raise ValueError('Bad token length: %d' % len(token)) sig, joined=token[:20], token[20:] if cryptutil.hmacSha1(self.store.getAuthKey(), joined) !=sig: raise ValueError('Bad token signature') split=joined.split('\\x00') if len(split) !=5: raise ValueError('Bad token contents(not enough fields)') try: ts=int(split[0]) except ValueError: raise ValueError('Bad token contents(timestamp bad)') if ts +self.TOKEN_LIFETIME < time.time(): raise ValueError('Token expired') return tuple(split[1:]) def _createAssociateRequest(self, dh=None, args=None): if args is None: args={} args.update({ 'openid.mode': 'associate', 'openid.assoc_type':'HMAC-SHA1', }) if dh: cpub=cryptutil.longToBase64(dh.public) args.update({ 'openid.session_type':'DH-SHA1', 'openid.dh_consumer_public': cpub, }) if not dh.usingDefaultValues(): args.update({ 'openid.dh_modulus': cryptutil.longToBase64(dh.modulus), 'openid.dh_gen': cryptutil.longToBase64(dh.generator), }) return args def _parseAssociation(self, results, dh, server_url): try: assoc_type=results['assoc_type'] if assoc_type !='HMAC-SHA1': fmt='Unsupported assoc_type returned from server %s: %s' oidutil.log(fmt %(server_url, assoc_type)) return None assoc_handle=results['assoc_handle'] try: expires_in=int(results.get('expires_in', '0')) except ValueError, e: fmt='Getting Association: invalid expires_in field: %s' oidutil.log(fmt %(e[0],)) return None session_type=results.get('session_type') if session_type is None: secret=oidutil.fromBase64(results['mac_key']) else: if session_type !='DH-SHA1': fmt='Unsupported session_type from server %s: %s' oidutil.log(fmt %(server_url, session_type)) return None if dh is None: fmt='Not expecting a DH-SHA1 session from server %s' oidutil.log(fmt %(server_url)) return None spub=cryptutil.base64ToLong(results['dh_server_public']) enc_mac_key=oidutil.fromBase64(results['enc_mac_key']) secret=dh.xorSecret(spub, enc_mac_key) assoc=Association.fromExpiresIn( expires_in, assoc_handle, secret, assoc_type) self.store.storeAssociation(server_url, assoc) return assoc except KeyError, e: fmt='Getting association: missing key in response from %s: %s' oidutil.log(fmt %(server_url, e[0])) return None class OpenIDAuthRequest(object): def __init__(self, token, assoc, endpoint): \"\"\" Creates a new OpenIDAuthRequest object. This just stores each argument in an appropriately named field. Users of this library should not create instances of this class. Instances of this class are created by the library when needed. \"\"\" self.assoc=assoc self.endpoint=endpoint self.extra_args={} self.token=token def addExtensionArg(self, namespace, key, value): arg_name='.'.join('openid', namespace, key) self.extra_args[arg_name]=value def redirectURL(self, trust_root, return_to, immediate=False): if immediate: mode='checkid_immediate' else: mode='checkid_setup' redir_args={ 'openid.mode': mode, 'openid.identity': self.endpoint.getServerID(), 'openid.return_to': return_to, 'openid.trust_root': trust_root, } if self.assoc: redir_args['openid.assoc_handle']=self.assoc.handle redir_args.update(self.extra_args) return oidutil.appendArgs(self.endpoint.server_url, redir_args) class OpenIDConsumerResponse(object): status=None class SuccessResponse(OpenIDConsumerResponse): status='success' def __init__(self, identity_url, signed_args): self.identity_url=identity_url self.signed_args=signed_args def fromQuery(cls, identity_url, query, signed): signed_args={} for field_name in signed.split(','): field_name='openid.' +field_name signed_args[field_name]=query.get(field_name, '') return cls(identity_url, signed_args) fromQuery=classmethod(fromQuery) def extensionResponse(self, prefix): response={} prefix='openid.%s.' %(prefix,) prefix_len=len(prefix) for k, v in self.signed_args.iteritems(): if k.startswith(prefix): response_key=k[prefix_len:] response[response_key]=v return response class FailureResponse(OpenIDConsumerResponse): status='failure' def __init__(self, identity_url=None, message=None): self.identity_url=identity_url self.message=message class CancelResponse(OpenIDConsumerResponse): status='cancelled' def __init__(self, identity_url=None): self.identity_url=identity_url class SetupNeededResponse(OpenIDConsumerResponse): status='setup_needed' def __init__(self, identity_url=None, setup_url=None): self.identity_url=identity_url self.setup_url=setup_url ","sourceWithComments":"\"\"\"\nThis module documents the main interface with the OpenID consumer\nlibary.  The only part of the library which has to be used and isn't\ndocumented in full here is the store required to create an\nC{L{OpenIDConsumer}} instance.  More on the abstract store type and\nconcrete implementations of it that are provided in the documentation\nfor the C{L{__init__<OpenIDConsumer.__init__>}} method of the\nC{L{OpenIDConsumer}} class.\n\n\nOVERVIEW\n========\n\n    The OpenID identity verification process most commonly uses the\n    following steps, as visible to the user of this library:\n\n        1. The user enters their OpenID into a field on the consumer's\n           site, and hits a login button.\n\n        2. The consumer site discovers the user's OpenID server using\n           the YADIS protocol.\n\n        3. The consumer site sends the browser a redirect to the\n           identity server.  This is the authentication request as\n           described in the OpenID specification.\n\n        4. The identity server's site sends the browser a redirect\n           back to the consumer site.  This redirect contains the\n           server's response to the authentication request.\n\n    The most important part of the flow to note is the consumer's site\n    must handle two separate HTTP requests in order to perform the\n    full identity check.\n\n\nLIBRARY DESIGN\n==============\n\n    This consumer library is designed with that flow in mind.  The\n    goal is to make it as easy as possible to perform the above steps\n    securely.\n\n    At a high level, there are two important parts in the consumer\n    library.  The first important part is this module, which contains\n    the interface to actually use this library.  The second is the\n    C{L{openid.store.interface}} module, which describes the\n    interface to use if you need to create a custom method for storing\n    the state this library needs to maintain between requests.\n\n    In general, the second part is less important for users of the\n    library to know about, as several implementations are provided\n    which cover a wide variety of situations in which consumers may\n    use the library.\n\n    This module contains a class, C{L{OpenIDConsumer}}, with methods\n    corresponding to the actions necessary in each of steps 2, 3, and\n    4 described in the overview.  Use of this library should be as easy\n    as creating an C{L{OpenIDConsumer}} instance and calling the methods\n    appropriate for the action the site wants to take.\n\n\nSTORES AND DUMB MODE\n====================\n\n    OpenID is a protocol that works best when the consumer site is\n    able to store some state.  This is the normal mode of operation\n    for the protocol, and is sometimes referred to as smart mode.\n    There is also a fallback mode, known as dumb mode, which is\n    available when the consumer site is not able to store state.  This\n    mode should be avoided when possible, as it leaves the\n    implementation more vulnerable to replay attacks.\n\n    The mode the library works in for normal operation is determined\n    by the store that it is given.  The store is an abstraction that\n    handles the data that the consumer needs to manage between http\n    requests in order to operate efficiently and securely.\n\n    Several store implementation are provided, and the interface is\n    fully documented so that custom stores can be used as well.  See\n    the documentation for the C{L{OpenIDConsumer}} class for more\n    information on the interface for stores.  The implementations that\n    are provided allow the consumer site to store the necessary data\n    in several different ways, including several SQL databases and\n    normal files on disk.\n\n    There is an additional concrete store provided that puts the\n    system in dumb mode.  This is not recommended, as it removes the\n    library's ability to stop replay attacks reliably.  It still uses\n    time-based checking to make replay attacks only possible within a\n    small window, but they remain possible within that window.  This\n    store should only be used if the consumer site has no way to\n    retain data between requests at all.\n\n\nIMMEDIATE MODE\n==============\n\n    In the flow described above, the user may need to confirm to the\n    identity server that it's ok to authorize his or her identity.\n    The server may draw pages asking for information from the user\n    before it redirects the browser back to the consumer's site.  This\n    is generally transparent to the consumer site, so it is typically\n    ignored as an implementation detail.\n\n    There can be times, however, where the consumer site wants to get\n    a response immediately.  When this is the case, the consumer can\n    put the library in immediate mode.  In immediate mode, there is an\n    extra response possible from the server, which is essentially the\n    server reporting that it doesn't have enough information to answer\n    the question yet.  In addition to saying that, the identity server\n    provides a URL to which the user can be sent to provide the needed\n    information and let the server finish handling the original\n    request.\n\n\nUSING THIS LIBRARY\n==================\n\n    Integrating this library into an application is usually a\n    relatively straightforward process.  The process should basically\n    follow this plan:\n\n    Add an OpenID login field somewhere on your site.  When an OpenID\n    is entered in that field and the form is submitted, it should make\n    a request to the your site which includes that OpenID URL.\n\n    To start, the application should get an C{L{OpenIDConsumer}}\n    instance, and call its C{L{begin<OpenIDConsumer.begin>}} method.\n    This method takes the OpenID URL and, optionally, a session\n    object.  If the application has any sort of session framework that\n    provides per-client state management, that should be used here.\n    The library just expects the session object to support a\n    C{dict}-like interface, if it provided.  If no session object is\n    provided, the application code needs to store the information that\n    would have been put in the session in an alternate location.  See\n    the documentation for the C{L{begin<OpenIDConsumer.begin>}} call\n    for more information.  The C{L{begin<OpenIDConsumer.begin>}}\n    method returns an C{L{OpenIDRequestBuilder}} object.\n\n    Next, the application should call the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on\n    the C{L{OpenIDRequestBuilder}} object.  The return_to URL is the\n    URL that the OpenID server will send the user back to after\n    attempting to verify his or her identity.  The trust_root is the\n    URL (or URL pattern) that identifies your web site to the user\n    when he or she is authorizing it.  Send a redirect to the\n    resulting URL to the user's browser.\n\n    That's the first half of the authentication process.  The second\n    half of the process is done after the user's ID server sends the\n    user's browser a redirect back to your site to complete their\n    login.\n\n    When that happens, the user will contact your site at the URL\n    given as the C{return_to} URL to the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made\n    above.  The request will have several query parameters added to\n    the URL by the identity server as the information necessary to\n    finish the request.\n\n    Get an C{L{OpenIDConsumer}} instance, and call its\n    C{L{complete<OpenIDConsumer.complete>}} method, passing in all the\n    received query arguments and either the user's session object or\n    the token saved earlier.  See the documentation for\n    C{L{OpenIDRequestBuilder}} for more information about the token.\n\n    There are multiple possible return types possible from that\n    method.  These indicate the whether or not the login was\n    successful, and include any additional information appropriate for\n    their type.\n\"\"\"\n\nimport string\nimport time\nimport urllib\nfrom urlparse import urlparse\n\nfrom urljr import fetchers\n\nfrom openid.consumer.discover import discover as openIDDiscover\nfrom openid.consumer.discover import yadis_available\nfrom openid import cryptutil\nfrom openid import kvform\nfrom openid import oidutil\nfrom openid.association import Association\nfrom openid.dh import DiffieHellman\n\n__all__ = ['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse',\n           'SetupNeededResponse', 'CancelResponse', 'FailureResponse']\n\nif yadis_available:\n    from yadis.manager import Discovery\n\nclass OpenIDConsumer(object):\n    session_key_prefix = \"_openid_consumer_\"\n\n    _token = 'last_token'\n\n    def __init__(self, session, store):\n        self.session = session\n        self.consumer = GenericOpenIDConsumer(store)\n        self._token_key = self.session_key_prefix + self._token\n\n    def begin(self, user_url):\n        openid_url = oidutil.normalizeUrl(user_url)\n        if yadis_available:\n            disco = Discovery(self.session, openid_url, 'XXX')\n            endpoint = disco.getNextService(openIDDiscover)\n        else:\n            _, endpoints = openIDDiscover(openid_url)\n            if not endpoints:\n                endpoint = None\n            else:\n                endpoint = endpoints[0]\n\n        if endpoint is None:\n            return None\n        else:\n            return self.beginWithoutDiscovery(endpoint)\n\n    def beginWithoutDiscovery(self, endpoint):\n        auth_req = self.consumer.begin(endpoint)\n        self.session[self._token_key] = auth_req.token\n        return auth_req\n\n    def complete(self, query):\n        token = self.session.get(self._token_key)\n        if token is None:\n            response = FailureResponse(None, 'No session state found')\n        else:\n            response = self.consumer.complete(query, token)\n\n        if response.status in ['success',\n                               'cancel'#maybe\n                               ]:\n            if yadis_available and response.identity_url is not None:\n                disco = Discovery(self.session, response.identity_url)\n                # This is OK to do even if we did not do discovery in\n                # the first place.\n                disco.cleanup()\n\n        return response\n\nclass GenericOpenIDConsumer(object):\n    \"\"\"This is the implementation of the common logic for OpenID\n    consumers. It is unaware of the application in which it is\n    running.\n    \"\"\"\n\n    TOKEN_LIFETIME = 60 * 5 # five minutes\n    NONCE_LEN = 8\n    NONCE_CHRS = string.letters + string.digits\n\n    def __init__(self, store):\n        \"\"\"\n        This method initializes a new C{L{OpenIDConsumer}} instance to\n        access the library.\n\n        @param store: This must be an object that implements the\n            interface in C{L{openid.store.interface.OpenIDStore}}.\n            Several concrete implementations are provided, to cover\n            most common use cases.  For stores backed by MySQL or\n            SQLite, see the C{L{openid.store.sqlstore.SQLStore}}\n            class and its sublcasses.  For a filesystem-backed store,\n            see the C{L{openid.store.filestore}} module.\n\n            As a last resort, if it isn't possible for the server to\n            store state at all, an instance of\n            C{L{openid.store.dumbstore.DumbStore}} can be used.  This\n            should be an absolute last resort, though, as it makes the\n            consumer vulnerable to replay attacks over the lifespan of\n            the tokens the library creates.\n\n        @type store: C{L{openid.store.interface.OpenIDStore}}\n\n        \"\"\"\n        self.store = store\n\n    def begin(self, service_endpoint):\n        nonce = self._createNonce()\n        token = self._genToken(\n            nonce,\n            service_endpoint.identity_url,\n            service_endpoint.getServerID(),\n            service_endpoint.server_url,\n            )\n        assoc = self._getAssociation(service_endpoint.server_url)\n        return OpenIDAuthRequest(token, assoc, service_endpoint)\n\n    def complete(self, query, token):\n        mode = query.get('openid.mode', '<no mode specified>')\n\n        # Get the current request's state\n        try:\n            pieces = self._splitToken(token)\n        except ValueError, why:\n            oidutil.log(why[0])\n            pieces = (None, None, None, None, None)\n\n        (nonce, identity_url, delegate, server_url) = pieces\n\n        if mode == 'cancel':\n            return CancelResponse(identity_url)\n        elif mode == 'error':\n            error = query.get('openid.error')\n            return FailureResponse(identity_url, error)\n        elif mode == 'id_res':\n            if identity_url is None:\n                return FailureResponse(identity_url, 'No session state found')\n            try:\n                response = self._doIdRes(\n                    query, identity_url, delegate, server_url)\n            except fetchers.HTTPFetchingError, why:\n                message = 'HTTP request failed: %s' % (str(why),)\n                return FailureResponse(identity_url, message)\n            else:\n                if (response.status == 'success' and\n                    not self.store.useNonce(nonce)):\n\n                    return FailureResponse(identity_url, 'Nonce already used')\n                else:\n                    return response\n        else:\n            return FailureResponse(identity_url,\n                                   'Invalid openid.mode: %r' % (mode,))\n\n    def _createNonce(self):\n        nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n        self.store.storeNonce(nonce)\n        return nonce\n\n    def _makeKVPost(self, args, server_url):\n        mode = args['openid.mode']\n        body = urllib.urlencode(args)\n\n        resp = fetchers.fetch(server_url, body=body)\n        if resp is None:\n            fmt = 'openid.mode=%s: failed to fetch URL: %s'\n            oidutil.log(fmt % (mode, server_url))\n            return None\n\n        response = kvform.kvToDict(resp.body)\n        if resp.status == 400:\n            server_error = response.get('error', '<no message from server>')\n            fmt = 'openid.mode=%s: error returned from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, server_error))\n            return None\n        elif resp.status != 200:\n            fmt = 'openid.mode=%s: bad status code from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, resp.status))\n            return None\n\n        return response\n\n    def _doIdRes(self, query, consumer_id, server_id, server_url):\n        user_setup_url = query.get('openid.user_setup_url')\n        if user_setup_url is not None:\n            return SetupNeededResponse(consumer_id, user_setup_url)\n\n        return_to = query.get('openid.return_to')\n        server_id2 = query.get('openid.identity')\n        assoc_handle = query.get('openid.assoc_handle')\n\n        if return_to is None or server_id is None or assoc_handle is None:\n            return FailureResponse(consumer_id, 'Missing required field')\n\n        if server_id != server_id2:\n            return FailureResponse(consumer_id, 'Server ID (delegate) mismatch')\n\n        signed = query.get('openid.signed')\n\n        assoc = self.store.getAssociation(server_url, assoc_handle)\n\n        if assoc is None:\n            # It's not an association we know about.  Dumb mode is our\n            # only possible path for recovery.\n            if self._checkAuth(query, server_url):\n                return SuccessResponse.fromQuery(consumer_id, query, signed)\n            else:\n                return FailureResponse(consumer_id,\n                                       'Server denied check_authentication')\n\n        if assoc.expiresIn <= 0:\n            # XXX: It might be a good idea sometimes to re-start the\n            # authentication with a new association. Doing it\n            # automatically opens the possibility for\n            # denial-of-service by a server that just returns expired\n            # associations (or really short-lived associations)\n            msg = 'Association with %s expired' % (server_url,)\n            return FailureResponse(consumer_id, msg)\n\n        # Check the signature\n        sig = query.get('openid.sig')\n        if sig is None or signed is None:\n            return FailureResponse(consumer_id, 'Missing argument signature')\n\n        signed_list = signed.split(',')\n        v_sig = assoc.signDict(signed_list, query)\n\n        if v_sig != sig:\n            return FailureResponse(consumer_id, 'Bad signature')\n\n        return SuccessResponse.fromQuery(consumer_id, query, signed)\n\n    def _checkAuth(self, query, server_url):\n        request = self._createCheckAuthRequest(query)\n        if request is None:\n            return False\n        response = self._makeKVPost(request, server_url)\n        if response is None:\n            return False\n        return self._processCheckAuthResponse(response)\n\n    def _createCheckAuthRequest(self, query):\n        signed = query.get('openid.signed')\n        if signed is None:\n            oidutil.log('No signature present; checkAuth aborted')\n            return None\n\n        # Arguments that are always passed to the server and not\n        # included in the signature.\n        whitelist = ['assoc_handle', 'sig', 'signed', 'invalidate_handle']\n        signed = signed.split(',') + whitelist\n\n        check_args = dict([(k, v) for k, v in query.iteritems()\n                           if k.startswith('openid.') and k[7:] in signed])\n\n        check_args['openid.mode'] = 'check_authentication'\n        return check_args\n\n    def _processCheckAuthResponse(self, response):\n        is_valid = response.get('is_valid', 'false')\n\n        if is_valid == 'true':\n            invalidate_handle = response.get('invalidate_handle')\n            if invalidate_handle is not None:\n                self.store.removeAssociation(server_url, invalidate_handle)\n\n            return True\n\n        oidutil.log('Server responds that checkAuth call is not valid')\n        return False\n\n    def _getAssociation(self, server_url):\n        if self.store.isDumb():\n            return None\n\n        assoc = self.store.getAssociation(server_url)\n\n        if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME:\n            proto = urlparse(server_url)[0]\n            if proto == 'https':\n                dh = None\n            else:\n                dh = DiffieHellman()\n\n            args = self._createAssociateRequest(dh)\n            try:\n                response = self._makeKVPost(args, server_url)\n            except fetchers.HTTPFetchingError, why:\n                oidutil.log('openid.associate request failed: %s' %\n                            (str(why),))\n                assoc = None\n            else:\n                assoc = self._parseAssociation(response, dh, server_url)\n\n        return assoc\n\n    def _genToken(self, nonce, consumer_id, server_id, server_url):\n        timestamp = str(int(time.time()))\n        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n        joined = '\\x00'.join(elements)\n        sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n\n        return oidutil.toBase64('%s%s' % (sig, joined))\n\n    def _splitToken(self, token):\n        token = oidutil.fromBase64(token)\n        if len(token) < 20:\n            raise ValueError('Bad token length: %d' % len(token))\n\n        sig, joined = token[:20], token[20:]\n        if cryptutil.hmacSha1(self.store.getAuthKey(), joined) != sig:\n            raise ValueError('Bad token signature')\n\n        split = joined.split('\\x00')\n        if len(split) != 5:\n            raise ValueError('Bad token contents (not enough fields)')\n\n        try:\n            ts = int(split[0])\n        except ValueError:\n            raise ValueError('Bad token contents (timestamp bad)')\n\n        if ts + self.TOKEN_LIFETIME < time.time():\n            raise ValueError('Token expired')\n\n        return tuple(split[1:])\n\n    def _createAssociateRequest(self, dh=None, args=None):\n        if args is None:\n            args = {}\n\n        args.update({\n            'openid.mode': 'associate',\n            'openid.assoc_type':'HMAC-SHA1',\n            })\n\n        if dh:\n            cpub = cryptutil.longToBase64(dh.public)\n\n            args.update({\n                'openid.session_type':'DH-SHA1',\n                'openid.dh_consumer_public': cpub,\n                })\n\n            if not dh.usingDefaultValues():\n                args.update({\n                    'openid.dh_modulus': cryptutil.longToBase64(dh.modulus),\n                    'openid.dh_gen': cryptutil.longToBase64(dh.generator),\n                    })\n\n        return args\n\n    def _parseAssociation(self, results, dh, server_url):\n        try:\n            assoc_type = results['assoc_type']\n            if assoc_type != 'HMAC-SHA1':\n                fmt = 'Unsupported assoc_type returned from server %s: %s'\n                oidutil.log(fmt % (server_url, assoc_type))\n                return None\n\n            assoc_handle = results['assoc_handle']\n            try:\n                expires_in = int(results.get('expires_in', '0'))\n            except ValueError, e:\n                fmt = 'Getting Association: invalid expires_in field: %s'\n                oidutil.log(fmt % (e[0],))\n                return None\n\n            session_type = results.get('session_type')\n            if session_type is None:\n                secret = oidutil.fromBase64(results['mac_key'])\n            else:\n                if session_type != 'DH-SHA1':\n                    fmt = 'Unsupported session_type from server %s: %s'\n                    oidutil.log(fmt % (server_url, session_type))\n                    return None\n                if dh is None:\n                    fmt = 'Not expecting a DH-SHA1 session from server %s'\n                    oidutil.log(fmt % (server_url))\n                    return None\n\n                spub = cryptutil.base64ToLong(results['dh_server_public'])\n                enc_mac_key = oidutil.fromBase64(results['enc_mac_key'])\n                secret = dh.xorSecret(spub, enc_mac_key)\n\n            assoc = Association.fromExpiresIn(\n                expires_in, assoc_handle, secret, assoc_type)\n            self.store.storeAssociation(server_url, assoc)\n\n            return assoc\n\n        except KeyError, e:\n            fmt = 'Getting association: missing key in response from %s: %s'\n            oidutil.log(fmt % (server_url, e[0]))\n            return None\n\nclass OpenIDAuthRequest(object):\n    def __init__(self, token, assoc, endpoint):\n        \"\"\"\n        Creates a new OpenIDAuthRequest object.  This just stores each\n        argument in an appropriately named field.\n\n        Users of this library should not create instances of this\n        class.  Instances of this class are created by the library\n        when needed.\n        \"\"\"\n        self.assoc = assoc\n        self.endpoint = endpoint\n        self.extra_args = {}\n        self.token = token\n\n    def addExtensionArg(self, namespace, key, value):\n        arg_name = '.'.join('openid', namespace, key)\n        self.extra_args[arg_name] = value\n\n    def redirectURL(self, trust_root, return_to, immediate=False):\n        if immediate:\n            mode = 'checkid_immediate'\n        else:\n            mode = 'checkid_setup'\n\n        redir_args = {\n            'openid.mode': mode,\n            'openid.identity': self.endpoint.getServerID(),\n            'openid.return_to': return_to,\n            'openid.trust_root': trust_root,\n            }\n\n        if self.assoc:\n            redir_args['openid.assoc_handle'] = self.assoc.handle\n\n        redir_args.update(self.extra_args)\n        return oidutil.appendArgs(self.endpoint.server_url, redir_args)\n\nclass OpenIDConsumerResponse(object):\n    status = None\n\nclass SuccessResponse(OpenIDConsumerResponse):\n    status = 'success'\n\n    def __init__(self, identity_url, signed_args):\n        self.identity_url = identity_url\n        self.signed_args = signed_args\n\n    def fromQuery(cls, identity_url, query, signed):\n        signed_args = {}\n        for field_name in signed.split(','):\n            field_name = 'openid.' + field_name\n            signed_args[field_name] = query.get(field_name, '')\n        return cls(identity_url, signed_args)\n\n    fromQuery = classmethod(fromQuery)\n\n    def extensionResponse(self, prefix):\n        response = {}\n        prefix = 'openid.%s.' % (prefix,)\n        prefix_len = len(prefix)\n        for k, v in self.signed_args.iteritems():\n            if k.startswith(prefix):\n                response_key = k[prefix_len:]\n                response[response_key] = v\n\n        return response\n\nclass FailureResponse(OpenIDConsumerResponse):\n    status = 'failure'\n\n    def __init__(self, identity_url=None, message=None):\n        self.identity_url = identity_url\n        self.message = message\n\nclass CancelResponse(OpenIDConsumerResponse):\n    status = 'cancelled'\n\n    def __init__(self, identity_url=None):\n        self.identity_url = identity_url\n\nclass SetupNeededResponse(OpenIDConsumerResponse):\n    status = 'setup_needed'\n\n    def __init__(self, identity_url=None, setup_url=None):\n        self.identity_url = identity_url\n        self.setup_url = setup_url\n"},"\/test\/consumer.py":{"changes":[{"diff":"\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n","add":5,"remove":2,"filename":"\/test\/consumer.py","badparts":["            'openid.return_to':return_to,","            'openid.return_to':return_to,"],"goodparts":["        new_return_to = q['openid.return_to']","        del q['openid.return_to']","        assert new_return_to.startswith(return_to)","            'nonce':request.return_to_args['nonce'],","            'openid.return_to':new_return_to,"]},{"diff":"\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","add":1,"remove":1,"filename":"\/test\/consumer.py","badparts":["        assert info.status == 'success'"],"goodparts":["        assert info.status == 'success', info.message"]}],"source":"\nimport urlparse import cgi import time from openid import cryptutil, dh, oidutil, kvform from openid.consumer.discover import OpenIDServiceEndpoint from openid.consumer.consumer import GenericOpenIDConsumer from openid import association from openid.consumer import parse from urljr.fetchers import HTTPResponse from urljr import fetchers import _memstore assocs=[ ('another 20-byte key.', 'Snarky'), ('\\x00' * 20, 'Zeros'), ] def parseQuery(qs): q={} for(k, v) in cgi.parse_qsl(qs): assert not q.has_key(k) q[k]=v return q def associate(qs, assoc_secret, assoc_handle): \"\"\"Do the server's half of the associate call, using the given secret and handle.\"\"\" q=parseQuery(qs) assert q['openid.mode']=='associate' assert q['openid.assoc_type']=='HMAC-SHA1' if q.get('openid.session_type')=='DH-SHA1': assert len(q)==6 or len(q)==4 d=dh.DiffieHellman.fromBase64( q.get('openid.dh_modulus'), q.get('openid.dh_gen')) composite=cryptutil.base64ToLong(q['openid.dh_consumer_public']) enc_mac_key=oidutil.toBase64(d.xorSecret(composite, assoc_secret)) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'session_type':'DH-SHA1', 'dh_server_public':cryptutil.longToBase64(d.public), 'enc_mac_key':enc_mac_key, } else: assert len(q)==2 mac_key=oidutil.toBase64(assoc_secret) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'mac_key':mac_key, } return kvform.dictToKV(reply_dict) class TestFetcher(object): def __init__(self, user_url, user_page,(assoc_secret, assoc_handle)): self.get_responses={user_url:self.response(user_url, 200, user_page)} self.assoc_secret=assoc_secret self.assoc_handle=assoc_handle self.num_assocs=0 def response(self, url, status, body): return HTTPResponse( final_url=url, status=status, headers={}, body=body) def fetch(self, url, body=None, headers=None): if body is None: if url in self.get_responses: return self.get_responses[url] else: try: body.index('openid.mode=associate') except ValueError: pass else: if urlparse.urlparse(url)[0]=='https': assert body.find('DH-SHA1')==-1 else: assert body.find('DH-SHA1') !=-1 response=associate( body, self.assoc_secret, self.assoc_handle) self.num_assocs +=1 return self.response(url, 200, response) return self.response(url, 404, 'Not found') def _test_success(server_url, user_url, delegate_url, links, immediate=False): store=_memstore.MemoryStore() if immediate: mode='checkid_immediate' else: mode='checkid_setup' endpoint=OpenIDServiceEndpoint() endpoint.identity_url=user_url endpoint.server_url=server_url endpoint.delegate=delegate_url fetcher=TestFetcher(None, None, assocs[0]) fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False) def run(): trust_root=consumer_url consumer=GenericOpenIDConsumer(store) request=consumer.begin(endpoint) return_to=consumer_url redirect_url=request.redirectURL(trust_root, return_to, immediate) parsed=urlparse.urlparse(redirect_url) qs=parsed[4] q=parseQuery(qs) assert q=={ 'openid.mode':mode, 'openid.identity':delegate_url, 'openid.trust_root':trust_root, 'openid.assoc_handle':fetcher.assoc_handle, 'openid.return_to':return_to, },(q, user_url, delegate_url, mode) assert redirect_url.startswith(server_url) query={ 'openid.mode':'id_res', 'openid.return_to':return_to, 'openid.identity':delegate_url, 'openid.assoc_handle':fetcher.assoc_handle, } assoc=store.getAssociation(server_url, fetcher.assoc_handle) assoc.addSignature(['mode', 'return_to', 'identity'], query) info=consumer.complete(query, request.token) assert info.status=='success' assert info.identity_url==user_url assert fetcher.num_assocs==0 run() assert fetcher.num_assocs==1 run() assert fetcher.num_assocs==1 store.removeAssociation(server_url, fetcher.assoc_handle) run() assert fetcher.num_assocs==2 run() assert fetcher.num_assocs==2 import unittest http_server_url='http:\/\/server.example.com\/' consumer_url='http:\/\/consumer.example.com\/' https_server_url='https:\/\/server.example.com\/' class TestSuccess(unittest.TestCase): server_url=http_server_url user_url='http:\/\/www.example.com\/user.html' delegate_url='http:\/\/consumer.example.com\/user' def setUp(self): self.links='<link rel=\"openid.server\" href=\"%s\" \/>' %( self.server_url,) self.delegate_links=('<link rel=\"openid.server\" href=\"%s\" \/>' '<link rel=\"openid.delegate\" href=\"%s\" \/>') %( self.server_url, self.delegate_url) def test_nodelegate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links) def test_nodelegateImmediate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links, True) def test_delegate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links) def test_delegateImmediate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links, True) class TestSuccessHTTPS(TestSuccess): server_url=https_server_url class TestConstruct(unittest.TestCase): def setUp(self): self.store_sentinel=object() def test_construct(self): oidc=GenericOpenIDConsumer(self.store_sentinel) self.failUnless(oidc.store is self.store_sentinel) def test_nostore(self): self.failUnlessRaises(TypeError, GenericOpenIDConsumer) class TestIdRes(unittest.TestCase): consumer_class=GenericOpenIDConsumer def setUp(self): self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.return_to=\"nonny\" self.server_id=\"sirod\" self.server_url=\"serlie\" self.consumer_id=\"consu\" class TestSetupNeeded(TestIdRes): def test_setupNeeded(self): setup_url='http:\/\/unittest\/setup-here' query={ 'openid.mode': 'id_res', 'openid.user_setup_url': setup_url, } ret=self.consumer._doIdRes(query, self.consumer_id, self.server_id, self.server_url, ) self.failUnlessEqual(ret.status, 'setup_needed') self.failUnlessEqual(ret.setup_url, setup_url) class CheckAuthHappened(Exception): pass class CheckAuthDetectingConsumer(GenericOpenIDConsumer): def _checkAuth(self, *args): raise CheckAuthHappened(args) class CatchLogs(object): def setUp(self): self.old_logger=oidutil.log oidutil.log=self.gotLogMessage self.messages=[] def gotLogMessage(self, message): self.messages.append(message) def tearDown(self): oidutil.log=self.old_logger class TestCheckAuthTriggered(TestIdRes, CatchLogs): consumer_class=CheckAuthDetectingConsumer def setUp(self): TestIdRes.setUp(self) CatchLogs.setUp(self) def _doIdRes(self, query): return self.consumer._doIdRes( query, self.consumer_id, self.server_id, self.server_url) def test_checkAuthTriggered(self): query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r %s' % (result, self.messages)) def test_checkAuthTriggeredWithAssoc(self): issued=time.time() lifetime=1000 assoc=association.Association( 'handle', 'secret', issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r' %(result,)) def test_expiredAssoc(self): issued=time.time() -10 lifetime=0 handle='handle' assoc=association.Association( handle, 'secret', issued, lifetime, 'HMAC-SHA1') self.failUnless(assoc.expiresIn <=0) self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':handle, } info=self._doIdRes(query) self.failUnlessEqual('failure', info.status) self.failUnlessEqual(self.consumer_id, info.identity_url) info.message.index('expired') def test_newerAssoc(self): lifetime=1000 good_issued=time.time() -10 good_handle='handle' good_assoc=association.Association( good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, good_assoc) bad_issued=time.time() -5 bad_handle='handle2' bad_assoc=association.Association( bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, bad_assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':good_handle, } good_assoc.addSignature(['return_to', 'identity'], query) info=self._doIdRes(query) self.failUnlessEqual(info.status, 'success') self.failUnlessEqual(self.consumer_id, info.identity_url) class MockFetcher(object): def __init__(self, response=None): self.response=response or HTTPResponse() self.fetches=[] def fetch(self, url, body=None, headers=None): self.fetches.append((url, body, headers)) return self.response class ExceptionRaisingMockFetcher(object): def fetch(self, url, body=None, headers=None): raise Exception('mock fetcher exception') class BadArgCheckingConsumer(GenericOpenIDConsumer): def _makeKVPost(self, args, _): assert args=={ 'openid.mode':'check_authentication', 'openid.signed':'foo', }, args return None class TestCheckAuth(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') query={'openid.signed': 'stuff, things'} r=self.consumer._checkAuth(query, http_server_url) self.failIf(r) self.failUnless(self.messages) def test_bad_args(self): query={ 'openid.signed':'foo', 'closid.foo':'something', } consumer=BadArgCheckingConsumer(self.store) consumer._checkAuth(query, 'does:\/\/not.matter') class TestFetchAssoc(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.consumer=self.consumer_class(self.store) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') r=self.consumer._makeKVPost({'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnlessEqual(r, None) self.failUnless(self.messages) def test_error_exception(self): self.fetcher=ExceptionRaisingMockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._makeKVPost, {'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnless(self.consumer._getAssociation('some:\/\/url') is None) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._checkAuth, {'openid.signed':''}, 'some:\/\/url') if __name__=='__main__': unittest.main() ","sourceWithComments":"import urlparse\nimport cgi\nimport time\n\nfrom openid import cryptutil, dh, oidutil, kvform\nfrom openid.consumer.discover import OpenIDServiceEndpoint\nfrom openid.consumer.consumer import GenericOpenIDConsumer\nfrom openid import association\n\nfrom openid.consumer import parse\n\nfrom urljr.fetchers import HTTPResponse\nfrom urljr import fetchers\n\nimport _memstore\n\nassocs = [\n    ('another 20-byte key.', 'Snarky'),\n    ('\\x00' * 20, 'Zeros'),\n    ]\n\ndef parseQuery(qs):\n    q = {}\n    for (k, v) in cgi.parse_qsl(qs):\n        assert not q.has_key(k)\n        q[k] = v\n    return q\n\ndef associate(qs, assoc_secret, assoc_handle):\n    \"\"\"Do the server's half of the associate call, using the given\n    secret and handle.\"\"\"\n    q = parseQuery(qs)\n    assert q['openid.mode'] == 'associate'\n    assert q['openid.assoc_type'] == 'HMAC-SHA1'\n    if q.get('openid.session_type') == 'DH-SHA1':\n        assert len(q) == 6 or len(q) == 4\n        d = dh.DiffieHellman.fromBase64(\n            q.get('openid.dh_modulus'), q.get('openid.dh_gen'))\n\n        composite = cryptutil.base64ToLong(q['openid.dh_consumer_public'])\n        enc_mac_key = oidutil.toBase64(d.xorSecret(composite, assoc_secret))\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'session_type':'DH-SHA1',\n            'dh_server_public':cryptutil.longToBase64(d.public),\n            'enc_mac_key':enc_mac_key,\n            }\n    else:\n        assert len(q) == 2\n        mac_key = oidutil.toBase64(assoc_secret)\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'mac_key':mac_key,\n            }\n\n    return kvform.dictToKV(reply_dict)\n\nclass TestFetcher(object):\n    def __init__(self, user_url, user_page, (assoc_secret, assoc_handle)):\n        self.get_responses = {user_url:self.response(user_url, 200, user_page)}\n        self.assoc_secret = assoc_secret\n        self.assoc_handle = assoc_handle\n        self.num_assocs = 0\n\n    def response(self, url, status, body):\n        return HTTPResponse(\n            final_url=url, status=status, headers={}, body=body)\n\n    def fetch(self, url, body=None, headers=None):\n        if body is None:\n            if url in self.get_responses:\n                return self.get_responses[url]\n        else:\n            try:\n                body.index('openid.mode=associate')\n            except ValueError:\n                pass # fall through\n            else:\n                if urlparse.urlparse(url)[0] == 'https':\n                    # Should not be doing DH-SHA1 when using HTTPS.\n                    assert body.find('DH-SHA1') == -1\n                else:\n                    assert body.find('DH-SHA1') != -1\n                response = associate(\n                    body, self.assoc_secret, self.assoc_handle)\n                self.num_assocs += 1\n                return self.response(url, 200, response)\n\n        return self.response(url, 404, 'Not found')\n\ndef _test_success(server_url, user_url, delegate_url, links, immediate=False):\n    store = _memstore.MemoryStore()\n    if immediate:\n        mode = 'checkid_immediate'\n    else:\n        mode = 'checkid_setup'\n\n    endpoint = OpenIDServiceEndpoint()\n    endpoint.identity_url = user_url\n    endpoint.server_url = server_url\n    endpoint.delegate = delegate_url\n\n    fetcher = TestFetcher(None, None, assocs[0])\n    fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False)\n\n    def run():\n        trust_root = consumer_url\n\n        consumer = GenericOpenIDConsumer(store)\n        request = consumer.begin(endpoint)\n\n        return_to = consumer_url\n        redirect_url = request.redirectURL(trust_root, return_to, immediate)\n\n        parsed = urlparse.urlparse(redirect_url)\n        qs = parsed[4]\n        q = parseQuery(qs)\n        assert q == {\n            'openid.mode':mode,\n            'openid.identity':delegate_url,\n            'openid.trust_root':trust_root,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            'openid.return_to':return_to,\n            }, (q, user_url, delegate_url, mode)\n\n        assert redirect_url.startswith(server_url)\n\n        query = {\n            'openid.mode':'id_res',\n            'openid.return_to':return_to,\n            'openid.identity':delegate_url,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            }\n\n        assoc = store.getAssociation(server_url, fetcher.assoc_handle)\n        assoc.addSignature(['mode', 'return_to', 'identity'], query)\n\n        info = consumer.complete(query, request.token)\n        assert info.status == 'success'\n        assert info.identity_url == user_url\n\n    assert fetcher.num_assocs == 0\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Another association is created if we remove the existing one\n    store.removeAssociation(server_url, fetcher.assoc_handle)\n    run()\n    assert fetcher.num_assocs == 2\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 2\n\nimport unittest\n\nhttp_server_url = 'http:\/\/server.example.com\/'\nconsumer_url = 'http:\/\/consumer.example.com\/'\nhttps_server_url = 'https:\/\/server.example.com\/'\n\nclass TestSuccess(unittest.TestCase):\n    server_url = http_server_url\n    user_url = 'http:\/\/www.example.com\/user.html'\n    delegate_url = 'http:\/\/consumer.example.com\/user'\n\n    def setUp(self):\n        self.links = '<link rel=\"openid.server\" href=\"%s\" \/>' % (\n            self.server_url,)\n\n        self.delegate_links = ('<link rel=\"openid.server\" href=\"%s\" \/>'\n                               '<link rel=\"openid.delegate\" href=\"%s\" \/>') % (\n            self.server_url, self.delegate_url)\n\n    def test_nodelegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links)\n\n    def test_nodelegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links, True)\n\n    def test_delegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links)\n\n    def test_delegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links, True)\n\n\nclass TestSuccessHTTPS(TestSuccess):\n    server_url = https_server_url\n\n\nclass TestConstruct(unittest.TestCase):\n    def setUp(self):\n        self.store_sentinel = object()\n\n    def test_construct(self):\n        oidc = GenericOpenIDConsumer(self.store_sentinel)\n        self.failUnless(oidc.store is self.store_sentinel)\n\n    def test_nostore(self):\n        self.failUnlessRaises(TypeError, GenericOpenIDConsumer)\n\n\nclass TestIdRes(unittest.TestCase):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        self.store = _memstore.MemoryStore()\n        self.consumer = self.consumer_class(self.store)\n        self.return_to = \"nonny\"\n        self.server_id = \"sirod\"\n        self.server_url = \"serlie\"\n        self.consumer_id = \"consu\"\n\nclass TestSetupNeeded(TestIdRes):\n    def test_setupNeeded(self):\n        setup_url = 'http:\/\/unittest\/setup-here'\n        query = {\n            'openid.mode': 'id_res',\n            'openid.user_setup_url': setup_url,\n            }\n        ret = self.consumer._doIdRes(query,\n                                     self.consumer_id,\n                                     self.server_id,\n                                     self.server_url,\n                                     )\n        self.failUnlessEqual(ret.status, 'setup_needed')\n        self.failUnlessEqual(ret.setup_url, setup_url)\n\nclass CheckAuthHappened(Exception): pass\n\nclass CheckAuthDetectingConsumer(GenericOpenIDConsumer):\n    def _checkAuth(self, *args):\n        raise CheckAuthHappened(args)\n\nclass CatchLogs(object):\n    def setUp(self):\n        self.old_logger = oidutil.log\n        oidutil.log = self.gotLogMessage\n        self.messages = []\n\n    def gotLogMessage(self, message):\n        self.messages.append(message)\n\n    def tearDown(self):\n        oidutil.log = self.old_logger\n\nclass TestCheckAuthTriggered(TestIdRes, CatchLogs):\n    consumer_class = CheckAuthDetectingConsumer\n\n    def setUp(self):\n        TestIdRes.setUp(self)\n        CatchLogs.setUp(self)\n\n    def _doIdRes(self, query):\n        return self.consumer._doIdRes(\n            query,\n            self.consumer_id,\n            self.server_id,\n            self.server_url)\n\n    def test_checkAuthTriggered(self):\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r %s' %\n                      (result, self.messages))\n\n    def test_checkAuthTriggeredWithAssoc(self):\n        # Store an association for this server that does not match the\n        # handle that is in the query\n        issued = time.time()\n        lifetime = 1000\n        assoc = association.Association(\n            'handle', 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r' % (result,))\n\n    def test_expiredAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        issued = time.time() - 10\n        lifetime = 0\n        handle = 'handle'\n        assoc = association.Association(\n            handle, 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.failUnless(assoc.expiresIn <= 0)\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':handle,\n            }\n        info = self._doIdRes(query)\n        self.failUnlessEqual('failure', info.status)\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n        info.message.index('expired') # raises an exception if it's not there\n\n    def test_newerAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        lifetime = 1000\n\n        good_issued = time.time() - 10\n        good_handle = 'handle'\n        good_assoc = association.Association(\n            good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, good_assoc)\n\n        bad_issued = time.time() - 5\n        bad_handle = 'handle2'\n        bad_assoc = association.Association(\n            bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, bad_assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':good_handle,\n            }\n\n        good_assoc.addSignature(['return_to', 'identity'], query)\n        info = self._doIdRes(query)\n        self.failUnlessEqual(info.status, 'success')\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n\n\nclass MockFetcher(object):\n    def __init__(self, response=None):\n        self.response = response or HTTPResponse()\n        self.fetches = []\n\n    def fetch(self, url, body=None, headers=None):\n        self.fetches.append((url, body, headers))\n        return self.response\n\nclass ExceptionRaisingMockFetcher(object):\n    def fetch(self, url, body=None, headers=None):\n        raise Exception('mock fetcher exception')\n\nclass BadArgCheckingConsumer(GenericOpenIDConsumer):\n    def _makeKVPost(self, args, _):\n        assert args == {\n            'openid.mode':'check_authentication',\n            'openid.signed':'foo',\n            }, args\n        return None\n\nclass TestCheckAuth(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n\n        self.consumer = self.consumer_class(self.store)\n\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        query = {'openid.signed': 'stuff, things'}\n        r = self.consumer._checkAuth(query, http_server_url)\n        self.failIf(r)\n        self.failUnless(self.messages)\n\n    def test_bad_args(self):\n        query = {\n            'openid.signed':'foo',\n            'closid.foo':'something',\n            }\n        consumer = BadArgCheckingConsumer(self.store)\n        consumer._checkAuth(query, 'does:\/\/not.matter')\n\nclass TestFetchAssoc(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.consumer = self.consumer_class(self.store)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        r = self.consumer._makeKVPost({'openid.mode':'associate'},\n                                      \"http:\/\/server_url\")\n        self.failUnlessEqual(r, None)\n        self.failUnless(self.messages)\n\n    def test_error_exception(self):\n        self.fetcher = ExceptionRaisingMockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._makeKVPost,\n                              {'openid.mode':'associate'},\n                              \"http:\/\/server_url\")\n\n        # exception fetching returns no association\n        self.failUnless(self.consumer._getAssociation('some:\/\/url') is None)\n\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._checkAuth,\n                              {'openid.signed':''},\n                              'some:\/\/url')\n\nif __name__ == '__main__':\n    unittest.main()\n"}},"msg":"[project @ Added nonce to return_to to fix replay attack vulnerability]"}},"https:\/\/github.com\/lillialexis\/python-openid":{"f05703e45f3ef162c4d927dc712b95cbac163bb4":{"url":"https:\/\/api.github.com\/repos\/lillialexis\/python-openid\/commits\/f05703e45f3ef162c4d927dc712b95cbac163bb4","html_url":"https:\/\/github.com\/lillialexis\/python-openid\/commit\/f05703e45f3ef162c4d927dc712b95cbac163bb4","message":"[project @ Added nonce to return_to to fix replay attack vulnerability]","sha":"f05703e45f3ef162c4d927dc712b95cbac163bb4","keyword":"replay attack vulnerable","diff":"diff --git a\/openid\/consumer\/consumer.py b\/openid\/consumer\/consumer.py\nindex b7a93bc..49f5663 100644\n--- a\/openid\/consumer\/consumer.py\n+++ b\/openid\/consumer\/consumer.py\n@@ -173,6 +173,7 @@\n import string\n import time\n import urllib\n+import cgi\n from urlparse import urlparse\n \n from urljr import fetchers\n@@ -279,13 +280,14 @@ class and its sublcasses.  For a filesystem-backed store,\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n@@ -295,9 +297,9 @@ def complete(self, query, token):\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n@@ -314,16 +316,39 @@ def complete(self, query, token):\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n@@ -466,9 +491,9 @@ def _getAssociation(self, server_url):\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n@@ -484,7 +509,7 @@ def _splitToken(self, token):\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n@@ -567,7 +592,7 @@ def _parseAssociation(self, results, dh, server_url):\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n@@ -579,6 +604,7 @@ def __init__(self, token, assoc, endpoint):\n         self.assoc = assoc\n         self.endpoint = endpoint\n         self.extra_args = {}\n+        self.return_to_args = {}\n         self.token = token\n \n     def addExtensionArg(self, namespace, key, value):\n@@ -591,6 +617,8 @@ def redirectURL(self, trust_root, return_to, immediate=False):\n         else:\n             mode = 'checkid_setup'\n \n+        return_to = oidutil.appendArgs(return_to, self.return_to_args)\n+\n         redir_args = {\n             'openid.mode': mode,\n             'openid.identity': self.endpoint.getServerID(),\n@@ -634,6 +662,9 @@ def extensionResponse(self, prefix):\n \n         return response\n \n+    def getReturnTo(self):\n+        return self.signed_args['openid.return_to']\n+\n class FailureResponse(OpenIDConsumerResponse):\n     status = 'failure'\n \ndiff --git a\/test\/consumer.py b\/test\/consumer.py\nindex 343c7a1..1b8fbe7 100644\n--- a\/test\/consumer.py\n+++ b\/test\/consumer.py\n@@ -119,19 +119,22 @@ def run():\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n@@ -140,7 +143,7 @@ def run():\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","files":{"\/openid\/consumer\/consumer.py":{"changes":[{"diff":"\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n","add":3,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            nonce,","        return OpenIDAuthRequest(token, assoc, service_endpoint)"],"goodparts":["        request = OpenIDAuthRequest(token, assoc, service_endpoint)","        request.return_to_args['nonce'] = nonce","        return request"]},{"diff":"\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            pieces = (None, None, None, None, None)","        (nonce, identity_url, delegate, server_url) = pieces"],"goodparts":["            pieces = (None, None, None)","        (identity_url, delegate, server_url) = pieces"]},{"diff":"\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n","add":27,"remove":4,"filename":"\/openid\/consumer\/consumer.py","badparts":["                if (response.status == 'success' and","                    not self.store.useNonce(nonce)):","                    return FailureResponse(identity_url, 'Nonce already used')"],"goodparts":["                if response.status == 'success':","                    return self._checkNonce(response, query.get('nonce'))","    def _checkNonce(self, response, nonce):","        parsed_url = urlparse(response.getReturnTo())","        query = parsed_url[4]","        for k, v in cgi.parse_qsl(query):","            if k == 'nonce':","                if v != nonce:","                    return FailureResponse(response.identity_url,","                                           'Nonce mismatch')","                else:","                    break","        else:","            return FailureResponse(response.identity_url,","                                   'Nonce missing from return_to: %r'","                                   % (response.getReturnTo()))","        if not self.store.useNonce(nonce):","            return FailureResponse(response.identity_url,","                                   'Nonce missing from store')","        return response"]},{"diff":"\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def _genToken(self, nonce, consumer_id, server_id, server_url):","        elements = [timestamp, nonce, consumer_id, server_id, server_url]"],"goodparts":["    def _genToken(self, consumer_id, server_id, server_url):","        elements = [timestamp, consumer_id, server_id, server_url]"]},{"diff":"\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["        if len(split) != 5:"],"goodparts":["        if len(split) != 4:"]},{"diff":"\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def __init__(self, token, assoc, endpoint):"],"goodparts":["    def __init__(self, token, assoc, endpoint  ):"]}],"source":"\n\"\"\" This module documents the main interface with the OpenID consumer libary. The only part of the library which has to be used and isn't documented in full here is the store required to create an C{L{OpenIDConsumer}} instance. More on the abstract store type and concrete implementations of it that are provided in the documentation for the C{L{__init__<OpenIDConsumer.__init__>}} method of the C{L{OpenIDConsumer}} class. OVERVIEW ======== The OpenID identity verification process most commonly uses the following steps, as visible to the user of this library: 1. The user enters their OpenID into a field on the consumer's site, and hits a login button. 2. The consumer site discovers the user's OpenID server using the YADIS protocol. 3. The consumer site sends the browser a redirect to the identity server. This is the authentication request as described in the OpenID specification. 4. The identity server's site sends the browser a redirect back to the consumer site. This redirect contains the server's response to the authentication request. The most important part of the flow to note is the consumer's site must handle two separate HTTP requests in order to perform the full identity check. LIBRARY DESIGN ============== This consumer library is designed with that flow in mind. The goal is to make it as easy as possible to perform the above steps securely. At a high level, there are two important parts in the consumer library. The first important part is this module, which contains the interface to actually use this library. The second is the C{L{openid.store.interface}} module, which describes the interface to use if you need to create a custom method for storing the state this library needs to maintain between requests. In general, the second part is less important for users of the library to know about, as several implementations are provided which cover a wide variety of situations in which consumers may use the library. This module contains a class, C{L{OpenIDConsumer}}, with methods corresponding to the actions necessary in each of steps 2, 3, and 4 described in the overview. Use of this library should be as easy as creating an C{L{OpenIDConsumer}} instance and calling the methods appropriate for the action the site wants to take. STORES AND DUMB MODE ==================== OpenID is a protocol that works best when the consumer site is able to store some state. This is the normal mode of operation for the protocol, and is sometimes referred to as smart mode. There is also a fallback mode, known as dumb mode, which is available when the consumer site is not able to store state. This mode should be avoided when possible, as it leaves the implementation more vulnerable to replay attacks. The mode the library works in for normal operation is determined by the store that it is given. The store is an abstraction that handles the data that the consumer needs to manage between http requests in order to operate efficiently and securely. Several store implementation are provided, and the interface is fully documented so that custom stores can be used as well. See the documentation for the C{L{OpenIDConsumer}} class for more information on the interface for stores. The implementations that are provided allow the consumer site to store the necessary data in several different ways, including several SQL databases and normal files on disk. There is an additional concrete store provided that puts the system in dumb mode. This is not recommended, as it removes the library's ability to stop replay attacks reliably. It still uses time-based checking to make replay attacks only possible within a small window, but they remain possible within that window. This store should only be used if the consumer site has no way to retain data between requests at all. IMMEDIATE MODE ============== In the flow described above, the user may need to confirm to the identity server that it's ok to authorize his or her identity. The server may draw pages asking for information from the user before it redirects the browser back to the consumer's site. This is generally transparent to the consumer site, so it is typically ignored as an implementation detail. There can be times, however, where the consumer site wants to get a response immediately. When this is the case, the consumer can put the library in immediate mode. In immediate mode, there is an extra response possible from the server, which is essentially the server reporting that it doesn't have enough information to answer the question yet. In addition to saying that, the identity server provides a URL to which the user can be sent to provide the needed information and let the server finish handling the original request. USING THIS LIBRARY ================== Integrating this library into an application is usually a relatively straightforward process. The process should basically follow this plan: Add an OpenID login field somewhere on your site. When an OpenID is entered in that field and the form is submitted, it should make a request to the your site which includes that OpenID URL. To start, the application should get an C{L{OpenIDConsumer}} instance, and call its C{L{begin<OpenIDConsumer.begin>}} method. This method takes the OpenID URL and, optionally, a session object. If the application has any sort of session framework that provides per-client state management, that should be used here. The library just expects the session object to support a C{dict}-like interface, if it provided. If no session object is provided, the application code needs to store the information that would have been put in the session in an alternate location. See the documentation for the C{L{begin<OpenIDConsumer.begin>}} call for more information. The C{L{begin<OpenIDConsumer.begin>}} method returns an C{L{OpenIDRequestBuilder}} object. Next, the application should call the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on the C{L{OpenIDRequestBuilder}} object. The return_to URL is the URL that the OpenID server will send the user back to after attempting to verify his or her identity. The trust_root is the URL(or URL pattern) that identifies your web site to the user when he or she is authorizing it. Send a redirect to the resulting URL to the user's browser. That's the first half of the authentication process. The second half of the process is done after the user's ID server sends the user's browser a redirect back to your site to complete their login. When that happens, the user will contact your site at the URL given as the C{return_to} URL to the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made above. The request will have several query parameters added to the URL by the identity server as the information necessary to finish the request. Get an C{L{OpenIDConsumer}} instance, and call its C{L{complete<OpenIDConsumer.complete>}} method, passing in all the received query arguments and either the user's session object or the token saved earlier. See the documentation for C{L{OpenIDRequestBuilder}} for more information about the token. There are multiple possible return types possible from that method. These indicate the whether or not the login was successful, and include any additional information appropriate for their type. \"\"\" import string import time import urllib from urlparse import urlparse from urljr import fetchers from openid.consumer.discover import discover as openIDDiscover from openid.consumer.discover import yadis_available from openid import cryptutil from openid import kvform from openid import oidutil from openid.association import Association from openid.dh import DiffieHellman __all__=['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse', 'SetupNeededResponse', 'CancelResponse', 'FailureResponse'] if yadis_available: from yadis.manager import Discovery class OpenIDConsumer(object): session_key_prefix=\"_openid_consumer_\" _token='last_token' def __init__(self, session, store): self.session=session self.consumer=GenericOpenIDConsumer(store) self._token_key=self.session_key_prefix +self._token def begin(self, user_url): openid_url=oidutil.normalizeUrl(user_url) if yadis_available: disco=Discovery(self.session, openid_url, 'XXX') endpoint=disco.getNextService(openIDDiscover) else: _, endpoints=openIDDiscover(openid_url) if not endpoints: endpoint=None else: endpoint=endpoints[0] if endpoint is None: return None else: return self.beginWithoutDiscovery(endpoint) def beginWithoutDiscovery(self, endpoint): auth_req=self.consumer.begin(endpoint) self.session[self._token_key]=auth_req.token return auth_req def complete(self, query): token=self.session.get(self._token_key) if token is None: response=FailureResponse(None, 'No session state found') else: response=self.consumer.complete(query, token) if response.status in['success', 'cancel' ]: if yadis_available and response.identity_url is not None: disco=Discovery(self.session, response.identity_url) disco.cleanup() return response class GenericOpenIDConsumer(object): \"\"\"This is the implementation of the common logic for OpenID consumers. It is unaware of the application in which it is running. \"\"\" TOKEN_LIFETIME=60 * 5 NONCE_LEN=8 NONCE_CHRS=string.letters +string.digits def __init__(self, store): \"\"\" This method initializes a new C{L{OpenIDConsumer}} instance to access the library. @param store: This must be an object that implements the interface in C{L{openid.store.interface.OpenIDStore}}. Several concrete implementations are provided, to cover most common use cases. For stores backed by MySQL or SQLite, see the C{L{openid.store.sqlstore.SQLStore}} class and its sublcasses. For a filesystem-backed store, see the C{L{openid.store.filestore}} module. As a last resort, if it isn't possible for the server to store state at all, an instance of C{L{openid.store.dumbstore.DumbStore}} can be used. This should be an absolute last resort, though, as it makes the consumer vulnerable to replay attacks over the lifespan of the tokens the library creates. @type store: C{L{openid.store.interface.OpenIDStore}} \"\"\" self.store=store def begin(self, service_endpoint): nonce=self._createNonce() token=self._genToken( nonce, service_endpoint.identity_url, service_endpoint.getServerID(), service_endpoint.server_url, ) assoc=self._getAssociation(service_endpoint.server_url) return OpenIDAuthRequest(token, assoc, service_endpoint) def complete(self, query, token): mode=query.get('openid.mode', '<no mode specified>') try: pieces=self._splitToken(token) except ValueError, why: oidutil.log(why[0]) pieces=(None, None, None, None, None) (nonce, identity_url, delegate, server_url)=pieces if mode=='cancel': return CancelResponse(identity_url) elif mode=='error': error=query.get('openid.error') return FailureResponse(identity_url, error) elif mode=='id_res': if identity_url is None: return FailureResponse(identity_url, 'No session state found') try: response=self._doIdRes( query, identity_url, delegate, server_url) except fetchers.HTTPFetchingError, why: message='HTTP request failed: %s' %(str(why),) return FailureResponse(identity_url, message) else: if(response.status=='success' and not self.store.useNonce(nonce)): return FailureResponse(identity_url, 'Nonce already used') else: return response else: return FailureResponse(identity_url, 'Invalid openid.mode: %r' %(mode,)) def _createNonce(self): nonce=cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS) self.store.storeNonce(nonce) return nonce def _makeKVPost(self, args, server_url): mode=args['openid.mode'] body=urllib.urlencode(args) resp=fetchers.fetch(server_url, body=body) if resp is None: fmt='openid.mode=%s: failed to fetch URL: %s' oidutil.log(fmt %(mode, server_url)) return None response=kvform.kvToDict(resp.body) if resp.status==400: server_error=response.get('error', '<no message from server>') fmt='openid.mode=%s: error returned from server %s: %s' oidutil.log(fmt %(mode, server_url, server_error)) return None elif resp.status !=200: fmt='openid.mode=%s: bad status code from server %s: %s' oidutil.log(fmt %(mode, server_url, resp.status)) return None return response def _doIdRes(self, query, consumer_id, server_id, server_url): user_setup_url=query.get('openid.user_setup_url') if user_setup_url is not None: return SetupNeededResponse(consumer_id, user_setup_url) return_to=query.get('openid.return_to') server_id2=query.get('openid.identity') assoc_handle=query.get('openid.assoc_handle') if return_to is None or server_id is None or assoc_handle is None: return FailureResponse(consumer_id, 'Missing required field') if server_id !=server_id2: return FailureResponse(consumer_id, 'Server ID(delegate) mismatch') signed=query.get('openid.signed') assoc=self.store.getAssociation(server_url, assoc_handle) if assoc is None: if self._checkAuth(query, server_url): return SuccessResponse.fromQuery(consumer_id, query, signed) else: return FailureResponse(consumer_id, 'Server denied check_authentication') if assoc.expiresIn <=0: msg='Association with %s expired' %(server_url,) return FailureResponse(consumer_id, msg) sig=query.get('openid.sig') if sig is None or signed is None: return FailureResponse(consumer_id, 'Missing argument signature') signed_list=signed.split(',') v_sig=assoc.signDict(signed_list, query) if v_sig !=sig: return FailureResponse(consumer_id, 'Bad signature') return SuccessResponse.fromQuery(consumer_id, query, signed) def _checkAuth(self, query, server_url): request=self._createCheckAuthRequest(query) if request is None: return False response=self._makeKVPost(request, server_url) if response is None: return False return self._processCheckAuthResponse(response) def _createCheckAuthRequest(self, query): signed=query.get('openid.signed') if signed is None: oidutil.log('No signature present; checkAuth aborted') return None whitelist=['assoc_handle', 'sig', 'signed', 'invalidate_handle'] signed=signed.split(',') +whitelist check_args=dict([(k, v) for k, v in query.iteritems() if k.startswith('openid.') and k[7:] in signed]) check_args['openid.mode']='check_authentication' return check_args def _processCheckAuthResponse(self, response): is_valid=response.get('is_valid', 'false') if is_valid=='true': invalidate_handle=response.get('invalidate_handle') if invalidate_handle is not None: self.store.removeAssociation(server_url, invalidate_handle) return True oidutil.log('Server responds that checkAuth call is not valid') return False def _getAssociation(self, server_url): if self.store.isDumb(): return None assoc=self.store.getAssociation(server_url) if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME: proto=urlparse(server_url)[0] if proto=='https': dh=None else: dh=DiffieHellman() args=self._createAssociateRequest(dh) try: response=self._makeKVPost(args, server_url) except fetchers.HTTPFetchingError, why: oidutil.log('openid.associate request failed: %s' % (str(why),)) assoc=None else: assoc=self._parseAssociation(response, dh, server_url) return assoc def _genToken(self, nonce, consumer_id, server_id, server_url): timestamp=str(int(time.time())) elements=[timestamp, nonce, consumer_id, server_id, server_url] joined='\\x00'.join(elements) sig=cryptutil.hmacSha1(self.store.getAuthKey(), joined) return oidutil.toBase64('%s%s' %(sig, joined)) def _splitToken(self, token): token=oidutil.fromBase64(token) if len(token) < 20: raise ValueError('Bad token length: %d' % len(token)) sig, joined=token[:20], token[20:] if cryptutil.hmacSha1(self.store.getAuthKey(), joined) !=sig: raise ValueError('Bad token signature') split=joined.split('\\x00') if len(split) !=5: raise ValueError('Bad token contents(not enough fields)') try: ts=int(split[0]) except ValueError: raise ValueError('Bad token contents(timestamp bad)') if ts +self.TOKEN_LIFETIME < time.time(): raise ValueError('Token expired') return tuple(split[1:]) def _createAssociateRequest(self, dh=None, args=None): if args is None: args={} args.update({ 'openid.mode': 'associate', 'openid.assoc_type':'HMAC-SHA1', }) if dh: cpub=cryptutil.longToBase64(dh.public) args.update({ 'openid.session_type':'DH-SHA1', 'openid.dh_consumer_public': cpub, }) if not dh.usingDefaultValues(): args.update({ 'openid.dh_modulus': cryptutil.longToBase64(dh.modulus), 'openid.dh_gen': cryptutil.longToBase64(dh.generator), }) return args def _parseAssociation(self, results, dh, server_url): try: assoc_type=results['assoc_type'] if assoc_type !='HMAC-SHA1': fmt='Unsupported assoc_type returned from server %s: %s' oidutil.log(fmt %(server_url, assoc_type)) return None assoc_handle=results['assoc_handle'] try: expires_in=int(results.get('expires_in', '0')) except ValueError, e: fmt='Getting Association: invalid expires_in field: %s' oidutil.log(fmt %(e[0],)) return None session_type=results.get('session_type') if session_type is None: secret=oidutil.fromBase64(results['mac_key']) else: if session_type !='DH-SHA1': fmt='Unsupported session_type from server %s: %s' oidutil.log(fmt %(server_url, session_type)) return None if dh is None: fmt='Not expecting a DH-SHA1 session from server %s' oidutil.log(fmt %(server_url)) return None spub=cryptutil.base64ToLong(results['dh_server_public']) enc_mac_key=oidutil.fromBase64(results['enc_mac_key']) secret=dh.xorSecret(spub, enc_mac_key) assoc=Association.fromExpiresIn( expires_in, assoc_handle, secret, assoc_type) self.store.storeAssociation(server_url, assoc) return assoc except KeyError, e: fmt='Getting association: missing key in response from %s: %s' oidutil.log(fmt %(server_url, e[0])) return None class OpenIDAuthRequest(object): def __init__(self, token, assoc, endpoint): \"\"\" Creates a new OpenIDAuthRequest object. This just stores each argument in an appropriately named field. Users of this library should not create instances of this class. Instances of this class are created by the library when needed. \"\"\" self.assoc=assoc self.endpoint=endpoint self.extra_args={} self.token=token def addExtensionArg(self, namespace, key, value): arg_name='.'.join('openid', namespace, key) self.extra_args[arg_name]=value def redirectURL(self, trust_root, return_to, immediate=False): if immediate: mode='checkid_immediate' else: mode='checkid_setup' redir_args={ 'openid.mode': mode, 'openid.identity': self.endpoint.getServerID(), 'openid.return_to': return_to, 'openid.trust_root': trust_root, } if self.assoc: redir_args['openid.assoc_handle']=self.assoc.handle redir_args.update(self.extra_args) return oidutil.appendArgs(self.endpoint.server_url, redir_args) class OpenIDConsumerResponse(object): status=None class SuccessResponse(OpenIDConsumerResponse): status='success' def __init__(self, identity_url, signed_args): self.identity_url=identity_url self.signed_args=signed_args def fromQuery(cls, identity_url, query, signed): signed_args={} for field_name in signed.split(','): field_name='openid.' +field_name signed_args[field_name]=query.get(field_name, '') return cls(identity_url, signed_args) fromQuery=classmethod(fromQuery) def extensionResponse(self, prefix): response={} prefix='openid.%s.' %(prefix,) prefix_len=len(prefix) for k, v in self.signed_args.iteritems(): if k.startswith(prefix): response_key=k[prefix_len:] response[response_key]=v return response class FailureResponse(OpenIDConsumerResponse): status='failure' def __init__(self, identity_url=None, message=None): self.identity_url=identity_url self.message=message class CancelResponse(OpenIDConsumerResponse): status='cancelled' def __init__(self, identity_url=None): self.identity_url=identity_url class SetupNeededResponse(OpenIDConsumerResponse): status='setup_needed' def __init__(self, identity_url=None, setup_url=None): self.identity_url=identity_url self.setup_url=setup_url ","sourceWithComments":"\"\"\"\nThis module documents the main interface with the OpenID consumer\nlibary.  The only part of the library which has to be used and isn't\ndocumented in full here is the store required to create an\nC{L{OpenIDConsumer}} instance.  More on the abstract store type and\nconcrete implementations of it that are provided in the documentation\nfor the C{L{__init__<OpenIDConsumer.__init__>}} method of the\nC{L{OpenIDConsumer}} class.\n\n\nOVERVIEW\n========\n\n    The OpenID identity verification process most commonly uses the\n    following steps, as visible to the user of this library:\n\n        1. The user enters their OpenID into a field on the consumer's\n           site, and hits a login button.\n\n        2. The consumer site discovers the user's OpenID server using\n           the YADIS protocol.\n\n        3. The consumer site sends the browser a redirect to the\n           identity server.  This is the authentication request as\n           described in the OpenID specification.\n\n        4. The identity server's site sends the browser a redirect\n           back to the consumer site.  This redirect contains the\n           server's response to the authentication request.\n\n    The most important part of the flow to note is the consumer's site\n    must handle two separate HTTP requests in order to perform the\n    full identity check.\n\n\nLIBRARY DESIGN\n==============\n\n    This consumer library is designed with that flow in mind.  The\n    goal is to make it as easy as possible to perform the above steps\n    securely.\n\n    At a high level, there are two important parts in the consumer\n    library.  The first important part is this module, which contains\n    the interface to actually use this library.  The second is the\n    C{L{openid.store.interface}} module, which describes the\n    interface to use if you need to create a custom method for storing\n    the state this library needs to maintain between requests.\n\n    In general, the second part is less important for users of the\n    library to know about, as several implementations are provided\n    which cover a wide variety of situations in which consumers may\n    use the library.\n\n    This module contains a class, C{L{OpenIDConsumer}}, with methods\n    corresponding to the actions necessary in each of steps 2, 3, and\n    4 described in the overview.  Use of this library should be as easy\n    as creating an C{L{OpenIDConsumer}} instance and calling the methods\n    appropriate for the action the site wants to take.\n\n\nSTORES AND DUMB MODE\n====================\n\n    OpenID is a protocol that works best when the consumer site is\n    able to store some state.  This is the normal mode of operation\n    for the protocol, and is sometimes referred to as smart mode.\n    There is also a fallback mode, known as dumb mode, which is\n    available when the consumer site is not able to store state.  This\n    mode should be avoided when possible, as it leaves the\n    implementation more vulnerable to replay attacks.\n\n    The mode the library works in for normal operation is determined\n    by the store that it is given.  The store is an abstraction that\n    handles the data that the consumer needs to manage between http\n    requests in order to operate efficiently and securely.\n\n    Several store implementation are provided, and the interface is\n    fully documented so that custom stores can be used as well.  See\n    the documentation for the C{L{OpenIDConsumer}} class for more\n    information on the interface for stores.  The implementations that\n    are provided allow the consumer site to store the necessary data\n    in several different ways, including several SQL databases and\n    normal files on disk.\n\n    There is an additional concrete store provided that puts the\n    system in dumb mode.  This is not recommended, as it removes the\n    library's ability to stop replay attacks reliably.  It still uses\n    time-based checking to make replay attacks only possible within a\n    small window, but they remain possible within that window.  This\n    store should only be used if the consumer site has no way to\n    retain data between requests at all.\n\n\nIMMEDIATE MODE\n==============\n\n    In the flow described above, the user may need to confirm to the\n    identity server that it's ok to authorize his or her identity.\n    The server may draw pages asking for information from the user\n    before it redirects the browser back to the consumer's site.  This\n    is generally transparent to the consumer site, so it is typically\n    ignored as an implementation detail.\n\n    There can be times, however, where the consumer site wants to get\n    a response immediately.  When this is the case, the consumer can\n    put the library in immediate mode.  In immediate mode, there is an\n    extra response possible from the server, which is essentially the\n    server reporting that it doesn't have enough information to answer\n    the question yet.  In addition to saying that, the identity server\n    provides a URL to which the user can be sent to provide the needed\n    information and let the server finish handling the original\n    request.\n\n\nUSING THIS LIBRARY\n==================\n\n    Integrating this library into an application is usually a\n    relatively straightforward process.  The process should basically\n    follow this plan:\n\n    Add an OpenID login field somewhere on your site.  When an OpenID\n    is entered in that field and the form is submitted, it should make\n    a request to the your site which includes that OpenID URL.\n\n    To start, the application should get an C{L{OpenIDConsumer}}\n    instance, and call its C{L{begin<OpenIDConsumer.begin>}} method.\n    This method takes the OpenID URL and, optionally, a session\n    object.  If the application has any sort of session framework that\n    provides per-client state management, that should be used here.\n    The library just expects the session object to support a\n    C{dict}-like interface, if it provided.  If no session object is\n    provided, the application code needs to store the information that\n    would have been put in the session in an alternate location.  See\n    the documentation for the C{L{begin<OpenIDConsumer.begin>}} call\n    for more information.  The C{L{begin<OpenIDConsumer.begin>}}\n    method returns an C{L{OpenIDRequestBuilder}} object.\n\n    Next, the application should call the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on\n    the C{L{OpenIDRequestBuilder}} object.  The return_to URL is the\n    URL that the OpenID server will send the user back to after\n    attempting to verify his or her identity.  The trust_root is the\n    URL (or URL pattern) that identifies your web site to the user\n    when he or she is authorizing it.  Send a redirect to the\n    resulting URL to the user's browser.\n\n    That's the first half of the authentication process.  The second\n    half of the process is done after the user's ID server sends the\n    user's browser a redirect back to your site to complete their\n    login.\n\n    When that happens, the user will contact your site at the URL\n    given as the C{return_to} URL to the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made\n    above.  The request will have several query parameters added to\n    the URL by the identity server as the information necessary to\n    finish the request.\n\n    Get an C{L{OpenIDConsumer}} instance, and call its\n    C{L{complete<OpenIDConsumer.complete>}} method, passing in all the\n    received query arguments and either the user's session object or\n    the token saved earlier.  See the documentation for\n    C{L{OpenIDRequestBuilder}} for more information about the token.\n\n    There are multiple possible return types possible from that\n    method.  These indicate the whether or not the login was\n    successful, and include any additional information appropriate for\n    their type.\n\"\"\"\n\nimport string\nimport time\nimport urllib\nfrom urlparse import urlparse\n\nfrom urljr import fetchers\n\nfrom openid.consumer.discover import discover as openIDDiscover\nfrom openid.consumer.discover import yadis_available\nfrom openid import cryptutil\nfrom openid import kvform\nfrom openid import oidutil\nfrom openid.association import Association\nfrom openid.dh import DiffieHellman\n\n__all__ = ['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse',\n           'SetupNeededResponse', 'CancelResponse', 'FailureResponse']\n\nif yadis_available:\n    from yadis.manager import Discovery\n\nclass OpenIDConsumer(object):\n    session_key_prefix = \"_openid_consumer_\"\n\n    _token = 'last_token'\n\n    def __init__(self, session, store):\n        self.session = session\n        self.consumer = GenericOpenIDConsumer(store)\n        self._token_key = self.session_key_prefix + self._token\n\n    def begin(self, user_url):\n        openid_url = oidutil.normalizeUrl(user_url)\n        if yadis_available:\n            disco = Discovery(self.session, openid_url, 'XXX')\n            endpoint = disco.getNextService(openIDDiscover)\n        else:\n            _, endpoints = openIDDiscover(openid_url)\n            if not endpoints:\n                endpoint = None\n            else:\n                endpoint = endpoints[0]\n\n        if endpoint is None:\n            return None\n        else:\n            return self.beginWithoutDiscovery(endpoint)\n\n    def beginWithoutDiscovery(self, endpoint):\n        auth_req = self.consumer.begin(endpoint)\n        self.session[self._token_key] = auth_req.token\n        return auth_req\n\n    def complete(self, query):\n        token = self.session.get(self._token_key)\n        if token is None:\n            response = FailureResponse(None, 'No session state found')\n        else:\n            response = self.consumer.complete(query, token)\n\n        if response.status in ['success',\n                               'cancel'#maybe\n                               ]:\n            if yadis_available and response.identity_url is not None:\n                disco = Discovery(self.session, response.identity_url)\n                # This is OK to do even if we did not do discovery in\n                # the first place.\n                disco.cleanup()\n\n        return response\n\nclass GenericOpenIDConsumer(object):\n    \"\"\"This is the implementation of the common logic for OpenID\n    consumers. It is unaware of the application in which it is\n    running.\n    \"\"\"\n\n    TOKEN_LIFETIME = 60 * 5 # five minutes\n    NONCE_LEN = 8\n    NONCE_CHRS = string.letters + string.digits\n\n    def __init__(self, store):\n        \"\"\"\n        This method initializes a new C{L{OpenIDConsumer}} instance to\n        access the library.\n\n        @param store: This must be an object that implements the\n            interface in C{L{openid.store.interface.OpenIDStore}}.\n            Several concrete implementations are provided, to cover\n            most common use cases.  For stores backed by MySQL or\n            SQLite, see the C{L{openid.store.sqlstore.SQLStore}}\n            class and its sublcasses.  For a filesystem-backed store,\n            see the C{L{openid.store.filestore}} module.\n\n            As a last resort, if it isn't possible for the server to\n            store state at all, an instance of\n            C{L{openid.store.dumbstore.DumbStore}} can be used.  This\n            should be an absolute last resort, though, as it makes the\n            consumer vulnerable to replay attacks over the lifespan of\n            the tokens the library creates.\n\n        @type store: C{L{openid.store.interface.OpenIDStore}}\n\n        \"\"\"\n        self.store = store\n\n    def begin(self, service_endpoint):\n        nonce = self._createNonce()\n        token = self._genToken(\n            nonce,\n            service_endpoint.identity_url,\n            service_endpoint.getServerID(),\n            service_endpoint.server_url,\n            )\n        assoc = self._getAssociation(service_endpoint.server_url)\n        return OpenIDAuthRequest(token, assoc, service_endpoint)\n\n    def complete(self, query, token):\n        mode = query.get('openid.mode', '<no mode specified>')\n\n        # Get the current request's state\n        try:\n            pieces = self._splitToken(token)\n        except ValueError, why:\n            oidutil.log(why[0])\n            pieces = (None, None, None, None, None)\n\n        (nonce, identity_url, delegate, server_url) = pieces\n\n        if mode == 'cancel':\n            return CancelResponse(identity_url)\n        elif mode == 'error':\n            error = query.get('openid.error')\n            return FailureResponse(identity_url, error)\n        elif mode == 'id_res':\n            if identity_url is None:\n                return FailureResponse(identity_url, 'No session state found')\n            try:\n                response = self._doIdRes(\n                    query, identity_url, delegate, server_url)\n            except fetchers.HTTPFetchingError, why:\n                message = 'HTTP request failed: %s' % (str(why),)\n                return FailureResponse(identity_url, message)\n            else:\n                if (response.status == 'success' and\n                    not self.store.useNonce(nonce)):\n\n                    return FailureResponse(identity_url, 'Nonce already used')\n                else:\n                    return response\n        else:\n            return FailureResponse(identity_url,\n                                   'Invalid openid.mode: %r' % (mode,))\n\n    def _createNonce(self):\n        nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n        self.store.storeNonce(nonce)\n        return nonce\n\n    def _makeKVPost(self, args, server_url):\n        mode = args['openid.mode']\n        body = urllib.urlencode(args)\n\n        resp = fetchers.fetch(server_url, body=body)\n        if resp is None:\n            fmt = 'openid.mode=%s: failed to fetch URL: %s'\n            oidutil.log(fmt % (mode, server_url))\n            return None\n\n        response = kvform.kvToDict(resp.body)\n        if resp.status == 400:\n            server_error = response.get('error', '<no message from server>')\n            fmt = 'openid.mode=%s: error returned from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, server_error))\n            return None\n        elif resp.status != 200:\n            fmt = 'openid.mode=%s: bad status code from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, resp.status))\n            return None\n\n        return response\n\n    def _doIdRes(self, query, consumer_id, server_id, server_url):\n        user_setup_url = query.get('openid.user_setup_url')\n        if user_setup_url is not None:\n            return SetupNeededResponse(consumer_id, user_setup_url)\n\n        return_to = query.get('openid.return_to')\n        server_id2 = query.get('openid.identity')\n        assoc_handle = query.get('openid.assoc_handle')\n\n        if return_to is None or server_id is None or assoc_handle is None:\n            return FailureResponse(consumer_id, 'Missing required field')\n\n        if server_id != server_id2:\n            return FailureResponse(consumer_id, 'Server ID (delegate) mismatch')\n\n        signed = query.get('openid.signed')\n\n        assoc = self.store.getAssociation(server_url, assoc_handle)\n\n        if assoc is None:\n            # It's not an association we know about.  Dumb mode is our\n            # only possible path for recovery.\n            if self._checkAuth(query, server_url):\n                return SuccessResponse.fromQuery(consumer_id, query, signed)\n            else:\n                return FailureResponse(consumer_id,\n                                       'Server denied check_authentication')\n\n        if assoc.expiresIn <= 0:\n            # XXX: It might be a good idea sometimes to re-start the\n            # authentication with a new association. Doing it\n            # automatically opens the possibility for\n            # denial-of-service by a server that just returns expired\n            # associations (or really short-lived associations)\n            msg = 'Association with %s expired' % (server_url,)\n            return FailureResponse(consumer_id, msg)\n\n        # Check the signature\n        sig = query.get('openid.sig')\n        if sig is None or signed is None:\n            return FailureResponse(consumer_id, 'Missing argument signature')\n\n        signed_list = signed.split(',')\n        v_sig = assoc.signDict(signed_list, query)\n\n        if v_sig != sig:\n            return FailureResponse(consumer_id, 'Bad signature')\n\n        return SuccessResponse.fromQuery(consumer_id, query, signed)\n\n    def _checkAuth(self, query, server_url):\n        request = self._createCheckAuthRequest(query)\n        if request is None:\n            return False\n        response = self._makeKVPost(request, server_url)\n        if response is None:\n            return False\n        return self._processCheckAuthResponse(response)\n\n    def _createCheckAuthRequest(self, query):\n        signed = query.get('openid.signed')\n        if signed is None:\n            oidutil.log('No signature present; checkAuth aborted')\n            return None\n\n        # Arguments that are always passed to the server and not\n        # included in the signature.\n        whitelist = ['assoc_handle', 'sig', 'signed', 'invalidate_handle']\n        signed = signed.split(',') + whitelist\n\n        check_args = dict([(k, v) for k, v in query.iteritems()\n                           if k.startswith('openid.') and k[7:] in signed])\n\n        check_args['openid.mode'] = 'check_authentication'\n        return check_args\n\n    def _processCheckAuthResponse(self, response):\n        is_valid = response.get('is_valid', 'false')\n\n        if is_valid == 'true':\n            invalidate_handle = response.get('invalidate_handle')\n            if invalidate_handle is not None:\n                self.store.removeAssociation(server_url, invalidate_handle)\n\n            return True\n\n        oidutil.log('Server responds that checkAuth call is not valid')\n        return False\n\n    def _getAssociation(self, server_url):\n        if self.store.isDumb():\n            return None\n\n        assoc = self.store.getAssociation(server_url)\n\n        if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME:\n            proto = urlparse(server_url)[0]\n            if proto == 'https':\n                dh = None\n            else:\n                dh = DiffieHellman()\n\n            args = self._createAssociateRequest(dh)\n            try:\n                response = self._makeKVPost(args, server_url)\n            except fetchers.HTTPFetchingError, why:\n                oidutil.log('openid.associate request failed: %s' %\n                            (str(why),))\n                assoc = None\n            else:\n                assoc = self._parseAssociation(response, dh, server_url)\n\n        return assoc\n\n    def _genToken(self, nonce, consumer_id, server_id, server_url):\n        timestamp = str(int(time.time()))\n        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n        joined = '\\x00'.join(elements)\n        sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n\n        return oidutil.toBase64('%s%s' % (sig, joined))\n\n    def _splitToken(self, token):\n        token = oidutil.fromBase64(token)\n        if len(token) < 20:\n            raise ValueError('Bad token length: %d' % len(token))\n\n        sig, joined = token[:20], token[20:]\n        if cryptutil.hmacSha1(self.store.getAuthKey(), joined) != sig:\n            raise ValueError('Bad token signature')\n\n        split = joined.split('\\x00')\n        if len(split) != 5:\n            raise ValueError('Bad token contents (not enough fields)')\n\n        try:\n            ts = int(split[0])\n        except ValueError:\n            raise ValueError('Bad token contents (timestamp bad)')\n\n        if ts + self.TOKEN_LIFETIME < time.time():\n            raise ValueError('Token expired')\n\n        return tuple(split[1:])\n\n    def _createAssociateRequest(self, dh=None, args=None):\n        if args is None:\n            args = {}\n\n        args.update({\n            'openid.mode': 'associate',\n            'openid.assoc_type':'HMAC-SHA1',\n            })\n\n        if dh:\n            cpub = cryptutil.longToBase64(dh.public)\n\n            args.update({\n                'openid.session_type':'DH-SHA1',\n                'openid.dh_consumer_public': cpub,\n                })\n\n            if not dh.usingDefaultValues():\n                args.update({\n                    'openid.dh_modulus': cryptutil.longToBase64(dh.modulus),\n                    'openid.dh_gen': cryptutil.longToBase64(dh.generator),\n                    })\n\n        return args\n\n    def _parseAssociation(self, results, dh, server_url):\n        try:\n            assoc_type = results['assoc_type']\n            if assoc_type != 'HMAC-SHA1':\n                fmt = 'Unsupported assoc_type returned from server %s: %s'\n                oidutil.log(fmt % (server_url, assoc_type))\n                return None\n\n            assoc_handle = results['assoc_handle']\n            try:\n                expires_in = int(results.get('expires_in', '0'))\n            except ValueError, e:\n                fmt = 'Getting Association: invalid expires_in field: %s'\n                oidutil.log(fmt % (e[0],))\n                return None\n\n            session_type = results.get('session_type')\n            if session_type is None:\n                secret = oidutil.fromBase64(results['mac_key'])\n            else:\n                if session_type != 'DH-SHA1':\n                    fmt = 'Unsupported session_type from server %s: %s'\n                    oidutil.log(fmt % (server_url, session_type))\n                    return None\n                if dh is None:\n                    fmt = 'Not expecting a DH-SHA1 session from server %s'\n                    oidutil.log(fmt % (server_url))\n                    return None\n\n                spub = cryptutil.base64ToLong(results['dh_server_public'])\n                enc_mac_key = oidutil.fromBase64(results['enc_mac_key'])\n                secret = dh.xorSecret(spub, enc_mac_key)\n\n            assoc = Association.fromExpiresIn(\n                expires_in, assoc_handle, secret, assoc_type)\n            self.store.storeAssociation(server_url, assoc)\n\n            return assoc\n\n        except KeyError, e:\n            fmt = 'Getting association: missing key in response from %s: %s'\n            oidutil.log(fmt % (server_url, e[0]))\n            return None\n\nclass OpenIDAuthRequest(object):\n    def __init__(self, token, assoc, endpoint):\n        \"\"\"\n        Creates a new OpenIDAuthRequest object.  This just stores each\n        argument in an appropriately named field.\n\n        Users of this library should not create instances of this\n        class.  Instances of this class are created by the library\n        when needed.\n        \"\"\"\n        self.assoc = assoc\n        self.endpoint = endpoint\n        self.extra_args = {}\n        self.token = token\n\n    def addExtensionArg(self, namespace, key, value):\n        arg_name = '.'.join('openid', namespace, key)\n        self.extra_args[arg_name] = value\n\n    def redirectURL(self, trust_root, return_to, immediate=False):\n        if immediate:\n            mode = 'checkid_immediate'\n        else:\n            mode = 'checkid_setup'\n\n        redir_args = {\n            'openid.mode': mode,\n            'openid.identity': self.endpoint.getServerID(),\n            'openid.return_to': return_to,\n            'openid.trust_root': trust_root,\n            }\n\n        if self.assoc:\n            redir_args['openid.assoc_handle'] = self.assoc.handle\n\n        redir_args.update(self.extra_args)\n        return oidutil.appendArgs(self.endpoint.server_url, redir_args)\n\nclass OpenIDConsumerResponse(object):\n    status = None\n\nclass SuccessResponse(OpenIDConsumerResponse):\n    status = 'success'\n\n    def __init__(self, identity_url, signed_args):\n        self.identity_url = identity_url\n        self.signed_args = signed_args\n\n    def fromQuery(cls, identity_url, query, signed):\n        signed_args = {}\n        for field_name in signed.split(','):\n            field_name = 'openid.' + field_name\n            signed_args[field_name] = query.get(field_name, '')\n        return cls(identity_url, signed_args)\n\n    fromQuery = classmethod(fromQuery)\n\n    def extensionResponse(self, prefix):\n        response = {}\n        prefix = 'openid.%s.' % (prefix,)\n        prefix_len = len(prefix)\n        for k, v in self.signed_args.iteritems():\n            if k.startswith(prefix):\n                response_key = k[prefix_len:]\n                response[response_key] = v\n\n        return response\n\nclass FailureResponse(OpenIDConsumerResponse):\n    status = 'failure'\n\n    def __init__(self, identity_url=None, message=None):\n        self.identity_url = identity_url\n        self.message = message\n\nclass CancelResponse(OpenIDConsumerResponse):\n    status = 'cancelled'\n\n    def __init__(self, identity_url=None):\n        self.identity_url = identity_url\n\nclass SetupNeededResponse(OpenIDConsumerResponse):\n    status = 'setup_needed'\n\n    def __init__(self, identity_url=None, setup_url=None):\n        self.identity_url = identity_url\n        self.setup_url = setup_url\n"},"\/test\/consumer.py":{"changes":[{"diff":"\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n","add":5,"remove":2,"filename":"\/test\/consumer.py","badparts":["            'openid.return_to':return_to,","            'openid.return_to':return_to,"],"goodparts":["        new_return_to = q['openid.return_to']","        del q['openid.return_to']","        assert new_return_to.startswith(return_to)","            'nonce':request.return_to_args['nonce'],","            'openid.return_to':new_return_to,"]},{"diff":"\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","add":1,"remove":1,"filename":"\/test\/consumer.py","badparts":["        assert info.status == 'success'"],"goodparts":["        assert info.status == 'success', info.message"]}],"source":"\nimport urlparse import cgi import time from openid import cryptutil, dh, oidutil, kvform from openid.consumer.discover import OpenIDServiceEndpoint from openid.consumer.consumer import GenericOpenIDConsumer from openid import association from openid.consumer import parse from urljr.fetchers import HTTPResponse from urljr import fetchers import _memstore assocs=[ ('another 20-byte key.', 'Snarky'), ('\\x00' * 20, 'Zeros'), ] def parseQuery(qs): q={} for(k, v) in cgi.parse_qsl(qs): assert not q.has_key(k) q[k]=v return q def associate(qs, assoc_secret, assoc_handle): \"\"\"Do the server's half of the associate call, using the given secret and handle.\"\"\" q=parseQuery(qs) assert q['openid.mode']=='associate' assert q['openid.assoc_type']=='HMAC-SHA1' if q.get('openid.session_type')=='DH-SHA1': assert len(q)==6 or len(q)==4 d=dh.DiffieHellman.fromBase64( q.get('openid.dh_modulus'), q.get('openid.dh_gen')) composite=cryptutil.base64ToLong(q['openid.dh_consumer_public']) enc_mac_key=oidutil.toBase64(d.xorSecret(composite, assoc_secret)) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'session_type':'DH-SHA1', 'dh_server_public':cryptutil.longToBase64(d.public), 'enc_mac_key':enc_mac_key, } else: assert len(q)==2 mac_key=oidutil.toBase64(assoc_secret) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'mac_key':mac_key, } return kvform.dictToKV(reply_dict) class TestFetcher(object): def __init__(self, user_url, user_page,(assoc_secret, assoc_handle)): self.get_responses={user_url:self.response(user_url, 200, user_page)} self.assoc_secret=assoc_secret self.assoc_handle=assoc_handle self.num_assocs=0 def response(self, url, status, body): return HTTPResponse( final_url=url, status=status, headers={}, body=body) def fetch(self, url, body=None, headers=None): if body is None: if url in self.get_responses: return self.get_responses[url] else: try: body.index('openid.mode=associate') except ValueError: pass else: if urlparse.urlparse(url)[0]=='https': assert body.find('DH-SHA1')==-1 else: assert body.find('DH-SHA1') !=-1 response=associate( body, self.assoc_secret, self.assoc_handle) self.num_assocs +=1 return self.response(url, 200, response) return self.response(url, 404, 'Not found') def _test_success(server_url, user_url, delegate_url, links, immediate=False): store=_memstore.MemoryStore() if immediate: mode='checkid_immediate' else: mode='checkid_setup' endpoint=OpenIDServiceEndpoint() endpoint.identity_url=user_url endpoint.server_url=server_url endpoint.delegate=delegate_url fetcher=TestFetcher(None, None, assocs[0]) fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False) def run(): trust_root=consumer_url consumer=GenericOpenIDConsumer(store) request=consumer.begin(endpoint) return_to=consumer_url redirect_url=request.redirectURL(trust_root, return_to, immediate) parsed=urlparse.urlparse(redirect_url) qs=parsed[4] q=parseQuery(qs) assert q=={ 'openid.mode':mode, 'openid.identity':delegate_url, 'openid.trust_root':trust_root, 'openid.assoc_handle':fetcher.assoc_handle, 'openid.return_to':return_to, },(q, user_url, delegate_url, mode) assert redirect_url.startswith(server_url) query={ 'openid.mode':'id_res', 'openid.return_to':return_to, 'openid.identity':delegate_url, 'openid.assoc_handle':fetcher.assoc_handle, } assoc=store.getAssociation(server_url, fetcher.assoc_handle) assoc.addSignature(['mode', 'return_to', 'identity'], query) info=consumer.complete(query, request.token) assert info.status=='success' assert info.identity_url==user_url assert fetcher.num_assocs==0 run() assert fetcher.num_assocs==1 run() assert fetcher.num_assocs==1 store.removeAssociation(server_url, fetcher.assoc_handle) run() assert fetcher.num_assocs==2 run() assert fetcher.num_assocs==2 import unittest http_server_url='http:\/\/server.example.com\/' consumer_url='http:\/\/consumer.example.com\/' https_server_url='https:\/\/server.example.com\/' class TestSuccess(unittest.TestCase): server_url=http_server_url user_url='http:\/\/www.example.com\/user.html' delegate_url='http:\/\/consumer.example.com\/user' def setUp(self): self.links='<link rel=\"openid.server\" href=\"%s\" \/>' %( self.server_url,) self.delegate_links=('<link rel=\"openid.server\" href=\"%s\" \/>' '<link rel=\"openid.delegate\" href=\"%s\" \/>') %( self.server_url, self.delegate_url) def test_nodelegate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links) def test_nodelegateImmediate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links, True) def test_delegate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links) def test_delegateImmediate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links, True) class TestSuccessHTTPS(TestSuccess): server_url=https_server_url class TestConstruct(unittest.TestCase): def setUp(self): self.store_sentinel=object() def test_construct(self): oidc=GenericOpenIDConsumer(self.store_sentinel) self.failUnless(oidc.store is self.store_sentinel) def test_nostore(self): self.failUnlessRaises(TypeError, GenericOpenIDConsumer) class TestIdRes(unittest.TestCase): consumer_class=GenericOpenIDConsumer def setUp(self): self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.return_to=\"nonny\" self.server_id=\"sirod\" self.server_url=\"serlie\" self.consumer_id=\"consu\" class TestSetupNeeded(TestIdRes): def test_setupNeeded(self): setup_url='http:\/\/unittest\/setup-here' query={ 'openid.mode': 'id_res', 'openid.user_setup_url': setup_url, } ret=self.consumer._doIdRes(query, self.consumer_id, self.server_id, self.server_url, ) self.failUnlessEqual(ret.status, 'setup_needed') self.failUnlessEqual(ret.setup_url, setup_url) class CheckAuthHappened(Exception): pass class CheckAuthDetectingConsumer(GenericOpenIDConsumer): def _checkAuth(self, *args): raise CheckAuthHappened(args) class CatchLogs(object): def setUp(self): self.old_logger=oidutil.log oidutil.log=self.gotLogMessage self.messages=[] def gotLogMessage(self, message): self.messages.append(message) def tearDown(self): oidutil.log=self.old_logger class TestCheckAuthTriggered(TestIdRes, CatchLogs): consumer_class=CheckAuthDetectingConsumer def setUp(self): TestIdRes.setUp(self) CatchLogs.setUp(self) def _doIdRes(self, query): return self.consumer._doIdRes( query, self.consumer_id, self.server_id, self.server_url) def test_checkAuthTriggered(self): query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r %s' % (result, self.messages)) def test_checkAuthTriggeredWithAssoc(self): issued=time.time() lifetime=1000 assoc=association.Association( 'handle', 'secret', issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r' %(result,)) def test_expiredAssoc(self): issued=time.time() -10 lifetime=0 handle='handle' assoc=association.Association( handle, 'secret', issued, lifetime, 'HMAC-SHA1') self.failUnless(assoc.expiresIn <=0) self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':handle, } info=self._doIdRes(query) self.failUnlessEqual('failure', info.status) self.failUnlessEqual(self.consumer_id, info.identity_url) info.message.index('expired') def test_newerAssoc(self): lifetime=1000 good_issued=time.time() -10 good_handle='handle' good_assoc=association.Association( good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, good_assoc) bad_issued=time.time() -5 bad_handle='handle2' bad_assoc=association.Association( bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, bad_assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':good_handle, } good_assoc.addSignature(['return_to', 'identity'], query) info=self._doIdRes(query) self.failUnlessEqual(info.status, 'success') self.failUnlessEqual(self.consumer_id, info.identity_url) class MockFetcher(object): def __init__(self, response=None): self.response=response or HTTPResponse() self.fetches=[] def fetch(self, url, body=None, headers=None): self.fetches.append((url, body, headers)) return self.response class ExceptionRaisingMockFetcher(object): def fetch(self, url, body=None, headers=None): raise Exception('mock fetcher exception') class BadArgCheckingConsumer(GenericOpenIDConsumer): def _makeKVPost(self, args, _): assert args=={ 'openid.mode':'check_authentication', 'openid.signed':'foo', }, args return None class TestCheckAuth(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') query={'openid.signed': 'stuff, things'} r=self.consumer._checkAuth(query, http_server_url) self.failIf(r) self.failUnless(self.messages) def test_bad_args(self): query={ 'openid.signed':'foo', 'closid.foo':'something', } consumer=BadArgCheckingConsumer(self.store) consumer._checkAuth(query, 'does:\/\/not.matter') class TestFetchAssoc(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.consumer=self.consumer_class(self.store) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') r=self.consumer._makeKVPost({'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnlessEqual(r, None) self.failUnless(self.messages) def test_error_exception(self): self.fetcher=ExceptionRaisingMockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._makeKVPost, {'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnless(self.consumer._getAssociation('some:\/\/url') is None) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._checkAuth, {'openid.signed':''}, 'some:\/\/url') if __name__=='__main__': unittest.main() ","sourceWithComments":"import urlparse\nimport cgi\nimport time\n\nfrom openid import cryptutil, dh, oidutil, kvform\nfrom openid.consumer.discover import OpenIDServiceEndpoint\nfrom openid.consumer.consumer import GenericOpenIDConsumer\nfrom openid import association\n\nfrom openid.consumer import parse\n\nfrom urljr.fetchers import HTTPResponse\nfrom urljr import fetchers\n\nimport _memstore\n\nassocs = [\n    ('another 20-byte key.', 'Snarky'),\n    ('\\x00' * 20, 'Zeros'),\n    ]\n\ndef parseQuery(qs):\n    q = {}\n    for (k, v) in cgi.parse_qsl(qs):\n        assert not q.has_key(k)\n        q[k] = v\n    return q\n\ndef associate(qs, assoc_secret, assoc_handle):\n    \"\"\"Do the server's half of the associate call, using the given\n    secret and handle.\"\"\"\n    q = parseQuery(qs)\n    assert q['openid.mode'] == 'associate'\n    assert q['openid.assoc_type'] == 'HMAC-SHA1'\n    if q.get('openid.session_type') == 'DH-SHA1':\n        assert len(q) == 6 or len(q) == 4\n        d = dh.DiffieHellman.fromBase64(\n            q.get('openid.dh_modulus'), q.get('openid.dh_gen'))\n\n        composite = cryptutil.base64ToLong(q['openid.dh_consumer_public'])\n        enc_mac_key = oidutil.toBase64(d.xorSecret(composite, assoc_secret))\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'session_type':'DH-SHA1',\n            'dh_server_public':cryptutil.longToBase64(d.public),\n            'enc_mac_key':enc_mac_key,\n            }\n    else:\n        assert len(q) == 2\n        mac_key = oidutil.toBase64(assoc_secret)\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'mac_key':mac_key,\n            }\n\n    return kvform.dictToKV(reply_dict)\n\nclass TestFetcher(object):\n    def __init__(self, user_url, user_page, (assoc_secret, assoc_handle)):\n        self.get_responses = {user_url:self.response(user_url, 200, user_page)}\n        self.assoc_secret = assoc_secret\n        self.assoc_handle = assoc_handle\n        self.num_assocs = 0\n\n    def response(self, url, status, body):\n        return HTTPResponse(\n            final_url=url, status=status, headers={}, body=body)\n\n    def fetch(self, url, body=None, headers=None):\n        if body is None:\n            if url in self.get_responses:\n                return self.get_responses[url]\n        else:\n            try:\n                body.index('openid.mode=associate')\n            except ValueError:\n                pass # fall through\n            else:\n                if urlparse.urlparse(url)[0] == 'https':\n                    # Should not be doing DH-SHA1 when using HTTPS.\n                    assert body.find('DH-SHA1') == -1\n                else:\n                    assert body.find('DH-SHA1') != -1\n                response = associate(\n                    body, self.assoc_secret, self.assoc_handle)\n                self.num_assocs += 1\n                return self.response(url, 200, response)\n\n        return self.response(url, 404, 'Not found')\n\ndef _test_success(server_url, user_url, delegate_url, links, immediate=False):\n    store = _memstore.MemoryStore()\n    if immediate:\n        mode = 'checkid_immediate'\n    else:\n        mode = 'checkid_setup'\n\n    endpoint = OpenIDServiceEndpoint()\n    endpoint.identity_url = user_url\n    endpoint.server_url = server_url\n    endpoint.delegate = delegate_url\n\n    fetcher = TestFetcher(None, None, assocs[0])\n    fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False)\n\n    def run():\n        trust_root = consumer_url\n\n        consumer = GenericOpenIDConsumer(store)\n        request = consumer.begin(endpoint)\n\n        return_to = consumer_url\n        redirect_url = request.redirectURL(trust_root, return_to, immediate)\n\n        parsed = urlparse.urlparse(redirect_url)\n        qs = parsed[4]\n        q = parseQuery(qs)\n        assert q == {\n            'openid.mode':mode,\n            'openid.identity':delegate_url,\n            'openid.trust_root':trust_root,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            'openid.return_to':return_to,\n            }, (q, user_url, delegate_url, mode)\n\n        assert redirect_url.startswith(server_url)\n\n        query = {\n            'openid.mode':'id_res',\n            'openid.return_to':return_to,\n            'openid.identity':delegate_url,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            }\n\n        assoc = store.getAssociation(server_url, fetcher.assoc_handle)\n        assoc.addSignature(['mode', 'return_to', 'identity'], query)\n\n        info = consumer.complete(query, request.token)\n        assert info.status == 'success'\n        assert info.identity_url == user_url\n\n    assert fetcher.num_assocs == 0\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Another association is created if we remove the existing one\n    store.removeAssociation(server_url, fetcher.assoc_handle)\n    run()\n    assert fetcher.num_assocs == 2\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 2\n\nimport unittest\n\nhttp_server_url = 'http:\/\/server.example.com\/'\nconsumer_url = 'http:\/\/consumer.example.com\/'\nhttps_server_url = 'https:\/\/server.example.com\/'\n\nclass TestSuccess(unittest.TestCase):\n    server_url = http_server_url\n    user_url = 'http:\/\/www.example.com\/user.html'\n    delegate_url = 'http:\/\/consumer.example.com\/user'\n\n    def setUp(self):\n        self.links = '<link rel=\"openid.server\" href=\"%s\" \/>' % (\n            self.server_url,)\n\n        self.delegate_links = ('<link rel=\"openid.server\" href=\"%s\" \/>'\n                               '<link rel=\"openid.delegate\" href=\"%s\" \/>') % (\n            self.server_url, self.delegate_url)\n\n    def test_nodelegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links)\n\n    def test_nodelegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links, True)\n\n    def test_delegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links)\n\n    def test_delegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links, True)\n\n\nclass TestSuccessHTTPS(TestSuccess):\n    server_url = https_server_url\n\n\nclass TestConstruct(unittest.TestCase):\n    def setUp(self):\n        self.store_sentinel = object()\n\n    def test_construct(self):\n        oidc = GenericOpenIDConsumer(self.store_sentinel)\n        self.failUnless(oidc.store is self.store_sentinel)\n\n    def test_nostore(self):\n        self.failUnlessRaises(TypeError, GenericOpenIDConsumer)\n\n\nclass TestIdRes(unittest.TestCase):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        self.store = _memstore.MemoryStore()\n        self.consumer = self.consumer_class(self.store)\n        self.return_to = \"nonny\"\n        self.server_id = \"sirod\"\n        self.server_url = \"serlie\"\n        self.consumer_id = \"consu\"\n\nclass TestSetupNeeded(TestIdRes):\n    def test_setupNeeded(self):\n        setup_url = 'http:\/\/unittest\/setup-here'\n        query = {\n            'openid.mode': 'id_res',\n            'openid.user_setup_url': setup_url,\n            }\n        ret = self.consumer._doIdRes(query,\n                                     self.consumer_id,\n                                     self.server_id,\n                                     self.server_url,\n                                     )\n        self.failUnlessEqual(ret.status, 'setup_needed')\n        self.failUnlessEqual(ret.setup_url, setup_url)\n\nclass CheckAuthHappened(Exception): pass\n\nclass CheckAuthDetectingConsumer(GenericOpenIDConsumer):\n    def _checkAuth(self, *args):\n        raise CheckAuthHappened(args)\n\nclass CatchLogs(object):\n    def setUp(self):\n        self.old_logger = oidutil.log\n        oidutil.log = self.gotLogMessage\n        self.messages = []\n\n    def gotLogMessage(self, message):\n        self.messages.append(message)\n\n    def tearDown(self):\n        oidutil.log = self.old_logger\n\nclass TestCheckAuthTriggered(TestIdRes, CatchLogs):\n    consumer_class = CheckAuthDetectingConsumer\n\n    def setUp(self):\n        TestIdRes.setUp(self)\n        CatchLogs.setUp(self)\n\n    def _doIdRes(self, query):\n        return self.consumer._doIdRes(\n            query,\n            self.consumer_id,\n            self.server_id,\n            self.server_url)\n\n    def test_checkAuthTriggered(self):\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r %s' %\n                      (result, self.messages))\n\n    def test_checkAuthTriggeredWithAssoc(self):\n        # Store an association for this server that does not match the\n        # handle that is in the query\n        issued = time.time()\n        lifetime = 1000\n        assoc = association.Association(\n            'handle', 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r' % (result,))\n\n    def test_expiredAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        issued = time.time() - 10\n        lifetime = 0\n        handle = 'handle'\n        assoc = association.Association(\n            handle, 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.failUnless(assoc.expiresIn <= 0)\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':handle,\n            }\n        info = self._doIdRes(query)\n        self.failUnlessEqual('failure', info.status)\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n        info.message.index('expired') # raises an exception if it's not there\n\n    def test_newerAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        lifetime = 1000\n\n        good_issued = time.time() - 10\n        good_handle = 'handle'\n        good_assoc = association.Association(\n            good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, good_assoc)\n\n        bad_issued = time.time() - 5\n        bad_handle = 'handle2'\n        bad_assoc = association.Association(\n            bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, bad_assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':good_handle,\n            }\n\n        good_assoc.addSignature(['return_to', 'identity'], query)\n        info = self._doIdRes(query)\n        self.failUnlessEqual(info.status, 'success')\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n\n\nclass MockFetcher(object):\n    def __init__(self, response=None):\n        self.response = response or HTTPResponse()\n        self.fetches = []\n\n    def fetch(self, url, body=None, headers=None):\n        self.fetches.append((url, body, headers))\n        return self.response\n\nclass ExceptionRaisingMockFetcher(object):\n    def fetch(self, url, body=None, headers=None):\n        raise Exception('mock fetcher exception')\n\nclass BadArgCheckingConsumer(GenericOpenIDConsumer):\n    def _makeKVPost(self, args, _):\n        assert args == {\n            'openid.mode':'check_authentication',\n            'openid.signed':'foo',\n            }, args\n        return None\n\nclass TestCheckAuth(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n\n        self.consumer = self.consumer_class(self.store)\n\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        query = {'openid.signed': 'stuff, things'}\n        r = self.consumer._checkAuth(query, http_server_url)\n        self.failIf(r)\n        self.failUnless(self.messages)\n\n    def test_bad_args(self):\n        query = {\n            'openid.signed':'foo',\n            'closid.foo':'something',\n            }\n        consumer = BadArgCheckingConsumer(self.store)\n        consumer._checkAuth(query, 'does:\/\/not.matter')\n\nclass TestFetchAssoc(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.consumer = self.consumer_class(self.store)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        r = self.consumer._makeKVPost({'openid.mode':'associate'},\n                                      \"http:\/\/server_url\")\n        self.failUnlessEqual(r, None)\n        self.failUnless(self.messages)\n\n    def test_error_exception(self):\n        self.fetcher = ExceptionRaisingMockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._makeKVPost,\n                              {'openid.mode':'associate'},\n                              \"http:\/\/server_url\")\n\n        # exception fetching returns no association\n        self.failUnless(self.consumer._getAssociation('some:\/\/url') is None)\n\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._checkAuth,\n                              {'openid.signed':''},\n                              'some:\/\/url')\n\nif __name__ == '__main__':\n    unittest.main()\n"}},"msg":"[project @ Added nonce to return_to to fix replay attack vulnerability]"}},"https:\/\/github.com\/The-Actual-Damien\/openid":{"f05703e45f3ef162c4d927dc712b95cbac163bb4":{"url":"https:\/\/api.github.com\/repos\/The-Actual-Damien\/openid\/commits\/f05703e45f3ef162c4d927dc712b95cbac163bb4","html_url":"https:\/\/github.com\/The-Actual-Damien\/openid\/commit\/f05703e45f3ef162c4d927dc712b95cbac163bb4","message":"[project @ Added nonce to return_to to fix replay attack vulnerability]","sha":"f05703e45f3ef162c4d927dc712b95cbac163bb4","keyword":"replay attack vulnerable","diff":"diff --git a\/openid\/consumer\/consumer.py b\/openid\/consumer\/consumer.py\nindex b7a93bc..49f5663 100644\n--- a\/openid\/consumer\/consumer.py\n+++ b\/openid\/consumer\/consumer.py\n@@ -173,6 +173,7 @@\n import string\n import time\n import urllib\n+import cgi\n from urlparse import urlparse\n \n from urljr import fetchers\n@@ -279,13 +280,14 @@ class and its sublcasses.  For a filesystem-backed store,\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n@@ -295,9 +297,9 @@ def complete(self, query, token):\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n@@ -314,16 +316,39 @@ def complete(self, query, token):\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n@@ -466,9 +491,9 @@ def _getAssociation(self, server_url):\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n@@ -484,7 +509,7 @@ def _splitToken(self, token):\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n@@ -567,7 +592,7 @@ def _parseAssociation(self, results, dh, server_url):\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n@@ -579,6 +604,7 @@ def __init__(self, token, assoc, endpoint):\n         self.assoc = assoc\n         self.endpoint = endpoint\n         self.extra_args = {}\n+        self.return_to_args = {}\n         self.token = token\n \n     def addExtensionArg(self, namespace, key, value):\n@@ -591,6 +617,8 @@ def redirectURL(self, trust_root, return_to, immediate=False):\n         else:\n             mode = 'checkid_setup'\n \n+        return_to = oidutil.appendArgs(return_to, self.return_to_args)\n+\n         redir_args = {\n             'openid.mode': mode,\n             'openid.identity': self.endpoint.getServerID(),\n@@ -634,6 +662,9 @@ def extensionResponse(self, prefix):\n \n         return response\n \n+    def getReturnTo(self):\n+        return self.signed_args['openid.return_to']\n+\n class FailureResponse(OpenIDConsumerResponse):\n     status = 'failure'\n \ndiff --git a\/test\/consumer.py b\/test\/consumer.py\nindex 343c7a1..1b8fbe7 100644\n--- a\/test\/consumer.py\n+++ b\/test\/consumer.py\n@@ -119,19 +119,22 @@ def run():\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n@@ -140,7 +143,7 @@ def run():\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","files":{"\/openid\/consumer\/consumer.py":{"changes":[{"diff":"\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n","add":3,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            nonce,","        return OpenIDAuthRequest(token, assoc, service_endpoint)"],"goodparts":["        request = OpenIDAuthRequest(token, assoc, service_endpoint)","        request.return_to_args['nonce'] = nonce","        return request"]},{"diff":"\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            pieces = (None, None, None, None, None)","        (nonce, identity_url, delegate, server_url) = pieces"],"goodparts":["            pieces = (None, None, None)","        (identity_url, delegate, server_url) = pieces"]},{"diff":"\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n","add":27,"remove":4,"filename":"\/openid\/consumer\/consumer.py","badparts":["                if (response.status == 'success' and","                    not self.store.useNonce(nonce)):","                    return FailureResponse(identity_url, 'Nonce already used')"],"goodparts":["                if response.status == 'success':","                    return self._checkNonce(response, query.get('nonce'))","    def _checkNonce(self, response, nonce):","        parsed_url = urlparse(response.getReturnTo())","        query = parsed_url[4]","        for k, v in cgi.parse_qsl(query):","            if k == 'nonce':","                if v != nonce:","                    return FailureResponse(response.identity_url,","                                           'Nonce mismatch')","                else:","                    break","        else:","            return FailureResponse(response.identity_url,","                                   'Nonce missing from return_to: %r'","                                   % (response.getReturnTo()))","        if not self.store.useNonce(nonce):","            return FailureResponse(response.identity_url,","                                   'Nonce missing from store')","        return response"]},{"diff":"\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def _genToken(self, nonce, consumer_id, server_id, server_url):","        elements = [timestamp, nonce, consumer_id, server_id, server_url]"],"goodparts":["    def _genToken(self, consumer_id, server_id, server_url):","        elements = [timestamp, consumer_id, server_id, server_url]"]},{"diff":"\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["        if len(split) != 5:"],"goodparts":["        if len(split) != 4:"]},{"diff":"\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def __init__(self, token, assoc, endpoint):"],"goodparts":["    def __init__(self, token, assoc, endpoint  ):"]}],"source":"\n\"\"\" This module documents the main interface with the OpenID consumer libary. The only part of the library which has to be used and isn't documented in full here is the store required to create an C{L{OpenIDConsumer}} instance. More on the abstract store type and concrete implementations of it that are provided in the documentation for the C{L{__init__<OpenIDConsumer.__init__>}} method of the C{L{OpenIDConsumer}} class. OVERVIEW ======== The OpenID identity verification process most commonly uses the following steps, as visible to the user of this library: 1. The user enters their OpenID into a field on the consumer's site, and hits a login button. 2. The consumer site discovers the user's OpenID server using the YADIS protocol. 3. The consumer site sends the browser a redirect to the identity server. This is the authentication request as described in the OpenID specification. 4. The identity server's site sends the browser a redirect back to the consumer site. This redirect contains the server's response to the authentication request. The most important part of the flow to note is the consumer's site must handle two separate HTTP requests in order to perform the full identity check. LIBRARY DESIGN ============== This consumer library is designed with that flow in mind. The goal is to make it as easy as possible to perform the above steps securely. At a high level, there are two important parts in the consumer library. The first important part is this module, which contains the interface to actually use this library. The second is the C{L{openid.store.interface}} module, which describes the interface to use if you need to create a custom method for storing the state this library needs to maintain between requests. In general, the second part is less important for users of the library to know about, as several implementations are provided which cover a wide variety of situations in which consumers may use the library. This module contains a class, C{L{OpenIDConsumer}}, with methods corresponding to the actions necessary in each of steps 2, 3, and 4 described in the overview. Use of this library should be as easy as creating an C{L{OpenIDConsumer}} instance and calling the methods appropriate for the action the site wants to take. STORES AND DUMB MODE ==================== OpenID is a protocol that works best when the consumer site is able to store some state. This is the normal mode of operation for the protocol, and is sometimes referred to as smart mode. There is also a fallback mode, known as dumb mode, which is available when the consumer site is not able to store state. This mode should be avoided when possible, as it leaves the implementation more vulnerable to replay attacks. The mode the library works in for normal operation is determined by the store that it is given. The store is an abstraction that handles the data that the consumer needs to manage between http requests in order to operate efficiently and securely. Several store implementation are provided, and the interface is fully documented so that custom stores can be used as well. See the documentation for the C{L{OpenIDConsumer}} class for more information on the interface for stores. The implementations that are provided allow the consumer site to store the necessary data in several different ways, including several SQL databases and normal files on disk. There is an additional concrete store provided that puts the system in dumb mode. This is not recommended, as it removes the library's ability to stop replay attacks reliably. It still uses time-based checking to make replay attacks only possible within a small window, but they remain possible within that window. This store should only be used if the consumer site has no way to retain data between requests at all. IMMEDIATE MODE ============== In the flow described above, the user may need to confirm to the identity server that it's ok to authorize his or her identity. The server may draw pages asking for information from the user before it redirects the browser back to the consumer's site. This is generally transparent to the consumer site, so it is typically ignored as an implementation detail. There can be times, however, where the consumer site wants to get a response immediately. When this is the case, the consumer can put the library in immediate mode. In immediate mode, there is an extra response possible from the server, which is essentially the server reporting that it doesn't have enough information to answer the question yet. In addition to saying that, the identity server provides a URL to which the user can be sent to provide the needed information and let the server finish handling the original request. USING THIS LIBRARY ================== Integrating this library into an application is usually a relatively straightforward process. The process should basically follow this plan: Add an OpenID login field somewhere on your site. When an OpenID is entered in that field and the form is submitted, it should make a request to the your site which includes that OpenID URL. To start, the application should get an C{L{OpenIDConsumer}} instance, and call its C{L{begin<OpenIDConsumer.begin>}} method. This method takes the OpenID URL and, optionally, a session object. If the application has any sort of session framework that provides per-client state management, that should be used here. The library just expects the session object to support a C{dict}-like interface, if it provided. If no session object is provided, the application code needs to store the information that would have been put in the session in an alternate location. See the documentation for the C{L{begin<OpenIDConsumer.begin>}} call for more information. The C{L{begin<OpenIDConsumer.begin>}} method returns an C{L{OpenIDRequestBuilder}} object. Next, the application should call the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on the C{L{OpenIDRequestBuilder}} object. The return_to URL is the URL that the OpenID server will send the user back to after attempting to verify his or her identity. The trust_root is the URL(or URL pattern) that identifies your web site to the user when he or she is authorizing it. Send a redirect to the resulting URL to the user's browser. That's the first half of the authentication process. The second half of the process is done after the user's ID server sends the user's browser a redirect back to your site to complete their login. When that happens, the user will contact your site at the URL given as the C{return_to} URL to the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made above. The request will have several query parameters added to the URL by the identity server as the information necessary to finish the request. Get an C{L{OpenIDConsumer}} instance, and call its C{L{complete<OpenIDConsumer.complete>}} method, passing in all the received query arguments and either the user's session object or the token saved earlier. See the documentation for C{L{OpenIDRequestBuilder}} for more information about the token. There are multiple possible return types possible from that method. These indicate the whether or not the login was successful, and include any additional information appropriate for their type. \"\"\" import string import time import urllib from urlparse import urlparse from urljr import fetchers from openid.consumer.discover import discover as openIDDiscover from openid.consumer.discover import yadis_available from openid import cryptutil from openid import kvform from openid import oidutil from openid.association import Association from openid.dh import DiffieHellman __all__=['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse', 'SetupNeededResponse', 'CancelResponse', 'FailureResponse'] if yadis_available: from yadis.manager import Discovery class OpenIDConsumer(object): session_key_prefix=\"_openid_consumer_\" _token='last_token' def __init__(self, session, store): self.session=session self.consumer=GenericOpenIDConsumer(store) self._token_key=self.session_key_prefix +self._token def begin(self, user_url): openid_url=oidutil.normalizeUrl(user_url) if yadis_available: disco=Discovery(self.session, openid_url, 'XXX') endpoint=disco.getNextService(openIDDiscover) else: _, endpoints=openIDDiscover(openid_url) if not endpoints: endpoint=None else: endpoint=endpoints[0] if endpoint is None: return None else: return self.beginWithoutDiscovery(endpoint) def beginWithoutDiscovery(self, endpoint): auth_req=self.consumer.begin(endpoint) self.session[self._token_key]=auth_req.token return auth_req def complete(self, query): token=self.session.get(self._token_key) if token is None: response=FailureResponse(None, 'No session state found') else: response=self.consumer.complete(query, token) if response.status in['success', 'cancel' ]: if yadis_available and response.identity_url is not None: disco=Discovery(self.session, response.identity_url) disco.cleanup() return response class GenericOpenIDConsumer(object): \"\"\"This is the implementation of the common logic for OpenID consumers. It is unaware of the application in which it is running. \"\"\" TOKEN_LIFETIME=60 * 5 NONCE_LEN=8 NONCE_CHRS=string.letters +string.digits def __init__(self, store): \"\"\" This method initializes a new C{L{OpenIDConsumer}} instance to access the library. @param store: This must be an object that implements the interface in C{L{openid.store.interface.OpenIDStore}}. Several concrete implementations are provided, to cover most common use cases. For stores backed by MySQL or SQLite, see the C{L{openid.store.sqlstore.SQLStore}} class and its sublcasses. For a filesystem-backed store, see the C{L{openid.store.filestore}} module. As a last resort, if it isn't possible for the server to store state at all, an instance of C{L{openid.store.dumbstore.DumbStore}} can be used. This should be an absolute last resort, though, as it makes the consumer vulnerable to replay attacks over the lifespan of the tokens the library creates. @type store: C{L{openid.store.interface.OpenIDStore}} \"\"\" self.store=store def begin(self, service_endpoint): nonce=self._createNonce() token=self._genToken( nonce, service_endpoint.identity_url, service_endpoint.getServerID(), service_endpoint.server_url, ) assoc=self._getAssociation(service_endpoint.server_url) return OpenIDAuthRequest(token, assoc, service_endpoint) def complete(self, query, token): mode=query.get('openid.mode', '<no mode specified>') try: pieces=self._splitToken(token) except ValueError, why: oidutil.log(why[0]) pieces=(None, None, None, None, None) (nonce, identity_url, delegate, server_url)=pieces if mode=='cancel': return CancelResponse(identity_url) elif mode=='error': error=query.get('openid.error') return FailureResponse(identity_url, error) elif mode=='id_res': if identity_url is None: return FailureResponse(identity_url, 'No session state found') try: response=self._doIdRes( query, identity_url, delegate, server_url) except fetchers.HTTPFetchingError, why: message='HTTP request failed: %s' %(str(why),) return FailureResponse(identity_url, message) else: if(response.status=='success' and not self.store.useNonce(nonce)): return FailureResponse(identity_url, 'Nonce already used') else: return response else: return FailureResponse(identity_url, 'Invalid openid.mode: %r' %(mode,)) def _createNonce(self): nonce=cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS) self.store.storeNonce(nonce) return nonce def _makeKVPost(self, args, server_url): mode=args['openid.mode'] body=urllib.urlencode(args) resp=fetchers.fetch(server_url, body=body) if resp is None: fmt='openid.mode=%s: failed to fetch URL: %s' oidutil.log(fmt %(mode, server_url)) return None response=kvform.kvToDict(resp.body) if resp.status==400: server_error=response.get('error', '<no message from server>') fmt='openid.mode=%s: error returned from server %s: %s' oidutil.log(fmt %(mode, server_url, server_error)) return None elif resp.status !=200: fmt='openid.mode=%s: bad status code from server %s: %s' oidutil.log(fmt %(mode, server_url, resp.status)) return None return response def _doIdRes(self, query, consumer_id, server_id, server_url): user_setup_url=query.get('openid.user_setup_url') if user_setup_url is not None: return SetupNeededResponse(consumer_id, user_setup_url) return_to=query.get('openid.return_to') server_id2=query.get('openid.identity') assoc_handle=query.get('openid.assoc_handle') if return_to is None or server_id is None or assoc_handle is None: return FailureResponse(consumer_id, 'Missing required field') if server_id !=server_id2: return FailureResponse(consumer_id, 'Server ID(delegate) mismatch') signed=query.get('openid.signed') assoc=self.store.getAssociation(server_url, assoc_handle) if assoc is None: if self._checkAuth(query, server_url): return SuccessResponse.fromQuery(consumer_id, query, signed) else: return FailureResponse(consumer_id, 'Server denied check_authentication') if assoc.expiresIn <=0: msg='Association with %s expired' %(server_url,) return FailureResponse(consumer_id, msg) sig=query.get('openid.sig') if sig is None or signed is None: return FailureResponse(consumer_id, 'Missing argument signature') signed_list=signed.split(',') v_sig=assoc.signDict(signed_list, query) if v_sig !=sig: return FailureResponse(consumer_id, 'Bad signature') return SuccessResponse.fromQuery(consumer_id, query, signed) def _checkAuth(self, query, server_url): request=self._createCheckAuthRequest(query) if request is None: return False response=self._makeKVPost(request, server_url) if response is None: return False return self._processCheckAuthResponse(response) def _createCheckAuthRequest(self, query): signed=query.get('openid.signed') if signed is None: oidutil.log('No signature present; checkAuth aborted') return None whitelist=['assoc_handle', 'sig', 'signed', 'invalidate_handle'] signed=signed.split(',') +whitelist check_args=dict([(k, v) for k, v in query.iteritems() if k.startswith('openid.') and k[7:] in signed]) check_args['openid.mode']='check_authentication' return check_args def _processCheckAuthResponse(self, response): is_valid=response.get('is_valid', 'false') if is_valid=='true': invalidate_handle=response.get('invalidate_handle') if invalidate_handle is not None: self.store.removeAssociation(server_url, invalidate_handle) return True oidutil.log('Server responds that checkAuth call is not valid') return False def _getAssociation(self, server_url): if self.store.isDumb(): return None assoc=self.store.getAssociation(server_url) if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME: proto=urlparse(server_url)[0] if proto=='https': dh=None else: dh=DiffieHellman() args=self._createAssociateRequest(dh) try: response=self._makeKVPost(args, server_url) except fetchers.HTTPFetchingError, why: oidutil.log('openid.associate request failed: %s' % (str(why),)) assoc=None else: assoc=self._parseAssociation(response, dh, server_url) return assoc def _genToken(self, nonce, consumer_id, server_id, server_url): timestamp=str(int(time.time())) elements=[timestamp, nonce, consumer_id, server_id, server_url] joined='\\x00'.join(elements) sig=cryptutil.hmacSha1(self.store.getAuthKey(), joined) return oidutil.toBase64('%s%s' %(sig, joined)) def _splitToken(self, token): token=oidutil.fromBase64(token) if len(token) < 20: raise ValueError('Bad token length: %d' % len(token)) sig, joined=token[:20], token[20:] if cryptutil.hmacSha1(self.store.getAuthKey(), joined) !=sig: raise ValueError('Bad token signature') split=joined.split('\\x00') if len(split) !=5: raise ValueError('Bad token contents(not enough fields)') try: ts=int(split[0]) except ValueError: raise ValueError('Bad token contents(timestamp bad)') if ts +self.TOKEN_LIFETIME < time.time(): raise ValueError('Token expired') return tuple(split[1:]) def _createAssociateRequest(self, dh=None, args=None): if args is None: args={} args.update({ 'openid.mode': 'associate', 'openid.assoc_type':'HMAC-SHA1', }) if dh: cpub=cryptutil.longToBase64(dh.public) args.update({ 'openid.session_type':'DH-SHA1', 'openid.dh_consumer_public': cpub, }) if not dh.usingDefaultValues(): args.update({ 'openid.dh_modulus': cryptutil.longToBase64(dh.modulus), 'openid.dh_gen': cryptutil.longToBase64(dh.generator), }) return args def _parseAssociation(self, results, dh, server_url): try: assoc_type=results['assoc_type'] if assoc_type !='HMAC-SHA1': fmt='Unsupported assoc_type returned from server %s: %s' oidutil.log(fmt %(server_url, assoc_type)) return None assoc_handle=results['assoc_handle'] try: expires_in=int(results.get('expires_in', '0')) except ValueError, e: fmt='Getting Association: invalid expires_in field: %s' oidutil.log(fmt %(e[0],)) return None session_type=results.get('session_type') if session_type is None: secret=oidutil.fromBase64(results['mac_key']) else: if session_type !='DH-SHA1': fmt='Unsupported session_type from server %s: %s' oidutil.log(fmt %(server_url, session_type)) return None if dh is None: fmt='Not expecting a DH-SHA1 session from server %s' oidutil.log(fmt %(server_url)) return None spub=cryptutil.base64ToLong(results['dh_server_public']) enc_mac_key=oidutil.fromBase64(results['enc_mac_key']) secret=dh.xorSecret(spub, enc_mac_key) assoc=Association.fromExpiresIn( expires_in, assoc_handle, secret, assoc_type) self.store.storeAssociation(server_url, assoc) return assoc except KeyError, e: fmt='Getting association: missing key in response from %s: %s' oidutil.log(fmt %(server_url, e[0])) return None class OpenIDAuthRequest(object): def __init__(self, token, assoc, endpoint): \"\"\" Creates a new OpenIDAuthRequest object. This just stores each argument in an appropriately named field. Users of this library should not create instances of this class. Instances of this class are created by the library when needed. \"\"\" self.assoc=assoc self.endpoint=endpoint self.extra_args={} self.token=token def addExtensionArg(self, namespace, key, value): arg_name='.'.join('openid', namespace, key) self.extra_args[arg_name]=value def redirectURL(self, trust_root, return_to, immediate=False): if immediate: mode='checkid_immediate' else: mode='checkid_setup' redir_args={ 'openid.mode': mode, 'openid.identity': self.endpoint.getServerID(), 'openid.return_to': return_to, 'openid.trust_root': trust_root, } if self.assoc: redir_args['openid.assoc_handle']=self.assoc.handle redir_args.update(self.extra_args) return oidutil.appendArgs(self.endpoint.server_url, redir_args) class OpenIDConsumerResponse(object): status=None class SuccessResponse(OpenIDConsumerResponse): status='success' def __init__(self, identity_url, signed_args): self.identity_url=identity_url self.signed_args=signed_args def fromQuery(cls, identity_url, query, signed): signed_args={} for field_name in signed.split(','): field_name='openid.' +field_name signed_args[field_name]=query.get(field_name, '') return cls(identity_url, signed_args) fromQuery=classmethod(fromQuery) def extensionResponse(self, prefix): response={} prefix='openid.%s.' %(prefix,) prefix_len=len(prefix) for k, v in self.signed_args.iteritems(): if k.startswith(prefix): response_key=k[prefix_len:] response[response_key]=v return response class FailureResponse(OpenIDConsumerResponse): status='failure' def __init__(self, identity_url=None, message=None): self.identity_url=identity_url self.message=message class CancelResponse(OpenIDConsumerResponse): status='cancelled' def __init__(self, identity_url=None): self.identity_url=identity_url class SetupNeededResponse(OpenIDConsumerResponse): status='setup_needed' def __init__(self, identity_url=None, setup_url=None): self.identity_url=identity_url self.setup_url=setup_url ","sourceWithComments":"\"\"\"\nThis module documents the main interface with the OpenID consumer\nlibary.  The only part of the library which has to be used and isn't\ndocumented in full here is the store required to create an\nC{L{OpenIDConsumer}} instance.  More on the abstract store type and\nconcrete implementations of it that are provided in the documentation\nfor the C{L{__init__<OpenIDConsumer.__init__>}} method of the\nC{L{OpenIDConsumer}} class.\n\n\nOVERVIEW\n========\n\n    The OpenID identity verification process most commonly uses the\n    following steps, as visible to the user of this library:\n\n        1. The user enters their OpenID into a field on the consumer's\n           site, and hits a login button.\n\n        2. The consumer site discovers the user's OpenID server using\n           the YADIS protocol.\n\n        3. The consumer site sends the browser a redirect to the\n           identity server.  This is the authentication request as\n           described in the OpenID specification.\n\n        4. The identity server's site sends the browser a redirect\n           back to the consumer site.  This redirect contains the\n           server's response to the authentication request.\n\n    The most important part of the flow to note is the consumer's site\n    must handle two separate HTTP requests in order to perform the\n    full identity check.\n\n\nLIBRARY DESIGN\n==============\n\n    This consumer library is designed with that flow in mind.  The\n    goal is to make it as easy as possible to perform the above steps\n    securely.\n\n    At a high level, there are two important parts in the consumer\n    library.  The first important part is this module, which contains\n    the interface to actually use this library.  The second is the\n    C{L{openid.store.interface}} module, which describes the\n    interface to use if you need to create a custom method for storing\n    the state this library needs to maintain between requests.\n\n    In general, the second part is less important for users of the\n    library to know about, as several implementations are provided\n    which cover a wide variety of situations in which consumers may\n    use the library.\n\n    This module contains a class, C{L{OpenIDConsumer}}, with methods\n    corresponding to the actions necessary in each of steps 2, 3, and\n    4 described in the overview.  Use of this library should be as easy\n    as creating an C{L{OpenIDConsumer}} instance and calling the methods\n    appropriate for the action the site wants to take.\n\n\nSTORES AND DUMB MODE\n====================\n\n    OpenID is a protocol that works best when the consumer site is\n    able to store some state.  This is the normal mode of operation\n    for the protocol, and is sometimes referred to as smart mode.\n    There is also a fallback mode, known as dumb mode, which is\n    available when the consumer site is not able to store state.  This\n    mode should be avoided when possible, as it leaves the\n    implementation more vulnerable to replay attacks.\n\n    The mode the library works in for normal operation is determined\n    by the store that it is given.  The store is an abstraction that\n    handles the data that the consumer needs to manage between http\n    requests in order to operate efficiently and securely.\n\n    Several store implementation are provided, and the interface is\n    fully documented so that custom stores can be used as well.  See\n    the documentation for the C{L{OpenIDConsumer}} class for more\n    information on the interface for stores.  The implementations that\n    are provided allow the consumer site to store the necessary data\n    in several different ways, including several SQL databases and\n    normal files on disk.\n\n    There is an additional concrete store provided that puts the\n    system in dumb mode.  This is not recommended, as it removes the\n    library's ability to stop replay attacks reliably.  It still uses\n    time-based checking to make replay attacks only possible within a\n    small window, but they remain possible within that window.  This\n    store should only be used if the consumer site has no way to\n    retain data between requests at all.\n\n\nIMMEDIATE MODE\n==============\n\n    In the flow described above, the user may need to confirm to the\n    identity server that it's ok to authorize his or her identity.\n    The server may draw pages asking for information from the user\n    before it redirects the browser back to the consumer's site.  This\n    is generally transparent to the consumer site, so it is typically\n    ignored as an implementation detail.\n\n    There can be times, however, where the consumer site wants to get\n    a response immediately.  When this is the case, the consumer can\n    put the library in immediate mode.  In immediate mode, there is an\n    extra response possible from the server, which is essentially the\n    server reporting that it doesn't have enough information to answer\n    the question yet.  In addition to saying that, the identity server\n    provides a URL to which the user can be sent to provide the needed\n    information and let the server finish handling the original\n    request.\n\n\nUSING THIS LIBRARY\n==================\n\n    Integrating this library into an application is usually a\n    relatively straightforward process.  The process should basically\n    follow this plan:\n\n    Add an OpenID login field somewhere on your site.  When an OpenID\n    is entered in that field and the form is submitted, it should make\n    a request to the your site which includes that OpenID URL.\n\n    To start, the application should get an C{L{OpenIDConsumer}}\n    instance, and call its C{L{begin<OpenIDConsumer.begin>}} method.\n    This method takes the OpenID URL and, optionally, a session\n    object.  If the application has any sort of session framework that\n    provides per-client state management, that should be used here.\n    The library just expects the session object to support a\n    C{dict}-like interface, if it provided.  If no session object is\n    provided, the application code needs to store the information that\n    would have been put in the session in an alternate location.  See\n    the documentation for the C{L{begin<OpenIDConsumer.begin>}} call\n    for more information.  The C{L{begin<OpenIDConsumer.begin>}}\n    method returns an C{L{OpenIDRequestBuilder}} object.\n\n    Next, the application should call the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on\n    the C{L{OpenIDRequestBuilder}} object.  The return_to URL is the\n    URL that the OpenID server will send the user back to after\n    attempting to verify his or her identity.  The trust_root is the\n    URL (or URL pattern) that identifies your web site to the user\n    when he or she is authorizing it.  Send a redirect to the\n    resulting URL to the user's browser.\n\n    That's the first half of the authentication process.  The second\n    half of the process is done after the user's ID server sends the\n    user's browser a redirect back to your site to complete their\n    login.\n\n    When that happens, the user will contact your site at the URL\n    given as the C{return_to} URL to the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made\n    above.  The request will have several query parameters added to\n    the URL by the identity server as the information necessary to\n    finish the request.\n\n    Get an C{L{OpenIDConsumer}} instance, and call its\n    C{L{complete<OpenIDConsumer.complete>}} method, passing in all the\n    received query arguments and either the user's session object or\n    the token saved earlier.  See the documentation for\n    C{L{OpenIDRequestBuilder}} for more information about the token.\n\n    There are multiple possible return types possible from that\n    method.  These indicate the whether or not the login was\n    successful, and include any additional information appropriate for\n    their type.\n\"\"\"\n\nimport string\nimport time\nimport urllib\nfrom urlparse import urlparse\n\nfrom urljr import fetchers\n\nfrom openid.consumer.discover import discover as openIDDiscover\nfrom openid.consumer.discover import yadis_available\nfrom openid import cryptutil\nfrom openid import kvform\nfrom openid import oidutil\nfrom openid.association import Association\nfrom openid.dh import DiffieHellman\n\n__all__ = ['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse',\n           'SetupNeededResponse', 'CancelResponse', 'FailureResponse']\n\nif yadis_available:\n    from yadis.manager import Discovery\n\nclass OpenIDConsumer(object):\n    session_key_prefix = \"_openid_consumer_\"\n\n    _token = 'last_token'\n\n    def __init__(self, session, store):\n        self.session = session\n        self.consumer = GenericOpenIDConsumer(store)\n        self._token_key = self.session_key_prefix + self._token\n\n    def begin(self, user_url):\n        openid_url = oidutil.normalizeUrl(user_url)\n        if yadis_available:\n            disco = Discovery(self.session, openid_url, 'XXX')\n            endpoint = disco.getNextService(openIDDiscover)\n        else:\n            _, endpoints = openIDDiscover(openid_url)\n            if not endpoints:\n                endpoint = None\n            else:\n                endpoint = endpoints[0]\n\n        if endpoint is None:\n            return None\n        else:\n            return self.beginWithoutDiscovery(endpoint)\n\n    def beginWithoutDiscovery(self, endpoint):\n        auth_req = self.consumer.begin(endpoint)\n        self.session[self._token_key] = auth_req.token\n        return auth_req\n\n    def complete(self, query):\n        token = self.session.get(self._token_key)\n        if token is None:\n            response = FailureResponse(None, 'No session state found')\n        else:\n            response = self.consumer.complete(query, token)\n\n        if response.status in ['success',\n                               'cancel'#maybe\n                               ]:\n            if yadis_available and response.identity_url is not None:\n                disco = Discovery(self.session, response.identity_url)\n                # This is OK to do even if we did not do discovery in\n                # the first place.\n                disco.cleanup()\n\n        return response\n\nclass GenericOpenIDConsumer(object):\n    \"\"\"This is the implementation of the common logic for OpenID\n    consumers. It is unaware of the application in which it is\n    running.\n    \"\"\"\n\n    TOKEN_LIFETIME = 60 * 5 # five minutes\n    NONCE_LEN = 8\n    NONCE_CHRS = string.letters + string.digits\n\n    def __init__(self, store):\n        \"\"\"\n        This method initializes a new C{L{OpenIDConsumer}} instance to\n        access the library.\n\n        @param store: This must be an object that implements the\n            interface in C{L{openid.store.interface.OpenIDStore}}.\n            Several concrete implementations are provided, to cover\n            most common use cases.  For stores backed by MySQL or\n            SQLite, see the C{L{openid.store.sqlstore.SQLStore}}\n            class and its sublcasses.  For a filesystem-backed store,\n            see the C{L{openid.store.filestore}} module.\n\n            As a last resort, if it isn't possible for the server to\n            store state at all, an instance of\n            C{L{openid.store.dumbstore.DumbStore}} can be used.  This\n            should be an absolute last resort, though, as it makes the\n            consumer vulnerable to replay attacks over the lifespan of\n            the tokens the library creates.\n\n        @type store: C{L{openid.store.interface.OpenIDStore}}\n\n        \"\"\"\n        self.store = store\n\n    def begin(self, service_endpoint):\n        nonce = self._createNonce()\n        token = self._genToken(\n            nonce,\n            service_endpoint.identity_url,\n            service_endpoint.getServerID(),\n            service_endpoint.server_url,\n            )\n        assoc = self._getAssociation(service_endpoint.server_url)\n        return OpenIDAuthRequest(token, assoc, service_endpoint)\n\n    def complete(self, query, token):\n        mode = query.get('openid.mode', '<no mode specified>')\n\n        # Get the current request's state\n        try:\n            pieces = self._splitToken(token)\n        except ValueError, why:\n            oidutil.log(why[0])\n            pieces = (None, None, None, None, None)\n\n        (nonce, identity_url, delegate, server_url) = pieces\n\n        if mode == 'cancel':\n            return CancelResponse(identity_url)\n        elif mode == 'error':\n            error = query.get('openid.error')\n            return FailureResponse(identity_url, error)\n        elif mode == 'id_res':\n            if identity_url is None:\n                return FailureResponse(identity_url, 'No session state found')\n            try:\n                response = self._doIdRes(\n                    query, identity_url, delegate, server_url)\n            except fetchers.HTTPFetchingError, why:\n                message = 'HTTP request failed: %s' % (str(why),)\n                return FailureResponse(identity_url, message)\n            else:\n                if (response.status == 'success' and\n                    not self.store.useNonce(nonce)):\n\n                    return FailureResponse(identity_url, 'Nonce already used')\n                else:\n                    return response\n        else:\n            return FailureResponse(identity_url,\n                                   'Invalid openid.mode: %r' % (mode,))\n\n    def _createNonce(self):\n        nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n        self.store.storeNonce(nonce)\n        return nonce\n\n    def _makeKVPost(self, args, server_url):\n        mode = args['openid.mode']\n        body = urllib.urlencode(args)\n\n        resp = fetchers.fetch(server_url, body=body)\n        if resp is None:\n            fmt = 'openid.mode=%s: failed to fetch URL: %s'\n            oidutil.log(fmt % (mode, server_url))\n            return None\n\n        response = kvform.kvToDict(resp.body)\n        if resp.status == 400:\n            server_error = response.get('error', '<no message from server>')\n            fmt = 'openid.mode=%s: error returned from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, server_error))\n            return None\n        elif resp.status != 200:\n            fmt = 'openid.mode=%s: bad status code from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, resp.status))\n            return None\n\n        return response\n\n    def _doIdRes(self, query, consumer_id, server_id, server_url):\n        user_setup_url = query.get('openid.user_setup_url')\n        if user_setup_url is not None:\n            return SetupNeededResponse(consumer_id, user_setup_url)\n\n        return_to = query.get('openid.return_to')\n        server_id2 = query.get('openid.identity')\n        assoc_handle = query.get('openid.assoc_handle')\n\n        if return_to is None or server_id is None or assoc_handle is None:\n            return FailureResponse(consumer_id, 'Missing required field')\n\n        if server_id != server_id2:\n            return FailureResponse(consumer_id, 'Server ID (delegate) mismatch')\n\n        signed = query.get('openid.signed')\n\n        assoc = self.store.getAssociation(server_url, assoc_handle)\n\n        if assoc is None:\n            # It's not an association we know about.  Dumb mode is our\n            # only possible path for recovery.\n            if self._checkAuth(query, server_url):\n                return SuccessResponse.fromQuery(consumer_id, query, signed)\n            else:\n                return FailureResponse(consumer_id,\n                                       'Server denied check_authentication')\n\n        if assoc.expiresIn <= 0:\n            # XXX: It might be a good idea sometimes to re-start the\n            # authentication with a new association. Doing it\n            # automatically opens the possibility for\n            # denial-of-service by a server that just returns expired\n            # associations (or really short-lived associations)\n            msg = 'Association with %s expired' % (server_url,)\n            return FailureResponse(consumer_id, msg)\n\n        # Check the signature\n        sig = query.get('openid.sig')\n        if sig is None or signed is None:\n            return FailureResponse(consumer_id, 'Missing argument signature')\n\n        signed_list = signed.split(',')\n        v_sig = assoc.signDict(signed_list, query)\n\n        if v_sig != sig:\n            return FailureResponse(consumer_id, 'Bad signature')\n\n        return SuccessResponse.fromQuery(consumer_id, query, signed)\n\n    def _checkAuth(self, query, server_url):\n        request = self._createCheckAuthRequest(query)\n        if request is None:\n            return False\n        response = self._makeKVPost(request, server_url)\n        if response is None:\n            return False\n        return self._processCheckAuthResponse(response)\n\n    def _createCheckAuthRequest(self, query):\n        signed = query.get('openid.signed')\n        if signed is None:\n            oidutil.log('No signature present; checkAuth aborted')\n            return None\n\n        # Arguments that are always passed to the server and not\n        # included in the signature.\n        whitelist = ['assoc_handle', 'sig', 'signed', 'invalidate_handle']\n        signed = signed.split(',') + whitelist\n\n        check_args = dict([(k, v) for k, v in query.iteritems()\n                           if k.startswith('openid.') and k[7:] in signed])\n\n        check_args['openid.mode'] = 'check_authentication'\n        return check_args\n\n    def _processCheckAuthResponse(self, response):\n        is_valid = response.get('is_valid', 'false')\n\n        if is_valid == 'true':\n            invalidate_handle = response.get('invalidate_handle')\n            if invalidate_handle is not None:\n                self.store.removeAssociation(server_url, invalidate_handle)\n\n            return True\n\n        oidutil.log('Server responds that checkAuth call is not valid')\n        return False\n\n    def _getAssociation(self, server_url):\n        if self.store.isDumb():\n            return None\n\n        assoc = self.store.getAssociation(server_url)\n\n        if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME:\n            proto = urlparse(server_url)[0]\n            if proto == 'https':\n                dh = None\n            else:\n                dh = DiffieHellman()\n\n            args = self._createAssociateRequest(dh)\n            try:\n                response = self._makeKVPost(args, server_url)\n            except fetchers.HTTPFetchingError, why:\n                oidutil.log('openid.associate request failed: %s' %\n                            (str(why),))\n                assoc = None\n            else:\n                assoc = self._parseAssociation(response, dh, server_url)\n\n        return assoc\n\n    def _genToken(self, nonce, consumer_id, server_id, server_url):\n        timestamp = str(int(time.time()))\n        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n        joined = '\\x00'.join(elements)\n        sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n\n        return oidutil.toBase64('%s%s' % (sig, joined))\n\n    def _splitToken(self, token):\n        token = oidutil.fromBase64(token)\n        if len(token) < 20:\n            raise ValueError('Bad token length: %d' % len(token))\n\n        sig, joined = token[:20], token[20:]\n        if cryptutil.hmacSha1(self.store.getAuthKey(), joined) != sig:\n            raise ValueError('Bad token signature')\n\n        split = joined.split('\\x00')\n        if len(split) != 5:\n            raise ValueError('Bad token contents (not enough fields)')\n\n        try:\n            ts = int(split[0])\n        except ValueError:\n            raise ValueError('Bad token contents (timestamp bad)')\n\n        if ts + self.TOKEN_LIFETIME < time.time():\n            raise ValueError('Token expired')\n\n        return tuple(split[1:])\n\n    def _createAssociateRequest(self, dh=None, args=None):\n        if args is None:\n            args = {}\n\n        args.update({\n            'openid.mode': 'associate',\n            'openid.assoc_type':'HMAC-SHA1',\n            })\n\n        if dh:\n            cpub = cryptutil.longToBase64(dh.public)\n\n            args.update({\n                'openid.session_type':'DH-SHA1',\n                'openid.dh_consumer_public': cpub,\n                })\n\n            if not dh.usingDefaultValues():\n                args.update({\n                    'openid.dh_modulus': cryptutil.longToBase64(dh.modulus),\n                    'openid.dh_gen': cryptutil.longToBase64(dh.generator),\n                    })\n\n        return args\n\n    def _parseAssociation(self, results, dh, server_url):\n        try:\n            assoc_type = results['assoc_type']\n            if assoc_type != 'HMAC-SHA1':\n                fmt = 'Unsupported assoc_type returned from server %s: %s'\n                oidutil.log(fmt % (server_url, assoc_type))\n                return None\n\n            assoc_handle = results['assoc_handle']\n            try:\n                expires_in = int(results.get('expires_in', '0'))\n            except ValueError, e:\n                fmt = 'Getting Association: invalid expires_in field: %s'\n                oidutil.log(fmt % (e[0],))\n                return None\n\n            session_type = results.get('session_type')\n            if session_type is None:\n                secret = oidutil.fromBase64(results['mac_key'])\n            else:\n                if session_type != 'DH-SHA1':\n                    fmt = 'Unsupported session_type from server %s: %s'\n                    oidutil.log(fmt % (server_url, session_type))\n                    return None\n                if dh is None:\n                    fmt = 'Not expecting a DH-SHA1 session from server %s'\n                    oidutil.log(fmt % (server_url))\n                    return None\n\n                spub = cryptutil.base64ToLong(results['dh_server_public'])\n                enc_mac_key = oidutil.fromBase64(results['enc_mac_key'])\n                secret = dh.xorSecret(spub, enc_mac_key)\n\n            assoc = Association.fromExpiresIn(\n                expires_in, assoc_handle, secret, assoc_type)\n            self.store.storeAssociation(server_url, assoc)\n\n            return assoc\n\n        except KeyError, e:\n            fmt = 'Getting association: missing key in response from %s: %s'\n            oidutil.log(fmt % (server_url, e[0]))\n            return None\n\nclass OpenIDAuthRequest(object):\n    def __init__(self, token, assoc, endpoint):\n        \"\"\"\n        Creates a new OpenIDAuthRequest object.  This just stores each\n        argument in an appropriately named field.\n\n        Users of this library should not create instances of this\n        class.  Instances of this class are created by the library\n        when needed.\n        \"\"\"\n        self.assoc = assoc\n        self.endpoint = endpoint\n        self.extra_args = {}\n        self.token = token\n\n    def addExtensionArg(self, namespace, key, value):\n        arg_name = '.'.join('openid', namespace, key)\n        self.extra_args[arg_name] = value\n\n    def redirectURL(self, trust_root, return_to, immediate=False):\n        if immediate:\n            mode = 'checkid_immediate'\n        else:\n            mode = 'checkid_setup'\n\n        redir_args = {\n            'openid.mode': mode,\n            'openid.identity': self.endpoint.getServerID(),\n            'openid.return_to': return_to,\n            'openid.trust_root': trust_root,\n            }\n\n        if self.assoc:\n            redir_args['openid.assoc_handle'] = self.assoc.handle\n\n        redir_args.update(self.extra_args)\n        return oidutil.appendArgs(self.endpoint.server_url, redir_args)\n\nclass OpenIDConsumerResponse(object):\n    status = None\n\nclass SuccessResponse(OpenIDConsumerResponse):\n    status = 'success'\n\n    def __init__(self, identity_url, signed_args):\n        self.identity_url = identity_url\n        self.signed_args = signed_args\n\n    def fromQuery(cls, identity_url, query, signed):\n        signed_args = {}\n        for field_name in signed.split(','):\n            field_name = 'openid.' + field_name\n            signed_args[field_name] = query.get(field_name, '')\n        return cls(identity_url, signed_args)\n\n    fromQuery = classmethod(fromQuery)\n\n    def extensionResponse(self, prefix):\n        response = {}\n        prefix = 'openid.%s.' % (prefix,)\n        prefix_len = len(prefix)\n        for k, v in self.signed_args.iteritems():\n            if k.startswith(prefix):\n                response_key = k[prefix_len:]\n                response[response_key] = v\n\n        return response\n\nclass FailureResponse(OpenIDConsumerResponse):\n    status = 'failure'\n\n    def __init__(self, identity_url=None, message=None):\n        self.identity_url = identity_url\n        self.message = message\n\nclass CancelResponse(OpenIDConsumerResponse):\n    status = 'cancelled'\n\n    def __init__(self, identity_url=None):\n        self.identity_url = identity_url\n\nclass SetupNeededResponse(OpenIDConsumerResponse):\n    status = 'setup_needed'\n\n    def __init__(self, identity_url=None, setup_url=None):\n        self.identity_url = identity_url\n        self.setup_url = setup_url\n"},"\/test\/consumer.py":{"changes":[{"diff":"\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n","add":5,"remove":2,"filename":"\/test\/consumer.py","badparts":["            'openid.return_to':return_to,","            'openid.return_to':return_to,"],"goodparts":["        new_return_to = q['openid.return_to']","        del q['openid.return_to']","        assert new_return_to.startswith(return_to)","            'nonce':request.return_to_args['nonce'],","            'openid.return_to':new_return_to,"]},{"diff":"\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","add":1,"remove":1,"filename":"\/test\/consumer.py","badparts":["        assert info.status == 'success'"],"goodparts":["        assert info.status == 'success', info.message"]}],"source":"\nimport urlparse import cgi import time from openid import cryptutil, dh, oidutil, kvform from openid.consumer.discover import OpenIDServiceEndpoint from openid.consumer.consumer import GenericOpenIDConsumer from openid import association from openid.consumer import parse from urljr.fetchers import HTTPResponse from urljr import fetchers import _memstore assocs=[ ('another 20-byte key.', 'Snarky'), ('\\x00' * 20, 'Zeros'), ] def parseQuery(qs): q={} for(k, v) in cgi.parse_qsl(qs): assert not q.has_key(k) q[k]=v return q def associate(qs, assoc_secret, assoc_handle): \"\"\"Do the server's half of the associate call, using the given secret and handle.\"\"\" q=parseQuery(qs) assert q['openid.mode']=='associate' assert q['openid.assoc_type']=='HMAC-SHA1' if q.get('openid.session_type')=='DH-SHA1': assert len(q)==6 or len(q)==4 d=dh.DiffieHellman.fromBase64( q.get('openid.dh_modulus'), q.get('openid.dh_gen')) composite=cryptutil.base64ToLong(q['openid.dh_consumer_public']) enc_mac_key=oidutil.toBase64(d.xorSecret(composite, assoc_secret)) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'session_type':'DH-SHA1', 'dh_server_public':cryptutil.longToBase64(d.public), 'enc_mac_key':enc_mac_key, } else: assert len(q)==2 mac_key=oidutil.toBase64(assoc_secret) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'mac_key':mac_key, } return kvform.dictToKV(reply_dict) class TestFetcher(object): def __init__(self, user_url, user_page,(assoc_secret, assoc_handle)): self.get_responses={user_url:self.response(user_url, 200, user_page)} self.assoc_secret=assoc_secret self.assoc_handle=assoc_handle self.num_assocs=0 def response(self, url, status, body): return HTTPResponse( final_url=url, status=status, headers={}, body=body) def fetch(self, url, body=None, headers=None): if body is None: if url in self.get_responses: return self.get_responses[url] else: try: body.index('openid.mode=associate') except ValueError: pass else: if urlparse.urlparse(url)[0]=='https': assert body.find('DH-SHA1')==-1 else: assert body.find('DH-SHA1') !=-1 response=associate( body, self.assoc_secret, self.assoc_handle) self.num_assocs +=1 return self.response(url, 200, response) return self.response(url, 404, 'Not found') def _test_success(server_url, user_url, delegate_url, links, immediate=False): store=_memstore.MemoryStore() if immediate: mode='checkid_immediate' else: mode='checkid_setup' endpoint=OpenIDServiceEndpoint() endpoint.identity_url=user_url endpoint.server_url=server_url endpoint.delegate=delegate_url fetcher=TestFetcher(None, None, assocs[0]) fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False) def run(): trust_root=consumer_url consumer=GenericOpenIDConsumer(store) request=consumer.begin(endpoint) return_to=consumer_url redirect_url=request.redirectURL(trust_root, return_to, immediate) parsed=urlparse.urlparse(redirect_url) qs=parsed[4] q=parseQuery(qs) assert q=={ 'openid.mode':mode, 'openid.identity':delegate_url, 'openid.trust_root':trust_root, 'openid.assoc_handle':fetcher.assoc_handle, 'openid.return_to':return_to, },(q, user_url, delegate_url, mode) assert redirect_url.startswith(server_url) query={ 'openid.mode':'id_res', 'openid.return_to':return_to, 'openid.identity':delegate_url, 'openid.assoc_handle':fetcher.assoc_handle, } assoc=store.getAssociation(server_url, fetcher.assoc_handle) assoc.addSignature(['mode', 'return_to', 'identity'], query) info=consumer.complete(query, request.token) assert info.status=='success' assert info.identity_url==user_url assert fetcher.num_assocs==0 run() assert fetcher.num_assocs==1 run() assert fetcher.num_assocs==1 store.removeAssociation(server_url, fetcher.assoc_handle) run() assert fetcher.num_assocs==2 run() assert fetcher.num_assocs==2 import unittest http_server_url='http:\/\/server.example.com\/' consumer_url='http:\/\/consumer.example.com\/' https_server_url='https:\/\/server.example.com\/' class TestSuccess(unittest.TestCase): server_url=http_server_url user_url='http:\/\/www.example.com\/user.html' delegate_url='http:\/\/consumer.example.com\/user' def setUp(self): self.links='<link rel=\"openid.server\" href=\"%s\" \/>' %( self.server_url,) self.delegate_links=('<link rel=\"openid.server\" href=\"%s\" \/>' '<link rel=\"openid.delegate\" href=\"%s\" \/>') %( self.server_url, self.delegate_url) def test_nodelegate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links) def test_nodelegateImmediate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links, True) def test_delegate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links) def test_delegateImmediate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links, True) class TestSuccessHTTPS(TestSuccess): server_url=https_server_url class TestConstruct(unittest.TestCase): def setUp(self): self.store_sentinel=object() def test_construct(self): oidc=GenericOpenIDConsumer(self.store_sentinel) self.failUnless(oidc.store is self.store_sentinel) def test_nostore(self): self.failUnlessRaises(TypeError, GenericOpenIDConsumer) class TestIdRes(unittest.TestCase): consumer_class=GenericOpenIDConsumer def setUp(self): self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.return_to=\"nonny\" self.server_id=\"sirod\" self.server_url=\"serlie\" self.consumer_id=\"consu\" class TestSetupNeeded(TestIdRes): def test_setupNeeded(self): setup_url='http:\/\/unittest\/setup-here' query={ 'openid.mode': 'id_res', 'openid.user_setup_url': setup_url, } ret=self.consumer._doIdRes(query, self.consumer_id, self.server_id, self.server_url, ) self.failUnlessEqual(ret.status, 'setup_needed') self.failUnlessEqual(ret.setup_url, setup_url) class CheckAuthHappened(Exception): pass class CheckAuthDetectingConsumer(GenericOpenIDConsumer): def _checkAuth(self, *args): raise CheckAuthHappened(args) class CatchLogs(object): def setUp(self): self.old_logger=oidutil.log oidutil.log=self.gotLogMessage self.messages=[] def gotLogMessage(self, message): self.messages.append(message) def tearDown(self): oidutil.log=self.old_logger class TestCheckAuthTriggered(TestIdRes, CatchLogs): consumer_class=CheckAuthDetectingConsumer def setUp(self): TestIdRes.setUp(self) CatchLogs.setUp(self) def _doIdRes(self, query): return self.consumer._doIdRes( query, self.consumer_id, self.server_id, self.server_url) def test_checkAuthTriggered(self): query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r %s' % (result, self.messages)) def test_checkAuthTriggeredWithAssoc(self): issued=time.time() lifetime=1000 assoc=association.Association( 'handle', 'secret', issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r' %(result,)) def test_expiredAssoc(self): issued=time.time() -10 lifetime=0 handle='handle' assoc=association.Association( handle, 'secret', issued, lifetime, 'HMAC-SHA1') self.failUnless(assoc.expiresIn <=0) self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':handle, } info=self._doIdRes(query) self.failUnlessEqual('failure', info.status) self.failUnlessEqual(self.consumer_id, info.identity_url) info.message.index('expired') def test_newerAssoc(self): lifetime=1000 good_issued=time.time() -10 good_handle='handle' good_assoc=association.Association( good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, good_assoc) bad_issued=time.time() -5 bad_handle='handle2' bad_assoc=association.Association( bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, bad_assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':good_handle, } good_assoc.addSignature(['return_to', 'identity'], query) info=self._doIdRes(query) self.failUnlessEqual(info.status, 'success') self.failUnlessEqual(self.consumer_id, info.identity_url) class MockFetcher(object): def __init__(self, response=None): self.response=response or HTTPResponse() self.fetches=[] def fetch(self, url, body=None, headers=None): self.fetches.append((url, body, headers)) return self.response class ExceptionRaisingMockFetcher(object): def fetch(self, url, body=None, headers=None): raise Exception('mock fetcher exception') class BadArgCheckingConsumer(GenericOpenIDConsumer): def _makeKVPost(self, args, _): assert args=={ 'openid.mode':'check_authentication', 'openid.signed':'foo', }, args return None class TestCheckAuth(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') query={'openid.signed': 'stuff, things'} r=self.consumer._checkAuth(query, http_server_url) self.failIf(r) self.failUnless(self.messages) def test_bad_args(self): query={ 'openid.signed':'foo', 'closid.foo':'something', } consumer=BadArgCheckingConsumer(self.store) consumer._checkAuth(query, 'does:\/\/not.matter') class TestFetchAssoc(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.consumer=self.consumer_class(self.store) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') r=self.consumer._makeKVPost({'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnlessEqual(r, None) self.failUnless(self.messages) def test_error_exception(self): self.fetcher=ExceptionRaisingMockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._makeKVPost, {'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnless(self.consumer._getAssociation('some:\/\/url') is None) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._checkAuth, {'openid.signed':''}, 'some:\/\/url') if __name__=='__main__': unittest.main() ","sourceWithComments":"import urlparse\nimport cgi\nimport time\n\nfrom openid import cryptutil, dh, oidutil, kvform\nfrom openid.consumer.discover import OpenIDServiceEndpoint\nfrom openid.consumer.consumer import GenericOpenIDConsumer\nfrom openid import association\n\nfrom openid.consumer import parse\n\nfrom urljr.fetchers import HTTPResponse\nfrom urljr import fetchers\n\nimport _memstore\n\nassocs = [\n    ('another 20-byte key.', 'Snarky'),\n    ('\\x00' * 20, 'Zeros'),\n    ]\n\ndef parseQuery(qs):\n    q = {}\n    for (k, v) in cgi.parse_qsl(qs):\n        assert not q.has_key(k)\n        q[k] = v\n    return q\n\ndef associate(qs, assoc_secret, assoc_handle):\n    \"\"\"Do the server's half of the associate call, using the given\n    secret and handle.\"\"\"\n    q = parseQuery(qs)\n    assert q['openid.mode'] == 'associate'\n    assert q['openid.assoc_type'] == 'HMAC-SHA1'\n    if q.get('openid.session_type') == 'DH-SHA1':\n        assert len(q) == 6 or len(q) == 4\n        d = dh.DiffieHellman.fromBase64(\n            q.get('openid.dh_modulus'), q.get('openid.dh_gen'))\n\n        composite = cryptutil.base64ToLong(q['openid.dh_consumer_public'])\n        enc_mac_key = oidutil.toBase64(d.xorSecret(composite, assoc_secret))\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'session_type':'DH-SHA1',\n            'dh_server_public':cryptutil.longToBase64(d.public),\n            'enc_mac_key':enc_mac_key,\n            }\n    else:\n        assert len(q) == 2\n        mac_key = oidutil.toBase64(assoc_secret)\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'mac_key':mac_key,\n            }\n\n    return kvform.dictToKV(reply_dict)\n\nclass TestFetcher(object):\n    def __init__(self, user_url, user_page, (assoc_secret, assoc_handle)):\n        self.get_responses = {user_url:self.response(user_url, 200, user_page)}\n        self.assoc_secret = assoc_secret\n        self.assoc_handle = assoc_handle\n        self.num_assocs = 0\n\n    def response(self, url, status, body):\n        return HTTPResponse(\n            final_url=url, status=status, headers={}, body=body)\n\n    def fetch(self, url, body=None, headers=None):\n        if body is None:\n            if url in self.get_responses:\n                return self.get_responses[url]\n        else:\n            try:\n                body.index('openid.mode=associate')\n            except ValueError:\n                pass # fall through\n            else:\n                if urlparse.urlparse(url)[0] == 'https':\n                    # Should not be doing DH-SHA1 when using HTTPS.\n                    assert body.find('DH-SHA1') == -1\n                else:\n                    assert body.find('DH-SHA1') != -1\n                response = associate(\n                    body, self.assoc_secret, self.assoc_handle)\n                self.num_assocs += 1\n                return self.response(url, 200, response)\n\n        return self.response(url, 404, 'Not found')\n\ndef _test_success(server_url, user_url, delegate_url, links, immediate=False):\n    store = _memstore.MemoryStore()\n    if immediate:\n        mode = 'checkid_immediate'\n    else:\n        mode = 'checkid_setup'\n\n    endpoint = OpenIDServiceEndpoint()\n    endpoint.identity_url = user_url\n    endpoint.server_url = server_url\n    endpoint.delegate = delegate_url\n\n    fetcher = TestFetcher(None, None, assocs[0])\n    fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False)\n\n    def run():\n        trust_root = consumer_url\n\n        consumer = GenericOpenIDConsumer(store)\n        request = consumer.begin(endpoint)\n\n        return_to = consumer_url\n        redirect_url = request.redirectURL(trust_root, return_to, immediate)\n\n        parsed = urlparse.urlparse(redirect_url)\n        qs = parsed[4]\n        q = parseQuery(qs)\n        assert q == {\n            'openid.mode':mode,\n            'openid.identity':delegate_url,\n            'openid.trust_root':trust_root,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            'openid.return_to':return_to,\n            }, (q, user_url, delegate_url, mode)\n\n        assert redirect_url.startswith(server_url)\n\n        query = {\n            'openid.mode':'id_res',\n            'openid.return_to':return_to,\n            'openid.identity':delegate_url,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            }\n\n        assoc = store.getAssociation(server_url, fetcher.assoc_handle)\n        assoc.addSignature(['mode', 'return_to', 'identity'], query)\n\n        info = consumer.complete(query, request.token)\n        assert info.status == 'success'\n        assert info.identity_url == user_url\n\n    assert fetcher.num_assocs == 0\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Another association is created if we remove the existing one\n    store.removeAssociation(server_url, fetcher.assoc_handle)\n    run()\n    assert fetcher.num_assocs == 2\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 2\n\nimport unittest\n\nhttp_server_url = 'http:\/\/server.example.com\/'\nconsumer_url = 'http:\/\/consumer.example.com\/'\nhttps_server_url = 'https:\/\/server.example.com\/'\n\nclass TestSuccess(unittest.TestCase):\n    server_url = http_server_url\n    user_url = 'http:\/\/www.example.com\/user.html'\n    delegate_url = 'http:\/\/consumer.example.com\/user'\n\n    def setUp(self):\n        self.links = '<link rel=\"openid.server\" href=\"%s\" \/>' % (\n            self.server_url,)\n\n        self.delegate_links = ('<link rel=\"openid.server\" href=\"%s\" \/>'\n                               '<link rel=\"openid.delegate\" href=\"%s\" \/>') % (\n            self.server_url, self.delegate_url)\n\n    def test_nodelegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links)\n\n    def test_nodelegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links, True)\n\n    def test_delegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links)\n\n    def test_delegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links, True)\n\n\nclass TestSuccessHTTPS(TestSuccess):\n    server_url = https_server_url\n\n\nclass TestConstruct(unittest.TestCase):\n    def setUp(self):\n        self.store_sentinel = object()\n\n    def test_construct(self):\n        oidc = GenericOpenIDConsumer(self.store_sentinel)\n        self.failUnless(oidc.store is self.store_sentinel)\n\n    def test_nostore(self):\n        self.failUnlessRaises(TypeError, GenericOpenIDConsumer)\n\n\nclass TestIdRes(unittest.TestCase):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        self.store = _memstore.MemoryStore()\n        self.consumer = self.consumer_class(self.store)\n        self.return_to = \"nonny\"\n        self.server_id = \"sirod\"\n        self.server_url = \"serlie\"\n        self.consumer_id = \"consu\"\n\nclass TestSetupNeeded(TestIdRes):\n    def test_setupNeeded(self):\n        setup_url = 'http:\/\/unittest\/setup-here'\n        query = {\n            'openid.mode': 'id_res',\n            'openid.user_setup_url': setup_url,\n            }\n        ret = self.consumer._doIdRes(query,\n                                     self.consumer_id,\n                                     self.server_id,\n                                     self.server_url,\n                                     )\n        self.failUnlessEqual(ret.status, 'setup_needed')\n        self.failUnlessEqual(ret.setup_url, setup_url)\n\nclass CheckAuthHappened(Exception): pass\n\nclass CheckAuthDetectingConsumer(GenericOpenIDConsumer):\n    def _checkAuth(self, *args):\n        raise CheckAuthHappened(args)\n\nclass CatchLogs(object):\n    def setUp(self):\n        self.old_logger = oidutil.log\n        oidutil.log = self.gotLogMessage\n        self.messages = []\n\n    def gotLogMessage(self, message):\n        self.messages.append(message)\n\n    def tearDown(self):\n        oidutil.log = self.old_logger\n\nclass TestCheckAuthTriggered(TestIdRes, CatchLogs):\n    consumer_class = CheckAuthDetectingConsumer\n\n    def setUp(self):\n        TestIdRes.setUp(self)\n        CatchLogs.setUp(self)\n\n    def _doIdRes(self, query):\n        return self.consumer._doIdRes(\n            query,\n            self.consumer_id,\n            self.server_id,\n            self.server_url)\n\n    def test_checkAuthTriggered(self):\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r %s' %\n                      (result, self.messages))\n\n    def test_checkAuthTriggeredWithAssoc(self):\n        # Store an association for this server that does not match the\n        # handle that is in the query\n        issued = time.time()\n        lifetime = 1000\n        assoc = association.Association(\n            'handle', 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r' % (result,))\n\n    def test_expiredAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        issued = time.time() - 10\n        lifetime = 0\n        handle = 'handle'\n        assoc = association.Association(\n            handle, 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.failUnless(assoc.expiresIn <= 0)\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':handle,\n            }\n        info = self._doIdRes(query)\n        self.failUnlessEqual('failure', info.status)\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n        info.message.index('expired') # raises an exception if it's not there\n\n    def test_newerAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        lifetime = 1000\n\n        good_issued = time.time() - 10\n        good_handle = 'handle'\n        good_assoc = association.Association(\n            good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, good_assoc)\n\n        bad_issued = time.time() - 5\n        bad_handle = 'handle2'\n        bad_assoc = association.Association(\n            bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, bad_assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':good_handle,\n            }\n\n        good_assoc.addSignature(['return_to', 'identity'], query)\n        info = self._doIdRes(query)\n        self.failUnlessEqual(info.status, 'success')\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n\n\nclass MockFetcher(object):\n    def __init__(self, response=None):\n        self.response = response or HTTPResponse()\n        self.fetches = []\n\n    def fetch(self, url, body=None, headers=None):\n        self.fetches.append((url, body, headers))\n        return self.response\n\nclass ExceptionRaisingMockFetcher(object):\n    def fetch(self, url, body=None, headers=None):\n        raise Exception('mock fetcher exception')\n\nclass BadArgCheckingConsumer(GenericOpenIDConsumer):\n    def _makeKVPost(self, args, _):\n        assert args == {\n            'openid.mode':'check_authentication',\n            'openid.signed':'foo',\n            }, args\n        return None\n\nclass TestCheckAuth(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n\n        self.consumer = self.consumer_class(self.store)\n\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        query = {'openid.signed': 'stuff, things'}\n        r = self.consumer._checkAuth(query, http_server_url)\n        self.failIf(r)\n        self.failUnless(self.messages)\n\n    def test_bad_args(self):\n        query = {\n            'openid.signed':'foo',\n            'closid.foo':'something',\n            }\n        consumer = BadArgCheckingConsumer(self.store)\n        consumer._checkAuth(query, 'does:\/\/not.matter')\n\nclass TestFetchAssoc(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.consumer = self.consumer_class(self.store)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        r = self.consumer._makeKVPost({'openid.mode':'associate'},\n                                      \"http:\/\/server_url\")\n        self.failUnlessEqual(r, None)\n        self.failUnless(self.messages)\n\n    def test_error_exception(self):\n        self.fetcher = ExceptionRaisingMockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._makeKVPost,\n                              {'openid.mode':'associate'},\n                              \"http:\/\/server_url\")\n\n        # exception fetching returns no association\n        self.failUnless(self.consumer._getAssociation('some:\/\/url') is None)\n\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._checkAuth,\n                              {'openid.signed':''},\n                              'some:\/\/url')\n\nif __name__ == '__main__':\n    unittest.main()\n"}},"msg":"[project @ Added nonce to return_to to fix replay attack vulnerability]"}},"https:\/\/github.com\/openid\/python-openid":{"f05703e45f3ef162c4d927dc712b95cbac163bb4":{"url":"https:\/\/api.github.com\/repos\/openid\/python-openid\/commits\/f05703e45f3ef162c4d927dc712b95cbac163bb4","html_url":"https:\/\/github.com\/openid\/python-openid\/commit\/f05703e45f3ef162c4d927dc712b95cbac163bb4","message":"[project @ Added nonce to return_to to fix replay attack vulnerability]","sha":"f05703e45f3ef162c4d927dc712b95cbac163bb4","keyword":"replay attack vulnerable","diff":"diff --git a\/openid\/consumer\/consumer.py b\/openid\/consumer\/consumer.py\nindex b7a93bc0..49f56634 100644\n--- a\/openid\/consumer\/consumer.py\n+++ b\/openid\/consumer\/consumer.py\n@@ -173,6 +173,7 @@\n import string\n import time\n import urllib\n+import cgi\n from urlparse import urlparse\n \n from urljr import fetchers\n@@ -279,13 +280,14 @@ class and its sublcasses.  For a filesystem-backed store,\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n@@ -295,9 +297,9 @@ def complete(self, query, token):\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n@@ -314,16 +316,39 @@ def complete(self, query, token):\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n@@ -466,9 +491,9 @@ def _getAssociation(self, server_url):\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n@@ -484,7 +509,7 @@ def _splitToken(self, token):\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n@@ -567,7 +592,7 @@ def _parseAssociation(self, results, dh, server_url):\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n@@ -579,6 +604,7 @@ def __init__(self, token, assoc, endpoint):\n         self.assoc = assoc\n         self.endpoint = endpoint\n         self.extra_args = {}\n+        self.return_to_args = {}\n         self.token = token\n \n     def addExtensionArg(self, namespace, key, value):\n@@ -591,6 +617,8 @@ def redirectURL(self, trust_root, return_to, immediate=False):\n         else:\n             mode = 'checkid_setup'\n \n+        return_to = oidutil.appendArgs(return_to, self.return_to_args)\n+\n         redir_args = {\n             'openid.mode': mode,\n             'openid.identity': self.endpoint.getServerID(),\n@@ -634,6 +662,9 @@ def extensionResponse(self, prefix):\n \n         return response\n \n+    def getReturnTo(self):\n+        return self.signed_args['openid.return_to']\n+\n class FailureResponse(OpenIDConsumerResponse):\n     status = 'failure'\n \ndiff --git a\/test\/consumer.py b\/test\/consumer.py\nindex 343c7a11..1b8fbe7a 100644\n--- a\/test\/consumer.py\n+++ b\/test\/consumer.py\n@@ -119,19 +119,22 @@ def run():\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n@@ -140,7 +143,7 @@ def run():\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","files":{"\/openid\/consumer\/consumer.py":{"changes":[{"diff":"\n     def begin(self, service_endpoint):\n         nonce = self._createNonce()\n         token = self._genToken(\n-            nonce,\n             service_endpoint.identity_url,\n             service_endpoint.getServerID(),\n             service_endpoint.server_url,\n             )\n         assoc = self._getAssociation(service_endpoint.server_url)\n-        return OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request = OpenIDAuthRequest(token, assoc, service_endpoint)\n+        request.return_to_args['nonce'] = nonce\n+        return request\n \n     def complete(self, query, token):\n         mode = query.get('openid.mode', '<no mode specified>')\n","add":3,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            nonce,","        return OpenIDAuthRequest(token, assoc, service_endpoint)"],"goodparts":["        request = OpenIDAuthRequest(token, assoc, service_endpoint)","        request.return_to_args['nonce'] = nonce","        return request"]},{"diff":"\n             pieces = self._splitToken(token)\n         except ValueError, why:\n             oidutil.log(why[0])\n-            pieces = (None, None, None, None, None)\n+            pieces = (None, None, None)\n \n-        (nonce, identity_url, delegate, server_url) = pieces\n+        (identity_url, delegate, server_url) = pieces\n \n         if mode == 'cancel':\n             return CancelResponse(identity_url)\n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["            pieces = (None, None, None, None, None)","        (nonce, identity_url, delegate, server_url) = pieces"],"goodparts":["            pieces = (None, None, None)","        (identity_url, delegate, server_url) = pieces"]},{"diff":"\n                 message = 'HTTP request failed: %s' % (str(why),)\n                 return FailureResponse(identity_url, message)\n             else:\n-                if (response.status == 'success' and\n-                    not self.store.useNonce(nonce)):\n-\n-                    return FailureResponse(identity_url, 'Nonce already used')\n+                if response.status == 'success':\n+                    return self._checkNonce(response, query.get('nonce'))\n                 else:\n                     return response\n         else:\n             return FailureResponse(identity_url,\n                                    'Invalid openid.mode: %r' % (mode,))\n \n+    def _checkNonce(self, response, nonce):\n+        parsed_url = urlparse(response.getReturnTo())\n+        query = parsed_url[4]\n+        for k, v in cgi.parse_qsl(query):\n+            if k == 'nonce':\n+                if v != nonce:\n+                    return FailureResponse(response.identity_url,\n+                                           'Nonce mismatch')\n+                else:\n+                    break\n+        else:\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from return_to: %r'\n+                                   % (response.getReturnTo()))\n+\n+        # The nonce matches the signed nonce in the openid.return_to\n+        # response parameter\n+        if not self.store.useNonce(nonce):\n+            return FailureResponse(response.identity_url,\n+                                   'Nonce missing from store')\n+\n+        # If the nonce check succeeded, return the original success\n+        # response\n+        return response\n+\n     def _createNonce(self):\n         nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n         self.store.storeNonce(nonce)\n","add":27,"remove":4,"filename":"\/openid\/consumer\/consumer.py","badparts":["                if (response.status == 'success' and","                    not self.store.useNonce(nonce)):","                    return FailureResponse(identity_url, 'Nonce already used')"],"goodparts":["                if response.status == 'success':","                    return self._checkNonce(response, query.get('nonce'))","    def _checkNonce(self, response, nonce):","        parsed_url = urlparse(response.getReturnTo())","        query = parsed_url[4]","        for k, v in cgi.parse_qsl(query):","            if k == 'nonce':","                if v != nonce:","                    return FailureResponse(response.identity_url,","                                           'Nonce mismatch')","                else:","                    break","        else:","            return FailureResponse(response.identity_url,","                                   'Nonce missing from return_to: %r'","                                   % (response.getReturnTo()))","        if not self.store.useNonce(nonce):","            return FailureResponse(response.identity_url,","                                   'Nonce missing from store')","        return response"]},{"diff":"\n \n         return assoc\n \n-    def _genToken(self, nonce, consumer_id, server_id, server_url):\n+    def _genToken(self, consumer_id, server_id, server_url):\n         timestamp = str(int(time.time()))\n-        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n+        elements = [timestamp, consumer_id, server_id, server_url]\n         joined = '\\x00'.join(elements)\n         sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n \n","add":2,"remove":2,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def _genToken(self, nonce, consumer_id, server_id, server_url):","        elements = [timestamp, nonce, consumer_id, server_id, server_url]"],"goodparts":["    def _genToken(self, consumer_id, server_id, server_url):","        elements = [timestamp, consumer_id, server_id, server_url]"]},{"diff":"\n             raise ValueError('Bad token signature')\n \n         split = joined.split('\\x00')\n-        if len(split) != 5:\n+        if len(split) != 4:\n             raise ValueError('Bad token contents (not enough fields)')\n \n         try:\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["        if len(split) != 5:"],"goodparts":["        if len(split) != 4:"]},{"diff":"\n             return None\n \n class OpenIDAuthRequest(object):\n-    def __init__(self, token, assoc, endpoint):\n+    def __init__(self, token, assoc, endpoint  ):\n         \"\"\"\n         Creates a new OpenIDAuthRequest object.  This just stores each\n         argument in an appropriately named field.\n","add":1,"remove":1,"filename":"\/openid\/consumer\/consumer.py","badparts":["    def __init__(self, token, assoc, endpoint):"],"goodparts":["    def __init__(self, token, assoc, endpoint  ):"]}],"source":"\n\"\"\" This module documents the main interface with the OpenID consumer libary. The only part of the library which has to be used and isn't documented in full here is the store required to create an C{L{OpenIDConsumer}} instance. More on the abstract store type and concrete implementations of it that are provided in the documentation for the C{L{__init__<OpenIDConsumer.__init__>}} method of the C{L{OpenIDConsumer}} class. OVERVIEW ======== The OpenID identity verification process most commonly uses the following steps, as visible to the user of this library: 1. The user enters their OpenID into a field on the consumer's site, and hits a login button. 2. The consumer site discovers the user's OpenID server using the YADIS protocol. 3. The consumer site sends the browser a redirect to the identity server. This is the authentication request as described in the OpenID specification. 4. The identity server's site sends the browser a redirect back to the consumer site. This redirect contains the server's response to the authentication request. The most important part of the flow to note is the consumer's site must handle two separate HTTP requests in order to perform the full identity check. LIBRARY DESIGN ============== This consumer library is designed with that flow in mind. The goal is to make it as easy as possible to perform the above steps securely. At a high level, there are two important parts in the consumer library. The first important part is this module, which contains the interface to actually use this library. The second is the C{L{openid.store.interface}} module, which describes the interface to use if you need to create a custom method for storing the state this library needs to maintain between requests. In general, the second part is less important for users of the library to know about, as several implementations are provided which cover a wide variety of situations in which consumers may use the library. This module contains a class, C{L{OpenIDConsumer}}, with methods corresponding to the actions necessary in each of steps 2, 3, and 4 described in the overview. Use of this library should be as easy as creating an C{L{OpenIDConsumer}} instance and calling the methods appropriate for the action the site wants to take. STORES AND DUMB MODE ==================== OpenID is a protocol that works best when the consumer site is able to store some state. This is the normal mode of operation for the protocol, and is sometimes referred to as smart mode. There is also a fallback mode, known as dumb mode, which is available when the consumer site is not able to store state. This mode should be avoided when possible, as it leaves the implementation more vulnerable to replay attacks. The mode the library works in for normal operation is determined by the store that it is given. The store is an abstraction that handles the data that the consumer needs to manage between http requests in order to operate efficiently and securely. Several store implementation are provided, and the interface is fully documented so that custom stores can be used as well. See the documentation for the C{L{OpenIDConsumer}} class for more information on the interface for stores. The implementations that are provided allow the consumer site to store the necessary data in several different ways, including several SQL databases and normal files on disk. There is an additional concrete store provided that puts the system in dumb mode. This is not recommended, as it removes the library's ability to stop replay attacks reliably. It still uses time-based checking to make replay attacks only possible within a small window, but they remain possible within that window. This store should only be used if the consumer site has no way to retain data between requests at all. IMMEDIATE MODE ============== In the flow described above, the user may need to confirm to the identity server that it's ok to authorize his or her identity. The server may draw pages asking for information from the user before it redirects the browser back to the consumer's site. This is generally transparent to the consumer site, so it is typically ignored as an implementation detail. There can be times, however, where the consumer site wants to get a response immediately. When this is the case, the consumer can put the library in immediate mode. In immediate mode, there is an extra response possible from the server, which is essentially the server reporting that it doesn't have enough information to answer the question yet. In addition to saying that, the identity server provides a URL to which the user can be sent to provide the needed information and let the server finish handling the original request. USING THIS LIBRARY ================== Integrating this library into an application is usually a relatively straightforward process. The process should basically follow this plan: Add an OpenID login field somewhere on your site. When an OpenID is entered in that field and the form is submitted, it should make a request to the your site which includes that OpenID URL. To start, the application should get an C{L{OpenIDConsumer}} instance, and call its C{L{begin<OpenIDConsumer.begin>}} method. This method takes the OpenID URL and, optionally, a session object. If the application has any sort of session framework that provides per-client state management, that should be used here. The library just expects the session object to support a C{dict}-like interface, if it provided. If no session object is provided, the application code needs to store the information that would have been put in the session in an alternate location. See the documentation for the C{L{begin<OpenIDConsumer.begin>}} call for more information. The C{L{begin<OpenIDConsumer.begin>}} method returns an C{L{OpenIDRequestBuilder}} object. Next, the application should call the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on the C{L{OpenIDRequestBuilder}} object. The return_to URL is the URL that the OpenID server will send the user back to after attempting to verify his or her identity. The trust_root is the URL(or URL pattern) that identifies your web site to the user when he or she is authorizing it. Send a redirect to the resulting URL to the user's browser. That's the first half of the authentication process. The second half of the process is done after the user's ID server sends the user's browser a redirect back to your site to complete their login. When that happens, the user will contact your site at the URL given as the C{return_to} URL to the C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made above. The request will have several query parameters added to the URL by the identity server as the information necessary to finish the request. Get an C{L{OpenIDConsumer}} instance, and call its C{L{complete<OpenIDConsumer.complete>}} method, passing in all the received query arguments and either the user's session object or the token saved earlier. See the documentation for C{L{OpenIDRequestBuilder}} for more information about the token. There are multiple possible return types possible from that method. These indicate the whether or not the login was successful, and include any additional information appropriate for their type. \"\"\" import string import time import urllib from urlparse import urlparse from urljr import fetchers from openid.consumer.discover import discover as openIDDiscover from openid.consumer.discover import yadis_available from openid import cryptutil from openid import kvform from openid import oidutil from openid.association import Association from openid.dh import DiffieHellman __all__=['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse', 'SetupNeededResponse', 'CancelResponse', 'FailureResponse'] if yadis_available: from yadis.manager import Discovery class OpenIDConsumer(object): session_key_prefix=\"_openid_consumer_\" _token='last_token' def __init__(self, session, store): self.session=session self.consumer=GenericOpenIDConsumer(store) self._token_key=self.session_key_prefix +self._token def begin(self, user_url): openid_url=oidutil.normalizeUrl(user_url) if yadis_available: disco=Discovery(self.session, openid_url, 'XXX') endpoint=disco.getNextService(openIDDiscover) else: _, endpoints=openIDDiscover(openid_url) if not endpoints: endpoint=None else: endpoint=endpoints[0] if endpoint is None: return None else: return self.beginWithoutDiscovery(endpoint) def beginWithoutDiscovery(self, endpoint): auth_req=self.consumer.begin(endpoint) self.session[self._token_key]=auth_req.token return auth_req def complete(self, query): token=self.session.get(self._token_key) if token is None: response=FailureResponse(None, 'No session state found') else: response=self.consumer.complete(query, token) if response.status in['success', 'cancel' ]: if yadis_available and response.identity_url is not None: disco=Discovery(self.session, response.identity_url) disco.cleanup() return response class GenericOpenIDConsumer(object): \"\"\"This is the implementation of the common logic for OpenID consumers. It is unaware of the application in which it is running. \"\"\" TOKEN_LIFETIME=60 * 5 NONCE_LEN=8 NONCE_CHRS=string.letters +string.digits def __init__(self, store): \"\"\" This method initializes a new C{L{OpenIDConsumer}} instance to access the library. @param store: This must be an object that implements the interface in C{L{openid.store.interface.OpenIDStore}}. Several concrete implementations are provided, to cover most common use cases. For stores backed by MySQL or SQLite, see the C{L{openid.store.sqlstore.SQLStore}} class and its sublcasses. For a filesystem-backed store, see the C{L{openid.store.filestore}} module. As a last resort, if it isn't possible for the server to store state at all, an instance of C{L{openid.store.dumbstore.DumbStore}} can be used. This should be an absolute last resort, though, as it makes the consumer vulnerable to replay attacks over the lifespan of the tokens the library creates. @type store: C{L{openid.store.interface.OpenIDStore}} \"\"\" self.store=store def begin(self, service_endpoint): nonce=self._createNonce() token=self._genToken( nonce, service_endpoint.identity_url, service_endpoint.getServerID(), service_endpoint.server_url, ) assoc=self._getAssociation(service_endpoint.server_url) return OpenIDAuthRequest(token, assoc, service_endpoint) def complete(self, query, token): mode=query.get('openid.mode', '<no mode specified>') try: pieces=self._splitToken(token) except ValueError, why: oidutil.log(why[0]) pieces=(None, None, None, None, None) (nonce, identity_url, delegate, server_url)=pieces if mode=='cancel': return CancelResponse(identity_url) elif mode=='error': error=query.get('openid.error') return FailureResponse(identity_url, error) elif mode=='id_res': if identity_url is None: return FailureResponse(identity_url, 'No session state found') try: response=self._doIdRes( query, identity_url, delegate, server_url) except fetchers.HTTPFetchingError, why: message='HTTP request failed: %s' %(str(why),) return FailureResponse(identity_url, message) else: if(response.status=='success' and not self.store.useNonce(nonce)): return FailureResponse(identity_url, 'Nonce already used') else: return response else: return FailureResponse(identity_url, 'Invalid openid.mode: %r' %(mode,)) def _createNonce(self): nonce=cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS) self.store.storeNonce(nonce) return nonce def _makeKVPost(self, args, server_url): mode=args['openid.mode'] body=urllib.urlencode(args) resp=fetchers.fetch(server_url, body=body) if resp is None: fmt='openid.mode=%s: failed to fetch URL: %s' oidutil.log(fmt %(mode, server_url)) return None response=kvform.kvToDict(resp.body) if resp.status==400: server_error=response.get('error', '<no message from server>') fmt='openid.mode=%s: error returned from server %s: %s' oidutil.log(fmt %(mode, server_url, server_error)) return None elif resp.status !=200: fmt='openid.mode=%s: bad status code from server %s: %s' oidutil.log(fmt %(mode, server_url, resp.status)) return None return response def _doIdRes(self, query, consumer_id, server_id, server_url): user_setup_url=query.get('openid.user_setup_url') if user_setup_url is not None: return SetupNeededResponse(consumer_id, user_setup_url) return_to=query.get('openid.return_to') server_id2=query.get('openid.identity') assoc_handle=query.get('openid.assoc_handle') if return_to is None or server_id is None or assoc_handle is None: return FailureResponse(consumer_id, 'Missing required field') if server_id !=server_id2: return FailureResponse(consumer_id, 'Server ID(delegate) mismatch') signed=query.get('openid.signed') assoc=self.store.getAssociation(server_url, assoc_handle) if assoc is None: if self._checkAuth(query, server_url): return SuccessResponse.fromQuery(consumer_id, query, signed) else: return FailureResponse(consumer_id, 'Server denied check_authentication') if assoc.expiresIn <=0: msg='Association with %s expired' %(server_url,) return FailureResponse(consumer_id, msg) sig=query.get('openid.sig') if sig is None or signed is None: return FailureResponse(consumer_id, 'Missing argument signature') signed_list=signed.split(',') v_sig=assoc.signDict(signed_list, query) if v_sig !=sig: return FailureResponse(consumer_id, 'Bad signature') return SuccessResponse.fromQuery(consumer_id, query, signed) def _checkAuth(self, query, server_url): request=self._createCheckAuthRequest(query) if request is None: return False response=self._makeKVPost(request, server_url) if response is None: return False return self._processCheckAuthResponse(response) def _createCheckAuthRequest(self, query): signed=query.get('openid.signed') if signed is None: oidutil.log('No signature present; checkAuth aborted') return None whitelist=['assoc_handle', 'sig', 'signed', 'invalidate_handle'] signed=signed.split(',') +whitelist check_args=dict([(k, v) for k, v in query.iteritems() if k.startswith('openid.') and k[7:] in signed]) check_args['openid.mode']='check_authentication' return check_args def _processCheckAuthResponse(self, response): is_valid=response.get('is_valid', 'false') if is_valid=='true': invalidate_handle=response.get('invalidate_handle') if invalidate_handle is not None: self.store.removeAssociation(server_url, invalidate_handle) return True oidutil.log('Server responds that checkAuth call is not valid') return False def _getAssociation(self, server_url): if self.store.isDumb(): return None assoc=self.store.getAssociation(server_url) if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME: proto=urlparse(server_url)[0] if proto=='https': dh=None else: dh=DiffieHellman() args=self._createAssociateRequest(dh) try: response=self._makeKVPost(args, server_url) except fetchers.HTTPFetchingError, why: oidutil.log('openid.associate request failed: %s' % (str(why),)) assoc=None else: assoc=self._parseAssociation(response, dh, server_url) return assoc def _genToken(self, nonce, consumer_id, server_id, server_url): timestamp=str(int(time.time())) elements=[timestamp, nonce, consumer_id, server_id, server_url] joined='\\x00'.join(elements) sig=cryptutil.hmacSha1(self.store.getAuthKey(), joined) return oidutil.toBase64('%s%s' %(sig, joined)) def _splitToken(self, token): token=oidutil.fromBase64(token) if len(token) < 20: raise ValueError('Bad token length: %d' % len(token)) sig, joined=token[:20], token[20:] if cryptutil.hmacSha1(self.store.getAuthKey(), joined) !=sig: raise ValueError('Bad token signature') split=joined.split('\\x00') if len(split) !=5: raise ValueError('Bad token contents(not enough fields)') try: ts=int(split[0]) except ValueError: raise ValueError('Bad token contents(timestamp bad)') if ts +self.TOKEN_LIFETIME < time.time(): raise ValueError('Token expired') return tuple(split[1:]) def _createAssociateRequest(self, dh=None, args=None): if args is None: args={} args.update({ 'openid.mode': 'associate', 'openid.assoc_type':'HMAC-SHA1', }) if dh: cpub=cryptutil.longToBase64(dh.public) args.update({ 'openid.session_type':'DH-SHA1', 'openid.dh_consumer_public': cpub, }) if not dh.usingDefaultValues(): args.update({ 'openid.dh_modulus': cryptutil.longToBase64(dh.modulus), 'openid.dh_gen': cryptutil.longToBase64(dh.generator), }) return args def _parseAssociation(self, results, dh, server_url): try: assoc_type=results['assoc_type'] if assoc_type !='HMAC-SHA1': fmt='Unsupported assoc_type returned from server %s: %s' oidutil.log(fmt %(server_url, assoc_type)) return None assoc_handle=results['assoc_handle'] try: expires_in=int(results.get('expires_in', '0')) except ValueError, e: fmt='Getting Association: invalid expires_in field: %s' oidutil.log(fmt %(e[0],)) return None session_type=results.get('session_type') if session_type is None: secret=oidutil.fromBase64(results['mac_key']) else: if session_type !='DH-SHA1': fmt='Unsupported session_type from server %s: %s' oidutil.log(fmt %(server_url, session_type)) return None if dh is None: fmt='Not expecting a DH-SHA1 session from server %s' oidutil.log(fmt %(server_url)) return None spub=cryptutil.base64ToLong(results['dh_server_public']) enc_mac_key=oidutil.fromBase64(results['enc_mac_key']) secret=dh.xorSecret(spub, enc_mac_key) assoc=Association.fromExpiresIn( expires_in, assoc_handle, secret, assoc_type) self.store.storeAssociation(server_url, assoc) return assoc except KeyError, e: fmt='Getting association: missing key in response from %s: %s' oidutil.log(fmt %(server_url, e[0])) return None class OpenIDAuthRequest(object): def __init__(self, token, assoc, endpoint): \"\"\" Creates a new OpenIDAuthRequest object. This just stores each argument in an appropriately named field. Users of this library should not create instances of this class. Instances of this class are created by the library when needed. \"\"\" self.assoc=assoc self.endpoint=endpoint self.extra_args={} self.token=token def addExtensionArg(self, namespace, key, value): arg_name='.'.join('openid', namespace, key) self.extra_args[arg_name]=value def redirectURL(self, trust_root, return_to, immediate=False): if immediate: mode='checkid_immediate' else: mode='checkid_setup' redir_args={ 'openid.mode': mode, 'openid.identity': self.endpoint.getServerID(), 'openid.return_to': return_to, 'openid.trust_root': trust_root, } if self.assoc: redir_args['openid.assoc_handle']=self.assoc.handle redir_args.update(self.extra_args) return oidutil.appendArgs(self.endpoint.server_url, redir_args) class OpenIDConsumerResponse(object): status=None class SuccessResponse(OpenIDConsumerResponse): status='success' def __init__(self, identity_url, signed_args): self.identity_url=identity_url self.signed_args=signed_args def fromQuery(cls, identity_url, query, signed): signed_args={} for field_name in signed.split(','): field_name='openid.' +field_name signed_args[field_name]=query.get(field_name, '') return cls(identity_url, signed_args) fromQuery=classmethod(fromQuery) def extensionResponse(self, prefix): response={} prefix='openid.%s.' %(prefix,) prefix_len=len(prefix) for k, v in self.signed_args.iteritems(): if k.startswith(prefix): response_key=k[prefix_len:] response[response_key]=v return response class FailureResponse(OpenIDConsumerResponse): status='failure' def __init__(self, identity_url=None, message=None): self.identity_url=identity_url self.message=message class CancelResponse(OpenIDConsumerResponse): status='cancelled' def __init__(self, identity_url=None): self.identity_url=identity_url class SetupNeededResponse(OpenIDConsumerResponse): status='setup_needed' def __init__(self, identity_url=None, setup_url=None): self.identity_url=identity_url self.setup_url=setup_url ","sourceWithComments":"\"\"\"\nThis module documents the main interface with the OpenID consumer\nlibary.  The only part of the library which has to be used and isn't\ndocumented in full here is the store required to create an\nC{L{OpenIDConsumer}} instance.  More on the abstract store type and\nconcrete implementations of it that are provided in the documentation\nfor the C{L{__init__<OpenIDConsumer.__init__>}} method of the\nC{L{OpenIDConsumer}} class.\n\n\nOVERVIEW\n========\n\n    The OpenID identity verification process most commonly uses the\n    following steps, as visible to the user of this library:\n\n        1. The user enters their OpenID into a field on the consumer's\n           site, and hits a login button.\n\n        2. The consumer site discovers the user's OpenID server using\n           the YADIS protocol.\n\n        3. The consumer site sends the browser a redirect to the\n           identity server.  This is the authentication request as\n           described in the OpenID specification.\n\n        4. The identity server's site sends the browser a redirect\n           back to the consumer site.  This redirect contains the\n           server's response to the authentication request.\n\n    The most important part of the flow to note is the consumer's site\n    must handle two separate HTTP requests in order to perform the\n    full identity check.\n\n\nLIBRARY DESIGN\n==============\n\n    This consumer library is designed with that flow in mind.  The\n    goal is to make it as easy as possible to perform the above steps\n    securely.\n\n    At a high level, there are two important parts in the consumer\n    library.  The first important part is this module, which contains\n    the interface to actually use this library.  The second is the\n    C{L{openid.store.interface}} module, which describes the\n    interface to use if you need to create a custom method for storing\n    the state this library needs to maintain between requests.\n\n    In general, the second part is less important for users of the\n    library to know about, as several implementations are provided\n    which cover a wide variety of situations in which consumers may\n    use the library.\n\n    This module contains a class, C{L{OpenIDConsumer}}, with methods\n    corresponding to the actions necessary in each of steps 2, 3, and\n    4 described in the overview.  Use of this library should be as easy\n    as creating an C{L{OpenIDConsumer}} instance and calling the methods\n    appropriate for the action the site wants to take.\n\n\nSTORES AND DUMB MODE\n====================\n\n    OpenID is a protocol that works best when the consumer site is\n    able to store some state.  This is the normal mode of operation\n    for the protocol, and is sometimes referred to as smart mode.\n    There is also a fallback mode, known as dumb mode, which is\n    available when the consumer site is not able to store state.  This\n    mode should be avoided when possible, as it leaves the\n    implementation more vulnerable to replay attacks.\n\n    The mode the library works in for normal operation is determined\n    by the store that it is given.  The store is an abstraction that\n    handles the data that the consumer needs to manage between http\n    requests in order to operate efficiently and securely.\n\n    Several store implementation are provided, and the interface is\n    fully documented so that custom stores can be used as well.  See\n    the documentation for the C{L{OpenIDConsumer}} class for more\n    information on the interface for stores.  The implementations that\n    are provided allow the consumer site to store the necessary data\n    in several different ways, including several SQL databases and\n    normal files on disk.\n\n    There is an additional concrete store provided that puts the\n    system in dumb mode.  This is not recommended, as it removes the\n    library's ability to stop replay attacks reliably.  It still uses\n    time-based checking to make replay attacks only possible within a\n    small window, but they remain possible within that window.  This\n    store should only be used if the consumer site has no way to\n    retain data between requests at all.\n\n\nIMMEDIATE MODE\n==============\n\n    In the flow described above, the user may need to confirm to the\n    identity server that it's ok to authorize his or her identity.\n    The server may draw pages asking for information from the user\n    before it redirects the browser back to the consumer's site.  This\n    is generally transparent to the consumer site, so it is typically\n    ignored as an implementation detail.\n\n    There can be times, however, where the consumer site wants to get\n    a response immediately.  When this is the case, the consumer can\n    put the library in immediate mode.  In immediate mode, there is an\n    extra response possible from the server, which is essentially the\n    server reporting that it doesn't have enough information to answer\n    the question yet.  In addition to saying that, the identity server\n    provides a URL to which the user can be sent to provide the needed\n    information and let the server finish handling the original\n    request.\n\n\nUSING THIS LIBRARY\n==================\n\n    Integrating this library into an application is usually a\n    relatively straightforward process.  The process should basically\n    follow this plan:\n\n    Add an OpenID login field somewhere on your site.  When an OpenID\n    is entered in that field and the form is submitted, it should make\n    a request to the your site which includes that OpenID URL.\n\n    To start, the application should get an C{L{OpenIDConsumer}}\n    instance, and call its C{L{begin<OpenIDConsumer.begin>}} method.\n    This method takes the OpenID URL and, optionally, a session\n    object.  If the application has any sort of session framework that\n    provides per-client state management, that should be used here.\n    The library just expects the session object to support a\n    C{dict}-like interface, if it provided.  If no session object is\n    provided, the application code needs to store the information that\n    would have been put in the session in an alternate location.  See\n    the documentation for the C{L{begin<OpenIDConsumer.begin>}} call\n    for more information.  The C{L{begin<OpenIDConsumer.begin>}}\n    method returns an C{L{OpenIDRequestBuilder}} object.\n\n    Next, the application should call the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} method on\n    the C{L{OpenIDRequestBuilder}} object.  The return_to URL is the\n    URL that the OpenID server will send the user back to after\n    attempting to verify his or her identity.  The trust_root is the\n    URL (or URL pattern) that identifies your web site to the user\n    when he or she is authorizing it.  Send a redirect to the\n    resulting URL to the user's browser.\n\n    That's the first half of the authentication process.  The second\n    half of the process is done after the user's ID server sends the\n    user's browser a redirect back to your site to complete their\n    login.\n\n    When that happens, the user will contact your site at the URL\n    given as the C{return_to} URL to the\n    C{L{buildRedirect<OpenIDRequestBuilder.buildRedirect>}} call made\n    above.  The request will have several query parameters added to\n    the URL by the identity server as the information necessary to\n    finish the request.\n\n    Get an C{L{OpenIDConsumer}} instance, and call its\n    C{L{complete<OpenIDConsumer.complete>}} method, passing in all the\n    received query arguments and either the user's session object or\n    the token saved earlier.  See the documentation for\n    C{L{OpenIDRequestBuilder}} for more information about the token.\n\n    There are multiple possible return types possible from that\n    method.  These indicate the whether or not the login was\n    successful, and include any additional information appropriate for\n    their type.\n\"\"\"\n\nimport string\nimport time\nimport urllib\nfrom urlparse import urlparse\n\nfrom urljr import fetchers\n\nfrom openid.consumer.discover import discover as openIDDiscover\nfrom openid.consumer.discover import yadis_available\nfrom openid import cryptutil\nfrom openid import kvform\nfrom openid import oidutil\nfrom openid.association import Association\nfrom openid.dh import DiffieHellman\n\n__all__ = ['OpenIDAuthRequest', 'OpenIDConsumer', 'SuccessResponse',\n           'SetupNeededResponse', 'CancelResponse', 'FailureResponse']\n\nif yadis_available:\n    from yadis.manager import Discovery\n\nclass OpenIDConsumer(object):\n    session_key_prefix = \"_openid_consumer_\"\n\n    _token = 'last_token'\n\n    def __init__(self, session, store):\n        self.session = session\n        self.consumer = GenericOpenIDConsumer(store)\n        self._token_key = self.session_key_prefix + self._token\n\n    def begin(self, user_url):\n        openid_url = oidutil.normalizeUrl(user_url)\n        if yadis_available:\n            disco = Discovery(self.session, openid_url, 'XXX')\n            endpoint = disco.getNextService(openIDDiscover)\n        else:\n            _, endpoints = openIDDiscover(openid_url)\n            if not endpoints:\n                endpoint = None\n            else:\n                endpoint = endpoints[0]\n\n        if endpoint is None:\n            return None\n        else:\n            return self.beginWithoutDiscovery(endpoint)\n\n    def beginWithoutDiscovery(self, endpoint):\n        auth_req = self.consumer.begin(endpoint)\n        self.session[self._token_key] = auth_req.token\n        return auth_req\n\n    def complete(self, query):\n        token = self.session.get(self._token_key)\n        if token is None:\n            response = FailureResponse(None, 'No session state found')\n        else:\n            response = self.consumer.complete(query, token)\n\n        if response.status in ['success',\n                               'cancel'#maybe\n                               ]:\n            if yadis_available and response.identity_url is not None:\n                disco = Discovery(self.session, response.identity_url)\n                # This is OK to do even if we did not do discovery in\n                # the first place.\n                disco.cleanup()\n\n        return response\n\nclass GenericOpenIDConsumer(object):\n    \"\"\"This is the implementation of the common logic for OpenID\n    consumers. It is unaware of the application in which it is\n    running.\n    \"\"\"\n\n    TOKEN_LIFETIME = 60 * 5 # five minutes\n    NONCE_LEN = 8\n    NONCE_CHRS = string.letters + string.digits\n\n    def __init__(self, store):\n        \"\"\"\n        This method initializes a new C{L{OpenIDConsumer}} instance to\n        access the library.\n\n        @param store: This must be an object that implements the\n            interface in C{L{openid.store.interface.OpenIDStore}}.\n            Several concrete implementations are provided, to cover\n            most common use cases.  For stores backed by MySQL or\n            SQLite, see the C{L{openid.store.sqlstore.SQLStore}}\n            class and its sublcasses.  For a filesystem-backed store,\n            see the C{L{openid.store.filestore}} module.\n\n            As a last resort, if it isn't possible for the server to\n            store state at all, an instance of\n            C{L{openid.store.dumbstore.DumbStore}} can be used.  This\n            should be an absolute last resort, though, as it makes the\n            consumer vulnerable to replay attacks over the lifespan of\n            the tokens the library creates.\n\n        @type store: C{L{openid.store.interface.OpenIDStore}}\n\n        \"\"\"\n        self.store = store\n\n    def begin(self, service_endpoint):\n        nonce = self._createNonce()\n        token = self._genToken(\n            nonce,\n            service_endpoint.identity_url,\n            service_endpoint.getServerID(),\n            service_endpoint.server_url,\n            )\n        assoc = self._getAssociation(service_endpoint.server_url)\n        return OpenIDAuthRequest(token, assoc, service_endpoint)\n\n    def complete(self, query, token):\n        mode = query.get('openid.mode', '<no mode specified>')\n\n        # Get the current request's state\n        try:\n            pieces = self._splitToken(token)\n        except ValueError, why:\n            oidutil.log(why[0])\n            pieces = (None, None, None, None, None)\n\n        (nonce, identity_url, delegate, server_url) = pieces\n\n        if mode == 'cancel':\n            return CancelResponse(identity_url)\n        elif mode == 'error':\n            error = query.get('openid.error')\n            return FailureResponse(identity_url, error)\n        elif mode == 'id_res':\n            if identity_url is None:\n                return FailureResponse(identity_url, 'No session state found')\n            try:\n                response = self._doIdRes(\n                    query, identity_url, delegate, server_url)\n            except fetchers.HTTPFetchingError, why:\n                message = 'HTTP request failed: %s' % (str(why),)\n                return FailureResponse(identity_url, message)\n            else:\n                if (response.status == 'success' and\n                    not self.store.useNonce(nonce)):\n\n                    return FailureResponse(identity_url, 'Nonce already used')\n                else:\n                    return response\n        else:\n            return FailureResponse(identity_url,\n                                   'Invalid openid.mode: %r' % (mode,))\n\n    def _createNonce(self):\n        nonce = cryptutil.randomString(self.NONCE_LEN, self.NONCE_CHRS)\n        self.store.storeNonce(nonce)\n        return nonce\n\n    def _makeKVPost(self, args, server_url):\n        mode = args['openid.mode']\n        body = urllib.urlencode(args)\n\n        resp = fetchers.fetch(server_url, body=body)\n        if resp is None:\n            fmt = 'openid.mode=%s: failed to fetch URL: %s'\n            oidutil.log(fmt % (mode, server_url))\n            return None\n\n        response = kvform.kvToDict(resp.body)\n        if resp.status == 400:\n            server_error = response.get('error', '<no message from server>')\n            fmt = 'openid.mode=%s: error returned from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, server_error))\n            return None\n        elif resp.status != 200:\n            fmt = 'openid.mode=%s: bad status code from server %s: %s'\n            oidutil.log(fmt % (mode, server_url, resp.status))\n            return None\n\n        return response\n\n    def _doIdRes(self, query, consumer_id, server_id, server_url):\n        user_setup_url = query.get('openid.user_setup_url')\n        if user_setup_url is not None:\n            return SetupNeededResponse(consumer_id, user_setup_url)\n\n        return_to = query.get('openid.return_to')\n        server_id2 = query.get('openid.identity')\n        assoc_handle = query.get('openid.assoc_handle')\n\n        if return_to is None or server_id is None or assoc_handle is None:\n            return FailureResponse(consumer_id, 'Missing required field')\n\n        if server_id != server_id2:\n            return FailureResponse(consumer_id, 'Server ID (delegate) mismatch')\n\n        signed = query.get('openid.signed')\n\n        assoc = self.store.getAssociation(server_url, assoc_handle)\n\n        if assoc is None:\n            # It's not an association we know about.  Dumb mode is our\n            # only possible path for recovery.\n            if self._checkAuth(query, server_url):\n                return SuccessResponse.fromQuery(consumer_id, query, signed)\n            else:\n                return FailureResponse(consumer_id,\n                                       'Server denied check_authentication')\n\n        if assoc.expiresIn <= 0:\n            # XXX: It might be a good idea sometimes to re-start the\n            # authentication with a new association. Doing it\n            # automatically opens the possibility for\n            # denial-of-service by a server that just returns expired\n            # associations (or really short-lived associations)\n            msg = 'Association with %s expired' % (server_url,)\n            return FailureResponse(consumer_id, msg)\n\n        # Check the signature\n        sig = query.get('openid.sig')\n        if sig is None or signed is None:\n            return FailureResponse(consumer_id, 'Missing argument signature')\n\n        signed_list = signed.split(',')\n        v_sig = assoc.signDict(signed_list, query)\n\n        if v_sig != sig:\n            return FailureResponse(consumer_id, 'Bad signature')\n\n        return SuccessResponse.fromQuery(consumer_id, query, signed)\n\n    def _checkAuth(self, query, server_url):\n        request = self._createCheckAuthRequest(query)\n        if request is None:\n            return False\n        response = self._makeKVPost(request, server_url)\n        if response is None:\n            return False\n        return self._processCheckAuthResponse(response)\n\n    def _createCheckAuthRequest(self, query):\n        signed = query.get('openid.signed')\n        if signed is None:\n            oidutil.log('No signature present; checkAuth aborted')\n            return None\n\n        # Arguments that are always passed to the server and not\n        # included in the signature.\n        whitelist = ['assoc_handle', 'sig', 'signed', 'invalidate_handle']\n        signed = signed.split(',') + whitelist\n\n        check_args = dict([(k, v) for k, v in query.iteritems()\n                           if k.startswith('openid.') and k[7:] in signed])\n\n        check_args['openid.mode'] = 'check_authentication'\n        return check_args\n\n    def _processCheckAuthResponse(self, response):\n        is_valid = response.get('is_valid', 'false')\n\n        if is_valid == 'true':\n            invalidate_handle = response.get('invalidate_handle')\n            if invalidate_handle is not None:\n                self.store.removeAssociation(server_url, invalidate_handle)\n\n            return True\n\n        oidutil.log('Server responds that checkAuth call is not valid')\n        return False\n\n    def _getAssociation(self, server_url):\n        if self.store.isDumb():\n            return None\n\n        assoc = self.store.getAssociation(server_url)\n\n        if assoc is None or assoc.expiresIn < self.TOKEN_LIFETIME:\n            proto = urlparse(server_url)[0]\n            if proto == 'https':\n                dh = None\n            else:\n                dh = DiffieHellman()\n\n            args = self._createAssociateRequest(dh)\n            try:\n                response = self._makeKVPost(args, server_url)\n            except fetchers.HTTPFetchingError, why:\n                oidutil.log('openid.associate request failed: %s' %\n                            (str(why),))\n                assoc = None\n            else:\n                assoc = self._parseAssociation(response, dh, server_url)\n\n        return assoc\n\n    def _genToken(self, nonce, consumer_id, server_id, server_url):\n        timestamp = str(int(time.time()))\n        elements = [timestamp, nonce, consumer_id, server_id, server_url]\n        joined = '\\x00'.join(elements)\n        sig = cryptutil.hmacSha1(self.store.getAuthKey(), joined)\n\n        return oidutil.toBase64('%s%s' % (sig, joined))\n\n    def _splitToken(self, token):\n        token = oidutil.fromBase64(token)\n        if len(token) < 20:\n            raise ValueError('Bad token length: %d' % len(token))\n\n        sig, joined = token[:20], token[20:]\n        if cryptutil.hmacSha1(self.store.getAuthKey(), joined) != sig:\n            raise ValueError('Bad token signature')\n\n        split = joined.split('\\x00')\n        if len(split) != 5:\n            raise ValueError('Bad token contents (not enough fields)')\n\n        try:\n            ts = int(split[0])\n        except ValueError:\n            raise ValueError('Bad token contents (timestamp bad)')\n\n        if ts + self.TOKEN_LIFETIME < time.time():\n            raise ValueError('Token expired')\n\n        return tuple(split[1:])\n\n    def _createAssociateRequest(self, dh=None, args=None):\n        if args is None:\n            args = {}\n\n        args.update({\n            'openid.mode': 'associate',\n            'openid.assoc_type':'HMAC-SHA1',\n            })\n\n        if dh:\n            cpub = cryptutil.longToBase64(dh.public)\n\n            args.update({\n                'openid.session_type':'DH-SHA1',\n                'openid.dh_consumer_public': cpub,\n                })\n\n            if not dh.usingDefaultValues():\n                args.update({\n                    'openid.dh_modulus': cryptutil.longToBase64(dh.modulus),\n                    'openid.dh_gen': cryptutil.longToBase64(dh.generator),\n                    })\n\n        return args\n\n    def _parseAssociation(self, results, dh, server_url):\n        try:\n            assoc_type = results['assoc_type']\n            if assoc_type != 'HMAC-SHA1':\n                fmt = 'Unsupported assoc_type returned from server %s: %s'\n                oidutil.log(fmt % (server_url, assoc_type))\n                return None\n\n            assoc_handle = results['assoc_handle']\n            try:\n                expires_in = int(results.get('expires_in', '0'))\n            except ValueError, e:\n                fmt = 'Getting Association: invalid expires_in field: %s'\n                oidutil.log(fmt % (e[0],))\n                return None\n\n            session_type = results.get('session_type')\n            if session_type is None:\n                secret = oidutil.fromBase64(results['mac_key'])\n            else:\n                if session_type != 'DH-SHA1':\n                    fmt = 'Unsupported session_type from server %s: %s'\n                    oidutil.log(fmt % (server_url, session_type))\n                    return None\n                if dh is None:\n                    fmt = 'Not expecting a DH-SHA1 session from server %s'\n                    oidutil.log(fmt % (server_url))\n                    return None\n\n                spub = cryptutil.base64ToLong(results['dh_server_public'])\n                enc_mac_key = oidutil.fromBase64(results['enc_mac_key'])\n                secret = dh.xorSecret(spub, enc_mac_key)\n\n            assoc = Association.fromExpiresIn(\n                expires_in, assoc_handle, secret, assoc_type)\n            self.store.storeAssociation(server_url, assoc)\n\n            return assoc\n\n        except KeyError, e:\n            fmt = 'Getting association: missing key in response from %s: %s'\n            oidutil.log(fmt % (server_url, e[0]))\n            return None\n\nclass OpenIDAuthRequest(object):\n    def __init__(self, token, assoc, endpoint):\n        \"\"\"\n        Creates a new OpenIDAuthRequest object.  This just stores each\n        argument in an appropriately named field.\n\n        Users of this library should not create instances of this\n        class.  Instances of this class are created by the library\n        when needed.\n        \"\"\"\n        self.assoc = assoc\n        self.endpoint = endpoint\n        self.extra_args = {}\n        self.token = token\n\n    def addExtensionArg(self, namespace, key, value):\n        arg_name = '.'.join('openid', namespace, key)\n        self.extra_args[arg_name] = value\n\n    def redirectURL(self, trust_root, return_to, immediate=False):\n        if immediate:\n            mode = 'checkid_immediate'\n        else:\n            mode = 'checkid_setup'\n\n        redir_args = {\n            'openid.mode': mode,\n            'openid.identity': self.endpoint.getServerID(),\n            'openid.return_to': return_to,\n            'openid.trust_root': trust_root,\n            }\n\n        if self.assoc:\n            redir_args['openid.assoc_handle'] = self.assoc.handle\n\n        redir_args.update(self.extra_args)\n        return oidutil.appendArgs(self.endpoint.server_url, redir_args)\n\nclass OpenIDConsumerResponse(object):\n    status = None\n\nclass SuccessResponse(OpenIDConsumerResponse):\n    status = 'success'\n\n    def __init__(self, identity_url, signed_args):\n        self.identity_url = identity_url\n        self.signed_args = signed_args\n\n    def fromQuery(cls, identity_url, query, signed):\n        signed_args = {}\n        for field_name in signed.split(','):\n            field_name = 'openid.' + field_name\n            signed_args[field_name] = query.get(field_name, '')\n        return cls(identity_url, signed_args)\n\n    fromQuery = classmethod(fromQuery)\n\n    def extensionResponse(self, prefix):\n        response = {}\n        prefix = 'openid.%s.' % (prefix,)\n        prefix_len = len(prefix)\n        for k, v in self.signed_args.iteritems():\n            if k.startswith(prefix):\n                response_key = k[prefix_len:]\n                response[response_key] = v\n\n        return response\n\nclass FailureResponse(OpenIDConsumerResponse):\n    status = 'failure'\n\n    def __init__(self, identity_url=None, message=None):\n        self.identity_url = identity_url\n        self.message = message\n\nclass CancelResponse(OpenIDConsumerResponse):\n    status = 'cancelled'\n\n    def __init__(self, identity_url=None):\n        self.identity_url = identity_url\n\nclass SetupNeededResponse(OpenIDConsumerResponse):\n    status = 'setup_needed'\n\n    def __init__(self, identity_url=None, setup_url=None):\n        self.identity_url = identity_url\n        self.setup_url = setup_url\n"},"\/test\/consumer.py":{"changes":[{"diff":"\n         parsed = urlparse.urlparse(redirect_url)\n         qs = parsed[4]\n         q = parseQuery(qs)\n+        new_return_to = q['openid.return_to']\n+        del q['openid.return_to']\n         assert q == {\n             'openid.mode':mode,\n             'openid.identity':delegate_url,\n             'openid.trust_root':trust_root,\n             'openid.assoc_handle':fetcher.assoc_handle,\n-            'openid.return_to':return_to,\n             }, (q, user_url, delegate_url, mode)\n \n+        assert new_return_to.startswith(return_to)\n         assert redirect_url.startswith(server_url)\n \n         query = {\n+            'nonce':request.return_to_args['nonce'],\n             'openid.mode':'id_res',\n-            'openid.return_to':return_to,\n+            'openid.return_to':new_return_to,\n             'openid.identity':delegate_url,\n             'openid.assoc_handle':fetcher.assoc_handle,\n             }\n","add":5,"remove":2,"filename":"\/test\/consumer.py","badparts":["            'openid.return_to':return_to,","            'openid.return_to':return_to,"],"goodparts":["        new_return_to = q['openid.return_to']","        del q['openid.return_to']","        assert new_return_to.startswith(return_to)","            'nonce':request.return_to_args['nonce'],","            'openid.return_to':new_return_to,"]},{"diff":"\n         assoc.addSignature(['mode', 'return_to', 'identity'], query)\n \n         info = consumer.complete(query, request.token)\n-        assert info.status == 'success'\n+        assert info.status == 'success', info.message\n         assert info.identity_url == user_url\n \n     assert fetcher.num_assocs == 0\n","add":1,"remove":1,"filename":"\/test\/consumer.py","badparts":["        assert info.status == 'success'"],"goodparts":["        assert info.status == 'success', info.message"]}],"source":"\nimport urlparse import cgi import time from openid import cryptutil, dh, oidutil, kvform from openid.consumer.discover import OpenIDServiceEndpoint from openid.consumer.consumer import GenericOpenIDConsumer from openid import association from openid.consumer import parse from urljr.fetchers import HTTPResponse from urljr import fetchers import _memstore assocs=[ ('another 20-byte key.', 'Snarky'), ('\\x00' * 20, 'Zeros'), ] def parseQuery(qs): q={} for(k, v) in cgi.parse_qsl(qs): assert not q.has_key(k) q[k]=v return q def associate(qs, assoc_secret, assoc_handle): \"\"\"Do the server's half of the associate call, using the given secret and handle.\"\"\" q=parseQuery(qs) assert q['openid.mode']=='associate' assert q['openid.assoc_type']=='HMAC-SHA1' if q.get('openid.session_type')=='DH-SHA1': assert len(q)==6 or len(q)==4 d=dh.DiffieHellman.fromBase64( q.get('openid.dh_modulus'), q.get('openid.dh_gen')) composite=cryptutil.base64ToLong(q['openid.dh_consumer_public']) enc_mac_key=oidutil.toBase64(d.xorSecret(composite, assoc_secret)) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'session_type':'DH-SHA1', 'dh_server_public':cryptutil.longToBase64(d.public), 'enc_mac_key':enc_mac_key, } else: assert len(q)==2 mac_key=oidutil.toBase64(assoc_secret) reply_dict={ 'assoc_type':'HMAC-SHA1', 'assoc_handle':assoc_handle, 'expires_in':'600', 'mac_key':mac_key, } return kvform.dictToKV(reply_dict) class TestFetcher(object): def __init__(self, user_url, user_page,(assoc_secret, assoc_handle)): self.get_responses={user_url:self.response(user_url, 200, user_page)} self.assoc_secret=assoc_secret self.assoc_handle=assoc_handle self.num_assocs=0 def response(self, url, status, body): return HTTPResponse( final_url=url, status=status, headers={}, body=body) def fetch(self, url, body=None, headers=None): if body is None: if url in self.get_responses: return self.get_responses[url] else: try: body.index('openid.mode=associate') except ValueError: pass else: if urlparse.urlparse(url)[0]=='https': assert body.find('DH-SHA1')==-1 else: assert body.find('DH-SHA1') !=-1 response=associate( body, self.assoc_secret, self.assoc_handle) self.num_assocs +=1 return self.response(url, 200, response) return self.response(url, 404, 'Not found') def _test_success(server_url, user_url, delegate_url, links, immediate=False): store=_memstore.MemoryStore() if immediate: mode='checkid_immediate' else: mode='checkid_setup' endpoint=OpenIDServiceEndpoint() endpoint.identity_url=user_url endpoint.server_url=server_url endpoint.delegate=delegate_url fetcher=TestFetcher(None, None, assocs[0]) fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False) def run(): trust_root=consumer_url consumer=GenericOpenIDConsumer(store) request=consumer.begin(endpoint) return_to=consumer_url redirect_url=request.redirectURL(trust_root, return_to, immediate) parsed=urlparse.urlparse(redirect_url) qs=parsed[4] q=parseQuery(qs) assert q=={ 'openid.mode':mode, 'openid.identity':delegate_url, 'openid.trust_root':trust_root, 'openid.assoc_handle':fetcher.assoc_handle, 'openid.return_to':return_to, },(q, user_url, delegate_url, mode) assert redirect_url.startswith(server_url) query={ 'openid.mode':'id_res', 'openid.return_to':return_to, 'openid.identity':delegate_url, 'openid.assoc_handle':fetcher.assoc_handle, } assoc=store.getAssociation(server_url, fetcher.assoc_handle) assoc.addSignature(['mode', 'return_to', 'identity'], query) info=consumer.complete(query, request.token) assert info.status=='success' assert info.identity_url==user_url assert fetcher.num_assocs==0 run() assert fetcher.num_assocs==1 run() assert fetcher.num_assocs==1 store.removeAssociation(server_url, fetcher.assoc_handle) run() assert fetcher.num_assocs==2 run() assert fetcher.num_assocs==2 import unittest http_server_url='http:\/\/server.example.com\/' consumer_url='http:\/\/consumer.example.com\/' https_server_url='https:\/\/server.example.com\/' class TestSuccess(unittest.TestCase): server_url=http_server_url user_url='http:\/\/www.example.com\/user.html' delegate_url='http:\/\/consumer.example.com\/user' def setUp(self): self.links='<link rel=\"openid.server\" href=\"%s\" \/>' %( self.server_url,) self.delegate_links=('<link rel=\"openid.server\" href=\"%s\" \/>' '<link rel=\"openid.delegate\" href=\"%s\" \/>') %( self.server_url, self.delegate_url) def test_nodelegate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links) def test_nodelegateImmediate(self): _test_success(self.server_url, self.user_url, self.user_url, self.links, True) def test_delegate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links) def test_delegateImmediate(self): _test_success(self.server_url, self.user_url, self.delegate_url, self.delegate_links, True) class TestSuccessHTTPS(TestSuccess): server_url=https_server_url class TestConstruct(unittest.TestCase): def setUp(self): self.store_sentinel=object() def test_construct(self): oidc=GenericOpenIDConsumer(self.store_sentinel) self.failUnless(oidc.store is self.store_sentinel) def test_nostore(self): self.failUnlessRaises(TypeError, GenericOpenIDConsumer) class TestIdRes(unittest.TestCase): consumer_class=GenericOpenIDConsumer def setUp(self): self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.return_to=\"nonny\" self.server_id=\"sirod\" self.server_url=\"serlie\" self.consumer_id=\"consu\" class TestSetupNeeded(TestIdRes): def test_setupNeeded(self): setup_url='http:\/\/unittest\/setup-here' query={ 'openid.mode': 'id_res', 'openid.user_setup_url': setup_url, } ret=self.consumer._doIdRes(query, self.consumer_id, self.server_id, self.server_url, ) self.failUnlessEqual(ret.status, 'setup_needed') self.failUnlessEqual(ret.setup_url, setup_url) class CheckAuthHappened(Exception): pass class CheckAuthDetectingConsumer(GenericOpenIDConsumer): def _checkAuth(self, *args): raise CheckAuthHappened(args) class CatchLogs(object): def setUp(self): self.old_logger=oidutil.log oidutil.log=self.gotLogMessage self.messages=[] def gotLogMessage(self, message): self.messages.append(message) def tearDown(self): oidutil.log=self.old_logger class TestCheckAuthTriggered(TestIdRes, CatchLogs): consumer_class=CheckAuthDetectingConsumer def setUp(self): TestIdRes.setUp(self) CatchLogs.setUp(self) def _doIdRes(self, query): return self.consumer._doIdRes( query, self.consumer_id, self.server_id, self.server_url) def test_checkAuthTriggered(self): query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r %s' % (result, self.messages)) def test_checkAuthTriggeredWithAssoc(self): issued=time.time() lifetime=1000 assoc=association.Association( 'handle', 'secret', issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':'not_found', } try: result=self._doIdRes(query) except CheckAuthHappened: pass else: self.fail('_checkAuth did not happen. Result was: %r' %(result,)) def test_expiredAssoc(self): issued=time.time() -10 lifetime=0 handle='handle' assoc=association.Association( handle, 'secret', issued, lifetime, 'HMAC-SHA1') self.failUnless(assoc.expiresIn <=0) self.store.storeAssociation(self.server_url, assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':handle, } info=self._doIdRes(query) self.failUnlessEqual('failure', info.status) self.failUnlessEqual(self.consumer_id, info.identity_url) info.message.index('expired') def test_newerAssoc(self): lifetime=1000 good_issued=time.time() -10 good_handle='handle' good_assoc=association.Association( good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, good_assoc) bad_issued=time.time() -5 bad_handle='handle2' bad_assoc=association.Association( bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1') self.store.storeAssociation(self.server_url, bad_assoc) query={ 'openid.return_to':self.return_to, 'openid.identity':self.server_id, 'openid.assoc_handle':good_handle, } good_assoc.addSignature(['return_to', 'identity'], query) info=self._doIdRes(query) self.failUnlessEqual(info.status, 'success') self.failUnlessEqual(self.consumer_id, info.identity_url) class MockFetcher(object): def __init__(self, response=None): self.response=response or HTTPResponse() self.fetches=[] def fetch(self, url, body=None, headers=None): self.fetches.append((url, body, headers)) return self.response class ExceptionRaisingMockFetcher(object): def fetch(self, url, body=None, headers=None): raise Exception('mock fetcher exception') class BadArgCheckingConsumer(GenericOpenIDConsumer): def _makeKVPost(self, args, _): assert args=={ 'openid.mode':'check_authentication', 'openid.signed':'foo', }, args return None class TestCheckAuth(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.consumer=self.consumer_class(self.store) self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') query={'openid.signed': 'stuff, things'} r=self.consumer._checkAuth(query, http_server_url) self.failIf(r) self.failUnless(self.messages) def test_bad_args(self): query={ 'openid.signed':'foo', 'closid.foo':'something', } consumer=BadArgCheckingConsumer(self.store) consumer._checkAuth(query, 'does:\/\/not.matter') class TestFetchAssoc(unittest.TestCase, CatchLogs): consumer_class=GenericOpenIDConsumer def setUp(self): CatchLogs.setUp(self) self.store=_memstore.MemoryStore() self.fetcher=MockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.consumer=self.consumer_class(self.store) def test_error(self): self.fetcher.response=HTTPResponse( \"http:\/\/some_url\", 404,{'Hea': 'der'}, 'blah:blah\\n') r=self.consumer._makeKVPost({'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnlessEqual(r, None) self.failUnless(self.messages) def test_error_exception(self): self.fetcher=ExceptionRaisingMockFetcher() fetchers.setDefaultFetcher(self.fetcher) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._makeKVPost, {'openid.mode':'associate'}, \"http:\/\/server_url\") self.failUnless(self.consumer._getAssociation('some:\/\/url') is None) self.failUnlessRaises(fetchers.HTTPFetchingError, self.consumer._checkAuth, {'openid.signed':''}, 'some:\/\/url') if __name__=='__main__': unittest.main() ","sourceWithComments":"import urlparse\nimport cgi\nimport time\n\nfrom openid import cryptutil, dh, oidutil, kvform\nfrom openid.consumer.discover import OpenIDServiceEndpoint\nfrom openid.consumer.consumer import GenericOpenIDConsumer\nfrom openid import association\n\nfrom openid.consumer import parse\n\nfrom urljr.fetchers import HTTPResponse\nfrom urljr import fetchers\n\nimport _memstore\n\nassocs = [\n    ('another 20-byte key.', 'Snarky'),\n    ('\\x00' * 20, 'Zeros'),\n    ]\n\ndef parseQuery(qs):\n    q = {}\n    for (k, v) in cgi.parse_qsl(qs):\n        assert not q.has_key(k)\n        q[k] = v\n    return q\n\ndef associate(qs, assoc_secret, assoc_handle):\n    \"\"\"Do the server's half of the associate call, using the given\n    secret and handle.\"\"\"\n    q = parseQuery(qs)\n    assert q['openid.mode'] == 'associate'\n    assert q['openid.assoc_type'] == 'HMAC-SHA1'\n    if q.get('openid.session_type') == 'DH-SHA1':\n        assert len(q) == 6 or len(q) == 4\n        d = dh.DiffieHellman.fromBase64(\n            q.get('openid.dh_modulus'), q.get('openid.dh_gen'))\n\n        composite = cryptutil.base64ToLong(q['openid.dh_consumer_public'])\n        enc_mac_key = oidutil.toBase64(d.xorSecret(composite, assoc_secret))\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'session_type':'DH-SHA1',\n            'dh_server_public':cryptutil.longToBase64(d.public),\n            'enc_mac_key':enc_mac_key,\n            }\n    else:\n        assert len(q) == 2\n        mac_key = oidutil.toBase64(assoc_secret)\n        reply_dict = {\n            'assoc_type':'HMAC-SHA1',\n            'assoc_handle':assoc_handle,\n            'expires_in':'600',\n            'mac_key':mac_key,\n            }\n\n    return kvform.dictToKV(reply_dict)\n\nclass TestFetcher(object):\n    def __init__(self, user_url, user_page, (assoc_secret, assoc_handle)):\n        self.get_responses = {user_url:self.response(user_url, 200, user_page)}\n        self.assoc_secret = assoc_secret\n        self.assoc_handle = assoc_handle\n        self.num_assocs = 0\n\n    def response(self, url, status, body):\n        return HTTPResponse(\n            final_url=url, status=status, headers={}, body=body)\n\n    def fetch(self, url, body=None, headers=None):\n        if body is None:\n            if url in self.get_responses:\n                return self.get_responses[url]\n        else:\n            try:\n                body.index('openid.mode=associate')\n            except ValueError:\n                pass # fall through\n            else:\n                if urlparse.urlparse(url)[0] == 'https':\n                    # Should not be doing DH-SHA1 when using HTTPS.\n                    assert body.find('DH-SHA1') == -1\n                else:\n                    assert body.find('DH-SHA1') != -1\n                response = associate(\n                    body, self.assoc_secret, self.assoc_handle)\n                self.num_assocs += 1\n                return self.response(url, 200, response)\n\n        return self.response(url, 404, 'Not found')\n\ndef _test_success(server_url, user_url, delegate_url, links, immediate=False):\n    store = _memstore.MemoryStore()\n    if immediate:\n        mode = 'checkid_immediate'\n    else:\n        mode = 'checkid_setup'\n\n    endpoint = OpenIDServiceEndpoint()\n    endpoint.identity_url = user_url\n    endpoint.server_url = server_url\n    endpoint.delegate = delegate_url\n\n    fetcher = TestFetcher(None, None, assocs[0])\n    fetchers.setDefaultFetcher(fetcher, wrap_exceptions=False)\n\n    def run():\n        trust_root = consumer_url\n\n        consumer = GenericOpenIDConsumer(store)\n        request = consumer.begin(endpoint)\n\n        return_to = consumer_url\n        redirect_url = request.redirectURL(trust_root, return_to, immediate)\n\n        parsed = urlparse.urlparse(redirect_url)\n        qs = parsed[4]\n        q = parseQuery(qs)\n        assert q == {\n            'openid.mode':mode,\n            'openid.identity':delegate_url,\n            'openid.trust_root':trust_root,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            'openid.return_to':return_to,\n            }, (q, user_url, delegate_url, mode)\n\n        assert redirect_url.startswith(server_url)\n\n        query = {\n            'openid.mode':'id_res',\n            'openid.return_to':return_to,\n            'openid.identity':delegate_url,\n            'openid.assoc_handle':fetcher.assoc_handle,\n            }\n\n        assoc = store.getAssociation(server_url, fetcher.assoc_handle)\n        assoc.addSignature(['mode', 'return_to', 'identity'], query)\n\n        info = consumer.complete(query, request.token)\n        assert info.status == 'success'\n        assert info.identity_url == user_url\n\n    assert fetcher.num_assocs == 0\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 1\n\n    # Another association is created if we remove the existing one\n    store.removeAssociation(server_url, fetcher.assoc_handle)\n    run()\n    assert fetcher.num_assocs == 2\n\n    # Test that doing it again uses the existing association\n    run()\n    assert fetcher.num_assocs == 2\n\nimport unittest\n\nhttp_server_url = 'http:\/\/server.example.com\/'\nconsumer_url = 'http:\/\/consumer.example.com\/'\nhttps_server_url = 'https:\/\/server.example.com\/'\n\nclass TestSuccess(unittest.TestCase):\n    server_url = http_server_url\n    user_url = 'http:\/\/www.example.com\/user.html'\n    delegate_url = 'http:\/\/consumer.example.com\/user'\n\n    def setUp(self):\n        self.links = '<link rel=\"openid.server\" href=\"%s\" \/>' % (\n            self.server_url,)\n\n        self.delegate_links = ('<link rel=\"openid.server\" href=\"%s\" \/>'\n                               '<link rel=\"openid.delegate\" href=\"%s\" \/>') % (\n            self.server_url, self.delegate_url)\n\n    def test_nodelegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links)\n\n    def test_nodelegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.user_url, self.links, True)\n\n    def test_delegate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links)\n\n    def test_delegateImmediate(self):\n        _test_success(self.server_url, self.user_url,\n                      self.delegate_url, self.delegate_links, True)\n\n\nclass TestSuccessHTTPS(TestSuccess):\n    server_url = https_server_url\n\n\nclass TestConstruct(unittest.TestCase):\n    def setUp(self):\n        self.store_sentinel = object()\n\n    def test_construct(self):\n        oidc = GenericOpenIDConsumer(self.store_sentinel)\n        self.failUnless(oidc.store is self.store_sentinel)\n\n    def test_nostore(self):\n        self.failUnlessRaises(TypeError, GenericOpenIDConsumer)\n\n\nclass TestIdRes(unittest.TestCase):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        self.store = _memstore.MemoryStore()\n        self.consumer = self.consumer_class(self.store)\n        self.return_to = \"nonny\"\n        self.server_id = \"sirod\"\n        self.server_url = \"serlie\"\n        self.consumer_id = \"consu\"\n\nclass TestSetupNeeded(TestIdRes):\n    def test_setupNeeded(self):\n        setup_url = 'http:\/\/unittest\/setup-here'\n        query = {\n            'openid.mode': 'id_res',\n            'openid.user_setup_url': setup_url,\n            }\n        ret = self.consumer._doIdRes(query,\n                                     self.consumer_id,\n                                     self.server_id,\n                                     self.server_url,\n                                     )\n        self.failUnlessEqual(ret.status, 'setup_needed')\n        self.failUnlessEqual(ret.setup_url, setup_url)\n\nclass CheckAuthHappened(Exception): pass\n\nclass CheckAuthDetectingConsumer(GenericOpenIDConsumer):\n    def _checkAuth(self, *args):\n        raise CheckAuthHappened(args)\n\nclass CatchLogs(object):\n    def setUp(self):\n        self.old_logger = oidutil.log\n        oidutil.log = self.gotLogMessage\n        self.messages = []\n\n    def gotLogMessage(self, message):\n        self.messages.append(message)\n\n    def tearDown(self):\n        oidutil.log = self.old_logger\n\nclass TestCheckAuthTriggered(TestIdRes, CatchLogs):\n    consumer_class = CheckAuthDetectingConsumer\n\n    def setUp(self):\n        TestIdRes.setUp(self)\n        CatchLogs.setUp(self)\n\n    def _doIdRes(self, query):\n        return self.consumer._doIdRes(\n            query,\n            self.consumer_id,\n            self.server_id,\n            self.server_url)\n\n    def test_checkAuthTriggered(self):\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r %s' %\n                      (result, self.messages))\n\n    def test_checkAuthTriggeredWithAssoc(self):\n        # Store an association for this server that does not match the\n        # handle that is in the query\n        issued = time.time()\n        lifetime = 1000\n        assoc = association.Association(\n            'handle', 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':'not_found',\n            }\n        try:\n            result = self._doIdRes(query)\n        except CheckAuthHappened:\n            pass\n        else:\n            self.fail('_checkAuth did not happen. Result was: %r' % (result,))\n\n    def test_expiredAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        issued = time.time() - 10\n        lifetime = 0\n        handle = 'handle'\n        assoc = association.Association(\n            handle, 'secret', issued, lifetime, 'HMAC-SHA1')\n        self.failUnless(assoc.expiresIn <= 0)\n        self.store.storeAssociation(self.server_url, assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':handle,\n            }\n        info = self._doIdRes(query)\n        self.failUnlessEqual('failure', info.status)\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n        info.message.index('expired') # raises an exception if it's not there\n\n    def test_newerAssoc(self):\n        # Store an expired association for the server with the handle\n        # that is in the query\n        lifetime = 1000\n\n        good_issued = time.time() - 10\n        good_handle = 'handle'\n        good_assoc = association.Association(\n            good_handle, 'secret', good_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, good_assoc)\n\n        bad_issued = time.time() - 5\n        bad_handle = 'handle2'\n        bad_assoc = association.Association(\n            bad_handle, 'secret', bad_issued, lifetime, 'HMAC-SHA1')\n        self.store.storeAssociation(self.server_url, bad_assoc)\n\n        query = {\n            'openid.return_to':self.return_to,\n            'openid.identity':self.server_id,\n            'openid.assoc_handle':good_handle,\n            }\n\n        good_assoc.addSignature(['return_to', 'identity'], query)\n        info = self._doIdRes(query)\n        self.failUnlessEqual(info.status, 'success')\n        self.failUnlessEqual(self.consumer_id, info.identity_url)\n\n\nclass MockFetcher(object):\n    def __init__(self, response=None):\n        self.response = response or HTTPResponse()\n        self.fetches = []\n\n    def fetch(self, url, body=None, headers=None):\n        self.fetches.append((url, body, headers))\n        return self.response\n\nclass ExceptionRaisingMockFetcher(object):\n    def fetch(self, url, body=None, headers=None):\n        raise Exception('mock fetcher exception')\n\nclass BadArgCheckingConsumer(GenericOpenIDConsumer):\n    def _makeKVPost(self, args, _):\n        assert args == {\n            'openid.mode':'check_authentication',\n            'openid.signed':'foo',\n            }, args\n        return None\n\nclass TestCheckAuth(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n\n        self.consumer = self.consumer_class(self.store)\n\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        query = {'openid.signed': 'stuff, things'}\n        r = self.consumer._checkAuth(query, http_server_url)\n        self.failIf(r)\n        self.failUnless(self.messages)\n\n    def test_bad_args(self):\n        query = {\n            'openid.signed':'foo',\n            'closid.foo':'something',\n            }\n        consumer = BadArgCheckingConsumer(self.store)\n        consumer._checkAuth(query, 'does:\/\/not.matter')\n\nclass TestFetchAssoc(unittest.TestCase, CatchLogs):\n    consumer_class = GenericOpenIDConsumer\n\n    def setUp(self):\n        CatchLogs.setUp(self)\n        self.store = _memstore.MemoryStore()\n        self.fetcher = MockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.consumer = self.consumer_class(self.store)\n\n    def test_error(self):\n        self.fetcher.response = HTTPResponse(\n            \"http:\/\/some_url\", 404, {'Hea': 'der'}, 'blah:blah\\n')\n        r = self.consumer._makeKVPost({'openid.mode':'associate'},\n                                      \"http:\/\/server_url\")\n        self.failUnlessEqual(r, None)\n        self.failUnless(self.messages)\n\n    def test_error_exception(self):\n        self.fetcher = ExceptionRaisingMockFetcher()\n        fetchers.setDefaultFetcher(self.fetcher)\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._makeKVPost,\n                              {'openid.mode':'associate'},\n                              \"http:\/\/server_url\")\n\n        # exception fetching returns no association\n        self.failUnless(self.consumer._getAssociation('some:\/\/url') is None)\n\n        self.failUnlessRaises(fetchers.HTTPFetchingError,\n                              self.consumer._checkAuth,\n                              {'openid.signed':''},\n                              'some:\/\/url')\n\nif __name__ == '__main__':\n    unittest.main()\n"}},"msg":"[project @ Added nonce to return_to to fix replay attack vulnerability]"}},"https:\/\/github.com\/simensma\/sherpa":{"555e57c6c0d93f0708c4733df5b8603401b57fdf":{"url":"https:\/\/api.github.com\/repos\/simensma\/sherpa\/commits\/555e57c6c0d93f0708c4733df5b8603401b57fdf","html_url":"https:\/\/github.com\/simensma\/sherpa\/commit\/555e57c6c0d93f0708c4733df5b8603401b57fdf","message":"Ignore DNT connect timestamp\n\nThis makes us vulnerable to replay attacks which means that\ncommunication MUST be done using HTTPS, so that only the client\nhas access to the encrypted data, and will be inaccessible for any\nMITM","sha":"555e57c6c0d93f0708c4733df5b8603401b57fdf","keyword":"replay attack vulnerable","diff":"diff --git a\/apps\/connect\/util.py b\/apps\/connect\/util.py\nindex 4b8370d2c..c495fa719 100644\n--- a\/apps\/connect\/util.py\n+++ b\/apps\/connect\/util.py\n@@ -28,10 +28,7 @@ def get_request_data(request):\n     request_data, auth_index = try_keys(decrypt, client['auths'], request.GET['data'], request.GET.get('hmac'))\n     request_data = json.loads(request_data)\n \n-    # Check the transmit datestamp\n-    request_time = datetime.fromtimestamp(request_data['timestamp'])\n-    if datetime.now() - request_time > timedelta(seconds=settings.DNT_CONNECT_TIMEOUT):\n-        raise PermissionDenied\n+    # Note that the transmitted datestamp is now ignored and all requests are accepted\n \n     # Redirect to provided url, or the default if none provided\n     redirect_url = request_data['redirect_url'] if 'redirect_url' in request_data else client['default_redirect_url']\n","files":{"\/apps\/connect\/util.py":{"changes":[{"diff":"\n     request_data, auth_index = try_keys(decrypt, client['auths'], request.GET['data'], request.GET.get('hmac'))\n     request_data = json.loads(request_data)\n \n-    # Check the transmit datestamp\n-    request_time = datetime.fromtimestamp(request_data['timestamp'])\n-    if datetime.now() - request_time > timedelta(seconds=settings.DNT_CONNECT_TIMEOUT):\n-        raise PermissionDenied\n+    # Note that the transmitted datestamp is now ignored and all requests are accepted\n \n     # Redirect to provided url, or the default if none provided\n     redirect_url = request_data['redirect_url'] if 'redirect_url' in request_data else client['default_redirect_url']\n","add":1,"remove":4,"filename":"\/apps\/connect\/util.py","badparts":["    request_time = datetime.fromtimestamp(request_data['timestamp'])","    if datetime.now() - request_time > timedelta(seconds=settings.DNT_CONNECT_TIMEOUT):","        raise PermissionDenied"],"goodparts":[]}],"source":"\n from django.conf import settings from django.core.exceptions import PermissionDenied from django.shortcuts import redirect from Crypto.Cipher import AES from core import pkcs7 from urllib import quote_plus from datetime import datetime, timedelta import base64 import json import time import os import hmac import hashlib import logging logger=logging.getLogger('sherpa') def get_request_data(request): if not request.GET.get('client', '') in settings.DNT_CONNECT: raise PermissionDenied else: client=settings.DNT_CONNECT[request.GET['client']] request_data, auth_index=try_keys(decrypt, client['auths'], request.GET['data'], request.GET.get('hmac')) request_data=json.loads(request_data) request_time=datetime.fromtimestamp(request_data['timestamp']) if datetime.now() -request_time > timedelta(seconds=settings.DNT_CONNECT_TIMEOUT): raise PermissionDenied redirect_url=request_data['redirect_url'] if 'redirect_url' in request_data else client['default_redirect_url'] return client, request.GET['client'], auth_index, request_data, redirect_url def prepare_response(client, auth_index, response_data, redirect_url): response_data['timestamp']=int(time.time()) json_string=json.dumps(response_data) if auth_index is not None: encrypted_data, hmac_=encrypt(client['auths'][auth_index], json_string) else: encrypted_data, hmac_=try_keys(encrypt, client['auths'], json_string)[0] url_safe_data=quote_plus(encrypted_data) if hmac_ is None: return redirect(\"%s?data=%s\" %(redirect_url, url_safe_data)) else: url_safe_hmac=quote_plus(hmac_) return redirect(\"%s?data=%s&hmac=%s\" %(redirect_url, url_safe_data, url_safe_hmac)) def try_keys(method, auths, *args, **kwargs): \"\"\" Encryption and decryption is run through this method which tries all the specified keys, and if one succeeds, uses that, if not, raises the exception of the last attempted key. \"\"\" last_exception=None for auth_index, auth in enumerate(auths): try: return method(auth, *args, **kwargs), auth_index except Exception as e: last_exception=e raise last_exception def encrypt(auth, plaintext): padded_text=pkcs7.encode(plaintext, settings.DNT_CONNECT_BLOCK_SIZE) if auth['iv']: iv=os.urandom(settings.DNT_CONNECT_BLOCK_SIZE) cipher=AES.new(auth['key'], auth['cipher'], iv) ciphertext=iv +cipher.encrypt(padded_text) hmac_=calc_hmac(auth['key'], iv +plaintext) else: cipher=AES.new(auth['key'], auth['cipher']) ciphertext=cipher.encrypt(padded_text) hmac_=None encoded=base64.b64encode(ciphertext) return encoded, hmac_ def decrypt(auth, encoded, hmac_): try: decoded=base64.b64decode(encoded) if auth['iv']: iv, ciphertext=decoded[:settings.DNT_CONNECT_BLOCK_SIZE], decoded[settings.DNT_CONNECT_BLOCK_SIZE:] cipher=AES.new(auth['key'], auth['cipher'], iv) else: ciphertext=decoded cipher=AES.new(auth['key'], auth['cipher']) plaintext_padded=cipher.decrypt(ciphertext) plaintext=pkcs7.decode(plaintext_padded, settings.DNT_CONNECT_BLOCK_SIZE) if auth['iv'] and calc_hmac(auth['key'], iv +plaintext) !=hmac_: logger.warning(u\"Forespurt hmac matchet ikke egenkalkulert hmac\", extra={ 'our_hmac': calc_hmac(auth['key'], iv +plaintext), 'their_hmac': hmac_, 'encoded': encoded, 'plaintext': plaintext, 'auth': auth, } ) raise PermissionDenied return plaintext except TypeError: raise PermissionDenied def calc_hmac(key, data): return base64.b64encode(hmac.new(key, data, hashlib.sha512).digest()) def add_signon_session_value(request, value): request.session['dntconnect']['signon']=value request.session.modified=True def get_member_data(user): if not user.is_member(): return{ 'sherpa_id': user.id, 'er_medlem': False, 'fornavn': user.get_first_name(), 'etternavn': user.get_last_name(), 'epost': user.get_email() } else: def api_gender_output(gender): if gender=='m': return 'M' elif gender=='f': return 'K' address=user.get_address() dob=user.get_birth_date() if dob is not None: dob=dob.strftime(\"%Y-%m-%d\") return{ 'sherpa_id': user.id, 'er_medlem': True, 'medlemsnummer': user.memberid, 'aktivt_medlemskap': user.has_paid(), 'fornavn': user.get_first_name(), 'etternavn': user.get_last_name(), 'f\u00f8dt': dob, 'kj\u00f8nn': api_gender_output(user.get_gender()), 'epost': user.get_email(), 'mobil': user.get_phone_mobile(), 'adresse':{ 'adresse1': address.field1, 'adresse2': address.field2, 'adresse3': address.field3, 'postnummer': address.zipcode.zipcode if address.country.code=='NO' else None, 'poststed': address.zipcode.area.title() if address.country.code=='NO' else None, 'land':{ 'kode': address.country.code, 'navn': address.country.name } }, } ","sourceWithComments":"# encoding: utf-8\n\nfrom django.conf import settings\nfrom django.core.exceptions import PermissionDenied\nfrom django.shortcuts import redirect\n\nfrom Crypto.Cipher import AES\nfrom core import pkcs7\n\nfrom urllib import quote_plus\nfrom datetime import datetime, timedelta\nimport base64\nimport json\nimport time\nimport os\nimport hmac\nimport hashlib\nimport logging\n\nlogger = logging.getLogger('sherpa')\n\ndef get_request_data(request):\n    if not request.GET.get('client', '') in settings.DNT_CONNECT:\n        raise PermissionDenied\n    else:\n        client = settings.DNT_CONNECT[request.GET['client']]\n\n    request_data, auth_index = try_keys(decrypt, client['auths'], request.GET['data'], request.GET.get('hmac'))\n    request_data = json.loads(request_data)\n\n    # Check the transmit datestamp\n    request_time = datetime.fromtimestamp(request_data['timestamp'])\n    if datetime.now() - request_time > timedelta(seconds=settings.DNT_CONNECT_TIMEOUT):\n        raise PermissionDenied\n\n    # Redirect to provided url, or the default if none provided\n    redirect_url = request_data['redirect_url'] if 'redirect_url' in request_data else client['default_redirect_url']\n\n    return client, request.GET['client'], auth_index, request_data, redirect_url\n\ndef prepare_response(client, auth_index, response_data, redirect_url):\n    # Add the current timestamp\n    response_data['timestamp'] = int(time.time())\n\n    # Encrypt the complete data package\n    json_string = json.dumps(response_data)\n    if auth_index is not None:\n        # Use the authentication method which worked when decrypting\n        encrypted_data, hmac_ = encrypt(client['auths'][auth_index], json_string)\n    else:\n        # This special case handles old sessions and can likely be removed after a couple of weeks\n        encrypted_data, hmac_ = try_keys(encrypt, client['auths'], json_string)[0]\n    url_safe_data = quote_plus(encrypted_data)\n\n    if hmac_ is None:\n        return redirect(\"%s?data=%s\" % (redirect_url, url_safe_data))\n    else:\n        url_safe_hmac = quote_plus(hmac_)\n        return redirect(\"%s?data=%s&hmac=%s\" % (redirect_url, url_safe_data, url_safe_hmac))\n\ndef try_keys(method, auths, *args, **kwargs):\n    \"\"\"\n    Encryption and decryption is run through this method which tries all the specified keys, and if one succeeds, uses\n    that, if not, raises the exception of the last attempted key.\n    \"\"\"\n    last_exception = None\n    for auth_index, auth in enumerate(auths):\n        try:\n            return method(auth, *args, **kwargs), auth_index\n        except Exception as e:\n            last_exception = e\n    # None of the keys worked, raise the last exception\n    raise last_exception\n\ndef encrypt(auth, plaintext):\n    padded_text = pkcs7.encode(plaintext, settings.DNT_CONNECT_BLOCK_SIZE)\n\n    if auth['iv']:\n        iv = os.urandom(settings.DNT_CONNECT_BLOCK_SIZE)\n        cipher = AES.new(auth['key'], auth['cipher'], iv)\n        ciphertext = iv + cipher.encrypt(padded_text)\n        hmac_ = calc_hmac(auth['key'], iv + plaintext)\n    else:\n        cipher = AES.new(auth['key'], auth['cipher'])\n        ciphertext = cipher.encrypt(padded_text)\n        hmac_ = None\n\n    encoded = base64.b64encode(ciphertext)\n    return encoded, hmac_\n\ndef decrypt(auth, encoded, hmac_):\n    try:\n        decoded = base64.b64decode(encoded)\n\n        if auth['iv']:\n            iv, ciphertext = decoded[:settings.DNT_CONNECT_BLOCK_SIZE], decoded[settings.DNT_CONNECT_BLOCK_SIZE:]\n            cipher = AES.new(auth['key'], auth['cipher'], iv)\n        else:\n            ciphertext = decoded\n            cipher = AES.new(auth['key'], auth['cipher'])\n\n        plaintext_padded = cipher.decrypt(ciphertext)\n        plaintext = pkcs7.decode(plaintext_padded, settings.DNT_CONNECT_BLOCK_SIZE)\n\n        if auth['iv'] and calc_hmac(auth['key'], iv + plaintext) != hmac_:\n            logger.warning(u\"Forespurt hmac matchet ikke egenkalkulert hmac\",\n                extra={\n                    'our_hmac': calc_hmac(auth['key'], iv + plaintext),\n                    'their_hmac': hmac_,\n                    'encoded': encoded,\n                    'plaintext': plaintext,\n                    'auth': auth,\n                }\n            )\n            raise PermissionDenied\n\n        return plaintext\n    except TypeError:\n        # Can e.g. be incorrect padding if they forgot to URLEncode the data\n        raise PermissionDenied\n\ndef calc_hmac(key, data):\n    return base64.b64encode(hmac.new(key, data, hashlib.sha512).digest())\n\ndef add_signon_session_value(request, value):\n    request.session['dntconnect']['signon'] = value\n    request.session.modified = True\n\ndef get_member_data(user):\n    if not user.is_member():\n        return {\n            'sherpa_id': user.id,\n            'er_medlem': False,\n            'fornavn': user.get_first_name(),\n            'etternavn': user.get_last_name(),\n            'epost': user.get_email()\n        }\n    else:\n        # The gender definition is in norwegian\n        def api_gender_output(gender):\n            if gender == 'm':\n                return 'M'\n            elif gender == 'f':\n                return 'K'\n\n        address = user.get_address()\n        dob = user.get_birth_date()\n        if dob is not None:\n            dob = dob.strftime(\"%Y-%m-%d\")\n\n        return {\n            'sherpa_id': user.id,\n            'er_medlem': True,\n            'medlemsnummer': user.memberid,\n            'aktivt_medlemskap': user.has_paid(),\n            'fornavn': user.get_first_name(),\n            'etternavn': user.get_last_name(),\n            'f\u00f8dt': dob,\n            'kj\u00f8nn': api_gender_output(user.get_gender()),\n            'epost': user.get_email(),\n            'mobil': user.get_phone_mobile(),\n            'adresse': {\n                'adresse1': address.field1,\n                'adresse2': address.field2,\n                'adresse3': address.field3,\n                'postnummer': address.zipcode.zipcode if address.country.code == 'NO' else None,\n                'poststed': address.zipcode.area.title() if address.country.code == 'NO' else None,\n                'land': {\n                    'kode': address.country.code,\n                    'navn': address.country.name\n                }\n            },\n        }\n"}},"msg":"Ignore DNT connect timestamp\n\nThis makes us vulnerable to replay attacks which means that\ncommunication MUST be done using HTTPS, so that only the client\nhas access to the encrypted data, and will be inaccessible for any\nMITM"}}}